{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "\n",
    "# Bayesian Methods for Hackers style sheet\n",
    "plt.style.use('bmh')\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PeriodicLogger — helper logger class at the end of each epoch\n",
    "\n",
    "class PeriodicLogger(Callback):\n",
    "    \"\"\"\n",
    "    A helper callback class that only prints the losses once in 'display' epochs\n",
    "    \"\"\"    \n",
    "    def __init__(self, display=100):\n",
    "        self.display = display\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.epochs = 0\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.epochs += 1\n",
    "        if self.epochs % self.display == 0:\n",
    "            print(\"Epoch: %d - loss: %f - val_loss: %f\" % (self.epochs, logs['loss'], logs['val_loss']))\n",
    "\n",
    "periodic_logger_250 = PeriodicLogger(250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping and a function that computes the house price for each example\n",
    "\n",
    "per_meter_mapping = {    \n",
    "    'Mercaz': 500,\n",
    "    'Old North': 350,\n",
    "    'Florentine': 230\n",
    "    }\n",
    "\n",
    "per_room_additional_price = {    \n",
    "    'Mercaz': 15. * 10 ** 4,\n",
    "    'Old North': 8. * 10 ** 4,\n",
    "    'Florentine': 5. * 10 ** 4\n",
    "    }\n",
    "\n",
    "def house_price_func(row):    \n",
    "    \"\"\"\n",
    "    house_price_func is the function f(a,s,n).    \n",
    "    :param row: dict (contains the keys: ['area', 'size', 'n_rooms'])\n",
    "    :return: float\n",
    "    \"\"\"\n",
    "    area, size, n_rooms = row['area'], row['size'], row['n_rooms']\n",
    "    return size * per_meter_mapping[area] + n_rooms * per_room_additional_price[area]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create toy data\n",
    "\n",
    "AREAS = ['Mercaz', 'Old North', 'Florentine']\n",
    "def create_samples(n_samples): \n",
    "    \"\"\"\n",
    "    Helper method that creates dataset DataFrames\n",
    "    Note that the np.random.choice call only determines the number of rooms and the size of the house\n",
    "    (the price, which we calculate later, is deterministic)\n",
    "    \n",
    "    :param n_samples: int (number of samples for each area (suburb))\n",
    "    :return: pd.DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    samples = []\n",
    "\n",
    "    for n_rooms in np.random.choice(range(1, 6), n_samples):\n",
    "            samples += [(area, int(np.random.normal(25, 5)), n_rooms) for area in AREAS]\n",
    "\n",
    "    return pd.DataFrame(samples, columns=['area', 'size', 'n_rooms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train and validation sets\n",
    "train = create_samples(n_samples=1000)\n",
    "val = create_samples(n_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the prices for each set\n",
    "train['price'] = train.apply(house_price_func, axis=1)\n",
    "val['price'] = val.apply(house_price_func, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>size</th>\n",
       "      <th>n_rooms</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mercaz</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>760000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Old North</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>409800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Florentine</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>257130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mercaz</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>311000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Old North</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>167700.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         area  size  n_rooms     price\n",
       "0      Mercaz    20        5  760000.0\n",
       "1   Old North    28        5  409800.0\n",
       "2  Florentine    31        5  257130.0\n",
       "3      Mercaz    22        2  311000.0\n",
       "4   Old North    22        2  167700.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and the Y vectors\n",
    "# We will separate the continuous and categorical variables\n",
    "continuous_cols = ['size', 'n_rooms']\n",
    "categorical_cols = ['area']\n",
    "y_col = ['price']\n",
    "\n",
    "X_train_continuous = train[continuous_cols]\n",
    "X_train_categorical = train[categorical_cols]\n",
    "y_train = train[y_col]\n",
    "\n",
    "X_val_continuous = val[continuous_cols]\n",
    "X_val_categorical = val[categorical_cols]\n",
    "y_val = val[y_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing both train and test sets to have 0 mean and std. of 1 using the train set mean and std.\n",
    "# This will give each feature an equal initial importance and speed up the training time\n",
    "train_mean = X_train_continuous.mean(axis=0)\n",
    "train_std = X_train_continuous.std(axis=0)\n",
    "\n",
    "X_train_continuous = X_train_continuous - train_mean\n",
    "X_train_continuous /= train_std\n",
    "\n",
    "X_val_continuous = X_val_continuous - train_mean\n",
    "X_val_continuous /= train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model using a categorical variable\n",
    "# First, let’s define a helper class for the categorical variable\n",
    "\n",
    "class EmbeddingMapping():\n",
    "    \"\"\"\n",
    "    Helper class for handling categorical variables\n",
    "    An instance of this class should be defined for each categorical variable we want to use.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, series):\n",
    "        # get a list of unique values\n",
    "        values = series.unique().tolist()\n",
    "        # Set a dictionary mapping from values to integer value\n",
    "        # In our example this will be {'Mercaz': 1, 'Old North': 2, 'Florentine': 3}\n",
    "        self.embedding_dict = {value: int_value + 1 for int_value, value in enumerate(values)}\n",
    "        # The num_values will be used as the input_dim when defining the embedding layer. \n",
    "        # It will also be returned for unseen values \n",
    "        self.num_values = len(values) + 1\n",
    "\n",
    "    def get_mapping(self, value):\n",
    "        # If the value was seen in the training set, return its integer mapping\n",
    "        if value in self.embedding_dict:\n",
    "            return self.embedding_dict[value]\n",
    "        # Else, return the same integer for unseen values\n",
    "        else:\n",
    "            return self.num_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an embedding column for the train/validation sets\n",
    "area_mapping = EmbeddingMapping(X_train_categorical['area'])\n",
    "X_train_categorical = X_train_categorical.assign(area_mapping=X_train_categorical[\n",
    "'area'].apply(area_mapping.get_mapping))\n",
    "X_val_categorical = X_val_categorical.assign(area_mapping=X_val_categorical[\n",
    "'area'].apply(area_mapping.get_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>area_mapping</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mercaz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Old North</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Florentine</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mercaz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Old North</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         area  area_mapping\n",
       "0      Mercaz             1\n",
       "1   Old North             2\n",
       "2  Florentine             3\n",
       "3      Mercaz             1\n",
       "4   Old North             2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_categorical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0708 16:19:55.269750 4602951104 deprecation.py:506] From /Users/zeevkalyuzhner/.virtualenvs/effort-estimation/lib/python3.7/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Define the input layers\n",
    "# Define the embedding input\n",
    "area_input = Input(shape=(1,), dtype='int32') \n",
    "# Decide to what vector size we want to map our 'area' variable. \n",
    "# I'll use 1 here because we only have three areas\n",
    "embeddings_output = 1\n",
    "# Let’s define the embedding layer and flatten it\n",
    "area_embedings = Embedding(output_dim=embeddings_output, input_dim=area_mapping.num_values, input_length=1)(area_input)\n",
    "area_embedings = keras.layers.Reshape((embeddings_output,))(area_embedings)\n",
    "# Define the continuous variables input (just like before)\n",
    "continuous_input = Input(shape=(X_train_continuous.shape[1], ))\n",
    "# Concatenate continuous and embeddings inputs\n",
    "all_input = keras.layers.concatenate([continuous_input, area_embedings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0708 16:20:15.353287 4602951104 deprecation.py:506] From /Users/zeevkalyuzhner/.virtualenvs/effort-estimation/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# We’ll define a simple model with 2 hidden layers, with 25 neurons each.\n",
    "# Define the model\n",
    "\n",
    "units=25\n",
    "dense1 = Dense(units=units, activation='relu')(all_input)\n",
    "dense2 = Dense(units, activation='relu')(dense1)\n",
    "predictions = Dense(1)(dense2)\n",
    "# Note using the input object 'area_input' not 'area_embeddings'\n",
    "model = Model(inputs=[continuous_input, area_input], outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3000 samples, validate on 300 samples\n",
      "Epoch 1/10000\n",
      "3000/3000 [==============================] - 0s 114us/sample - loss: 3831507040.0759 - val_loss: 656359428.6933\n",
      "Epoch 2/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 455957416.2347 - val_loss: 116453553.9200\n",
      "Epoch 3/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 48774222.9573 - val_loss: 14420662.8000\n",
      "Epoch 4/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 8418490.6793 - val_loss: 4755843.9533\n",
      "Epoch 5/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 3586433.3020 - val_loss: 2229914.7733\n",
      "Epoch 6/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 1879214.5253 - val_loss: 1418773.0000\n",
      "Epoch 7/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 1198111.7720 - val_loss: 809568.4650\n",
      "Epoch 8/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 740914.7298 - val_loss: 561353.6254\n",
      "Epoch 9/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 517574.0712 - val_loss: 352821.9783\n",
      "Epoch 10/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 315722.8509 - val_loss: 236659.2050\n",
      "Epoch 11/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 199701.5604 - val_loss: 157491.2294\n",
      "Epoch 12/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 135955.2151 - val_loss: 100279.2906\n",
      "Epoch 13/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 88120.9027 - val_loss: 73793.9711\n",
      "Epoch 14/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 67619.7107 - val_loss: 56029.7402\n",
      "Epoch 15/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 54510.3907 - val_loss: 47791.1435\n",
      "Epoch 16/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 44204.7739 - val_loss: 37430.9158\n",
      "Epoch 17/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 38520.4897 - val_loss: 33872.0084\n",
      "Epoch 18/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 33858.1610 - val_loss: 27364.3145\n",
      "Epoch 19/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 29131.6630 - val_loss: 25083.8357\n",
      "Epoch 20/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 26963.0847 - val_loss: 21558.2827\n",
      "Epoch 21/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 23419.3177 - val_loss: 19994.2298\n",
      "Epoch 22/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 21272.0246 - val_loss: 18893.0310\n",
      "Epoch 23/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 19212.4538 - val_loss: 17439.3870\n",
      "Epoch 24/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 18379.6190 - val_loss: 17804.8308\n",
      "Epoch 25/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 16546.3862 - val_loss: 14459.5119\n",
      "Epoch 26/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 15302.7765 - val_loss: 14006.0531\n",
      "Epoch 27/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 14410.2552 - val_loss: 12866.2736\n",
      "Epoch 28/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 13029.8165 - val_loss: 11736.1749\n",
      "Epoch 29/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 12454.6779 - val_loss: 11046.3519\n",
      "Epoch 30/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 11515.2957 - val_loss: 11094.8182\n",
      "Epoch 31/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 11023.9632 - val_loss: 9535.9286\n",
      "Epoch 32/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 10421.3889 - val_loss: 10490.8429\n",
      "Epoch 33/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 10106.1370 - val_loss: 9459.0140\n",
      "Epoch 34/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 9194.1033 - val_loss: 9153.6155\n",
      "Epoch 35/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 8929.5276 - val_loss: 8741.8018\n",
      "Epoch 36/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 8949.0167 - val_loss: 8548.2912\n",
      "Epoch 37/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 8974.8310 - val_loss: 7662.2729\n",
      "Epoch 38/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 7573.2760 - val_loss: 6733.6077\n",
      "Epoch 39/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 6992.5756 - val_loss: 6552.8873\n",
      "Epoch 40/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 7360.8077 - val_loss: 6549.0178\n",
      "Epoch 41/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 7106.5475 - val_loss: 6356.0846\n",
      "Epoch 42/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 6389.0952 - val_loss: 5726.5264\n",
      "Epoch 43/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 5929.5927 - val_loss: 5849.0928\n",
      "Epoch 44/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 5622.3884 - val_loss: 5342.6669\n",
      "Epoch 45/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 5585.7539 - val_loss: 5533.0710\n",
      "Epoch 46/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 5405.4941 - val_loss: 4859.2662\n",
      "Epoch 47/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 5083.4170 - val_loss: 6089.8782\n",
      "Epoch 48/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 5122.2037 - val_loss: 4657.3302\n",
      "Epoch 49/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 4766.9747 - val_loss: 4407.5750\n",
      "Epoch 50/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 4463.4788 - val_loss: 4769.5568\n",
      "Epoch 51/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 4355.9578 - val_loss: 4269.7511\n",
      "Epoch 52/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 4134.4157 - val_loss: 4031.3005\n",
      "Epoch 53/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 3961.8364 - val_loss: 4268.2968\n",
      "Epoch 54/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 3825.6166 - val_loss: 3829.9212\n",
      "Epoch 55/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 3839.4626 - val_loss: 3999.6519\n",
      "Epoch 56/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 3633.4309 - val_loss: 3697.3270\n",
      "Epoch 57/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 3673.1480 - val_loss: 3631.3657\n",
      "Epoch 58/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 3743.6591 - val_loss: 3423.4377\n",
      "Epoch 59/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 3613.0875 - val_loss: 3397.2431\n",
      "Epoch 60/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 3375.3852 - val_loss: 3465.9516\n",
      "Epoch 61/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 3197.3684 - val_loss: 3159.0436\n",
      "Epoch 62/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 3012.3910 - val_loss: 3174.5728\n",
      "Epoch 63/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 2919.5013 - val_loss: 2976.0088\n",
      "Epoch 64/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 2801.7003 - val_loss: 3068.4572\n",
      "Epoch 65/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 2750.4922 - val_loss: 3302.3953\n",
      "Epoch 66/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 2981.1788 - val_loss: 3155.3913\n",
      "Epoch 67/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 2662.0334 - val_loss: 2748.9095\n",
      "Epoch 68/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 2566.2920 - val_loss: 2686.4050\n",
      "Epoch 69/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 2524.5390 - val_loss: 3117.3801\n",
      "Epoch 70/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 2515.6900 - val_loss: 2619.9664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 2522.6843 - val_loss: 2574.9363\n",
      "Epoch 72/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 2505.3180 - val_loss: 2743.2748\n",
      "Epoch 73/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 2361.4986 - val_loss: 2606.0480\n",
      "Epoch 74/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 2297.6411 - val_loss: 2452.0170\n",
      "Epoch 75/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 2322.6370 - val_loss: 2466.9068\n",
      "Epoch 76/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 2159.3511 - val_loss: 2340.0644\n",
      "Epoch 77/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 2145.2463 - val_loss: 2358.0988\n",
      "Epoch 78/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 2078.5930 - val_loss: 2255.7773\n",
      "Epoch 79/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 2074.6435 - val_loss: 2263.7873\n",
      "Epoch 80/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 2049.4467 - val_loss: 2339.9793\n",
      "Epoch 81/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 2071.1306 - val_loss: 2199.3064\n",
      "Epoch 82/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 2068.6785 - val_loss: 2239.9405\n",
      "Epoch 83/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1968.3639 - val_loss: 2260.3111\n",
      "Epoch 84/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1966.8924 - val_loss: 2210.8077\n",
      "Epoch 85/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1872.0577 - val_loss: 2155.4161\n",
      "Epoch 86/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 1882.3036 - val_loss: 2104.2684\n",
      "Epoch 87/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 1850.1005 - val_loss: 2277.0071\n",
      "Epoch 88/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1855.6689 - val_loss: 2132.0564\n",
      "Epoch 89/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1847.3870 - val_loss: 2103.2381\n",
      "Epoch 90/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1805.9445 - val_loss: 1994.1329\n",
      "Epoch 91/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1849.7686 - val_loss: 2109.6637\n",
      "Epoch 92/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1792.2698 - val_loss: 1965.3688\n",
      "Epoch 93/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1965.1223 - val_loss: 1950.6428\n",
      "Epoch 94/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1759.2886 - val_loss: 1919.7672\n",
      "Epoch 95/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1682.7420 - val_loss: 2009.1769\n",
      "Epoch 96/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1743.8901 - val_loss: 2007.9117\n",
      "Epoch 97/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1728.2457 - val_loss: 1905.3778\n",
      "Epoch 98/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1690.9721 - val_loss: 1935.6317\n",
      "Epoch 99/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1745.8248 - val_loss: 2027.0763\n",
      "Epoch 100/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1690.0939 - val_loss: 1769.0269\n",
      "Epoch 101/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1647.7947 - val_loss: 1752.0699\n",
      "Epoch 102/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1656.0000 - val_loss: 1967.4686\n",
      "Epoch 103/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1608.4836 - val_loss: 1754.0051\n",
      "Epoch 104/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1652.6797 - val_loss: 1859.3378\n",
      "Epoch 105/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1696.7232 - val_loss: 1891.0297\n",
      "Epoch 106/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1673.0587 - val_loss: 1701.9641\n",
      "Epoch 107/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1611.2856 - val_loss: 1686.8258\n",
      "Epoch 108/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1511.3780 - val_loss: 1726.0375\n",
      "Epoch 109/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1477.6485 - val_loss: 1694.2152\n",
      "Epoch 110/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1467.9379 - val_loss: 1646.7012\n",
      "Epoch 111/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1487.8012 - val_loss: 1721.0573\n",
      "Epoch 112/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1422.0149 - val_loss: 1688.4294\n",
      "Epoch 113/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1455.3304 - val_loss: 1677.8825\n",
      "Epoch 114/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 1472.4889 - val_loss: 1725.9966\n",
      "Epoch 115/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1402.1017 - val_loss: 1677.2355\n",
      "Epoch 116/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 1486.5256 - val_loss: 1634.1369\n",
      "Epoch 117/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 1400.5881 - val_loss: 1746.5752\n",
      "Epoch 118/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 1385.4575 - val_loss: 1603.5327\n",
      "Epoch 119/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 1427.3073 - val_loss: 1706.3894\n",
      "Epoch 120/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1402.7361 - val_loss: 1610.5313\n",
      "Epoch 121/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1374.8607 - val_loss: 1574.4284\n",
      "Epoch 122/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1394.7703 - val_loss: 1598.2613\n",
      "Epoch 123/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1335.5263 - val_loss: 1631.1644\n",
      "Epoch 124/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1481.6032 - val_loss: 1583.8176\n",
      "Epoch 125/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1359.1660 - val_loss: 1537.7640\n",
      "Epoch 126/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1357.7966 - val_loss: 1603.3430\n",
      "Epoch 127/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1285.4687 - val_loss: 1522.7297\n",
      "Epoch 128/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1269.8943 - val_loss: 1715.7297\n",
      "Epoch 129/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1351.1989 - val_loss: 1605.3125\n",
      "Epoch 130/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1294.3124 - val_loss: 1548.7566\n",
      "Epoch 131/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1291.4162 - val_loss: 1511.3397\n",
      "Epoch 132/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1247.7021 - val_loss: 1635.7310\n",
      "Epoch 133/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1276.2573 - val_loss: 1609.1129\n",
      "Epoch 134/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1283.8463 - val_loss: 1531.9388\n",
      "Epoch 135/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1270.2247 - val_loss: 1677.1805\n",
      "Epoch 136/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1334.2725 - val_loss: 1472.9341\n",
      "Epoch 137/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1225.0784 - val_loss: 1484.6980\n",
      "Epoch 138/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 1241.6272 - val_loss: 1481.5064\n",
      "Epoch 139/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1185.8808 - val_loss: 1482.1804\n",
      "Epoch 140/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 1242.7690 - val_loss: 1515.6268\n",
      "Epoch 141/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 1228.0443 - val_loss: 1418.9367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 1221.1887 - val_loss: 1534.9140\n",
      "Epoch 143/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 1210.6503 - val_loss: 1418.9086\n",
      "Epoch 144/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 1230.3397 - val_loss: 1426.4258\n",
      "Epoch 145/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 1161.1461 - val_loss: 1433.2432\n",
      "Epoch 146/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1173.8786 - val_loss: 1387.2926\n",
      "Epoch 147/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1157.1018 - val_loss: 1400.6266\n",
      "Epoch 148/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1154.6934 - val_loss: 1553.9078\n",
      "Epoch 149/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1282.5107 - val_loss: 1409.5396\n",
      "Epoch 150/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1218.4088 - val_loss: 1410.8719\n",
      "Epoch 151/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1194.8389 - val_loss: 1360.8595\n",
      "Epoch 152/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1161.3266 - val_loss: 1404.9681\n",
      "Epoch 153/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1187.2268 - val_loss: 1460.7648\n",
      "Epoch 154/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1183.0170 - val_loss: 1449.1966\n",
      "Epoch 155/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1140.4644 - val_loss: 1388.1822\n",
      "Epoch 156/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1158.9424 - val_loss: 1379.0501\n",
      "Epoch 157/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 1107.2115 - val_loss: 1336.7359\n",
      "Epoch 158/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 1105.1125 - val_loss: 1528.7919\n",
      "Epoch 159/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1173.4775 - val_loss: 1386.4302\n",
      "Epoch 160/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1124.4485 - val_loss: 1473.6678\n",
      "Epoch 161/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 1108.2018 - val_loss: 1380.8945\n",
      "Epoch 162/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1091.6553 - val_loss: 1393.1417\n",
      "Epoch 163/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1131.2459 - val_loss: 1319.1866\n",
      "Epoch 164/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 1090.5933 - val_loss: 1365.2722\n",
      "Epoch 165/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 1083.3593 - val_loss: 1297.5672\n",
      "Epoch 166/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 1089.3449 - val_loss: 1303.9998\n",
      "Epoch 167/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 1078.6192 - val_loss: 1328.1192\n",
      "Epoch 168/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1069.8611 - val_loss: 1393.6216\n",
      "Epoch 169/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 1075.2999 - val_loss: 1276.8476\n",
      "Epoch 170/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 1088.1028 - val_loss: 1318.2906\n",
      "Epoch 171/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 1139.1236 - val_loss: 1263.1879\n",
      "Epoch 172/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 1038.2677 - val_loss: 1337.2783\n",
      "Epoch 173/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 1064.2571 - val_loss: 1266.3680\n",
      "Epoch 174/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1058.0331 - val_loss: 1288.3874\n",
      "Epoch 175/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1043.8934 - val_loss: 1310.6581\n",
      "Epoch 176/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1068.3251 - val_loss: 1267.7454\n",
      "Epoch 177/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 1061.7225 - val_loss: 1239.6603\n",
      "Epoch 178/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 1028.0762 - val_loss: 1291.3843\n",
      "Epoch 179/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 1035.6907 - val_loss: 1245.8827\n",
      "Epoch 180/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 1025.0238 - val_loss: 1259.3979\n",
      "Epoch 181/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 1047.0760 - val_loss: 1257.8086\n",
      "Epoch 182/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 1032.0571 - val_loss: 1305.5469\n",
      "Epoch 183/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1019.7190 - val_loss: 1235.6708\n",
      "Epoch 184/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 1007.6610 - val_loss: 1301.2779\n",
      "Epoch 185/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 1066.0835 - val_loss: 1395.3837\n",
      "Epoch 186/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 1058.8374 - val_loss: 1214.9720\n",
      "Epoch 187/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 1023.6099 - val_loss: 1244.1794\n",
      "Epoch 188/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 1012.7574 - val_loss: 1233.4706\n",
      "Epoch 189/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 997.5199 - val_loss: 1211.6281\n",
      "Epoch 190/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 1020.3076 - val_loss: 1239.3260\n",
      "Epoch 191/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 992.5098 - val_loss: 1203.8121\n",
      "Epoch 192/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 993.7746 - val_loss: 1198.8578\n",
      "Epoch 193/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 1013.8948 - val_loss: 1190.3421\n",
      "Epoch 194/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1002.7232 - val_loss: 1211.4733\n",
      "Epoch 195/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 985.3254 - val_loss: 1183.9312\n",
      "Epoch 196/10000\n",
      "3000/3000 [==============================] - ETA: 0s - loss: 911.388 - 0s 11us/sample - loss: 971.9985 - val_loss: 1224.8690\n",
      "Epoch 197/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 970.1108 - val_loss: 1293.4100\n",
      "Epoch 198/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 1044.3645 - val_loss: 1190.4997\n",
      "Epoch 199/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 967.5969 - val_loss: 1233.2804\n",
      "Epoch 200/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 970.6225 - val_loss: 1205.7287\n",
      "Epoch 201/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 952.4139 - val_loss: 1181.2478\n",
      "Epoch 202/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 955.3587 - val_loss: 1168.5025\n",
      "Epoch 203/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 967.0022 - val_loss: 1157.6522\n",
      "Epoch 204/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 960.5017 - val_loss: 1174.3785\n",
      "Epoch 205/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 958.6493 - val_loss: 1196.0304\n",
      "Epoch 206/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 965.4436 - val_loss: 1193.9879\n",
      "Epoch 207/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 981.1201 - val_loss: 1196.9233\n",
      "Epoch 208/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 957.2636 - val_loss: 1160.5266\n",
      "Epoch 209/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 946.7874 - val_loss: 1160.5693\n",
      "Epoch 210/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 922.0427 - val_loss: 1156.3939\n",
      "Epoch 211/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 924.6096 - val_loss: 1160.7815\n",
      "Epoch 212/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 947.4325 - val_loss: 1158.4493\n",
      "Epoch 213/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 935.1675 - val_loss: 1136.5831\n",
      "Epoch 214/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 927.4439 - val_loss: 1153.9353\n",
      "Epoch 215/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 935.9233 - val_loss: 1130.8507\n",
      "Epoch 216/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 957.7342 - val_loss: 1127.5571\n",
      "Epoch 217/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 936.0929 - val_loss: 1144.0504\n",
      "Epoch 218/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 909.6645 - val_loss: 1119.9959\n",
      "Epoch 219/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 954.6217 - val_loss: 1245.7579\n",
      "Epoch 220/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 954.7784 - val_loss: 1189.7744\n",
      "Epoch 221/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 940.3132 - val_loss: 1110.3922\n",
      "Epoch 222/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 913.8656 - val_loss: 1129.7615\n",
      "Epoch 223/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 947.2026 - val_loss: 1147.2472\n",
      "Epoch 224/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 936.5581 - val_loss: 1181.4345\n",
      "Epoch 225/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 950.4617 - val_loss: 1114.1197\n",
      "Epoch 226/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 934.5339 - val_loss: 1098.4513\n",
      "Epoch 227/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 903.8507 - val_loss: 1104.5728\n",
      "Epoch 228/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 909.4206 - val_loss: 1138.4775\n",
      "Epoch 229/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 908.5620 - val_loss: 1085.9438\n",
      "Epoch 230/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 890.1536 - val_loss: 1092.4962\n",
      "Epoch 231/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 895.3459 - val_loss: 1157.4968\n",
      "Epoch 232/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 925.0204 - val_loss: 1114.3039\n",
      "Epoch 233/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 885.8287 - val_loss: 1091.8713\n",
      "Epoch 234/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 892.0978 - val_loss: 1102.3005\n",
      "Epoch 235/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 894.4662 - val_loss: 1094.4180\n",
      "Epoch 236/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 900.0846 - val_loss: 1074.0816\n",
      "Epoch 237/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 882.5707 - val_loss: 1071.0506\n",
      "Epoch 238/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 873.8142 - val_loss: 1100.2025\n",
      "Epoch 239/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 901.8025 - val_loss: 1113.5930\n",
      "Epoch 240/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 869.2184 - val_loss: 1068.0774\n",
      "Epoch 241/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 902.8594 - val_loss: 1094.3987\n",
      "Epoch 242/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 881.6211 - val_loss: 1105.9594\n",
      "Epoch 243/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 883.0467 - val_loss: 1086.5630\n",
      "Epoch 244/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 864.5253 - val_loss: 1043.7078\n",
      "Epoch 245/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 863.3945 - val_loss: 1101.1163\n",
      "Epoch 246/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 861.4265 - val_loss: 1050.7466\n",
      "Epoch 247/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 880.9683 - val_loss: 1046.3481\n",
      "Epoch 248/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 863.3675 - val_loss: 1074.0187\n",
      "Epoch 249/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 886.0645 - val_loss: 1158.2308\n",
      "Epoch 250/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 737.3785Epoch: 250 - loss: 912.494540 - val_loss: 1046.458415\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 912.4945 - val_loss: 1046.4584\n",
      "Epoch 251/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 853.2859 - val_loss: 1059.1770\n",
      "Epoch 252/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 870.7048 - val_loss: 1059.4828\n",
      "Epoch 253/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 857.8072 - val_loss: 1054.1846\n",
      "Epoch 254/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 869.9738 - val_loss: 1071.2815\n",
      "Epoch 255/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 889.2542 - val_loss: 1083.7420\n",
      "Epoch 256/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 875.0441 - val_loss: 1032.5690\n",
      "Epoch 257/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 872.1829 - val_loss: 1044.2338\n",
      "Epoch 258/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 872.5095 - val_loss: 1083.9821\n",
      "Epoch 259/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 854.6418 - val_loss: 1036.7144\n",
      "Epoch 260/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 876.2269 - val_loss: 1041.9471\n",
      "Epoch 261/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 869.8564 - val_loss: 1046.6576\n",
      "Epoch 262/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 860.0974 - val_loss: 1029.3563\n",
      "Epoch 263/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 846.2574 - val_loss: 1050.7142\n",
      "Epoch 264/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 875.9218 - val_loss: 1017.2179\n",
      "Epoch 265/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 872.5318 - val_loss: 1014.9069\n",
      "Epoch 266/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 852.5378 - val_loss: 1093.7964\n",
      "Epoch 267/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 849.9492 - val_loss: 1056.9021\n",
      "Epoch 268/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 839.9589 - val_loss: 1038.8017\n",
      "Epoch 269/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 854.9208 - val_loss: 1020.4067\n",
      "Epoch 270/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 846.7079 - val_loss: 1010.8928\n",
      "Epoch 271/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 841.4249 - val_loss: 1044.4753\n",
      "Epoch 272/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 828.9262 - val_loss: 998.9076\n",
      "Epoch 273/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 824.3391 - val_loss: 1001.6658\n",
      "Epoch 274/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 874.9028 - val_loss: 1132.1788\n",
      "Epoch 275/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 861.5809 - val_loss: 1008.3455\n",
      "Epoch 276/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 836.4381 - val_loss: 1072.7277\n",
      "Epoch 277/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 834.7620 - val_loss: 1066.6639\n",
      "Epoch 278/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 839.4161 - val_loss: 1024.9679\n",
      "Epoch 279/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 830.4787 - val_loss: 1037.8732\n",
      "Epoch 280/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 841.6457 - val_loss: 1012.7329\n",
      "Epoch 281/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 822.1729 - val_loss: 985.3915\n",
      "Epoch 282/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 816.4047 - val_loss: 999.6785\n",
      "Epoch 283/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 830.8860 - val_loss: 992.4271\n",
      "Epoch 284/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 817.7073 - val_loss: 984.1354\n",
      "Epoch 285/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 831.1881 - val_loss: 1007.5474\n",
      "Epoch 286/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 808.1622 - val_loss: 974.8644\n",
      "Epoch 287/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 807.9847 - val_loss: 974.9726\n",
      "Epoch 288/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 804.3333 - val_loss: 1009.9022\n",
      "Epoch 289/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 835.8400 - val_loss: 1018.6417\n",
      "Epoch 290/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 820.2727 - val_loss: 1047.4620\n",
      "Epoch 291/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 824.0597 - val_loss: 1040.8705\n",
      "Epoch 292/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 815.3446 - val_loss: 977.0525\n",
      "Epoch 293/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 816.7712 - val_loss: 1034.8729\n",
      "Epoch 294/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 827.1995 - val_loss: 1007.7967\n",
      "Epoch 295/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 849.4701 - val_loss: 1041.3550\n",
      "Epoch 296/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 837.0091 - val_loss: 1034.9270\n",
      "Epoch 297/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 816.6211 - val_loss: 967.6646\n",
      "Epoch 298/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 794.7047 - val_loss: 1006.0075\n",
      "Epoch 299/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 809.0349 - val_loss: 970.2595\n",
      "Epoch 300/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 810.3814 - val_loss: 982.1552\n",
      "Epoch 301/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 811.5370 - val_loss: 986.5906\n",
      "Epoch 302/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 794.2761 - val_loss: 972.8652\n",
      "Epoch 303/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 796.5398 - val_loss: 978.9702\n",
      "Epoch 304/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 795.3838 - val_loss: 982.2824\n",
      "Epoch 305/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 806.5734 - val_loss: 1009.6724\n",
      "Epoch 306/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 811.5961 - val_loss: 1009.4347\n",
      "Epoch 307/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 812.6441 - val_loss: 953.9535\n",
      "Epoch 308/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 815.6766 - val_loss: 958.9925\n",
      "Epoch 309/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 784.0541 - val_loss: 975.1034\n",
      "Epoch 310/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 797.6830 - val_loss: 970.5850\n",
      "Epoch 311/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 797.2822 - val_loss: 991.1071\n",
      "Epoch 312/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 801.2181 - val_loss: 996.2072\n",
      "Epoch 313/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 783.2941 - val_loss: 1064.3318\n",
      "Epoch 314/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 795.6007 - val_loss: 986.4781\n",
      "Epoch 315/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 808.8044 - val_loss: 960.9503\n",
      "Epoch 316/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 810.3698 - val_loss: 977.3113\n",
      "Epoch 317/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 802.6849 - val_loss: 973.7611\n",
      "Epoch 318/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 790.0258 - val_loss: 954.6293\n",
      "Epoch 319/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 796.0412 - val_loss: 937.3349\n",
      "Epoch 320/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 798.7273 - val_loss: 954.9922\n",
      "Epoch 321/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 774.9253 - val_loss: 978.5982\n",
      "Epoch 322/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 799.7489 - val_loss: 980.2806\n",
      "Epoch 323/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 776.2685 - val_loss: 972.1457\n",
      "Epoch 324/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 791.0904 - val_loss: 954.2228\n",
      "Epoch 325/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 779.5280 - val_loss: 945.0287\n",
      "Epoch 326/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 789.7577 - val_loss: 968.2099\n",
      "Epoch 327/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 782.1736 - val_loss: 943.3556\n",
      "Epoch 328/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 778.9402 - val_loss: 932.5776\n",
      "Epoch 329/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 769.8158 - val_loss: 936.8287\n",
      "Epoch 330/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 782.0517 - val_loss: 941.8226\n",
      "Epoch 331/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 780.0380 - val_loss: 942.0630\n",
      "Epoch 332/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 778.6338 - val_loss: 943.0180\n",
      "Epoch 333/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 800.5719 - val_loss: 972.0739\n",
      "Epoch 334/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 787.3901 - val_loss: 945.6537\n",
      "Epoch 335/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 790.0642 - val_loss: 932.4193\n",
      "Epoch 336/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 776.8307 - val_loss: 938.5475\n",
      "Epoch 337/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 765.4045 - val_loss: 947.6933\n",
      "Epoch 338/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 763.5301 - val_loss: 929.4091\n",
      "Epoch 339/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 760.1067 - val_loss: 966.3074\n",
      "Epoch 340/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 776.1430 - val_loss: 931.5204\n",
      "Epoch 341/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 763.0233 - val_loss: 914.3895\n",
      "Epoch 342/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 781.0930 - val_loss: 964.6978\n",
      "Epoch 343/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 785.9694 - val_loss: 927.0289\n",
      "Epoch 344/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 777.5828 - val_loss: 929.3818\n",
      "Epoch 345/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 791.6261 - val_loss: 937.4492\n",
      "Epoch 346/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 782.6085 - val_loss: 914.3252\n",
      "Epoch 347/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 768.7448 - val_loss: 908.0510\n",
      "Epoch 348/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 771.5217 - val_loss: 936.8382\n",
      "Epoch 349/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 770.8539 - val_loss: 926.4831\n",
      "Epoch 350/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 760.9959 - val_loss: 906.9290\n",
      "Epoch 351/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 750.8296 - val_loss: 927.7253\n",
      "Epoch 352/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 757.3945 - val_loss: 941.1664\n",
      "Epoch 353/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 761.4683 - val_loss: 909.4383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 759.3745 - val_loss: 903.4051\n",
      "Epoch 355/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 751.8196 - val_loss: 922.9983\n",
      "Epoch 356/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 750.3511 - val_loss: 957.7414\n",
      "Epoch 357/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 764.0346 - val_loss: 920.9848\n",
      "Epoch 358/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 774.5141 - val_loss: 924.1249\n",
      "Epoch 359/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 762.7437 - val_loss: 921.6947\n",
      "Epoch 360/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 752.9278 - val_loss: 927.5127\n",
      "Epoch 361/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 753.1972 - val_loss: 915.5567\n",
      "Epoch 362/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 745.0174 - val_loss: 898.3888\n",
      "Epoch 363/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 743.0301 - val_loss: 902.3460\n",
      "Epoch 364/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 778.3101 - val_loss: 897.3570\n",
      "Epoch 365/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 750.5238 - val_loss: 942.2778\n",
      "Epoch 366/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 771.9926 - val_loss: 916.3833\n",
      "Epoch 367/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 758.9159 - val_loss: 897.1363\n",
      "Epoch 368/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 752.6170 - val_loss: 919.6279\n",
      "Epoch 369/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 747.4460 - val_loss: 944.9106\n",
      "Epoch 370/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 757.0268 - val_loss: 928.5163\n",
      "Epoch 371/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 744.4822 - val_loss: 904.8299\n",
      "Epoch 372/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 738.1692 - val_loss: 915.3661\n",
      "Epoch 373/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 745.8246 - val_loss: 914.3584\n",
      "Epoch 374/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 751.4046 - val_loss: 895.0203\n",
      "Epoch 375/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 737.5235 - val_loss: 887.5983\n",
      "Epoch 376/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 735.1482 - val_loss: 896.9484\n",
      "Epoch 377/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 738.5343 - val_loss: 914.5020\n",
      "Epoch 378/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 758.1212 - val_loss: 910.3137\n",
      "Epoch 379/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 739.1401 - val_loss: 885.3225\n",
      "Epoch 380/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 756.7507 - val_loss: 923.2407\n",
      "Epoch 381/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 752.4719 - val_loss: 893.2127\n",
      "Epoch 382/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 730.2450 - val_loss: 895.9436\n",
      "Epoch 383/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 748.8351 - val_loss: 892.6448\n",
      "Epoch 384/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 733.5117 - val_loss: 914.7813\n",
      "Epoch 385/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 732.0510 - val_loss: 924.5528\n",
      "Epoch 386/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 741.0188 - val_loss: 893.2848\n",
      "Epoch 387/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 738.1601 - val_loss: 902.3330\n",
      "Epoch 388/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 741.4745 - val_loss: 874.5286\n",
      "Epoch 389/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 733.6472 - val_loss: 876.7885\n",
      "Epoch 390/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 750.1568 - val_loss: 872.4614\n",
      "Epoch 391/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 735.1472 - val_loss: 885.6432\n",
      "Epoch 392/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 726.4847 - val_loss: 886.0826\n",
      "Epoch 393/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 735.3918 - val_loss: 885.9078\n",
      "Epoch 394/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 743.5769 - val_loss: 875.1234\n",
      "Epoch 395/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 727.2514 - val_loss: 889.0033\n",
      "Epoch 396/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 727.4022 - val_loss: 871.2812\n",
      "Epoch 397/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 751.6392 - val_loss: 927.7569\n",
      "Epoch 398/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 738.6952 - val_loss: 869.8401\n",
      "Epoch 399/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 724.8631 - val_loss: 887.6573\n",
      "Epoch 400/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 737.1980 - val_loss: 881.0393\n",
      "Epoch 401/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 728.5296 - val_loss: 894.7652\n",
      "Epoch 402/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 742.7469 - val_loss: 895.7057\n",
      "Epoch 403/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 729.8848 - val_loss: 887.7244\n",
      "Epoch 404/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 756.1018 - val_loss: 867.0614\n",
      "Epoch 405/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 721.3640 - val_loss: 893.5556\n",
      "Epoch 406/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 729.0113 - val_loss: 886.0296\n",
      "Epoch 407/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 726.5115 - val_loss: 864.9886\n",
      "Epoch 408/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 724.8807 - val_loss: 878.3135\n",
      "Epoch 409/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 716.5491 - val_loss: 862.5845\n",
      "Epoch 410/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 707.8679 - val_loss: 900.8119\n",
      "Epoch 411/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 738.7309 - val_loss: 922.5379\n",
      "Epoch 412/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 732.1935 - val_loss: 930.7753\n",
      "Epoch 413/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 731.3680 - val_loss: 874.9466\n",
      "Epoch 414/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 726.9926 - val_loss: 862.8637\n",
      "Epoch 415/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 727.0106 - val_loss: 874.6814\n",
      "Epoch 416/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 718.8005 - val_loss: 876.1902\n",
      "Epoch 417/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 726.8792 - val_loss: 858.0943\n",
      "Epoch 418/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 721.1708 - val_loss: 851.8258\n",
      "Epoch 419/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 715.8881 - val_loss: 870.7991\n",
      "Epoch 420/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 709.8834 - val_loss: 865.1725\n",
      "Epoch 421/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 712.5422 - val_loss: 853.5993\n",
      "Epoch 422/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 707.8531 - val_loss: 877.2816\n",
      "Epoch 423/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 712.1666 - val_loss: 859.7240\n",
      "Epoch 424/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 714.2289 - val_loss: 857.1044\n",
      "Epoch 425/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 709.3054 - val_loss: 852.7340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 426/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 702.4001 - val_loss: 916.6919\n",
      "Epoch 427/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 724.4654 - val_loss: 854.8848\n",
      "Epoch 428/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 712.7288 - val_loss: 850.8678\n",
      "Epoch 429/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 720.2761 - val_loss: 864.1673\n",
      "Epoch 430/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 707.9918 - val_loss: 854.6788\n",
      "Epoch 431/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 709.1463 - val_loss: 861.7253\n",
      "Epoch 432/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 706.3817 - val_loss: 859.5563\n",
      "Epoch 433/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 724.1122 - val_loss: 893.4304\n",
      "Epoch 434/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 706.1126 - val_loss: 850.4472\n",
      "Epoch 435/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 730.7123 - val_loss: 864.4097\n",
      "Epoch 436/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 720.5978 - val_loss: 863.3266\n",
      "Epoch 437/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 711.2026 - val_loss: 839.5244\n",
      "Epoch 438/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 704.4723 - val_loss: 860.0270\n",
      "Epoch 439/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 702.8527 - val_loss: 853.9298\n",
      "Epoch 440/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 706.7922 - val_loss: 858.3869\n",
      "Epoch 441/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 703.9375 - val_loss: 836.8136\n",
      "Epoch 442/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 696.4048 - val_loss: 880.8716\n",
      "Epoch 443/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 701.2158 - val_loss: 838.0167\n",
      "Epoch 444/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 699.7916 - val_loss: 864.0426\n",
      "Epoch 445/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 705.5798 - val_loss: 856.7281\n",
      "Epoch 446/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 701.1294 - val_loss: 851.2587\n",
      "Epoch 447/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 714.0855 - val_loss: 842.9809\n",
      "Epoch 448/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 697.8930 - val_loss: 845.2386\n",
      "Epoch 449/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 694.5032 - val_loss: 848.1911\n",
      "Epoch 450/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 704.9918 - val_loss: 845.3019\n",
      "Epoch 451/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 701.7799 - val_loss: 840.6597\n",
      "Epoch 452/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 696.3122 - val_loss: 883.9526\n",
      "Epoch 453/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 712.8911 - val_loss: 835.3660\n",
      "Epoch 454/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 701.7228 - val_loss: 835.7531\n",
      "Epoch 455/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 703.4672 - val_loss: 830.8071\n",
      "Epoch 456/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 695.3781 - val_loss: 832.4673\n",
      "Epoch 457/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 692.2276 - val_loss: 852.4191\n",
      "Epoch 458/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 712.5694 - val_loss: 856.1061\n",
      "Epoch 459/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 707.4055 - val_loss: 838.7523\n",
      "Epoch 460/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 723.0199 - val_loss: 845.2082\n",
      "Epoch 461/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 711.8794 - val_loss: 829.3853\n",
      "Epoch 462/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 702.1556 - val_loss: 842.0674\n",
      "Epoch 463/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 685.7093 - val_loss: 826.9855\n",
      "Epoch 464/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 700.7006 - val_loss: 838.8639\n",
      "Epoch 465/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 693.7556 - val_loss: 832.0054\n",
      "Epoch 466/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 692.9456 - val_loss: 851.4366\n",
      "Epoch 467/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 693.6949 - val_loss: 848.7298\n",
      "Epoch 468/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 708.8057 - val_loss: 839.9362\n",
      "Epoch 469/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 701.7990 - val_loss: 830.0951\n",
      "Epoch 470/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 690.6308 - val_loss: 831.8203\n",
      "Epoch 471/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 703.0667 - val_loss: 834.8692\n",
      "Epoch 472/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 700.7486 - val_loss: 820.9531\n",
      "Epoch 473/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 695.4241 - val_loss: 821.5505\n",
      "Epoch 474/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 695.5069 - val_loss: 832.8811\n",
      "Epoch 475/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 699.5977 - val_loss: 836.0682\n",
      "Epoch 476/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 695.0667 - val_loss: 841.0260\n",
      "Epoch 477/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 697.9070 - val_loss: 833.1183\n",
      "Epoch 478/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 683.3186 - val_loss: 852.6826\n",
      "Epoch 479/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 691.2953 - val_loss: 852.1673\n",
      "Epoch 480/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 690.5974 - val_loss: 869.6365\n",
      "Epoch 481/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 700.7691 - val_loss: 837.0054\n",
      "Epoch 482/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 688.8194 - val_loss: 827.7413\n",
      "Epoch 483/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 692.6333 - val_loss: 828.8307\n",
      "Epoch 484/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 699.5821 - val_loss: 828.6474\n",
      "Epoch 485/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 686.5671 - val_loss: 842.7857\n",
      "Epoch 486/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 693.4523 - val_loss: 827.6732\n",
      "Epoch 487/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 684.9812 - val_loss: 827.7631\n",
      "Epoch 488/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 710.0280 - val_loss: 827.9899\n",
      "Epoch 489/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 678.2255 - val_loss: 821.3762\n",
      "Epoch 490/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 679.3542 - val_loss: 830.1030\n",
      "Epoch 491/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 680.7965 - val_loss: 811.9066\n",
      "Epoch 492/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 692.5519 - val_loss: 814.6061\n",
      "Epoch 493/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 690.9805 - val_loss: 822.9110\n",
      "Epoch 494/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 674.1904 - val_loss: 836.7865\n",
      "Epoch 495/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 683.0023 - val_loss: 818.0699\n",
      "Epoch 496/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 689.4619 - val_loss: 818.8454\n",
      "Epoch 497/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 678.0560 - val_loss: 809.6546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 498/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 696.2181 - val_loss: 876.2269\n",
      "Epoch 499/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 689.8017 - val_loss: 804.3363\n",
      "Epoch 500/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 478.7573Epoch: 500 - loss: 681.841059 - val_loss: 822.447564\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 681.8411 - val_loss: 822.4476\n",
      "Epoch 501/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 677.5587 - val_loss: 808.7517\n",
      "Epoch 502/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 679.7731 - val_loss: 810.3540\n",
      "Epoch 503/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 676.7172 - val_loss: 808.1456\n",
      "Epoch 504/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 677.5800 - val_loss: 808.1060\n",
      "Epoch 505/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 675.9723 - val_loss: 830.4959\n",
      "Epoch 506/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 682.7717 - val_loss: 829.8149\n",
      "Epoch 507/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 691.2395 - val_loss: 811.6312\n",
      "Epoch 508/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 687.2369 - val_loss: 818.7901\n",
      "Epoch 509/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 675.6581 - val_loss: 819.3912\n",
      "Epoch 510/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 668.8492 - val_loss: 810.1261\n",
      "Epoch 511/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 672.1300 - val_loss: 829.9520\n",
      "Epoch 512/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 676.1500 - val_loss: 828.2695\n",
      "Epoch 513/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 680.1551 - val_loss: 806.1284\n",
      "Epoch 514/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 674.9448 - val_loss: 807.3896\n",
      "Epoch 515/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 675.5408 - val_loss: 811.6296\n",
      "Epoch 516/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 689.7344 - val_loss: 812.1681\n",
      "Epoch 517/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 674.0705 - val_loss: 809.3242\n",
      "Epoch 518/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 675.9145 - val_loss: 815.0882\n",
      "Epoch 519/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 679.7790 - val_loss: 802.9363\n",
      "Epoch 520/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 671.8666 - val_loss: 813.4171\n",
      "Epoch 521/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 672.6485 - val_loss: 808.3637\n",
      "Epoch 522/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 675.0196 - val_loss: 825.9518\n",
      "Epoch 523/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 671.2571 - val_loss: 806.9968\n",
      "Epoch 524/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 679.7306 - val_loss: 824.3499\n",
      "Epoch 525/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 679.8991 - val_loss: 810.7366\n",
      "Epoch 526/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 676.9277 - val_loss: 794.8891\n",
      "Epoch 527/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 673.2284 - val_loss: 797.7165\n",
      "Epoch 528/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 669.2075 - val_loss: 799.0032\n",
      "Epoch 529/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 667.2821 - val_loss: 803.9060\n",
      "Epoch 530/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 679.7627 - val_loss: 806.3832\n",
      "Epoch 531/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 672.7469 - val_loss: 814.0479\n",
      "Epoch 532/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 675.8160 - val_loss: 807.4366\n",
      "Epoch 533/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 687.3410 - val_loss: 812.1693\n",
      "Epoch 534/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 688.3623 - val_loss: 794.8640\n",
      "Epoch 535/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 672.4056 - val_loss: 810.2254\n",
      "Epoch 536/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 669.3682 - val_loss: 796.0105\n",
      "Epoch 537/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 666.1191 - val_loss: 801.7307\n",
      "Epoch 538/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 666.9188 - val_loss: 795.1805\n",
      "Epoch 539/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 661.9070 - val_loss: 790.8363\n",
      "Epoch 540/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 669.8740 - val_loss: 803.7500\n",
      "Epoch 541/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 665.2502 - val_loss: 803.8162\n",
      "Epoch 542/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 677.8715 - val_loss: 805.8877\n",
      "Epoch 543/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 676.6841 - val_loss: 808.2988\n",
      "Epoch 544/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 666.6207 - val_loss: 792.2752\n",
      "Epoch 545/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 661.2523 - val_loss: 815.9503\n",
      "Epoch 546/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 665.6178 - val_loss: 788.2933\n",
      "Epoch 547/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 662.1311 - val_loss: 795.5686\n",
      "Epoch 548/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 662.7691 - val_loss: 798.3683\n",
      "Epoch 549/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 661.7337 - val_loss: 786.2758\n",
      "Epoch 550/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 663.3168 - val_loss: 797.7464\n",
      "Epoch 551/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 663.6807 - val_loss: 803.7561\n",
      "Epoch 552/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 662.0991 - val_loss: 817.6335\n",
      "Epoch 553/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 671.0281 - val_loss: 804.3988\n",
      "Epoch 554/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 669.0977 - val_loss: 791.5000\n",
      "Epoch 555/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 660.9448 - val_loss: 784.6084\n",
      "Epoch 556/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 663.9502 - val_loss: 790.1412\n",
      "Epoch 557/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 662.8637 - val_loss: 798.6491\n",
      "Epoch 558/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 660.9038 - val_loss: 788.8060\n",
      "Epoch 559/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 673.5940 - val_loss: 784.7988\n",
      "Epoch 560/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 656.7158 - val_loss: 797.1717\n",
      "Epoch 561/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 665.9559 - val_loss: 779.2837\n",
      "Epoch 562/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 662.1463 - val_loss: 798.4449\n",
      "Epoch 563/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 654.7315 - val_loss: 786.8693\n",
      "Epoch 564/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 659.6179 - val_loss: 799.7762\n",
      "Epoch 565/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 660.6807 - val_loss: 835.1216\n",
      "Epoch 566/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 665.9241 - val_loss: 780.3210\n",
      "Epoch 567/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 661.3686 - val_loss: 793.5210\n",
      "Epoch 568/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 661.9248 - val_loss: 791.1149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 569/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 665.0148 - val_loss: 786.4942\n",
      "Epoch 570/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 657.0275 - val_loss: 790.0629\n",
      "Epoch 571/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 662.8087 - val_loss: 781.4484\n",
      "Epoch 572/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 667.7343 - val_loss: 780.7538\n",
      "Epoch 573/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 665.7292 - val_loss: 795.3148\n",
      "Epoch 574/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 664.0973 - val_loss: 783.2572\n",
      "Epoch 575/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 655.0657 - val_loss: 775.1507\n",
      "Epoch 576/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 659.6451 - val_loss: 803.6210\n",
      "Epoch 577/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 657.3565 - val_loss: 789.7560\n",
      "Epoch 578/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 654.1990 - val_loss: 781.7672\n",
      "Epoch 579/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 653.4627 - val_loss: 787.5007\n",
      "Epoch 580/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 656.2442 - val_loss: 786.9959\n",
      "Epoch 581/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 657.8422 - val_loss: 791.5958\n",
      "Epoch 582/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 651.7995 - val_loss: 781.8453\n",
      "Epoch 583/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 654.7675 - val_loss: 776.9097\n",
      "Epoch 584/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 652.8255 - val_loss: 774.8841\n",
      "Epoch 585/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 649.1510 - val_loss: 797.4408\n",
      "Epoch 586/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 693.2181 - val_loss: 776.4150\n",
      "Epoch 587/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 660.8492 - val_loss: 788.5069\n",
      "Epoch 588/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 653.8719 - val_loss: 777.6514\n",
      "Epoch 589/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 652.6965 - val_loss: 782.5549\n",
      "Epoch 590/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 646.3623 - val_loss: 777.1798\n",
      "Epoch 591/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 660.3315 - val_loss: 773.4437\n",
      "Epoch 592/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 649.6638 - val_loss: 783.2052\n",
      "Epoch 593/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 658.3638 - val_loss: 773.6701\n",
      "Epoch 594/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 655.3079 - val_loss: 777.3868\n",
      "Epoch 595/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 649.5273 - val_loss: 783.4912\n",
      "Epoch 596/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 642.2580 - val_loss: 777.1365\n",
      "Epoch 597/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 647.7296 - val_loss: 768.2912\n",
      "Epoch 598/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 648.0614 - val_loss: 800.4902\n",
      "Epoch 599/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 643.2375 - val_loss: 776.7297\n",
      "Epoch 600/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 656.4500 - val_loss: 769.2911\n",
      "Epoch 601/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 649.1146 - val_loss: 795.5738\n",
      "Epoch 602/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 659.0947 - val_loss: 771.4271\n",
      "Epoch 603/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 651.7966 - val_loss: 789.0421\n",
      "Epoch 604/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 651.1063 - val_loss: 769.8345\n",
      "Epoch 605/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 650.3798 - val_loss: 776.5013\n",
      "Epoch 606/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 645.7928 - val_loss: 789.7254\n",
      "Epoch 607/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 647.5310 - val_loss: 775.5815\n",
      "Epoch 608/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 649.2608 - val_loss: 763.5419\n",
      "Epoch 609/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 656.4961 - val_loss: 771.7699\n",
      "Epoch 610/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 646.3741 - val_loss: 771.9666\n",
      "Epoch 611/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 647.0822 - val_loss: 770.7447\n",
      "Epoch 612/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 654.5190 - val_loss: 776.7167\n",
      "Epoch 613/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 653.9132 - val_loss: 772.7298\n",
      "Epoch 614/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 660.5097 - val_loss: 819.1273\n",
      "Epoch 615/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 643.6615 - val_loss: 766.6069\n",
      "Epoch 616/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 647.7850 - val_loss: 775.1999\n",
      "Epoch 617/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 654.3711 - val_loss: 771.7831\n",
      "Epoch 618/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 642.7678 - val_loss: 762.4693\n",
      "Epoch 619/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 643.1473 - val_loss: 785.9565\n",
      "Epoch 620/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 652.2410 - val_loss: 778.6015\n",
      "Epoch 621/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 643.4352 - val_loss: 764.7401\n",
      "Epoch 622/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 647.4727 - val_loss: 764.0047\n",
      "Epoch 623/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 638.9989 - val_loss: 779.5442\n",
      "Epoch 624/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 643.9975 - val_loss: 778.2749\n",
      "Epoch 625/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 644.1185 - val_loss: 763.3762\n",
      "Epoch 626/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 640.3441 - val_loss: 774.0078\n",
      "Epoch 627/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 641.7305 - val_loss: 778.2781\n",
      "Epoch 628/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 643.5775 - val_loss: 764.5234\n",
      "Epoch 629/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 644.0665 - val_loss: 791.6265\n",
      "Epoch 630/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 646.7241 - val_loss: 780.0452\n",
      "Epoch 631/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 656.0552 - val_loss: 782.4984\n",
      "Epoch 632/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 640.1241 - val_loss: 764.6579\n",
      "Epoch 633/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 642.0957 - val_loss: 768.8611\n",
      "Epoch 634/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 644.8164 - val_loss: 764.4926\n",
      "Epoch 635/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 640.3652 - val_loss: 760.0266\n",
      "Epoch 636/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 638.1478 - val_loss: 761.6941\n",
      "Epoch 637/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 637.8433 - val_loss: 767.9244\n",
      "Epoch 638/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 639.1555 - val_loss: 767.1171\n",
      "Epoch 639/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 645.1859 - val_loss: 761.3020\n",
      "Epoch 640/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 639.5861 - val_loss: 756.4126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 641/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 637.4696 - val_loss: 761.0838\n",
      "Epoch 642/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 640.8668 - val_loss: 760.1253\n",
      "Epoch 643/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 648.3694 - val_loss: 771.0679\n",
      "Epoch 644/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 638.7521 - val_loss: 766.7007\n",
      "Epoch 645/10000\n",
      "3000/3000 [==============================] - 0s 14us/sample - loss: 635.5671 - val_loss: 751.3173\n",
      "Epoch 646/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 640.0476 - val_loss: 754.3145\n",
      "Epoch 647/10000\n",
      "3000/3000 [==============================] - 0s 14us/sample - loss: 633.9855 - val_loss: 753.5900\n",
      "Epoch 648/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 644.4319 - val_loss: 775.1595\n",
      "Epoch 649/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 645.5773 - val_loss: 762.9742\n",
      "Epoch 650/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 636.7305 - val_loss: 756.1825\n",
      "Epoch 651/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 635.8489 - val_loss: 759.4688\n",
      "Epoch 652/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 636.1099 - val_loss: 763.1700\n",
      "Epoch 653/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 641.7380 - val_loss: 754.7529\n",
      "Epoch 654/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 640.3073 - val_loss: 763.8403\n",
      "Epoch 655/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 638.8419 - val_loss: 752.1344\n",
      "Epoch 656/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 638.3578 - val_loss: 756.8550\n",
      "Epoch 657/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 635.8436 - val_loss: 751.5124\n",
      "Epoch 658/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 644.4248 - val_loss: 750.6621\n",
      "Epoch 659/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 634.3718 - val_loss: 757.2286\n",
      "Epoch 660/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 635.6037 - val_loss: 759.6885\n",
      "Epoch 661/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 634.4171 - val_loss: 750.3393\n",
      "Epoch 662/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 644.2172 - val_loss: 773.5324\n",
      "Epoch 663/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 639.5587 - val_loss: 758.7013\n",
      "Epoch 664/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 632.8139 - val_loss: 755.2752\n",
      "Epoch 665/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 645.8077 - val_loss: 760.4568\n",
      "Epoch 666/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 643.3679 - val_loss: 754.8683\n",
      "Epoch 667/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 635.2187 - val_loss: 758.3816\n",
      "Epoch 668/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 627.6416 - val_loss: 755.5067\n",
      "Epoch 669/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 636.4011 - val_loss: 748.3924\n",
      "Epoch 670/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 628.9447 - val_loss: 757.7154\n",
      "Epoch 671/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 632.5678 - val_loss: 745.4115\n",
      "Epoch 672/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 627.6887 - val_loss: 751.5921\n",
      "Epoch 673/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 633.9812 - val_loss: 750.4099\n",
      "Epoch 674/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 635.1114 - val_loss: 779.4107\n",
      "Epoch 675/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 633.8726 - val_loss: 758.3740\n",
      "Epoch 676/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 630.0788 - val_loss: 760.7127\n",
      "Epoch 677/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 629.7901 - val_loss: 753.4273\n",
      "Epoch 678/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 630.4908 - val_loss: 744.7994\n",
      "Epoch 679/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 628.4541 - val_loss: 750.4815\n",
      "Epoch 680/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 626.0058 - val_loss: 747.4673\n",
      "Epoch 681/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 634.2778 - val_loss: 753.9230\n",
      "Epoch 682/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 633.2058 - val_loss: 750.7970\n",
      "Epoch 683/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 632.2107 - val_loss: 753.7867\n",
      "Epoch 684/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 629.1462 - val_loss: 748.4668\n",
      "Epoch 685/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 632.9862 - val_loss: 755.4525\n",
      "Epoch 686/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 631.6706 - val_loss: 743.6623\n",
      "Epoch 687/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 636.2844 - val_loss: 742.5409\n",
      "Epoch 688/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 636.7238 - val_loss: 757.7522\n",
      "Epoch 689/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 639.0259 - val_loss: 764.2031\n",
      "Epoch 690/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 638.6103 - val_loss: 748.7584\n",
      "Epoch 691/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 640.2583 - val_loss: 749.9531\n",
      "Epoch 692/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 640.3626 - val_loss: 754.2956\n",
      "Epoch 693/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 624.3566 - val_loss: 746.2701\n",
      "Epoch 694/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 634.0834 - val_loss: 745.0666\n",
      "Epoch 695/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 626.2392 - val_loss: 745.8336\n",
      "Epoch 696/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 626.3454 - val_loss: 753.3001\n",
      "Epoch 697/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 629.7330 - val_loss: 746.1336\n",
      "Epoch 698/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 629.0629 - val_loss: 751.3347\n",
      "Epoch 699/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 634.0071 - val_loss: 751.8371\n",
      "Epoch 700/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 630.4242 - val_loss: 756.2410\n",
      "Epoch 701/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 632.2567 - val_loss: 756.5175\n",
      "Epoch 702/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 631.5720 - val_loss: 746.7957\n",
      "Epoch 703/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 625.5387 - val_loss: 747.7961\n",
      "Epoch 704/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 623.5866 - val_loss: 738.1237\n",
      "Epoch 705/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 625.1581 - val_loss: 747.6050\n",
      "Epoch 706/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 630.1805 - val_loss: 742.2834\n",
      "Epoch 707/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 624.1941 - val_loss: 738.6140\n",
      "Epoch 708/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 629.7079 - val_loss: 740.6593\n",
      "Epoch 709/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 622.4148 - val_loss: 747.2503\n",
      "Epoch 710/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 625.2688 - val_loss: 738.1765\n",
      "Epoch 711/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 627.9290 - val_loss: 743.8135\n",
      "Epoch 712/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 626.8452 - val_loss: 739.4012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 713/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 632.9599 - val_loss: 750.9394\n",
      "Epoch 714/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 631.6194 - val_loss: 745.6483\n",
      "Epoch 715/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 620.5290 - val_loss: 745.4014\n",
      "Epoch 716/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 623.8687 - val_loss: 748.5949\n",
      "Epoch 717/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 624.0904 - val_loss: 743.3701\n",
      "Epoch 718/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 619.9231 - val_loss: 760.5137\n",
      "Epoch 719/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 633.7044 - val_loss: 752.5964\n",
      "Epoch 720/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 622.4823 - val_loss: 731.5017\n",
      "Epoch 721/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 636.9534 - val_loss: 749.7675\n",
      "Epoch 722/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 629.3688 - val_loss: 739.1377\n",
      "Epoch 723/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 626.8746 - val_loss: 736.8885\n",
      "Epoch 724/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 629.9445 - val_loss: 751.2229\n",
      "Epoch 725/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 632.9946 - val_loss: 767.2993\n",
      "Epoch 726/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 625.1697 - val_loss: 733.1850\n",
      "Epoch 727/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 624.2205 - val_loss: 756.4306\n",
      "Epoch 728/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 625.3727 - val_loss: 736.8785\n",
      "Epoch 729/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 623.5920 - val_loss: 736.5670\n",
      "Epoch 730/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 617.8353 - val_loss: 732.1577\n",
      "Epoch 731/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 626.3247 - val_loss: 743.0285\n",
      "Epoch 732/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 628.1280 - val_loss: 739.9409\n",
      "Epoch 733/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 624.0597 - val_loss: 736.4488\n",
      "Epoch 734/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 618.1042 - val_loss: 736.1169\n",
      "Epoch 735/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 617.2534 - val_loss: 742.4148\n",
      "Epoch 736/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 621.3077 - val_loss: 743.3086\n",
      "Epoch 737/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 619.1520 - val_loss: 727.4707\n",
      "Epoch 738/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 619.5591 - val_loss: 731.0007\n",
      "Epoch 739/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 621.2900 - val_loss: 739.0769\n",
      "Epoch 740/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 619.5110 - val_loss: 738.4429\n",
      "Epoch 741/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 629.4326 - val_loss: 739.9223\n",
      "Epoch 742/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 630.8671 - val_loss: 754.8504\n",
      "Epoch 743/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 627.3122 - val_loss: 735.4901\n",
      "Epoch 744/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 619.1490 - val_loss: 736.3736\n",
      "Epoch 745/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 615.3893 - val_loss: 733.9395\n",
      "Epoch 746/10000\n",
      "3000/3000 [==============================] - 0s 25us/sample - loss: 617.4380 - val_loss: 733.0855\n",
      "Epoch 747/10000\n",
      "3000/3000 [==============================] - 0s 14us/sample - loss: 618.8387 - val_loss: 737.1908\n",
      "Epoch 748/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 617.4874 - val_loss: 733.8149\n",
      "Epoch 749/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 618.0428 - val_loss: 727.9249\n",
      "Epoch 750/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 801.2530Epoch: 750 - loss: 615.370771 - val_loss: 730.190104\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 615.3708 - val_loss: 730.1901\n",
      "Epoch 751/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 614.1769 - val_loss: 730.4813\n",
      "Epoch 752/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 613.8391 - val_loss: 727.5578\n",
      "Epoch 753/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 613.7962 - val_loss: 738.7695\n",
      "Epoch 754/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 618.0673 - val_loss: 734.7943\n",
      "Epoch 755/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 617.5317 - val_loss: 732.9137\n",
      "Epoch 756/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 621.6938 - val_loss: 735.8107\n",
      "Epoch 757/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 622.7705 - val_loss: 732.3934\n",
      "Epoch 758/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 620.1091 - val_loss: 742.7695\n",
      "Epoch 759/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 617.6369 - val_loss: 725.8325\n",
      "Epoch 760/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 614.9832 - val_loss: 729.1354\n",
      "Epoch 761/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 617.5295 - val_loss: 724.3718\n",
      "Epoch 762/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 613.5844 - val_loss: 742.7587\n",
      "Epoch 763/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 614.6537 - val_loss: 725.7598\n",
      "Epoch 764/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 619.2701 - val_loss: 734.5314\n",
      "Epoch 765/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 621.6033 - val_loss: 725.5112\n",
      "Epoch 766/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 617.6881 - val_loss: 728.3203\n",
      "Epoch 767/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 615.9312 - val_loss: 730.8042\n",
      "Epoch 768/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 618.6912 - val_loss: 723.9821\n",
      "Epoch 769/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 618.0548 - val_loss: 728.0773\n",
      "Epoch 770/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 613.1090 - val_loss: 760.9916\n",
      "Epoch 771/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 629.5854 - val_loss: 728.6480\n",
      "Epoch 772/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 618.3987 - val_loss: 728.3853\n",
      "Epoch 773/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 613.4332 - val_loss: 737.7552\n",
      "Epoch 774/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 611.2872 - val_loss: 724.0878\n",
      "Epoch 775/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 614.7410 - val_loss: 749.2962\n",
      "Epoch 776/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 610.9862 - val_loss: 719.4281\n",
      "Epoch 777/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 611.9777 - val_loss: 724.8161\n",
      "Epoch 778/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 609.1185 - val_loss: 722.2155\n",
      "Epoch 779/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 611.6631 - val_loss: 722.7001\n",
      "Epoch 780/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 610.4655 - val_loss: 728.8687\n",
      "Epoch 781/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 615.2038 - val_loss: 738.6236\n",
      "Epoch 782/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 611.8001 - val_loss: 722.5393\n",
      "Epoch 783/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 617.3338 - val_loss: 723.4564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 784/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 612.8486 - val_loss: 727.2642\n",
      "Epoch 785/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 612.8325 - val_loss: 731.0340\n",
      "Epoch 786/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 614.5857 - val_loss: 728.4842\n",
      "Epoch 787/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 609.7609 - val_loss: 727.2920\n",
      "Epoch 788/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 613.2579 - val_loss: 726.2125\n",
      "Epoch 789/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 613.1851 - val_loss: 728.1683\n",
      "Epoch 790/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 614.7171 - val_loss: 725.3654\n",
      "Epoch 791/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 610.0393 - val_loss: 718.8694\n",
      "Epoch 792/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 613.1454 - val_loss: 722.2650\n",
      "Epoch 793/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 606.7874 - val_loss: 724.4896\n",
      "Epoch 794/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 612.4986 - val_loss: 724.1398\n",
      "Epoch 795/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 609.1754 - val_loss: 722.9238\n",
      "Epoch 796/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 611.2015 - val_loss: 721.6947\n",
      "Epoch 797/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 611.1364 - val_loss: 722.5124\n",
      "Epoch 798/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 608.6831 - val_loss: 729.7945\n",
      "Epoch 799/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 607.9250 - val_loss: 720.1338\n",
      "Epoch 800/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 609.4373 - val_loss: 718.3808\n",
      "Epoch 801/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 612.7537 - val_loss: 720.3028\n",
      "Epoch 802/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 619.5111 - val_loss: 720.1070\n",
      "Epoch 803/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 606.5967 - val_loss: 730.4658\n",
      "Epoch 804/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 608.5244 - val_loss: 717.8917\n",
      "Epoch 805/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 613.2737 - val_loss: 725.9854\n",
      "Epoch 806/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 610.4521 - val_loss: 735.6992\n",
      "Epoch 807/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 607.0352 - val_loss: 721.7736\n",
      "Epoch 808/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 606.2902 - val_loss: 725.8376\n",
      "Epoch 809/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 606.2630 - val_loss: 716.9014\n",
      "Epoch 810/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 610.4615 - val_loss: 728.9217\n",
      "Epoch 811/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 613.9564 - val_loss: 716.8850\n",
      "Epoch 812/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 608.2515 - val_loss: 714.6258\n",
      "Epoch 813/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 612.9505 - val_loss: 728.3424\n",
      "Epoch 814/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 614.3681 - val_loss: 727.6489\n",
      "Epoch 815/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 608.9970 - val_loss: 725.8173\n",
      "Epoch 816/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 612.2196 - val_loss: 728.8238\n",
      "Epoch 817/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 613.8400 - val_loss: 715.1684\n",
      "Epoch 818/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 607.0774 - val_loss: 734.5941\n",
      "Epoch 819/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 615.4533 - val_loss: 717.6176\n",
      "Epoch 820/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 613.6089 - val_loss: 720.9676\n",
      "Epoch 821/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 611.3535 - val_loss: 720.6532\n",
      "Epoch 822/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 604.4751 - val_loss: 722.3256\n",
      "Epoch 823/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 602.4699 - val_loss: 709.8296\n",
      "Epoch 824/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 603.8605 - val_loss: 719.6186\n",
      "Epoch 825/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 607.0949 - val_loss: 735.3883\n",
      "Epoch 826/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 602.1563 - val_loss: 712.1754\n",
      "Epoch 827/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 610.0061 - val_loss: 720.5619\n",
      "Epoch 828/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 604.5780 - val_loss: 717.8416\n",
      "Epoch 829/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 601.1185 - val_loss: 713.0101\n",
      "Epoch 830/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 606.7711 - val_loss: 718.2538\n",
      "Epoch 831/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 609.5998 - val_loss: 712.7080\n",
      "Epoch 832/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 608.9227 - val_loss: 714.8653\n",
      "Epoch 833/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 602.2820 - val_loss: 715.1618\n",
      "Epoch 834/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 603.8484 - val_loss: 717.8326\n",
      "Epoch 835/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 607.6049 - val_loss: 713.8838\n",
      "Epoch 836/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 611.9798 - val_loss: 725.6321\n",
      "Epoch 837/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 617.3436 - val_loss: 724.6101\n",
      "Epoch 838/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 605.3452 - val_loss: 716.1204\n",
      "Epoch 839/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 607.7099 - val_loss: 713.0818\n",
      "Epoch 840/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 605.8550 - val_loss: 715.8542\n",
      "Epoch 841/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 606.5127 - val_loss: 719.3548\n",
      "Epoch 842/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 602.2538 - val_loss: 717.9964\n",
      "Epoch 843/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 603.9209 - val_loss: 719.0772\n",
      "Epoch 844/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 608.3714 - val_loss: 710.0971\n",
      "Epoch 845/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 599.4524 - val_loss: 716.2716\n",
      "Epoch 846/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 602.9563 - val_loss: 707.9095\n",
      "Epoch 847/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 601.0008 - val_loss: 710.0657\n",
      "Epoch 848/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 604.0577 - val_loss: 729.7391\n",
      "Epoch 849/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 602.8017 - val_loss: 710.1241\n",
      "Epoch 850/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 601.6701 - val_loss: 733.0307\n",
      "Epoch 851/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 602.6764 - val_loss: 708.5084\n",
      "Epoch 852/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 604.2704 - val_loss: 712.7724\n",
      "Epoch 853/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 605.5090 - val_loss: 709.9261\n",
      "Epoch 854/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 607.9546 - val_loss: 706.8900\n",
      "Epoch 855/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 602.0857 - val_loss: 717.6188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 598.7361 - val_loss: 707.6242\n",
      "Epoch 857/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 601.0454 - val_loss: 714.7150\n",
      "Epoch 858/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 603.6320 - val_loss: 707.5677\n",
      "Epoch 859/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 597.4687 - val_loss: 709.9163\n",
      "Epoch 860/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 604.4197 - val_loss: 711.0475\n",
      "Epoch 861/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 597.7833 - val_loss: 713.4670\n",
      "Epoch 862/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 599.0798 - val_loss: 724.0584\n",
      "Epoch 863/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 602.7726 - val_loss: 712.8157\n",
      "Epoch 864/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 599.5966 - val_loss: 717.2176\n",
      "Epoch 865/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 599.6509 - val_loss: 715.9670\n",
      "Epoch 866/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 605.4226 - val_loss: 720.7147\n",
      "Epoch 867/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 601.2043 - val_loss: 705.9474\n",
      "Epoch 868/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 599.5366 - val_loss: 717.3259\n",
      "Epoch 869/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 602.1185 - val_loss: 709.8532\n",
      "Epoch 870/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 597.9718 - val_loss: 712.0110\n",
      "Epoch 871/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 602.5262 - val_loss: 719.2096\n",
      "Epoch 872/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 598.5339 - val_loss: 702.8368\n",
      "Epoch 873/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 597.6959 - val_loss: 710.6339\n",
      "Epoch 874/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 600.0653 - val_loss: 711.1764\n",
      "Epoch 875/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 598.4550 - val_loss: 709.9596\n",
      "Epoch 876/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 597.1769 - val_loss: 704.7058\n",
      "Epoch 877/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 599.1939 - val_loss: 708.4392\n",
      "Epoch 878/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 603.7493 - val_loss: 708.5340\n",
      "Epoch 879/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 599.4359 - val_loss: 709.2453\n",
      "Epoch 880/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 596.5506 - val_loss: 707.4354\n",
      "Epoch 881/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 599.6161 - val_loss: 710.6058\n",
      "Epoch 882/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 597.2573 - val_loss: 708.0265\n",
      "Epoch 883/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 605.2359 - val_loss: 724.8545\n",
      "Epoch 884/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 604.6729 - val_loss: 711.6483\n",
      "Epoch 885/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 598.6579 - val_loss: 715.5087\n",
      "Epoch 886/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 603.0391 - val_loss: 705.7188\n",
      "Epoch 887/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 597.0266 - val_loss: 702.5738\n",
      "Epoch 888/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 605.2244 - val_loss: 706.4931\n",
      "Epoch 889/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 597.0584 - val_loss: 706.8055\n",
      "Epoch 890/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 597.8140 - val_loss: 711.5487\n",
      "Epoch 891/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 597.6745 - val_loss: 707.5385\n",
      "Epoch 892/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 599.5606 - val_loss: 704.8987\n",
      "Epoch 893/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 597.3551 - val_loss: 703.1570\n",
      "Epoch 894/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 597.1946 - val_loss: 706.7589\n",
      "Epoch 895/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 593.6035 - val_loss: 707.6030\n",
      "Epoch 896/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 597.8373 - val_loss: 701.2610\n",
      "Epoch 897/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 594.4647 - val_loss: 710.6147\n",
      "Epoch 898/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 598.2589 - val_loss: 710.4632\n",
      "Epoch 899/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 594.9053 - val_loss: 711.2162\n",
      "Epoch 900/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 603.7437 - val_loss: 714.0762\n",
      "Epoch 901/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 595.4878 - val_loss: 707.2887\n",
      "Epoch 902/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 595.2049 - val_loss: 701.7611\n",
      "Epoch 903/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 599.0708 - val_loss: 701.9759\n",
      "Epoch 904/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 601.6275 - val_loss: 727.1159\n",
      "Epoch 905/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 598.1456 - val_loss: 700.2034\n",
      "Epoch 906/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 601.8660 - val_loss: 706.1642\n",
      "Epoch 907/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 595.8595 - val_loss: 701.1547\n",
      "Epoch 908/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 592.4212 - val_loss: 701.5208\n",
      "Epoch 909/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 597.1543 - val_loss: 703.0295\n",
      "Epoch 910/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 599.2923 - val_loss: 707.2260\n",
      "Epoch 911/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 593.8702 - val_loss: 700.3482\n",
      "Epoch 912/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 599.1179 - val_loss: 700.4184\n",
      "Epoch 913/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 595.7841 - val_loss: 704.5937\n",
      "Epoch 914/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 606.3154 - val_loss: 720.2304\n",
      "Epoch 915/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 606.9436 - val_loss: 712.5723\n",
      "Epoch 916/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 593.3015 - val_loss: 703.3210\n",
      "Epoch 917/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 591.2962 - val_loss: 712.7950\n",
      "Epoch 918/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 596.5977 - val_loss: 710.1412\n",
      "Epoch 919/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 604.1423 - val_loss: 702.9057\n",
      "Epoch 920/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 591.9268 - val_loss: 704.5682\n",
      "Epoch 921/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 593.1401 - val_loss: 697.2164\n",
      "Epoch 922/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 593.8081 - val_loss: 701.1314\n",
      "Epoch 923/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 595.0882 - val_loss: 699.9621\n",
      "Epoch 924/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 594.2508 - val_loss: 711.0443\n",
      "Epoch 925/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 597.0676 - val_loss: 702.3519\n",
      "Epoch 926/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 593.8039 - val_loss: 694.9806\n",
      "Epoch 927/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 590.3724 - val_loss: 697.1002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 928/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 590.2503 - val_loss: 699.9388\n",
      "Epoch 929/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 594.0766 - val_loss: 701.1169\n",
      "Epoch 930/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 593.0179 - val_loss: 698.9574\n",
      "Epoch 931/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 593.1797 - val_loss: 704.7691\n",
      "Epoch 932/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 591.9232 - val_loss: 697.6724\n",
      "Epoch 933/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 589.4326 - val_loss: 708.8771\n",
      "Epoch 934/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 595.0168 - val_loss: 698.4808\n",
      "Epoch 935/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 589.0323 - val_loss: 700.0618\n",
      "Epoch 936/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 593.4579 - val_loss: 695.1283\n",
      "Epoch 937/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 594.0116 - val_loss: 694.3897\n",
      "Epoch 938/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 596.4820 - val_loss: 705.7261\n",
      "Epoch 939/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 591.7153 - val_loss: 705.3801\n",
      "Epoch 940/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 597.2152 - val_loss: 702.7363\n",
      "Epoch 941/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 589.3884 - val_loss: 693.8066\n",
      "Epoch 942/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 591.5299 - val_loss: 693.7837\n",
      "Epoch 943/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 589.9677 - val_loss: 699.0796\n",
      "Epoch 944/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 589.8516 - val_loss: 696.3064\n",
      "Epoch 945/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 590.0467 - val_loss: 706.7537\n",
      "Epoch 946/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 593.9142 - val_loss: 697.5306\n",
      "Epoch 947/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 589.7304 - val_loss: 706.3115\n",
      "Epoch 948/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 589.0991 - val_loss: 690.1551\n",
      "Epoch 949/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 599.2246 - val_loss: 719.4014\n",
      "Epoch 950/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 605.7995 - val_loss: 696.5812\n",
      "Epoch 951/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 590.4763 - val_loss: 704.9257\n",
      "Epoch 952/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 591.4683 - val_loss: 704.3359\n",
      "Epoch 953/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 590.9763 - val_loss: 718.2779\n",
      "Epoch 954/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 593.5554 - val_loss: 698.4801\n",
      "Epoch 955/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 591.5847 - val_loss: 702.8661\n",
      "Epoch 956/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 590.9928 - val_loss: 693.0142\n",
      "Epoch 957/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 588.3960 - val_loss: 696.8787\n",
      "Epoch 958/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 589.3630 - val_loss: 696.2844\n",
      "Epoch 959/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 592.9280 - val_loss: 702.1495\n",
      "Epoch 960/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 586.3139 - val_loss: 692.0377\n",
      "Epoch 961/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 585.1306 - val_loss: 708.8706\n",
      "Epoch 962/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 595.4024 - val_loss: 701.8610\n",
      "Epoch 963/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 589.4916 - val_loss: 694.8802\n",
      "Epoch 964/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 595.7727 - val_loss: 700.4830\n",
      "Epoch 965/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 589.1572 - val_loss: 692.3449\n",
      "Epoch 966/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 586.7277 - val_loss: 695.5425\n",
      "Epoch 967/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 591.3560 - val_loss: 707.8325\n",
      "Epoch 968/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 600.9800 - val_loss: 696.6504\n",
      "Epoch 969/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 588.2329 - val_loss: 688.5947\n",
      "Epoch 970/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 595.7547 - val_loss: 705.4841\n",
      "Epoch 971/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 589.3808 - val_loss: 695.4850\n",
      "Epoch 972/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 596.8491 - val_loss: 693.4174\n",
      "Epoch 973/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 590.6732 - val_loss: 698.2298\n",
      "Epoch 974/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 590.2051 - val_loss: 693.5280\n",
      "Epoch 975/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 590.7668 - val_loss: 692.5672\n",
      "Epoch 976/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 586.5497 - val_loss: 700.7042\n",
      "Epoch 977/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 589.8498 - val_loss: 690.8306\n",
      "Epoch 978/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 586.0107 - val_loss: 691.3677\n",
      "Epoch 979/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 588.1057 - val_loss: 689.8701\n",
      "Epoch 980/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 585.4450 - val_loss: 696.5653\n",
      "Epoch 981/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 586.6936 - val_loss: 695.8654\n",
      "Epoch 982/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 589.4937 - val_loss: 690.9009\n",
      "Epoch 983/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 586.4187 - val_loss: 695.1274\n",
      "Epoch 984/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 587.4158 - val_loss: 691.1888\n",
      "Epoch 985/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 586.6523 - val_loss: 692.3138\n",
      "Epoch 986/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 590.2264 - val_loss: 705.2373\n",
      "Epoch 987/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 591.8383 - val_loss: 695.2370\n",
      "Epoch 988/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 589.3631 - val_loss: 702.5398\n",
      "Epoch 989/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 598.0224 - val_loss: 690.2148\n",
      "Epoch 990/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 594.3005 - val_loss: 703.1577\n",
      "Epoch 991/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 587.2674 - val_loss: 686.8658\n",
      "Epoch 992/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 589.4669 - val_loss: 686.8891\n",
      "Epoch 993/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 586.4075 - val_loss: 694.1816\n",
      "Epoch 994/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 591.2083 - val_loss: 697.3417\n",
      "Epoch 995/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 586.5508 - val_loss: 691.6474\n",
      "Epoch 996/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 583.6628 - val_loss: 687.8718\n",
      "Epoch 997/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 586.8236 - val_loss: 690.2201\n",
      "Epoch 998/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 591.3907 - val_loss: 693.9844\n",
      "Epoch 999/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 589.0827 - val_loss: 707.2243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 584.6235Epoch: 1000 - loss: 588.704569 - val_loss: 689.375140\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 588.7046 - val_loss: 689.3751\n",
      "Epoch 1001/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 584.5789 - val_loss: 695.0661\n",
      "Epoch 1002/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 582.6321 - val_loss: 691.3724\n",
      "Epoch 1003/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 587.3496 - val_loss: 690.4989\n",
      "Epoch 1004/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 583.8842 - val_loss: 692.5926\n",
      "Epoch 1005/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 590.5301 - val_loss: 697.1402\n",
      "Epoch 1006/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 593.7893 - val_loss: 695.5481\n",
      "Epoch 1007/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 584.3724 - val_loss: 690.1779\n",
      "Epoch 1008/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 582.0929 - val_loss: 689.3522\n",
      "Epoch 1009/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 584.6821 - val_loss: 697.1925\n",
      "Epoch 1010/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 584.2310 - val_loss: 694.6181\n",
      "Epoch 1011/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 582.2878 - val_loss: 690.6204\n",
      "Epoch 1012/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 583.1953 - val_loss: 689.5340\n",
      "Epoch 1013/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 584.3423 - val_loss: 692.4277\n",
      "Epoch 1014/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 585.9060 - val_loss: 684.6582\n",
      "Epoch 1015/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 585.1930 - val_loss: 687.4497\n",
      "Epoch 1016/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 592.5429 - val_loss: 692.0411\n",
      "Epoch 1017/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 583.1424 - val_loss: 686.6133\n",
      "Epoch 1018/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 586.2575 - val_loss: 689.2751\n",
      "Epoch 1019/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 581.3167 - val_loss: 687.1302\n",
      "Epoch 1020/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 580.1683 - val_loss: 687.5392\n",
      "Epoch 1021/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 586.2798 - val_loss: 694.8584\n",
      "Epoch 1022/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 582.5063 - val_loss: 684.3900\n",
      "Epoch 1023/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 581.1253 - val_loss: 682.9666\n",
      "Epoch 1024/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 579.3410 - val_loss: 686.8004\n",
      "Epoch 1025/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 579.6204 - val_loss: 683.4689\n",
      "Epoch 1026/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 585.3951 - val_loss: 694.3283\n",
      "Epoch 1027/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 583.4483 - val_loss: 685.7868\n",
      "Epoch 1028/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 584.6694 - val_loss: 684.5311\n",
      "Epoch 1029/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 580.5964 - val_loss: 687.9331\n",
      "Epoch 1030/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 581.2753 - val_loss: 689.0580\n",
      "Epoch 1031/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 578.6017 - val_loss: 683.7012\n",
      "Epoch 1032/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 580.2873 - val_loss: 696.6063\n",
      "Epoch 1033/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 583.8853 - val_loss: 685.5570\n",
      "Epoch 1034/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 581.0856 - val_loss: 688.7728\n",
      "Epoch 1035/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 585.2323 - val_loss: 687.2651\n",
      "Epoch 1036/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 581.4412 - val_loss: 697.1300\n",
      "Epoch 1037/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 588.1215 - val_loss: 688.5230\n",
      "Epoch 1038/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 580.7947 - val_loss: 692.2281\n",
      "Epoch 1039/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 583.0913 - val_loss: 682.7816\n",
      "Epoch 1040/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 580.9667 - val_loss: 682.7536\n",
      "Epoch 1041/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 579.7256 - val_loss: 686.3044\n",
      "Epoch 1042/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 584.2327 - val_loss: 685.5021\n",
      "Epoch 1043/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 597.0308 - val_loss: 691.4205\n",
      "Epoch 1044/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 583.7324 - val_loss: 684.1273\n",
      "Epoch 1045/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 581.8011 - val_loss: 683.8145\n",
      "Epoch 1046/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 581.2444 - val_loss: 685.3246\n",
      "Epoch 1047/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 583.1590 - val_loss: 682.4952\n",
      "Epoch 1048/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 581.4147 - val_loss: 682.3243\n",
      "Epoch 1049/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 578.0361 - val_loss: 688.7430\n",
      "Epoch 1050/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 584.0828 - val_loss: 684.1701\n",
      "Epoch 1051/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 587.0551 - val_loss: 694.2981\n",
      "Epoch 1052/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 583.3193 - val_loss: 681.0880\n",
      "Epoch 1053/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 581.4796 - val_loss: 684.4159\n",
      "Epoch 1054/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 580.4048 - val_loss: 686.7160\n",
      "Epoch 1055/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 578.3132 - val_loss: 695.9588\n",
      "Epoch 1056/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 578.7563 - val_loss: 680.5154\n",
      "Epoch 1057/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 590.3661 - val_loss: 688.4569\n",
      "Epoch 1058/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 581.5568 - val_loss: 689.5358\n",
      "Epoch 1059/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 580.9919 - val_loss: 689.7997\n",
      "Epoch 1060/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 582.6332 - val_loss: 682.4723\n",
      "Epoch 1061/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 585.1533 - val_loss: 682.1411\n",
      "Epoch 1062/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 585.1961 - val_loss: 686.0917\n",
      "Epoch 1063/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 581.0225 - val_loss: 682.5135\n",
      "Epoch 1064/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 576.3530 - val_loss: 684.6631\n",
      "Epoch 1065/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 580.1752 - val_loss: 691.7633\n",
      "Epoch 1066/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 583.1694 - val_loss: 683.6884\n",
      "Epoch 1067/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 584.7920 - val_loss: 681.6696\n",
      "Epoch 1068/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 577.1928 - val_loss: 686.4748\n",
      "Epoch 1069/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 577.8405 - val_loss: 682.5276\n",
      "Epoch 1070/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 577.8087 - val_loss: 680.2622\n",
      "Epoch 1071/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 575.8275 - val_loss: 680.5427\n",
      "Epoch 1072/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 580.4556 - val_loss: 684.3561\n",
      "Epoch 1073/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 581.6911 - val_loss: 679.3997\n",
      "Epoch 1074/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 576.1038 - val_loss: 682.4652\n",
      "Epoch 1075/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 578.6024 - val_loss: 685.8203\n",
      "Epoch 1076/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 578.0068 - val_loss: 681.6432\n",
      "Epoch 1077/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 577.2418 - val_loss: 683.8303\n",
      "Epoch 1078/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 575.6577 - val_loss: 682.6880\n",
      "Epoch 1079/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 576.2983 - val_loss: 680.0460\n",
      "Epoch 1080/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 578.9869 - val_loss: 684.2533\n",
      "Epoch 1081/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 578.7995 - val_loss: 683.1993\n",
      "Epoch 1082/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 575.4713 - val_loss: 686.4993\n",
      "Epoch 1083/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 582.8163 - val_loss: 682.5443\n",
      "Epoch 1084/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 576.5360 - val_loss: 682.9306\n",
      "Epoch 1085/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 576.0200 - val_loss: 685.8623\n",
      "Epoch 1086/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 576.8510 - val_loss: 688.2387\n",
      "Epoch 1087/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 576.8010 - val_loss: 681.1353\n",
      "Epoch 1088/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 583.6453 - val_loss: 688.9984\n",
      "Epoch 1089/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 580.2504 - val_loss: 683.7023\n",
      "Epoch 1090/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 576.7474 - val_loss: 678.9084\n",
      "Epoch 1091/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 575.2605 - val_loss: 682.0000\n",
      "Epoch 1092/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 577.2610 - val_loss: 679.1356\n",
      "Epoch 1093/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 577.2329 - val_loss: 679.6263\n",
      "Epoch 1094/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 578.4748 - val_loss: 684.9009\n",
      "Epoch 1095/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 581.5466 - val_loss: 681.1440\n",
      "Epoch 1096/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 575.7900 - val_loss: 680.4511\n",
      "Epoch 1097/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 572.4425 - val_loss: 676.9265\n",
      "Epoch 1098/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 575.1029 - val_loss: 682.3430\n",
      "Epoch 1099/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 576.3803 - val_loss: 681.1541\n",
      "Epoch 1100/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 576.3218 - val_loss: 679.9360\n",
      "Epoch 1101/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 579.8444 - val_loss: 677.9679\n",
      "Epoch 1102/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 579.6668 - val_loss: 677.1899\n",
      "Epoch 1103/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 576.0042 - val_loss: 678.9254\n",
      "Epoch 1104/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 576.5220 - val_loss: 684.4886\n",
      "Epoch 1105/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 578.0730 - val_loss: 687.4141\n",
      "Epoch 1106/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 576.1292 - val_loss: 672.5608\n",
      "Epoch 1107/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 588.1400 - val_loss: 683.3287\n",
      "Epoch 1108/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 582.7777 - val_loss: 677.4941\n",
      "Epoch 1109/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 589.4474 - val_loss: 686.3919\n",
      "Epoch 1110/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 578.4658 - val_loss: 684.3627\n",
      "Epoch 1111/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 575.8925 - val_loss: 672.6813\n",
      "Epoch 1112/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 575.4751 - val_loss: 681.0606\n",
      "Epoch 1113/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 573.7273 - val_loss: 688.4349\n",
      "Epoch 1114/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 573.9888 - val_loss: 683.0231\n",
      "Epoch 1115/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 574.9629 - val_loss: 680.4194\n",
      "Epoch 1116/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 573.9071 - val_loss: 676.5331\n",
      "Epoch 1117/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 576.4066 - val_loss: 680.7013\n",
      "Epoch 1118/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 575.9634 - val_loss: 679.5998\n",
      "Epoch 1119/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 579.2721 - val_loss: 687.1186\n",
      "Epoch 1120/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 575.8620 - val_loss: 673.4752\n",
      "Epoch 1121/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 576.5144 - val_loss: 678.1434\n",
      "Epoch 1122/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 573.2051 - val_loss: 677.7512\n",
      "Epoch 1123/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 573.1067 - val_loss: 673.5979\n",
      "Epoch 1124/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 574.3990 - val_loss: 678.4930\n",
      "Epoch 1125/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 572.2009 - val_loss: 680.5989\n",
      "Epoch 1126/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 573.4426 - val_loss: 673.4244\n",
      "Epoch 1127/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 577.0840 - val_loss: 678.2446\n",
      "Epoch 1128/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 576.6857 - val_loss: 682.4142\n",
      "Epoch 1129/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 573.5998 - val_loss: 672.5445\n",
      "Epoch 1130/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 580.6856 - val_loss: 678.6835\n",
      "Epoch 1131/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 572.7889 - val_loss: 677.9422\n",
      "Epoch 1132/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 574.7000 - val_loss: 676.5896\n",
      "Epoch 1133/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 573.7228 - val_loss: 672.0224\n",
      "Epoch 1134/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 574.5925 - val_loss: 669.5233\n",
      "Epoch 1135/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 572.7710 - val_loss: 679.5850\n",
      "Epoch 1136/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 571.7951 - val_loss: 674.0761\n",
      "Epoch 1137/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 578.0007 - val_loss: 675.1096\n",
      "Epoch 1138/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 572.4248 - val_loss: 676.3137\n",
      "Epoch 1139/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 571.5161 - val_loss: 672.0755\n",
      "Epoch 1140/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 571.8328 - val_loss: 675.4524\n",
      "Epoch 1141/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 572.0969 - val_loss: 678.8950\n",
      "Epoch 1142/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 572.1477 - val_loss: 682.2874\n",
      "Epoch 1143/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 577.1124 - val_loss: 675.7085\n",
      "Epoch 1144/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 572.7871 - val_loss: 684.9304\n",
      "Epoch 1145/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 577.9994 - val_loss: 675.0278\n",
      "Epoch 1146/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 574.4690 - val_loss: 678.0703\n",
      "Epoch 1147/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 575.9778 - val_loss: 672.3584\n",
      "Epoch 1148/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 572.5667 - val_loss: 673.7302\n",
      "Epoch 1149/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 572.4651 - val_loss: 677.0450\n",
      "Epoch 1150/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 575.1598 - val_loss: 672.7345\n",
      "Epoch 1151/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 571.1749 - val_loss: 676.7659\n",
      "Epoch 1152/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 572.3331 - val_loss: 677.4474\n",
      "Epoch 1153/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 574.0603 - val_loss: 671.7091\n",
      "Epoch 1154/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 573.4432 - val_loss: 667.7385\n",
      "Epoch 1155/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 577.6576 - val_loss: 679.4051\n",
      "Epoch 1156/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 573.4859 - val_loss: 678.0014\n",
      "Epoch 1157/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 574.3544 - val_loss: 673.7028\n",
      "Epoch 1158/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 569.1310 - val_loss: 677.5445\n",
      "Epoch 1159/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 573.1781 - val_loss: 679.2406\n",
      "Epoch 1160/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 570.2521 - val_loss: 676.9439\n",
      "Epoch 1161/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 571.7832 - val_loss: 674.3564\n",
      "Epoch 1162/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 571.5693 - val_loss: 677.8114\n",
      "Epoch 1163/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 573.0822 - val_loss: 669.2953\n",
      "Epoch 1164/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 568.8113 - val_loss: 674.7262\n",
      "Epoch 1165/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 569.3102 - val_loss: 677.1693\n",
      "Epoch 1166/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 571.8804 - val_loss: 678.6186\n",
      "Epoch 1167/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 574.1780 - val_loss: 677.9487\n",
      "Epoch 1168/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 570.4235 - val_loss: 675.1305\n",
      "Epoch 1169/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 569.7502 - val_loss: 679.5229\n",
      "Epoch 1170/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 571.4668 - val_loss: 674.1129\n",
      "Epoch 1171/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 572.8166 - val_loss: 674.4196\n",
      "Epoch 1172/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 568.7243 - val_loss: 680.8835\n",
      "Epoch 1173/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 572.2895 - val_loss: 677.0209\n",
      "Epoch 1174/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 570.4574 - val_loss: 677.2607\n",
      "Epoch 1175/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 569.0157 - val_loss: 679.3749\n",
      "Epoch 1176/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 570.4255 - val_loss: 672.6509\n",
      "Epoch 1177/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 568.9180 - val_loss: 673.1020\n",
      "Epoch 1178/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 571.0130 - val_loss: 672.8199\n",
      "Epoch 1179/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 570.7401 - val_loss: 667.3447\n",
      "Epoch 1180/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 570.7962 - val_loss: 671.6403\n",
      "Epoch 1181/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 568.5967 - val_loss: 672.8398\n",
      "Epoch 1182/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 566.9141 - val_loss: 669.8055\n",
      "Epoch 1183/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 568.8046 - val_loss: 669.6895\n",
      "Epoch 1184/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 571.3353 - val_loss: 674.4952\n",
      "Epoch 1185/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 574.9556 - val_loss: 677.1806\n",
      "Epoch 1186/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 569.5522 - val_loss: 670.0465\n",
      "Epoch 1187/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 570.0210 - val_loss: 670.9438\n",
      "Epoch 1188/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 568.8325 - val_loss: 674.7643\n",
      "Epoch 1189/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 571.0480 - val_loss: 674.6316\n",
      "Epoch 1190/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 567.3047 - val_loss: 670.7598\n",
      "Epoch 1191/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 568.7736 - val_loss: 679.2476\n",
      "Epoch 1192/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 567.9588 - val_loss: 670.2361\n",
      "Epoch 1193/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 566.3918 - val_loss: 675.0315\n",
      "Epoch 1194/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 570.3001 - val_loss: 675.7028\n",
      "Epoch 1195/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 575.9773 - val_loss: 668.8567\n",
      "Epoch 1196/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 570.2871 - val_loss: 672.1925\n",
      "Epoch 1197/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 577.9504 - val_loss: 670.6101\n",
      "Epoch 1198/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 567.6673 - val_loss: 674.5643\n",
      "Epoch 1199/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 567.8826 - val_loss: 671.6945\n",
      "Epoch 1200/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 567.3010 - val_loss: 674.4499\n",
      "Epoch 1201/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 567.8979 - val_loss: 674.6962\n",
      "Epoch 1202/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 567.4340 - val_loss: 666.3927\n",
      "Epoch 1203/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 569.3010 - val_loss: 668.8577\n",
      "Epoch 1204/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 572.5707 - val_loss: 671.6358\n",
      "Epoch 1205/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 565.6042 - val_loss: 668.2114\n",
      "Epoch 1206/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 568.7480 - val_loss: 675.2819\n",
      "Epoch 1207/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 571.2957 - val_loss: 669.7858\n",
      "Epoch 1208/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 569.8795 - val_loss: 665.0349\n",
      "Epoch 1209/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 567.7092 - val_loss: 666.6973\n",
      "Epoch 1210/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 568.6381 - val_loss: 670.9017\n",
      "Epoch 1211/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 567.0440 - val_loss: 665.5556\n",
      "Epoch 1212/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 565.9490 - val_loss: 670.5427\n",
      "Epoch 1213/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 566.1170 - val_loss: 670.7301\n",
      "Epoch 1214/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 569.8483 - val_loss: 672.9619\n",
      "Epoch 1215/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 566.2806 - val_loss: 670.5845\n",
      "Epoch 1216/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 569.1202 - val_loss: 667.3072\n",
      "Epoch 1217/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 564.6259 - val_loss: 665.9667\n",
      "Epoch 1218/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 568.9536 - val_loss: 674.2308\n",
      "Epoch 1219/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 569.9952 - val_loss: 675.0853\n",
      "Epoch 1220/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 572.6307 - val_loss: 671.4496\n",
      "Epoch 1221/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 566.1430 - val_loss: 675.3365\n",
      "Epoch 1222/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 567.2282 - val_loss: 667.4288\n",
      "Epoch 1223/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 568.7548 - val_loss: 662.7534\n",
      "Epoch 1224/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 565.6018 - val_loss: 666.6187\n",
      "Epoch 1225/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 568.0603 - val_loss: 669.8207\n",
      "Epoch 1226/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 564.4993 - val_loss: 664.6657\n",
      "Epoch 1227/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 564.6129 - val_loss: 665.6098\n",
      "Epoch 1228/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 569.8681 - val_loss: 664.6940\n",
      "Epoch 1229/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 564.1508 - val_loss: 667.2542\n",
      "Epoch 1230/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 569.8931 - val_loss: 667.1915\n",
      "Epoch 1231/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 569.0745 - val_loss: 660.3742\n",
      "Epoch 1232/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 566.6920 - val_loss: 668.0997\n",
      "Epoch 1233/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 566.5262 - val_loss: 672.8850\n",
      "Epoch 1234/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 565.4864 - val_loss: 668.3020\n",
      "Epoch 1235/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 566.0403 - val_loss: 667.9343\n",
      "Epoch 1236/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 563.2654 - val_loss: 669.2965\n",
      "Epoch 1237/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 570.4446 - val_loss: 668.6091\n",
      "Epoch 1238/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 570.2173 - val_loss: 671.0402\n",
      "Epoch 1239/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 571.3878 - val_loss: 670.1375\n",
      "Epoch 1240/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 564.4586 - val_loss: 667.9037\n",
      "Epoch 1241/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 563.3046 - val_loss: 663.1589\n",
      "Epoch 1242/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 562.6822 - val_loss: 665.1149\n",
      "Epoch 1243/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 564.1557 - val_loss: 671.4504\n",
      "Epoch 1244/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 562.6873 - val_loss: 662.2623\n",
      "Epoch 1245/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 566.3806 - val_loss: 664.0683\n",
      "Epoch 1246/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 565.6013 - val_loss: 665.9238\n",
      "Epoch 1247/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 566.3544 - val_loss: 667.1069\n",
      "Epoch 1248/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 564.4175 - val_loss: 667.0228\n",
      "Epoch 1249/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 565.4840 - val_loss: 665.0710\n",
      "Epoch 1250/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 905.0447Epoch: 1250 - loss: 566.211980 - val_loss: 665.364709\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 566.2120 - val_loss: 665.3647\n",
      "Epoch 1251/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 564.2741 - val_loss: 668.8275\n",
      "Epoch 1252/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 565.3098 - val_loss: 660.4964\n",
      "Epoch 1253/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 564.4484 - val_loss: 667.7806\n",
      "Epoch 1254/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 566.2864 - val_loss: 666.1447\n",
      "Epoch 1255/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 565.9351 - val_loss: 666.8356\n",
      "Epoch 1256/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 567.0341 - val_loss: 672.2484\n",
      "Epoch 1257/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 564.3278 - val_loss: 663.6202\n",
      "Epoch 1258/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 570.3451 - val_loss: 662.9380\n",
      "Epoch 1259/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 562.7757 - val_loss: 665.3804\n",
      "Epoch 1260/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 566.2778 - val_loss: 671.4857\n",
      "Epoch 1261/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 562.9480 - val_loss: 662.4940\n",
      "Epoch 1262/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 564.2835 - val_loss: 663.1402\n",
      "Epoch 1263/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 568.0415 - val_loss: 665.5275\n",
      "Epoch 1264/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 565.1356 - val_loss: 664.2315\n",
      "Epoch 1265/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 565.1618 - val_loss: 666.1338\n",
      "Epoch 1266/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 571.5375 - val_loss: 666.9388\n",
      "Epoch 1267/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 562.0126 - val_loss: 667.0004\n",
      "Epoch 1268/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 564.2632 - val_loss: 667.9062\n",
      "Epoch 1269/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 562.6809 - val_loss: 665.4107\n",
      "Epoch 1270/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 563.3140 - val_loss: 661.2933\n",
      "Epoch 1271/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 562.8747 - val_loss: 663.2078\n",
      "Epoch 1272/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 563.2386 - val_loss: 663.7818\n",
      "Epoch 1273/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 561.3756 - val_loss: 663.2970\n",
      "Epoch 1274/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 560.6562 - val_loss: 665.3685\n",
      "Epoch 1275/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 561.9226 - val_loss: 662.1118\n",
      "Epoch 1276/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 562.4055 - val_loss: 667.6611\n",
      "Epoch 1277/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 565.7719 - val_loss: 661.6915\n",
      "Epoch 1278/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 562.7715 - val_loss: 663.1914\n",
      "Epoch 1279/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 563.2121 - val_loss: 660.8418\n",
      "Epoch 1280/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 562.2787 - val_loss: 660.8144\n",
      "Epoch 1281/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 563.0815 - val_loss: 664.6882\n",
      "Epoch 1282/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 564.0794 - val_loss: 671.6956\n",
      "Epoch 1283/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 566.5829 - val_loss: 668.4692\n",
      "Epoch 1284/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 563.6549 - val_loss: 662.2376\n",
      "Epoch 1285/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 562.5378 - val_loss: 665.5111\n",
      "Epoch 1286/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 559.4931 - val_loss: 666.9965\n",
      "Epoch 1287/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 563.3447 - val_loss: 665.0187\n",
      "Epoch 1288/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 561.9161 - val_loss: 664.8938\n",
      "Epoch 1289/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 563.7242 - val_loss: 661.0826\n",
      "Epoch 1290/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 561.7050 - val_loss: 661.1169\n",
      "Epoch 1291/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 562.7040 - val_loss: 662.7713\n",
      "Epoch 1292/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 560.0770 - val_loss: 663.6580\n",
      "Epoch 1293/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 564.3786 - val_loss: 667.7822\n",
      "Epoch 1294/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 561.0310 - val_loss: 667.7550\n",
      "Epoch 1295/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 560.3626 - val_loss: 661.8933\n",
      "Epoch 1296/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 560.0259 - val_loss: 663.6745\n",
      "Epoch 1297/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 560.7359 - val_loss: 662.3470\n",
      "Epoch 1298/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 560.3990 - val_loss: 669.5522\n",
      "Epoch 1299/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 563.6096 - val_loss: 663.2634\n",
      "Epoch 1300/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 563.8389 - val_loss: 661.6660\n",
      "Epoch 1301/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 561.4027 - val_loss: 669.7502\n",
      "Epoch 1302/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 560.3236 - val_loss: 661.8266\n",
      "Epoch 1303/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 562.5010 - val_loss: 663.2765\n",
      "Epoch 1304/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 564.7615 - val_loss: 665.1893\n",
      "Epoch 1305/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 562.3306 - val_loss: 665.7012\n",
      "Epoch 1306/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 560.2055 - val_loss: 660.9740\n",
      "Epoch 1307/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 561.4080 - val_loss: 670.0331\n",
      "Epoch 1308/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 560.5491 - val_loss: 659.9811\n",
      "Epoch 1309/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 558.7964 - val_loss: 662.3332\n",
      "Epoch 1310/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 560.5832 - val_loss: 661.2820\n",
      "Epoch 1311/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 559.4590 - val_loss: 658.4106\n",
      "Epoch 1312/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 559.2595 - val_loss: 660.6786\n",
      "Epoch 1313/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 563.1312 - val_loss: 662.7391\n",
      "Epoch 1314/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 561.2968 - val_loss: 658.5414\n",
      "Epoch 1315/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 562.1050 - val_loss: 661.5096\n",
      "Epoch 1316/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 563.9993 - val_loss: 664.8535\n",
      "Epoch 1317/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 566.8941 - val_loss: 674.0582\n",
      "Epoch 1318/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 560.3498 - val_loss: 664.5133\n",
      "Epoch 1319/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 558.5325 - val_loss: 671.4694\n",
      "Epoch 1320/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 561.7475 - val_loss: 660.6912\n",
      "Epoch 1321/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 558.5019 - val_loss: 661.7603\n",
      "Epoch 1322/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 560.2755 - val_loss: 664.6665\n",
      "Epoch 1323/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 558.2229 - val_loss: 662.8518\n",
      "Epoch 1324/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 559.6269 - val_loss: 664.1208\n",
      "Epoch 1325/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 558.9437 - val_loss: 665.6863\n",
      "Epoch 1326/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 560.6299 - val_loss: 659.0670\n",
      "Epoch 1327/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 559.1986 - val_loss: 659.6157\n",
      "Epoch 1328/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 557.6261 - val_loss: 659.8933\n",
      "Epoch 1329/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 557.3210 - val_loss: 661.3087\n",
      "Epoch 1330/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 558.2986 - val_loss: 659.9295\n",
      "Epoch 1331/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 563.8759 - val_loss: 661.9092\n",
      "Epoch 1332/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 557.1412 - val_loss: 660.5902\n",
      "Epoch 1333/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 558.3742 - val_loss: 661.4449\n",
      "Epoch 1334/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 559.9113 - val_loss: 661.6075\n",
      "Epoch 1335/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 560.1837 - val_loss: 663.5432\n",
      "Epoch 1336/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 558.5852 - val_loss: 660.8241\n",
      "Epoch 1337/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 558.3568 - val_loss: 664.6345\n",
      "Epoch 1338/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 563.0660 - val_loss: 657.5413\n",
      "Epoch 1339/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 561.6076 - val_loss: 661.9419\n",
      "Epoch 1340/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 562.4091 - val_loss: 657.9036\n",
      "Epoch 1341/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 559.2324 - val_loss: 660.5427\n",
      "Epoch 1342/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 561.7272 - val_loss: 664.0095\n",
      "Epoch 1343/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 558.2619 - val_loss: 660.1024\n",
      "Epoch 1344/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 559.8156 - val_loss: 660.3470\n",
      "Epoch 1345/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 567.2504 - val_loss: 668.0635\n",
      "Epoch 1346/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 564.8284 - val_loss: 659.7329\n",
      "Epoch 1347/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 557.5603 - val_loss: 653.3964\n",
      "Epoch 1348/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 559.6323 - val_loss: 660.6317\n",
      "Epoch 1349/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 556.9080 - val_loss: 661.1398\n",
      "Epoch 1350/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 557.3941 - val_loss: 659.8657\n",
      "Epoch 1351/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 558.8352 - val_loss: 656.8556\n",
      "Epoch 1352/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 557.5219 - val_loss: 659.8357\n",
      "Epoch 1353/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 557.2079 - val_loss: 657.6991\n",
      "Epoch 1354/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 557.8169 - val_loss: 660.6384\n",
      "Epoch 1355/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 560.7252 - val_loss: 659.1030\n",
      "Epoch 1356/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 556.4817 - val_loss: 660.8655\n",
      "Epoch 1357/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 558.4404 - val_loss: 658.0191\n",
      "Epoch 1358/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 559.8262 - val_loss: 663.6859\n",
      "Epoch 1359/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 559.4685 - val_loss: 656.8329\n",
      "Epoch 1360/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 558.8617 - val_loss: 655.0635\n",
      "Epoch 1361/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 558.3215 - val_loss: 657.4516\n",
      "Epoch 1362/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 557.9748 - val_loss: 656.8192\n",
      "Epoch 1363/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 562.6057 - val_loss: 659.5955\n",
      "Epoch 1364/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 558.1121 - val_loss: 660.8811\n",
      "Epoch 1365/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 555.5233 - val_loss: 656.2364\n",
      "Epoch 1366/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 555.8070 - val_loss: 657.3664\n",
      "Epoch 1367/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 558.3290 - val_loss: 657.8968\n",
      "Epoch 1368/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 560.0899 - val_loss: 654.3163\n",
      "Epoch 1369/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 560.4895 - val_loss: 656.2443\n",
      "Epoch 1370/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 557.8060 - val_loss: 657.0917\n",
      "Epoch 1371/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 557.1858 - val_loss: 659.3589\n",
      "Epoch 1372/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 557.6387 - val_loss: 661.4542\n",
      "Epoch 1373/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 557.4207 - val_loss: 656.5332\n",
      "Epoch 1374/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 556.7734 - val_loss: 655.5306\n",
      "Epoch 1375/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 560.2840 - val_loss: 659.7059\n",
      "Epoch 1376/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 558.9655 - val_loss: 659.8779\n",
      "Epoch 1377/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 555.7370 - val_loss: 658.4212\n",
      "Epoch 1378/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 554.9099 - val_loss: 657.6338\n",
      "Epoch 1379/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 562.3177 - val_loss: 652.7292\n",
      "Epoch 1380/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 559.2521 - val_loss: 657.0014\n",
      "Epoch 1381/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 555.4607 - val_loss: 656.9771\n",
      "Epoch 1382/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 554.7731 - val_loss: 656.2558\n",
      "Epoch 1383/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 555.2056 - val_loss: 656.9932\n",
      "Epoch 1384/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 556.1424 - val_loss: 657.4330\n",
      "Epoch 1385/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 556.6414 - val_loss: 654.7818\n",
      "Epoch 1386/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 556.3709 - val_loss: 657.1797\n",
      "Epoch 1387/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 554.6866 - val_loss: 654.4458\n",
      "Epoch 1388/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 556.2402 - val_loss: 654.5744\n",
      "Epoch 1389/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 556.2063 - val_loss: 661.2591\n",
      "Epoch 1390/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 557.6300 - val_loss: 660.4607\n",
      "Epoch 1391/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 555.0392 - val_loss: 655.4957\n",
      "Epoch 1392/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 555.7248 - val_loss: 656.2723\n",
      "Epoch 1393/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 559.2589 - val_loss: 654.7985\n",
      "Epoch 1394/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 558.0777 - val_loss: 659.6675\n",
      "Epoch 1395/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 554.2670 - val_loss: 656.5451\n",
      "Epoch 1396/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 563.1696 - val_loss: 674.7883\n",
      "Epoch 1397/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 556.9637 - val_loss: 657.3334\n",
      "Epoch 1398/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 555.2478 - val_loss: 668.4251\n",
      "Epoch 1399/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 559.8461 - val_loss: 660.9298\n",
      "Epoch 1400/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 557.4487 - val_loss: 653.0835\n",
      "Epoch 1401/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 552.8586 - val_loss: 654.0889\n",
      "Epoch 1402/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 554.2854 - val_loss: 657.8173\n",
      "Epoch 1403/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 556.3504 - val_loss: 654.6847\n",
      "Epoch 1404/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 561.9138 - val_loss: 657.2526\n",
      "Epoch 1405/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 558.7545 - val_loss: 657.5831\n",
      "Epoch 1406/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 557.2809 - val_loss: 659.8202\n",
      "Epoch 1407/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 558.0427 - val_loss: 659.4562\n",
      "Epoch 1408/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 556.3311 - val_loss: 657.6776\n",
      "Epoch 1409/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 558.0703 - val_loss: 652.4829\n",
      "Epoch 1410/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 559.9102 - val_loss: 659.0639\n",
      "Epoch 1411/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 554.9318 - val_loss: 658.4635\n",
      "Epoch 1412/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 554.6160 - val_loss: 653.5838\n",
      "Epoch 1413/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 555.7442 - val_loss: 669.6780\n",
      "Epoch 1414/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 555.5984 - val_loss: 656.5491\n",
      "Epoch 1415/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 554.3563 - val_loss: 654.7285\n",
      "Epoch 1416/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 555.7119 - val_loss: 652.1173\n",
      "Epoch 1417/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 557.1827 - val_loss: 654.7241\n",
      "Epoch 1418/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 555.7652 - val_loss: 656.5555\n",
      "Epoch 1419/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 554.3182 - val_loss: 652.7655\n",
      "Epoch 1420/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 556.0313 - val_loss: 656.3295\n",
      "Epoch 1421/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 553.4671 - val_loss: 655.3819\n",
      "Epoch 1422/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 556.4811 - val_loss: 656.6547\n",
      "Epoch 1423/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 556.1025 - val_loss: 654.6214\n",
      "Epoch 1424/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 11us/sample - loss: 555.5205 - val_loss: 656.6623\n",
      "Epoch 1425/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 554.1455 - val_loss: 654.7745\n",
      "Epoch 1426/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 553.4144 - val_loss: 656.5395\n",
      "Epoch 1427/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 554.1830 - val_loss: 656.3901\n",
      "Epoch 1428/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 555.2491 - val_loss: 660.6302\n",
      "Epoch 1429/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 556.0931 - val_loss: 654.9088\n",
      "Epoch 1430/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 554.9798 - val_loss: 654.6182\n",
      "Epoch 1431/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 555.7856 - val_loss: 659.3481\n",
      "Epoch 1432/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 555.7146 - val_loss: 656.0110\n",
      "Epoch 1433/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 552.7625 - val_loss: 656.0314\n",
      "Epoch 1434/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 557.0565 - val_loss: 651.3121\n",
      "Epoch 1435/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 558.6951 - val_loss: 657.6074\n",
      "Epoch 1436/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 553.7633 - val_loss: 655.2737\n",
      "Epoch 1437/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 552.8127 - val_loss: 656.4114\n",
      "Epoch 1438/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 552.9276 - val_loss: 651.0724\n",
      "Epoch 1439/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 555.5674 - val_loss: 660.0298\n",
      "Epoch 1440/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 556.0874 - val_loss: 652.6423\n",
      "Epoch 1441/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 553.3359 - val_loss: 652.4785\n",
      "Epoch 1442/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 555.5679 - val_loss: 654.9630\n",
      "Epoch 1443/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 552.1446 - val_loss: 655.4439\n",
      "Epoch 1444/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 552.4192 - val_loss: 652.1783\n",
      "Epoch 1445/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 559.0619 - val_loss: 664.5271\n",
      "Epoch 1446/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 554.9598 - val_loss: 655.7292\n",
      "Epoch 1447/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 552.6077 - val_loss: 651.2009\n",
      "Epoch 1448/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 553.3689 - val_loss: 656.6192\n",
      "Epoch 1449/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 554.7138 - val_loss: 651.3368\n",
      "Epoch 1450/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 562.2181 - val_loss: 660.3304\n",
      "Epoch 1451/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 555.8376 - val_loss: 654.3899\n",
      "Epoch 1452/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 554.6661 - val_loss: 655.0116\n",
      "Epoch 1453/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 552.9582 - val_loss: 652.3776\n",
      "Epoch 1454/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 551.2585 - val_loss: 651.1217\n",
      "Epoch 1455/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 553.9767 - val_loss: 654.4247\n",
      "Epoch 1456/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 554.4674 - val_loss: 653.3293\n",
      "Epoch 1457/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 552.6010 - val_loss: 653.0211\n",
      "Epoch 1458/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 554.8448 - val_loss: 661.5910\n",
      "Epoch 1459/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 557.9635 - val_loss: 657.3811\n",
      "Epoch 1460/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 553.9217 - val_loss: 649.9133\n",
      "Epoch 1461/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 552.2069 - val_loss: 654.8024\n",
      "Epoch 1462/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 554.7928 - val_loss: 654.3702\n",
      "Epoch 1463/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 553.8365 - val_loss: 654.9744\n",
      "Epoch 1464/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 552.3469 - val_loss: 652.2350\n",
      "Epoch 1465/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 550.4991 - val_loss: 652.5267\n",
      "Epoch 1466/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 554.9192 - val_loss: 653.2137\n",
      "Epoch 1467/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 556.3217 - val_loss: 651.3080\n",
      "Epoch 1468/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 556.8589 - val_loss: 654.4230\n",
      "Epoch 1469/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 553.8542 - val_loss: 654.4376\n",
      "Epoch 1470/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 552.6602 - val_loss: 651.7590\n",
      "Epoch 1471/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 553.5783 - val_loss: 652.3435\n",
      "Epoch 1472/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 553.7770 - val_loss: 649.0442\n",
      "Epoch 1473/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 550.6187 - val_loss: 651.1189\n",
      "Epoch 1474/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 551.4869 - val_loss: 652.1470\n",
      "Epoch 1475/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 553.7653 - val_loss: 660.5822\n",
      "Epoch 1476/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 552.8462 - val_loss: 652.4318\n",
      "Epoch 1477/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 553.3037 - val_loss: 653.0159\n",
      "Epoch 1478/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 549.6787 - val_loss: 654.1326\n",
      "Epoch 1479/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 551.7589 - val_loss: 654.6832\n",
      "Epoch 1480/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 551.7559 - val_loss: 653.6243\n",
      "Epoch 1481/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 551.7890 - val_loss: 650.8257\n",
      "Epoch 1482/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 550.3878 - val_loss: 651.6480\n",
      "Epoch 1483/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 550.2847 - val_loss: 657.8874\n",
      "Epoch 1484/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 561.7887 - val_loss: 648.9689\n",
      "Epoch 1485/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 552.6901 - val_loss: 650.7397\n",
      "Epoch 1486/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 550.5884 - val_loss: 652.0943\n",
      "Epoch 1487/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 553.8172 - val_loss: 657.6758\n",
      "Epoch 1488/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 551.0219 - val_loss: 650.2044\n",
      "Epoch 1489/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 554.4849 - val_loss: 649.8085\n",
      "Epoch 1490/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 554.8187 - val_loss: 652.5314\n",
      "Epoch 1491/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 551.0619 - val_loss: 649.1493\n",
      "Epoch 1492/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 550.5570 - val_loss: 652.0057\n",
      "Epoch 1493/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 548.9588 - val_loss: 648.8478\n",
      "Epoch 1494/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 550.2433 - val_loss: 651.7719\n",
      "Epoch 1495/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 549.8625 - val_loss: 654.2145\n",
      "Epoch 1496/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 550.6748 - val_loss: 653.5049\n",
      "Epoch 1497/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 552.6449 - val_loss: 652.7921\n",
      "Epoch 1498/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 550.7416 - val_loss: 653.3192\n",
      "Epoch 1499/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 550.4566 - val_loss: 648.2534\n",
      "Epoch 1500/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 402.4891Epoch: 1500 - loss: 554.759295 - val_loss: 647.554800\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 554.7593 - val_loss: 647.5548\n",
      "Epoch 1501/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 550.5217 - val_loss: 650.4552\n",
      "Epoch 1502/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 555.0670 - val_loss: 655.5212\n",
      "Epoch 1503/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 555.5987 - val_loss: 646.6762\n",
      "Epoch 1504/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 552.4169 - val_loss: 649.8512\n",
      "Epoch 1505/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 556.4141 - val_loss: 650.0292\n",
      "Epoch 1506/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 551.2673 - val_loss: 654.2384\n",
      "Epoch 1507/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 553.0569 - val_loss: 654.3201\n",
      "Epoch 1508/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 552.9242 - val_loss: 649.3105\n",
      "Epoch 1509/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 552.3847 - val_loss: 648.0675\n",
      "Epoch 1510/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 552.0174 - val_loss: 650.5851\n",
      "Epoch 1511/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 548.1805 - val_loss: 648.5235\n",
      "Epoch 1512/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 555.9126 - val_loss: 658.3408\n",
      "Epoch 1513/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 550.6664 - val_loss: 649.2841\n",
      "Epoch 1514/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 552.0355 - val_loss: 649.4923\n",
      "Epoch 1515/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 552.6522 - val_loss: 648.2448\n",
      "Epoch 1516/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 552.1409 - val_loss: 650.5757\n",
      "Epoch 1517/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 551.4467 - val_loss: 648.0321\n",
      "Epoch 1518/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 550.4300 - val_loss: 648.2406\n",
      "Epoch 1519/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 550.6717 - val_loss: 652.8949\n",
      "Epoch 1520/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 551.6090 - val_loss: 649.6815\n",
      "Epoch 1521/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 551.1064 - val_loss: 648.4682\n",
      "Epoch 1522/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 551.2643 - val_loss: 649.5905\n",
      "Epoch 1523/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 548.8526 - val_loss: 646.4768\n",
      "Epoch 1524/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 549.8491 - val_loss: 646.7330\n",
      "Epoch 1525/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 548.7828 - val_loss: 646.6522\n",
      "Epoch 1526/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 548.7819 - val_loss: 647.4924\n",
      "Epoch 1527/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 549.1166 - val_loss: 649.3660\n",
      "Epoch 1528/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 549.1382 - val_loss: 649.0285\n",
      "Epoch 1529/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 550.1005 - val_loss: 648.3680\n",
      "Epoch 1530/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 548.9490 - val_loss: 651.2406\n",
      "Epoch 1531/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 550.5349 - val_loss: 648.1628\n",
      "Epoch 1532/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 549.9983 - val_loss: 646.0000\n",
      "Epoch 1533/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 549.7546 - val_loss: 645.6412\n",
      "Epoch 1534/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 552.6389 - val_loss: 647.3287\n",
      "Epoch 1535/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 555.1684 - val_loss: 652.2610\n",
      "Epoch 1536/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 550.4158 - val_loss: 648.1100\n",
      "Epoch 1537/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 552.0183 - val_loss: 650.2113\n",
      "Epoch 1538/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 551.6149 - val_loss: 653.0509\n",
      "Epoch 1539/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 550.0716 - val_loss: 647.2927\n",
      "Epoch 1540/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 548.7740 - val_loss: 647.3550\n",
      "Epoch 1541/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 548.7204 - val_loss: 649.6544\n",
      "Epoch 1542/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 548.5149 - val_loss: 646.7656\n",
      "Epoch 1543/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 554.3114 - val_loss: 645.4692\n",
      "Epoch 1544/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 548.7507 - val_loss: 649.8864\n",
      "Epoch 1545/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 548.7358 - val_loss: 650.1460\n",
      "Epoch 1546/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 548.6701 - val_loss: 650.9960\n",
      "Epoch 1547/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 549.6472 - val_loss: 650.1281\n",
      "Epoch 1548/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 548.0442 - val_loss: 651.7961\n",
      "Epoch 1549/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 550.2306 - val_loss: 651.2677\n",
      "Epoch 1550/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 553.8883 - val_loss: 648.5762\n",
      "Epoch 1551/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 549.0557 - val_loss: 654.1276\n",
      "Epoch 1552/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 551.4710 - val_loss: 644.8816\n",
      "Epoch 1553/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 551.1358 - val_loss: 648.5768\n",
      "Epoch 1554/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 548.7493 - val_loss: 648.3432\n",
      "Epoch 1555/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 548.1286 - val_loss: 646.8125\n",
      "Epoch 1556/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 549.1963 - val_loss: 651.3948\n",
      "Epoch 1557/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 548.8827 - val_loss: 648.8668\n",
      "Epoch 1558/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 546.0891 - val_loss: 649.2592\n",
      "Epoch 1559/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 549.9087 - val_loss: 652.0210\n",
      "Epoch 1560/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 549.5092 - val_loss: 647.7491\n",
      "Epoch 1561/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 546.8047 - val_loss: 645.5563\n",
      "Epoch 1562/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 551.8225 - val_loss: 645.9432\n",
      "Epoch 1563/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 546.9109 - val_loss: 648.5938\n",
      "Epoch 1564/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 547.8318 - val_loss: 651.6697\n",
      "Epoch 1565/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 546.9451 - val_loss: 644.8670\n",
      "Epoch 1566/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 546.5623 - val_loss: 646.7381\n",
      "Epoch 1567/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 545.9899 - val_loss: 645.4391\n",
      "Epoch 1568/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 546.8788 - val_loss: 647.3783\n",
      "Epoch 1569/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 546.0311 - val_loss: 649.5053\n",
      "Epoch 1570/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 547.8339 - val_loss: 655.7866\n",
      "Epoch 1571/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 551.1787 - val_loss: 649.3971\n",
      "Epoch 1572/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 548.4408 - val_loss: 647.1717\n",
      "Epoch 1573/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 547.9965 - val_loss: 648.0838\n",
      "Epoch 1574/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 549.2601 - val_loss: 646.7663\n",
      "Epoch 1575/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 547.5972 - val_loss: 645.5387\n",
      "Epoch 1576/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 547.6616 - val_loss: 646.9911\n",
      "Epoch 1577/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 547.2090 - val_loss: 648.0593\n",
      "Epoch 1578/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 547.6077 - val_loss: 646.7644\n",
      "Epoch 1579/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 547.5110 - val_loss: 648.8795\n",
      "Epoch 1580/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 547.5177 - val_loss: 647.0105\n",
      "Epoch 1581/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 548.3741 - val_loss: 647.7558\n",
      "Epoch 1582/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 547.9340 - val_loss: 647.7253\n",
      "Epoch 1583/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 547.7972 - val_loss: 648.3472\n",
      "Epoch 1584/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 547.8481 - val_loss: 647.8298\n",
      "Epoch 1585/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 548.1399 - val_loss: 645.6162\n",
      "Epoch 1586/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 549.0462 - val_loss: 643.8476\n",
      "Epoch 1587/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 549.2620 - val_loss: 650.5440\n",
      "Epoch 1588/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 549.5190 - val_loss: 644.3016\n",
      "Epoch 1589/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 546.8067 - val_loss: 645.9265\n",
      "Epoch 1590/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 547.6369 - val_loss: 645.9375\n",
      "Epoch 1591/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 550.4595 - val_loss: 646.6497\n",
      "Epoch 1592/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 546.2422 - val_loss: 647.1436\n",
      "Epoch 1593/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 545.3058 - val_loss: 648.1345\n",
      "Epoch 1594/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 546.4326 - val_loss: 645.0184\n",
      "Epoch 1595/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 547.1386 - val_loss: 644.7045\n",
      "Epoch 1596/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 545.1219 - val_loss: 645.8047\n",
      "Epoch 1597/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 545.5164 - val_loss: 646.3309\n",
      "Epoch 1598/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 550.6033 - val_loss: 651.5640\n",
      "Epoch 1599/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 547.9533 - val_loss: 648.2159\n",
      "Epoch 1600/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 546.6171 - val_loss: 647.2367\n",
      "Epoch 1601/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 546.1228 - val_loss: 647.0460\n",
      "Epoch 1602/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 549.2570 - val_loss: 645.9118\n",
      "Epoch 1603/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 548.2080 - val_loss: 645.3128\n",
      "Epoch 1604/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 545.5383 - val_loss: 645.7986\n",
      "Epoch 1605/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 545.7186 - val_loss: 644.0189\n",
      "Epoch 1606/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 547.8054 - val_loss: 645.0798\n",
      "Epoch 1607/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 548.0211 - val_loss: 650.2705\n",
      "Epoch 1608/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 546.0830 - val_loss: 643.6945\n",
      "Epoch 1609/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 545.7963 - val_loss: 644.8962\n",
      "Epoch 1610/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 546.5661 - val_loss: 646.3333\n",
      "Epoch 1611/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 545.8981 - val_loss: 644.4917\n",
      "Epoch 1612/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 545.7025 - val_loss: 645.6997\n",
      "Epoch 1613/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 546.7924 - val_loss: 645.6381\n",
      "Epoch 1614/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 548.5678 - val_loss: 646.5869\n",
      "Epoch 1615/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 546.5160 - val_loss: 647.3422\n",
      "Epoch 1616/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 548.8201 - val_loss: 647.4147\n",
      "Epoch 1617/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 548.8859 - val_loss: 645.0449\n",
      "Epoch 1618/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 548.3321 - val_loss: 640.4998\n",
      "Epoch 1619/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 550.8560 - val_loss: 649.9031\n",
      "Epoch 1620/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 547.3408 - val_loss: 645.9508\n",
      "Epoch 1621/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 546.3683 - val_loss: 646.0120\n",
      "Epoch 1622/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 545.7919 - val_loss: 642.2319\n",
      "Epoch 1623/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 546.0543 - val_loss: 644.8081\n",
      "Epoch 1624/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 544.6395 - val_loss: 643.2354\n",
      "Epoch 1625/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 546.7572 - val_loss: 647.2208\n",
      "Epoch 1626/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 544.7834 - val_loss: 643.2729\n",
      "Epoch 1627/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 545.6713 - val_loss: 641.7369\n",
      "Epoch 1628/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 546.5599 - val_loss: 646.1065\n",
      "Epoch 1629/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 544.9538 - val_loss: 646.0266\n",
      "Epoch 1630/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 547.7013 - val_loss: 643.9722\n",
      "Epoch 1631/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 545.9449 - val_loss: 649.0551\n",
      "Epoch 1632/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 547.0880 - val_loss: 646.1670\n",
      "Epoch 1633/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 544.2755 - val_loss: 644.2519\n",
      "Epoch 1634/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 544.2149 - val_loss: 647.9136\n",
      "Epoch 1635/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 544.1445 - val_loss: 643.9087\n",
      "Epoch 1636/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 544.9531 - val_loss: 643.3329\n",
      "Epoch 1637/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 546.7875 - val_loss: 643.3064\n",
      "Epoch 1638/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 546.0800 - val_loss: 642.9604\n",
      "Epoch 1639/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 547.1001 - val_loss: 641.7664\n",
      "Epoch 1640/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 543.7347 - val_loss: 644.6569\n",
      "Epoch 1641/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 544.0880 - val_loss: 641.9109\n",
      "Epoch 1642/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 546.6972 - val_loss: 651.1476\n",
      "Epoch 1643/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 544.8455 - val_loss: 644.6430\n",
      "Epoch 1644/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 545.6103 - val_loss: 644.2687\n",
      "Epoch 1645/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 546.3731 - val_loss: 641.1556\n",
      "Epoch 1646/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 543.7688 - val_loss: 644.8062\n",
      "Epoch 1647/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 547.3486 - val_loss: 641.0294\n",
      "Epoch 1648/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 543.4233 - val_loss: 642.2119\n",
      "Epoch 1649/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 546.7081 - val_loss: 642.3267\n",
      "Epoch 1650/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 542.8271 - val_loss: 643.3313\n",
      "Epoch 1651/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 543.0552 - val_loss: 643.2021\n",
      "Epoch 1652/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 542.7299 - val_loss: 644.0238\n",
      "Epoch 1653/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 544.0136 - val_loss: 641.0374\n",
      "Epoch 1654/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 544.3400 - val_loss: 643.5296\n",
      "Epoch 1655/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 544.2904 - val_loss: 646.1576\n",
      "Epoch 1656/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 544.7305 - val_loss: 641.4151\n",
      "Epoch 1657/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 542.5600 - val_loss: 642.8449\n",
      "Epoch 1658/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 546.9156 - val_loss: 639.5669\n",
      "Epoch 1659/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 543.9124 - val_loss: 645.8984\n",
      "Epoch 1660/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 544.7753 - val_loss: 647.5182\n",
      "Epoch 1661/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 543.0131 - val_loss: 641.9791\n",
      "Epoch 1662/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 546.5386 - val_loss: 640.6763\n",
      "Epoch 1663/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 546.1797 - val_loss: 644.5768\n",
      "Epoch 1664/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 546.0303 - val_loss: 651.7516\n",
      "Epoch 1665/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 545.5767 - val_loss: 645.9643\n",
      "Epoch 1666/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 544.3948 - val_loss: 644.5090\n",
      "Epoch 1667/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 545.1161 - val_loss: 640.4572\n",
      "Epoch 1668/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 543.0397 - val_loss: 641.3409\n",
      "Epoch 1669/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 544.4625 - val_loss: 641.3661\n",
      "Epoch 1670/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 543.6696 - val_loss: 642.2392\n",
      "Epoch 1671/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 545.5869 - val_loss: 640.0239\n",
      "Epoch 1672/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 540.9991 - val_loss: 643.5640\n",
      "Epoch 1673/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 543.1076 - val_loss: 640.1666\n",
      "Epoch 1674/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 542.3916 - val_loss: 640.3246\n",
      "Epoch 1675/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 545.1486 - val_loss: 647.5083\n",
      "Epoch 1676/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 545.0207 - val_loss: 642.3269\n",
      "Epoch 1677/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 543.8916 - val_loss: 645.5090\n",
      "Epoch 1678/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 545.6282 - val_loss: 641.4753\n",
      "Epoch 1679/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 543.3209 - val_loss: 642.4422\n",
      "Epoch 1680/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 542.7346 - val_loss: 642.8365\n",
      "Epoch 1681/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 545.5423 - val_loss: 636.6242\n",
      "Epoch 1682/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 548.7287 - val_loss: 642.4946\n",
      "Epoch 1683/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 540.3945 - val_loss: 645.1493\n",
      "Epoch 1684/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 541.6199 - val_loss: 641.4557\n",
      "Epoch 1685/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 541.5870 - val_loss: 641.0485\n",
      "Epoch 1686/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 542.6078 - val_loss: 642.3955\n",
      "Epoch 1687/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 543.0735 - val_loss: 646.5639\n",
      "Epoch 1688/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 544.7301 - val_loss: 646.3019\n",
      "Epoch 1689/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 544.8445 - val_loss: 639.4048\n",
      "Epoch 1690/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 542.8046 - val_loss: 641.2439\n",
      "Epoch 1691/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 541.5077 - val_loss: 644.9943\n",
      "Epoch 1692/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 541.6591 - val_loss: 642.0763\n",
      "Epoch 1693/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 543.3223 - val_loss: 642.8093\n",
      "Epoch 1694/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 544.5517 - val_loss: 639.3359\n",
      "Epoch 1695/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 550.2399 - val_loss: 648.4899\n",
      "Epoch 1696/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 544.1576 - val_loss: 649.3855\n",
      "Epoch 1697/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 545.8383 - val_loss: 641.1838\n",
      "Epoch 1698/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 543.6319 - val_loss: 639.5269\n",
      "Epoch 1699/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 542.7677 - val_loss: 642.6863\n",
      "Epoch 1700/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 541.6154 - val_loss: 643.2870\n",
      "Epoch 1701/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 540.5135 - val_loss: 638.6798\n",
      "Epoch 1702/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 540.8924 - val_loss: 640.6766\n",
      "Epoch 1703/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 542.3385 - val_loss: 641.2301\n",
      "Epoch 1704/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 541.7634 - val_loss: 644.0733\n",
      "Epoch 1705/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 540.8974 - val_loss: 641.3314\n",
      "Epoch 1706/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 540.8180 - val_loss: 641.4364\n",
      "Epoch 1707/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 544.2182 - val_loss: 641.8119\n",
      "Epoch 1708/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 545.0191 - val_loss: 641.1418\n",
      "Epoch 1709/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 540.7622 - val_loss: 639.0476\n",
      "Epoch 1710/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 540.7404 - val_loss: 640.1679\n",
      "Epoch 1711/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 541.3779 - val_loss: 644.5531\n",
      "Epoch 1712/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 542.7534 - val_loss: 645.6107\n",
      "Epoch 1713/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 541.0096 - val_loss: 640.7770\n",
      "Epoch 1714/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 542.1033 - val_loss: 642.8265\n",
      "Epoch 1715/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 543.1464 - val_loss: 640.2323\n",
      "Epoch 1716/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 542.8344 - val_loss: 639.5714\n",
      "Epoch 1717/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 542.7167 - val_loss: 640.5727\n",
      "Epoch 1718/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 544.3127 - val_loss: 640.7636\n",
      "Epoch 1719/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 543.2491 - val_loss: 641.2262\n",
      "Epoch 1720/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 542.9683 - val_loss: 641.0238\n",
      "Epoch 1721/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 541.0775 - val_loss: 640.0840\n",
      "Epoch 1722/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 542.6745 - val_loss: 639.5067\n",
      "Epoch 1723/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 540.1295 - val_loss: 640.9236\n",
      "Epoch 1724/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 540.3915 - val_loss: 640.3174\n",
      "Epoch 1725/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 544.0096 - val_loss: 637.0465\n",
      "Epoch 1726/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 543.1809 - val_loss: 639.7167\n",
      "Epoch 1727/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 541.2008 - val_loss: 637.9232\n",
      "Epoch 1728/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 540.1692 - val_loss: 641.1280\n",
      "Epoch 1729/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 543.1950 - val_loss: 639.9690\n",
      "Epoch 1730/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 541.5137 - val_loss: 638.6346\n",
      "Epoch 1731/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 543.6674 - val_loss: 643.2060\n",
      "Epoch 1732/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 540.3704 - val_loss: 643.6155\n",
      "Epoch 1733/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 543.7651 - val_loss: 643.1933\n",
      "Epoch 1734/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 541.1521 - val_loss: 638.4700\n",
      "Epoch 1735/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 541.4909 - val_loss: 641.8403\n",
      "Epoch 1736/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 540.8773 - val_loss: 639.1625\n",
      "Epoch 1737/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 540.2541 - val_loss: 640.1292\n",
      "Epoch 1738/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 540.7261 - val_loss: 641.2200\n",
      "Epoch 1739/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 540.4281 - val_loss: 640.6437\n",
      "Epoch 1740/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 541.4907 - val_loss: 644.1977\n",
      "Epoch 1741/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 540.1734 - val_loss: 642.0386\n",
      "Epoch 1742/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 539.7695 - val_loss: 641.1259\n",
      "Epoch 1743/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 540.5799 - val_loss: 638.3422\n",
      "Epoch 1744/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 540.4577 - val_loss: 635.7233\n",
      "Epoch 1745/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 539.7654 - val_loss: 640.6606\n",
      "Epoch 1746/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 542.2247 - val_loss: 640.7953\n",
      "Epoch 1747/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 540.0892 - val_loss: 639.2553\n",
      "Epoch 1748/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 538.7029 - val_loss: 636.4203\n",
      "Epoch 1749/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 540.0681 - val_loss: 638.5415\n",
      "Epoch 1750/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 440.1671Epoch: 1750 - loss: 539.641606 - val_loss: 638.743073\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 539.6416 - val_loss: 638.7431\n",
      "Epoch 1751/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 538.3850 - val_loss: 639.7673\n",
      "Epoch 1752/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 538.6327 - val_loss: 642.7310\n",
      "Epoch 1753/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 543.3359 - val_loss: 640.5741\n",
      "Epoch 1754/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 539.8610 - val_loss: 637.5266\n",
      "Epoch 1755/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 541.3091 - val_loss: 637.9247\n",
      "Epoch 1756/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 543.8460 - val_loss: 638.7394\n",
      "Epoch 1757/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 539.9064 - val_loss: 638.6831\n",
      "Epoch 1758/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 539.7671 - val_loss: 640.2101\n",
      "Epoch 1759/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 540.6005 - val_loss: 637.2828\n",
      "Epoch 1760/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 540.9539 - val_loss: 637.3552\n",
      "Epoch 1761/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 538.7054 - val_loss: 642.9332\n",
      "Epoch 1762/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 541.9008 - val_loss: 637.5028\n",
      "Epoch 1763/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 540.3107 - val_loss: 635.6181\n",
      "Epoch 1764/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 538.8648 - val_loss: 639.3335\n",
      "Epoch 1765/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 540.9576 - val_loss: 639.5253\n",
      "Epoch 1766/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 540.4624 - val_loss: 639.2842\n",
      "Epoch 1767/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 539.4084 - val_loss: 639.7436\n",
      "Epoch 1768/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 539.8029 - val_loss: 638.1661\n",
      "Epoch 1769/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 539.2578 - val_loss: 636.6635\n",
      "Epoch 1770/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 539.3900 - val_loss: 640.5057\n",
      "Epoch 1771/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 540.8624 - val_loss: 635.4355\n",
      "Epoch 1772/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 539.3575 - val_loss: 640.2756\n",
      "Epoch 1773/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 538.9018 - val_loss: 638.5137\n",
      "Epoch 1774/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 540.1369 - val_loss: 636.8246\n",
      "Epoch 1775/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 538.4688 - val_loss: 639.7871\n",
      "Epoch 1776/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 538.0481 - val_loss: 638.6718\n",
      "Epoch 1777/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 536.4337 - val_loss: 636.8931\n",
      "Epoch 1778/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 537.3174 - val_loss: 636.6798\n",
      "Epoch 1779/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 539.3481 - val_loss: 638.0270\n",
      "Epoch 1780/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 539.5933 - val_loss: 636.9551\n",
      "Epoch 1781/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 543.5750 - val_loss: 635.8272\n",
      "Epoch 1782/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 542.4592 - val_loss: 637.8280\n",
      "Epoch 1783/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 539.8541 - val_loss: 637.0259\n",
      "Epoch 1784/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 541.3590 - val_loss: 639.8009\n",
      "Epoch 1785/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 537.5733 - val_loss: 638.4021\n",
      "Epoch 1786/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 539.9947 - val_loss: 638.4094\n",
      "Epoch 1787/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 538.5890 - val_loss: 636.9456\n",
      "Epoch 1788/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 538.2068 - val_loss: 635.8461\n",
      "Epoch 1789/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 539.5423 - val_loss: 635.2556\n",
      "Epoch 1790/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 538.2180 - val_loss: 636.1728\n",
      "Epoch 1791/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 538.5454 - val_loss: 639.7576\n",
      "Epoch 1792/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 537.4926 - val_loss: 637.5907\n",
      "Epoch 1793/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 538.4759 - val_loss: 637.6630\n",
      "Epoch 1794/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 539.6121 - val_loss: 638.8464\n",
      "Epoch 1795/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 539.6175 - val_loss: 636.3285\n",
      "Epoch 1796/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 538.5773 - val_loss: 634.7519\n",
      "Epoch 1797/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 539.2102 - val_loss: 640.2158\n",
      "Epoch 1798/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 538.6244 - val_loss: 636.6358\n",
      "Epoch 1799/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 543.7196 - val_loss: 637.9410\n",
      "Epoch 1800/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 542.2826 - val_loss: 641.1599\n",
      "Epoch 1801/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 537.7465 - val_loss: 637.8345\n",
      "Epoch 1802/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 538.9384 - val_loss: 638.4088\n",
      "Epoch 1803/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 539.1986 - val_loss: 637.3600\n",
      "Epoch 1804/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 541.0062 - val_loss: 638.9482\n",
      "Epoch 1805/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 537.4853 - val_loss: 637.4018\n",
      "Epoch 1806/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 538.5402 - val_loss: 641.1887\n",
      "Epoch 1807/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 536.6844 - val_loss: 638.6693\n",
      "Epoch 1808/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 538.4088 - val_loss: 636.2676\n",
      "Epoch 1809/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 541.0535 - val_loss: 635.4415\n",
      "Epoch 1810/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 538.3790 - val_loss: 635.3320\n",
      "Epoch 1811/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 537.1319 - val_loss: 636.1229\n",
      "Epoch 1812/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 538.6495 - val_loss: 637.0038\n",
      "Epoch 1813/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 538.1749 - val_loss: 640.0671\n",
      "Epoch 1814/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 537.3909 - val_loss: 636.4868\n",
      "Epoch 1815/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 537.5601 - val_loss: 639.1144\n",
      "Epoch 1816/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 540.6662 - val_loss: 635.5118\n",
      "Epoch 1817/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 538.8464 - val_loss: 637.0107\n",
      "Epoch 1818/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 539.5923 - val_loss: 635.3083\n",
      "Epoch 1819/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 536.8764 - val_loss: 637.2192\n",
      "Epoch 1820/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 539.2765 - val_loss: 633.9865\n",
      "Epoch 1821/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 538.5795 - val_loss: 638.6229\n",
      "Epoch 1822/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 539.8929 - val_loss: 633.5253\n",
      "Epoch 1823/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 538.2111 - val_loss: 641.8296\n",
      "Epoch 1824/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 540.1189 - val_loss: 636.1240\n",
      "Epoch 1825/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 539.1288 - val_loss: 639.1172\n",
      "Epoch 1826/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 536.5401 - val_loss: 636.5994\n",
      "Epoch 1827/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 537.1467 - val_loss: 634.9182\n",
      "Epoch 1828/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 535.8483 - val_loss: 635.4291\n",
      "Epoch 1829/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 537.2610 - val_loss: 633.2292\n",
      "Epoch 1830/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 537.4867 - val_loss: 633.5817\n",
      "Epoch 1831/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 538.5993 - val_loss: 634.1718\n",
      "Epoch 1832/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 536.8209 - val_loss: 636.4731\n",
      "Epoch 1833/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 538.0846 - val_loss: 633.3555\n",
      "Epoch 1834/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 537.0671 - val_loss: 635.3769\n",
      "Epoch 1835/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 540.3463 - val_loss: 636.1126\n",
      "Epoch 1836/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 537.6161 - val_loss: 635.6764\n",
      "Epoch 1837/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 536.6721 - val_loss: 633.8258\n",
      "Epoch 1838/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 537.0799 - val_loss: 635.8238\n",
      "Epoch 1839/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 540.3051 - val_loss: 640.4901\n",
      "Epoch 1840/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 537.9674 - val_loss: 639.2522\n",
      "Epoch 1841/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 538.4566 - val_loss: 640.2697\n",
      "Epoch 1842/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 538.6535 - val_loss: 635.7267\n",
      "Epoch 1843/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 537.5407 - val_loss: 633.3093\n",
      "Epoch 1844/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 535.8233 - val_loss: 633.7888\n",
      "Epoch 1845/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 537.3812 - val_loss: 637.5620\n",
      "Epoch 1846/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 535.1765 - val_loss: 633.7772\n",
      "Epoch 1847/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 537.1289 - val_loss: 634.9136\n",
      "Epoch 1848/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 537.0110 - val_loss: 634.5707\n",
      "Epoch 1849/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 539.7924 - val_loss: 631.9316\n",
      "Epoch 1850/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 536.4859 - val_loss: 632.0991\n",
      "Epoch 1851/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 536.8040 - val_loss: 636.3799\n",
      "Epoch 1852/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 535.3839 - val_loss: 635.0420\n",
      "Epoch 1853/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 537.3621 - val_loss: 633.8111\n",
      "Epoch 1854/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 536.9202 - val_loss: 636.0949\n",
      "Epoch 1855/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 538.1043 - val_loss: 630.6918\n",
      "Epoch 1856/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 537.0614 - val_loss: 633.2503\n",
      "Epoch 1857/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 536.6242 - val_loss: 638.6716\n",
      "Epoch 1858/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 538.8185 - val_loss: 640.6791\n",
      "Epoch 1859/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 538.3007 - val_loss: 634.0934\n",
      "Epoch 1860/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 535.8515 - val_loss: 634.7408\n",
      "Epoch 1861/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 534.4001 - val_loss: 635.6662\n",
      "Epoch 1862/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 538.5527 - val_loss: 633.3904\n",
      "Epoch 1863/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 535.4786 - val_loss: 635.7955\n",
      "Epoch 1864/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 537.0766 - val_loss: 633.5861\n",
      "Epoch 1865/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 540.2242 - val_loss: 632.4618\n",
      "Epoch 1866/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 539.0306 - val_loss: 639.4800\n",
      "Epoch 1867/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 537.6374 - val_loss: 634.1899\n",
      "Epoch 1868/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 537.5795 - val_loss: 636.1704\n",
      "Epoch 1869/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 535.7517 - val_loss: 635.8045\n",
      "Epoch 1870/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 536.1646 - val_loss: 635.5500\n",
      "Epoch 1871/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 534.9579 - val_loss: 632.9079\n",
      "Epoch 1872/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 535.7492 - val_loss: 637.0482\n",
      "Epoch 1873/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 537.1435 - val_loss: 637.4498\n",
      "Epoch 1874/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 536.4398 - val_loss: 634.9553\n",
      "Epoch 1875/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 536.8557 - val_loss: 638.6751\n",
      "Epoch 1876/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 537.2072 - val_loss: 633.9745\n",
      "Epoch 1877/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 537.5397 - val_loss: 633.6130\n",
      "Epoch 1878/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 535.5895 - val_loss: 634.2651\n",
      "Epoch 1879/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 535.3378 - val_loss: 634.2741\n",
      "Epoch 1880/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 534.8512 - val_loss: 633.4516\n",
      "Epoch 1881/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 536.1824 - val_loss: 632.0566\n",
      "Epoch 1882/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 534.4702 - val_loss: 633.2590\n",
      "Epoch 1883/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 536.6685 - val_loss: 632.7115\n",
      "Epoch 1884/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 537.3225 - val_loss: 634.2457\n",
      "Epoch 1885/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 536.6110 - val_loss: 636.3924\n",
      "Epoch 1886/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 533.6255 - val_loss: 632.4337\n",
      "Epoch 1887/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 535.3023 - val_loss: 633.0572\n",
      "Epoch 1888/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 534.5556 - val_loss: 632.9506\n",
      "Epoch 1889/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 535.2121 - val_loss: 632.5069\n",
      "Epoch 1890/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 535.8664 - val_loss: 637.5158\n",
      "Epoch 1891/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 536.2608 - val_loss: 634.2283\n",
      "Epoch 1892/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 536.0228 - val_loss: 632.8008\n",
      "Epoch 1893/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 534.8352 - val_loss: 635.0962\n",
      "Epoch 1894/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 537.2385 - val_loss: 634.0882\n",
      "Epoch 1895/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 535.3498 - val_loss: 633.1789\n",
      "Epoch 1896/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 535.5990 - val_loss: 634.2168\n",
      "Epoch 1897/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 535.9968 - val_loss: 638.6010\n",
      "Epoch 1898/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 534.8160 - val_loss: 635.5643\n",
      "Epoch 1899/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 534.9413 - val_loss: 633.9881\n",
      "Epoch 1900/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 534.3736 - val_loss: 633.0239\n",
      "Epoch 1901/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 535.3179 - val_loss: 633.5826\n",
      "Epoch 1902/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 534.6326 - val_loss: 632.4027\n",
      "Epoch 1903/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 534.8673 - val_loss: 632.2324\n",
      "Epoch 1904/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 534.4403 - val_loss: 636.7882\n",
      "Epoch 1905/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 536.5177 - val_loss: 633.9908\n",
      "Epoch 1906/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 533.6554 - val_loss: 634.0974\n",
      "Epoch 1907/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 533.0815 - val_loss: 633.6776\n",
      "Epoch 1908/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 534.4678 - val_loss: 635.5213\n",
      "Epoch 1909/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 535.4756 - val_loss: 631.8460\n",
      "Epoch 1910/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 534.6054 - val_loss: 634.0712\n",
      "Epoch 1911/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 533.7118 - val_loss: 634.5330\n",
      "Epoch 1912/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 534.3534 - val_loss: 631.4581\n",
      "Epoch 1913/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 538.2553 - val_loss: 637.1509\n",
      "Epoch 1914/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 535.8892 - val_loss: 634.4384\n",
      "Epoch 1915/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 534.0075 - val_loss: 633.4569\n",
      "Epoch 1916/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 534.1162 - val_loss: 633.5088\n",
      "Epoch 1917/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 535.3934 - val_loss: 631.3528\n",
      "Epoch 1918/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 535.7737 - val_loss: 634.5268\n",
      "Epoch 1919/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 535.5981 - val_loss: 633.3865\n",
      "Epoch 1920/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 534.5661 - val_loss: 632.9751\n",
      "Epoch 1921/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 536.5229 - val_loss: 637.0675\n",
      "Epoch 1922/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 533.5409 - val_loss: 630.9274\n",
      "Epoch 1923/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 533.7626 - val_loss: 631.4185\n",
      "Epoch 1924/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 535.9786 - val_loss: 633.9316\n",
      "Epoch 1925/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 535.7160 - val_loss: 637.1574\n",
      "Epoch 1926/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 533.7056 - val_loss: 632.4175\n",
      "Epoch 1927/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.8095 - val_loss: 631.6849\n",
      "Epoch 1928/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.5008 - val_loss: 632.8786\n",
      "Epoch 1929/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 533.6018 - val_loss: 634.2294\n",
      "Epoch 1930/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 535.7094 - val_loss: 632.9974\n",
      "Epoch 1931/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 536.4169 - val_loss: 633.0325\n",
      "Epoch 1932/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 534.6335 - val_loss: 632.4323\n",
      "Epoch 1933/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 533.1412 - val_loss: 632.9282\n",
      "Epoch 1934/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 534.7245 - val_loss: 634.2268\n",
      "Epoch 1935/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 536.5881 - val_loss: 634.0143\n",
      "Epoch 1936/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 533.4681 - val_loss: 631.8005\n",
      "Epoch 1937/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 535.6483 - val_loss: 634.7204\n",
      "Epoch 1938/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 533.7251 - val_loss: 633.9422\n",
      "Epoch 1939/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 535.4328 - val_loss: 631.7441\n",
      "Epoch 1940/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 534.2220 - val_loss: 634.7166\n",
      "Epoch 1941/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 532.8844 - val_loss: 631.4867\n",
      "Epoch 1942/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 535.4836 - val_loss: 632.3394\n",
      "Epoch 1943/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.8166 - val_loss: 632.7878\n",
      "Epoch 1944/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 534.1089 - val_loss: 633.0356\n",
      "Epoch 1945/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 533.1133 - val_loss: 634.1861\n",
      "Epoch 1946/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.1521 - val_loss: 631.7661\n",
      "Epoch 1947/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 535.2616 - val_loss: 633.0622\n",
      "Epoch 1948/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 535.0510 - val_loss: 632.6589\n",
      "Epoch 1949/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.9086 - val_loss: 631.4857\n",
      "Epoch 1950/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 533.8673 - val_loss: 631.6133\n",
      "Epoch 1951/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 534.2508 - val_loss: 630.4299\n",
      "Epoch 1952/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 534.5108 - val_loss: 630.7901\n",
      "Epoch 1953/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 536.0822 - val_loss: 634.5031\n",
      "Epoch 1954/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 531.8581 - val_loss: 629.8185\n",
      "Epoch 1955/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 533.0524 - val_loss: 635.3482\n",
      "Epoch 1956/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 534.1897 - val_loss: 628.6409\n",
      "Epoch 1957/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 534.3096 - val_loss: 632.8214\n",
      "Epoch 1958/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.3334 - val_loss: 631.4583\n",
      "Epoch 1959/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 532.0000 - val_loss: 629.6178\n",
      "Epoch 1960/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.6589 - val_loss: 630.9223\n",
      "Epoch 1961/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.4870 - val_loss: 633.6722\n",
      "Epoch 1962/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 533.5204 - val_loss: 628.7629\n",
      "Epoch 1963/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 533.7179 - val_loss: 630.9337\n",
      "Epoch 1964/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.7227 - val_loss: 631.1481\n",
      "Epoch 1965/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.7896 - val_loss: 633.2184\n",
      "Epoch 1966/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 533.9964 - val_loss: 632.0375\n",
      "Epoch 1967/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.8518 - val_loss: 630.4645\n",
      "Epoch 1968/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 534.9715 - val_loss: 630.4236\n",
      "Epoch 1969/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.4736 - val_loss: 632.9948\n",
      "Epoch 1970/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.2704 - val_loss: 631.7173\n",
      "Epoch 1971/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 532.8887 - val_loss: 630.4851\n",
      "Epoch 1972/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 535.9208 - val_loss: 633.3844\n",
      "Epoch 1973/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 533.2562 - val_loss: 630.1399\n",
      "Epoch 1974/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 533.5436 - val_loss: 631.5507\n",
      "Epoch 1975/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 532.5673 - val_loss: 629.5301\n",
      "Epoch 1976/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 533.3029 - val_loss: 631.4408\n",
      "Epoch 1977/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 533.0504 - val_loss: 631.8913\n",
      "Epoch 1978/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 533.4307 - val_loss: 629.7408\n",
      "Epoch 1979/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 533.7893 - val_loss: 630.1590\n",
      "Epoch 1980/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.2929 - val_loss: 629.1259\n",
      "Epoch 1981/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 531.9836 - val_loss: 631.5184\n",
      "Epoch 1982/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 533.6213 - val_loss: 629.8842\n",
      "Epoch 1983/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 534.1380 - val_loss: 631.2713\n",
      "Epoch 1984/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 531.5779 - val_loss: 632.3420\n",
      "Epoch 1985/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 537.7745 - val_loss: 629.8376\n",
      "Epoch 1986/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 534.7332 - val_loss: 632.2770\n",
      "Epoch 1987/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.9315 - val_loss: 631.1193\n",
      "Epoch 1988/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.6912 - val_loss: 631.8408\n",
      "Epoch 1989/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.2944 - val_loss: 632.9094\n",
      "Epoch 1990/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 531.3781 - val_loss: 628.9542\n",
      "Epoch 1991/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.4289 - val_loss: 629.8471\n",
      "Epoch 1992/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 533.4652 - val_loss: 631.3977\n",
      "Epoch 1993/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.0168 - val_loss: 628.5307\n",
      "Epoch 1994/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 531.8029 - val_loss: 634.2742\n",
      "Epoch 1995/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 537.2910 - val_loss: 631.0152\n",
      "Epoch 1996/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 530.9344 - val_loss: 630.6638\n",
      "Epoch 1997/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.4460 - val_loss: 632.2435\n",
      "Epoch 1998/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 530.3527 - val_loss: 629.3759\n",
      "Epoch 1999/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.3789 - val_loss: 635.0637\n",
      "Epoch 2000/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 364.1490Epoch: 2000 - loss: 532.473886 - val_loss: 628.218931\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.4739 - val_loss: 628.2189\n",
      "Epoch 2001/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 531.5093 - val_loss: 628.3246\n",
      "Epoch 2002/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 533.2088 - val_loss: 628.2346\n",
      "Epoch 2003/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 531.7517 - val_loss: 632.4633\n",
      "Epoch 2004/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 531.9702 - val_loss: 629.5833\n",
      "Epoch 2005/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.3372 - val_loss: 628.3194\n",
      "Epoch 2006/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 533.8818 - val_loss: 628.2617\n",
      "Epoch 2007/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 531.2827 - val_loss: 630.2402\n",
      "Epoch 2008/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.3708 - val_loss: 633.5594\n",
      "Epoch 2009/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 531.9914 - val_loss: 630.0451\n",
      "Epoch 2010/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 530.8244 - val_loss: 629.4707\n",
      "Epoch 2011/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 529.9415 - val_loss: 629.5866\n",
      "Epoch 2012/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 533.9224 - val_loss: 633.7299\n",
      "Epoch 2013/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 531.2703 - val_loss: 630.9296\n",
      "Epoch 2014/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 530.8155 - val_loss: 629.1821\n",
      "Epoch 2015/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 533.2181 - val_loss: 628.4838\n",
      "Epoch 2016/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 533.3103 - val_loss: 634.2103\n",
      "Epoch 2017/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 530.6745 - val_loss: 631.2551\n",
      "Epoch 2018/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.9745 - val_loss: 630.1137\n",
      "Epoch 2019/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 531.3243 - val_loss: 629.0613\n",
      "Epoch 2020/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 530.9578 - val_loss: 631.6113\n",
      "Epoch 2021/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 530.1752 - val_loss: 628.6895\n",
      "Epoch 2022/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 531.7599 - val_loss: 628.4148\n",
      "Epoch 2023/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 529.3693 - val_loss: 630.7674\n",
      "Epoch 2024/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 530.7809 - val_loss: 630.7116\n",
      "Epoch 2025/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 530.8271 - val_loss: 629.2557\n",
      "Epoch 2026/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.8611 - val_loss: 627.6838\n",
      "Epoch 2027/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 531.1191 - val_loss: 628.5017\n",
      "Epoch 2028/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 531.8424 - val_loss: 625.7437\n",
      "Epoch 2029/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 531.2325 - val_loss: 631.1155\n",
      "Epoch 2030/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 530.7287 - val_loss: 630.4705\n",
      "Epoch 2031/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 531.5307 - val_loss: 631.1572\n",
      "Epoch 2032/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.4362 - val_loss: 629.2275\n",
      "Epoch 2033/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 531.6681 - val_loss: 630.4303\n",
      "Epoch 2034/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 531.2937 - val_loss: 627.8988\n",
      "Epoch 2035/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 530.2628 - val_loss: 629.8266\n",
      "Epoch 2036/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 529.9688 - val_loss: 628.2436\n",
      "Epoch 2037/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 531.1707 - val_loss: 628.3788\n",
      "Epoch 2038/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 530.3616 - val_loss: 627.0945\n",
      "Epoch 2039/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 530.8164 - val_loss: 626.3703\n",
      "Epoch 2040/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.2236 - val_loss: 630.6137\n",
      "Epoch 2041/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 530.5476 - val_loss: 627.7223\n",
      "Epoch 2042/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 530.1275 - val_loss: 629.0370\n",
      "Epoch 2043/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.0021 - val_loss: 628.5073\n",
      "Epoch 2044/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 530.9721 - val_loss: 629.1385\n",
      "Epoch 2045/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 530.5102 - val_loss: 630.4646\n",
      "Epoch 2046/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.4859 - val_loss: 624.7716\n",
      "Epoch 2047/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 529.7229 - val_loss: 630.5899\n",
      "Epoch 2048/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 530.3500 - val_loss: 629.2783\n",
      "Epoch 2049/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 529.8784 - val_loss: 630.0535\n",
      "Epoch 2050/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 529.2814 - val_loss: 627.4804\n",
      "Epoch 2051/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 529.7370 - val_loss: 625.8461\n",
      "Epoch 2052/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 531.0211 - val_loss: 632.4468\n",
      "Epoch 2053/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 531.6144 - val_loss: 626.7909\n",
      "Epoch 2054/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.8670 - val_loss: 628.1799\n",
      "Epoch 2055/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 529.9632 - val_loss: 629.5700\n",
      "Epoch 2056/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 530.4807 - val_loss: 627.4371\n",
      "Epoch 2057/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 530.4336 - val_loss: 628.2185\n",
      "Epoch 2058/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 529.5449 - val_loss: 626.1456\n",
      "Epoch 2059/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.4630 - val_loss: 628.1273\n",
      "Epoch 2060/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 529.8727 - val_loss: 627.4989\n",
      "Epoch 2061/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.6193 - val_loss: 628.3508\n",
      "Epoch 2062/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 529.6408 - val_loss: 627.9461\n",
      "Epoch 2063/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 529.4769 - val_loss: 630.5075\n",
      "Epoch 2064/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 531.7994 - val_loss: 627.0001\n",
      "Epoch 2065/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.7503 - val_loss: 626.5573\n",
      "Epoch 2066/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 529.7434 - val_loss: 629.8028\n",
      "Epoch 2067/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 529.2119 - val_loss: 627.1163\n",
      "Epoch 2068/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 530.1276 - val_loss: 630.0653\n",
      "Epoch 2069/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.9287 - val_loss: 626.1317\n",
      "Epoch 2070/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 531.2295 - val_loss: 626.4564\n",
      "Epoch 2071/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 531.2705 - val_loss: 627.2460\n",
      "Epoch 2072/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.9778 - val_loss: 626.2780\n",
      "Epoch 2073/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.0325 - val_loss: 626.8914\n",
      "Epoch 2074/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 530.4343 - val_loss: 627.3113\n",
      "Epoch 2075/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 530.4187 - val_loss: 628.9121\n",
      "Epoch 2076/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 529.3297 - val_loss: 625.9536\n",
      "Epoch 2077/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 529.5775 - val_loss: 628.4050\n",
      "Epoch 2078/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.4103 - val_loss: 626.5183\n",
      "Epoch 2079/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 529.4355 - val_loss: 628.3362\n",
      "Epoch 2080/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 531.2412 - val_loss: 627.4970\n",
      "Epoch 2081/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 530.1238 - val_loss: 625.5370\n",
      "Epoch 2082/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 530.0689 - val_loss: 627.2052\n",
      "Epoch 2083/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.4304 - val_loss: 628.8046\n",
      "Epoch 2084/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 531.5880 - val_loss: 627.6965\n",
      "Epoch 2085/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.7647 - val_loss: 626.3338\n",
      "Epoch 2086/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 536.0602 - val_loss: 635.0267\n",
      "Epoch 2087/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 530.0611 - val_loss: 628.2666\n",
      "Epoch 2088/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 530.4317 - val_loss: 626.6577\n",
      "Epoch 2089/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.2094 - val_loss: 625.4566\n",
      "Epoch 2090/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 530.3408 - val_loss: 627.8025\n",
      "Epoch 2091/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 531.4569 - val_loss: 629.0080\n",
      "Epoch 2092/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 529.1124 - val_loss: 625.1379\n",
      "Epoch 2093/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 532.2068 - val_loss: 624.3548\n",
      "Epoch 2094/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 529.1367 - val_loss: 625.0974\n",
      "Epoch 2095/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 530.3758 - val_loss: 629.8174\n",
      "Epoch 2096/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.6931 - val_loss: 627.8115\n",
      "Epoch 2097/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 531.6702 - val_loss: 626.1452\n",
      "Epoch 2098/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 533.8627 - val_loss: 626.7994\n",
      "Epoch 2099/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.9917 - val_loss: 627.1921\n",
      "Epoch 2100/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.4769 - val_loss: 625.8613\n",
      "Epoch 2101/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.7005 - val_loss: 627.8165\n",
      "Epoch 2102/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.7699 - val_loss: 626.3204\n",
      "Epoch 2103/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 530.6749 - val_loss: 628.7776\n",
      "Epoch 2104/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 529.8503 - val_loss: 627.7727\n",
      "Epoch 2105/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 530.2473 - val_loss: 627.5006\n",
      "Epoch 2106/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.0988 - val_loss: 625.1594\n",
      "Epoch 2107/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.5357 - val_loss: 626.1048\n",
      "Epoch 2108/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.2094 - val_loss: 625.6746\n",
      "Epoch 2109/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.7461 - val_loss: 624.2914\n",
      "Epoch 2110/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 530.6150 - val_loss: 627.2678\n",
      "Epoch 2111/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.3837 - val_loss: 625.5883\n",
      "Epoch 2112/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.4645 - val_loss: 623.9426\n",
      "Epoch 2113/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.7169 - val_loss: 627.8103\n",
      "Epoch 2114/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.4369 - val_loss: 627.4059\n",
      "Epoch 2115/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 530.1724 - val_loss: 623.2128\n",
      "Epoch 2116/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.6244 - val_loss: 624.3314\n",
      "Epoch 2117/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.3622 - val_loss: 626.0111\n",
      "Epoch 2118/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.7327 - val_loss: 624.6229\n",
      "Epoch 2119/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.6036 - val_loss: 626.6016\n",
      "Epoch 2120/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.8187 - val_loss: 625.6239\n",
      "Epoch 2121/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.3962 - val_loss: 629.5632\n",
      "Epoch 2122/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 529.5683 - val_loss: 625.1284\n",
      "Epoch 2123/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 529.7219 - val_loss: 624.7656\n",
      "Epoch 2124/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.7945 - val_loss: 623.7233\n",
      "Epoch 2125/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.8684 - val_loss: 625.0999\n",
      "Epoch 2126/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.2351 - val_loss: 628.1825\n",
      "Epoch 2127/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 529.0520 - val_loss: 625.7115\n",
      "Epoch 2128/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.1699 - val_loss: 628.3111\n",
      "Epoch 2129/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.8694 - val_loss: 626.5105\n",
      "Epoch 2130/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 531.2139 - val_loss: 625.1753\n",
      "Epoch 2131/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 529.9534 - val_loss: 627.1443\n",
      "Epoch 2132/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 531.0526 - val_loss: 628.1346\n",
      "Epoch 2133/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 531.1026 - val_loss: 628.0633\n",
      "Epoch 2134/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.9790 - val_loss: 625.6465\n",
      "Epoch 2135/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.0696 - val_loss: 623.0324\n",
      "Epoch 2136/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.6218 - val_loss: 625.4446\n",
      "Epoch 2137/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 530.2406 - val_loss: 625.0894\n",
      "Epoch 2138/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.3395 - val_loss: 624.2824\n",
      "Epoch 2139/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.3507 - val_loss: 624.6505\n",
      "Epoch 2140/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.7748 - val_loss: 624.1323\n",
      "Epoch 2141/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.3410 - val_loss: 624.5145\n",
      "Epoch 2142/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.3995 - val_loss: 625.6641\n",
      "Epoch 2143/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.6679 - val_loss: 622.5606\n",
      "Epoch 2144/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.7454 - val_loss: 627.3089\n",
      "Epoch 2145/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.5603 - val_loss: 625.9886\n",
      "Epoch 2146/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.3188 - val_loss: 624.8220\n",
      "Epoch 2147/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.0365 - val_loss: 626.7301\n",
      "Epoch 2148/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.7901 - val_loss: 626.1180\n",
      "Epoch 2149/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.9505 - val_loss: 626.3948\n",
      "Epoch 2150/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 525.7867 - val_loss: 625.0118\n",
      "Epoch 2151/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.7549 - val_loss: 624.7371\n",
      "Epoch 2152/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 530.3425 - val_loss: 628.8998\n",
      "Epoch 2153/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.3882 - val_loss: 623.6501\n",
      "Epoch 2154/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.2641 - val_loss: 623.0868\n",
      "Epoch 2155/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.5669 - val_loss: 625.7904\n",
      "Epoch 2156/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.0528 - val_loss: 626.4123\n",
      "Epoch 2157/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 525.7023 - val_loss: 625.6098\n",
      "Epoch 2158/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.9240 - val_loss: 625.7523\n",
      "Epoch 2159/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.3544 - val_loss: 622.6726\n",
      "Epoch 2160/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.5099 - val_loss: 624.4617\n",
      "Epoch 2161/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 533.3173 - val_loss: 623.1557\n",
      "Epoch 2162/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.9090 - val_loss: 625.6979\n",
      "Epoch 2163/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 525.5444 - val_loss: 625.6851\n",
      "Epoch 2164/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.6860 - val_loss: 623.4173\n",
      "Epoch 2165/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.7935 - val_loss: 622.7375\n",
      "Epoch 2166/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.9508 - val_loss: 625.3875\n",
      "Epoch 2167/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.6301 - val_loss: 626.1865\n",
      "Epoch 2168/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.7608 - val_loss: 624.4961\n",
      "Epoch 2169/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.4047 - val_loss: 624.9416\n",
      "Epoch 2170/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.2626 - val_loss: 625.9118\n",
      "Epoch 2171/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.7728 - val_loss: 624.8549\n",
      "Epoch 2172/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.0090 - val_loss: 624.6939\n",
      "Epoch 2173/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.8021 - val_loss: 623.9648\n",
      "Epoch 2174/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.1719 - val_loss: 625.5222\n",
      "Epoch 2175/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.0278 - val_loss: 623.9199\n",
      "Epoch 2176/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.9834 - val_loss: 622.7999\n",
      "Epoch 2177/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.3415 - val_loss: 624.2372\n",
      "Epoch 2178/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.2180 - val_loss: 627.1925\n",
      "Epoch 2179/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.0388 - val_loss: 623.4049\n",
      "Epoch 2180/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 525.5056 - val_loss: 624.3355\n",
      "Epoch 2181/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 525.8112 - val_loss: 624.4190\n",
      "Epoch 2182/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.5272 - val_loss: 624.7930\n",
      "Epoch 2183/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 525.9868 - val_loss: 625.6160\n",
      "Epoch 2184/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 525.3191 - val_loss: 624.7888\n",
      "Epoch 2185/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.3688 - val_loss: 623.0794\n",
      "Epoch 2186/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.0813 - val_loss: 625.3343\n",
      "Epoch 2187/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 525.2517 - val_loss: 622.9089\n",
      "Epoch 2188/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.0845 - val_loss: 622.9475\n",
      "Epoch 2189/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 529.6657 - val_loss: 624.2873\n",
      "Epoch 2190/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 525.6569 - val_loss: 623.1892\n",
      "Epoch 2191/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.2548 - val_loss: 623.7014\n",
      "Epoch 2192/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.1655 - val_loss: 627.1495\n",
      "Epoch 2193/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 529.3333 - val_loss: 624.9840\n",
      "Epoch 2194/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 529.6296 - val_loss: 625.2667\n",
      "Epoch 2195/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.8572 - val_loss: 623.6426\n",
      "Epoch 2196/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 529.7524 - val_loss: 628.3757\n",
      "Epoch 2197/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.9896 - val_loss: 624.5357\n",
      "Epoch 2198/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.4590 - val_loss: 624.3500\n",
      "Epoch 2199/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.0824 - val_loss: 622.0407\n",
      "Epoch 2200/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 525.9754 - val_loss: 623.3531\n",
      "Epoch 2201/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.6079 - val_loss: 622.1083\n",
      "Epoch 2202/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 525.2640 - val_loss: 624.9600\n",
      "Epoch 2203/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.5480 - val_loss: 622.3020\n",
      "Epoch 2204/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 525.6889 - val_loss: 624.1124\n",
      "Epoch 2205/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 525.1096 - val_loss: 622.8382\n",
      "Epoch 2206/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 525.0042 - val_loss: 623.9668\n",
      "Epoch 2207/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.9295 - val_loss: 623.1302\n",
      "Epoch 2208/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.0450 - val_loss: 622.8288\n",
      "Epoch 2209/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.4957 - val_loss: 624.7954\n",
      "Epoch 2210/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.2415 - val_loss: 621.5612\n",
      "Epoch 2211/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.3425 - val_loss: 624.5456\n",
      "Epoch 2212/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.1490 - val_loss: 622.0297\n",
      "Epoch 2213/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 529.3059 - val_loss: 624.0259\n",
      "Epoch 2214/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.1477 - val_loss: 623.2087\n",
      "Epoch 2215/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.1381 - val_loss: 623.6350\n",
      "Epoch 2216/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.6837 - val_loss: 621.2294\n",
      "Epoch 2217/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 525.7009 - val_loss: 623.2300\n",
      "Epoch 2218/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.8827 - val_loss: 622.7758\n",
      "Epoch 2219/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.5256 - val_loss: 624.6883\n",
      "Epoch 2220/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.3419 - val_loss: 622.1769\n",
      "Epoch 2221/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.4028 - val_loss: 622.1588\n",
      "Epoch 2222/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.1655 - val_loss: 623.5958\n",
      "Epoch 2223/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 525.9170 - val_loss: 624.0843\n",
      "Epoch 2224/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.4842 - val_loss: 621.9061\n",
      "Epoch 2225/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.8174 - val_loss: 626.1603\n",
      "Epoch 2226/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.0844 - val_loss: 624.8043\n",
      "Epoch 2227/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 525.3332 - val_loss: 622.3946\n",
      "Epoch 2228/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.0428 - val_loss: 625.0073\n",
      "Epoch 2229/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 525.6038 - val_loss: 625.9326\n",
      "Epoch 2230/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.0559 - val_loss: 623.7190\n",
      "Epoch 2231/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.9085 - val_loss: 622.4957\n",
      "Epoch 2232/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 525.6867 - val_loss: 623.5924\n",
      "Epoch 2233/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 525.8759 - val_loss: 622.8681\n",
      "Epoch 2234/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 525.7959 - val_loss: 621.8096\n",
      "Epoch 2235/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 525.6984 - val_loss: 621.7314\n",
      "Epoch 2236/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.0998 - val_loss: 621.5922\n",
      "Epoch 2237/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 525.3189 - val_loss: 620.1835\n",
      "Epoch 2238/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 525.7233 - val_loss: 622.5744\n",
      "Epoch 2239/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.1825 - val_loss: 625.1065\n",
      "Epoch 2240/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 528.7723 - val_loss: 623.2109\n",
      "Epoch 2241/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 525.2075 - val_loss: 622.2841\n",
      "Epoch 2242/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.7584 - val_loss: 624.9991\n",
      "Epoch 2243/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.5763 - val_loss: 624.8373\n",
      "Epoch 2244/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.9344 - val_loss: 624.8416\n",
      "Epoch 2245/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.4361 - val_loss: 620.2390\n",
      "Epoch 2246/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 525.8534 - val_loss: 622.1420\n",
      "Epoch 2247/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.8176 - val_loss: 625.0944\n",
      "Epoch 2248/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.1445 - val_loss: 623.2787\n",
      "Epoch 2249/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.9929 - val_loss: 623.2153\n",
      "Epoch 2250/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 541.4146Epoch: 2250 - loss: 523.851160 - val_loss: 622.160666\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.8512 - val_loss: 622.1607\n",
      "Epoch 2251/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.8040 - val_loss: 622.6582\n",
      "Epoch 2252/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 525.7915 - val_loss: 622.1281\n",
      "Epoch 2253/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.1535 - val_loss: 621.9068\n",
      "Epoch 2254/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.0619 - val_loss: 621.7112\n",
      "Epoch 2255/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.9027 - val_loss: 621.6119\n",
      "Epoch 2256/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.6885 - val_loss: 620.7412\n",
      "Epoch 2257/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 525.0120 - val_loss: 621.9771\n",
      "Epoch 2258/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.3428 - val_loss: 621.9926\n",
      "Epoch 2259/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.7720 - val_loss: 621.9122\n",
      "Epoch 2260/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.4007 - val_loss: 621.9385\n",
      "Epoch 2261/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.0960 - val_loss: 623.4422\n",
      "Epoch 2262/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.6254 - val_loss: 621.4007\n",
      "Epoch 2263/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.3411 - val_loss: 623.3488\n",
      "Epoch 2264/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.8577 - val_loss: 625.2351\n",
      "Epoch 2265/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.8130 - val_loss: 619.6391\n",
      "Epoch 2266/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 525.2750 - val_loss: 622.7349\n",
      "Epoch 2267/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.7658 - val_loss: 622.9860\n",
      "Epoch 2268/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.1372 - val_loss: 618.7265\n",
      "Epoch 2269/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.9798 - val_loss: 620.9895\n",
      "Epoch 2270/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.5184 - val_loss: 622.1858\n",
      "Epoch 2271/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.9770 - val_loss: 624.5069\n",
      "Epoch 2272/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.1958 - val_loss: 622.4027\n",
      "Epoch 2273/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.9828 - val_loss: 625.0462\n",
      "Epoch 2274/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 525.5177 - val_loss: 622.5989\n",
      "Epoch 2275/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.9123 - val_loss: 622.4670\n",
      "Epoch 2276/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.2359 - val_loss: 620.9491\n",
      "Epoch 2277/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.1658 - val_loss: 622.9509\n",
      "Epoch 2278/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.8673 - val_loss: 622.8356\n",
      "Epoch 2279/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.0541 - val_loss: 619.8810\n",
      "Epoch 2280/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 525.5235 - val_loss: 622.4335\n",
      "Epoch 2281/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.6193 - val_loss: 620.9727\n",
      "Epoch 2282/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 525.3824 - val_loss: 619.1661\n",
      "Epoch 2283/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.7554 - val_loss: 623.9752\n",
      "Epoch 2284/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.6136 - val_loss: 620.1801\n",
      "Epoch 2285/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.0565 - val_loss: 623.1798\n",
      "Epoch 2286/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.2542 - val_loss: 622.6103\n",
      "Epoch 2287/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.4042 - val_loss: 620.6124\n",
      "Epoch 2288/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 525.3491 - val_loss: 622.3346\n",
      "Epoch 2289/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.3089 - val_loss: 621.0038\n",
      "Epoch 2290/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.8986 - val_loss: 620.6433\n",
      "Epoch 2291/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.5484 - val_loss: 622.3375\n",
      "Epoch 2292/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.8675 - val_loss: 622.3254\n",
      "Epoch 2293/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.6813 - val_loss: 620.3946\n",
      "Epoch 2294/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.7042 - val_loss: 626.5123\n",
      "Epoch 2295/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.6426 - val_loss: 621.2542\n",
      "Epoch 2296/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.2682 - val_loss: 620.8564\n",
      "Epoch 2297/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.9567 - val_loss: 620.1518\n",
      "Epoch 2298/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.4595 - val_loss: 622.9674\n",
      "Epoch 2299/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 525.1452 - val_loss: 622.1497\n",
      "Epoch 2300/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.5919 - val_loss: 621.3736\n",
      "Epoch 2301/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.6629 - val_loss: 619.7575\n",
      "Epoch 2302/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.8145 - val_loss: 619.5020\n",
      "Epoch 2303/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.2431 - val_loss: 620.4795\n",
      "Epoch 2304/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 523.9925 - val_loss: 619.4633\n",
      "Epoch 2305/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.3325 - val_loss: 623.0746\n",
      "Epoch 2306/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.2046 - val_loss: 621.5270\n",
      "Epoch 2307/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.8021 - val_loss: 618.7879\n",
      "Epoch 2308/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.2041 - val_loss: 618.6331\n",
      "Epoch 2309/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.7831 - val_loss: 621.5446\n",
      "Epoch 2310/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.3908 - val_loss: 619.3151\n",
      "Epoch 2311/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.7348 - val_loss: 618.1244\n",
      "Epoch 2312/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.8086 - val_loss: 621.4924\n",
      "Epoch 2313/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.8764 - val_loss: 620.9048\n",
      "Epoch 2314/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.4950 - val_loss: 621.1749\n",
      "Epoch 2315/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.8628 - val_loss: 620.5044\n",
      "Epoch 2316/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.3532 - val_loss: 622.2887\n",
      "Epoch 2317/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.2753 - val_loss: 619.0436\n",
      "Epoch 2318/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.8739 - val_loss: 622.2972\n",
      "Epoch 2319/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.4969 - val_loss: 619.2127\n",
      "Epoch 2320/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.6228 - val_loss: 623.3280\n",
      "Epoch 2321/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.8615 - val_loss: 619.4839\n",
      "Epoch 2322/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.1371 - val_loss: 624.5363\n",
      "Epoch 2323/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.7221 - val_loss: 619.8044\n",
      "Epoch 2324/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.8319 - val_loss: 619.7175\n",
      "Epoch 2325/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.2002 - val_loss: 619.2222\n",
      "Epoch 2326/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.2766 - val_loss: 620.7655\n",
      "Epoch 2327/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 526.9000 - val_loss: 620.1722\n",
      "Epoch 2328/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 523.2165 - val_loss: 621.7121\n",
      "Epoch 2329/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.4358 - val_loss: 622.8386\n",
      "Epoch 2330/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.8084 - val_loss: 619.9848\n",
      "Epoch 2331/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.6118 - val_loss: 619.6287\n",
      "Epoch 2332/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.1216 - val_loss: 619.1657\n",
      "Epoch 2333/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.4969 - val_loss: 620.5108\n",
      "Epoch 2334/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 527.0907 - val_loss: 618.5324\n",
      "Epoch 2335/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.3257 - val_loss: 619.1234\n",
      "Epoch 2336/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.6471 - val_loss: 619.0470\n",
      "Epoch 2337/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.4350 - val_loss: 622.7891\n",
      "Epoch 2338/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.3997 - val_loss: 619.7079\n",
      "Epoch 2339/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.0966 - val_loss: 623.8991\n",
      "Epoch 2340/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.1566 - val_loss: 621.8511\n",
      "Epoch 2341/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.8596 - val_loss: 618.3084\n",
      "Epoch 2342/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.2427 - val_loss: 618.8391\n",
      "Epoch 2343/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.0149 - val_loss: 620.7644\n",
      "Epoch 2344/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.4799 - val_loss: 621.7620\n",
      "Epoch 2345/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.1527 - val_loss: 618.1585\n",
      "Epoch 2346/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.7788 - val_loss: 620.7031\n",
      "Epoch 2347/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.7390 - val_loss: 620.5654\n",
      "Epoch 2348/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.1620 - val_loss: 619.2707\n",
      "Epoch 2349/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.2301 - val_loss: 618.9542\n",
      "Epoch 2350/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.8692 - val_loss: 621.1524\n",
      "Epoch 2351/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.8999 - val_loss: 619.0944\n",
      "Epoch 2352/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.2285 - val_loss: 617.9930\n",
      "Epoch 2353/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.0930 - val_loss: 620.0457\n",
      "Epoch 2354/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.5994 - val_loss: 620.5473\n",
      "Epoch 2355/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.8441 - val_loss: 618.8013\n",
      "Epoch 2356/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.5302 - val_loss: 620.4951\n",
      "Epoch 2357/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.6367 - val_loss: 616.8854\n",
      "Epoch 2358/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.7105 - val_loss: 619.5354\n",
      "Epoch 2359/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.6327 - val_loss: 618.2500\n",
      "Epoch 2360/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.9223 - val_loss: 618.4987\n",
      "Epoch 2361/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.1044 - val_loss: 618.2898\n",
      "Epoch 2362/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.2526 - val_loss: 620.8826\n",
      "Epoch 2363/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 527.6422 - val_loss: 621.2422\n",
      "Epoch 2364/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.3868 - val_loss: 618.1788\n",
      "Epoch 2365/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.2973 - val_loss: 620.6584\n",
      "Epoch 2366/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.1995 - val_loss: 619.0656\n",
      "Epoch 2367/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.5997 - val_loss: 620.0142\n",
      "Epoch 2368/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.8958 - val_loss: 619.8150\n",
      "Epoch 2369/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.1835 - val_loss: 621.6940\n",
      "Epoch 2370/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.1204 - val_loss: 617.3332\n",
      "Epoch 2371/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.7291 - val_loss: 619.8689\n",
      "Epoch 2372/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.9309 - val_loss: 619.8607\n",
      "Epoch 2373/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.1182 - val_loss: 619.8704\n",
      "Epoch 2374/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.4245 - val_loss: 621.7526\n",
      "Epoch 2375/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.2611 - val_loss: 617.2721\n",
      "Epoch 2376/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.5891 - val_loss: 616.7019\n",
      "Epoch 2377/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.0811 - val_loss: 617.1185\n",
      "Epoch 2378/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.8491 - val_loss: 619.2761\n",
      "Epoch 2379/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.1007 - val_loss: 619.9380\n",
      "Epoch 2380/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.2641 - val_loss: 619.0403\n",
      "Epoch 2381/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.7244 - val_loss: 620.3432\n",
      "Epoch 2382/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.0318 - val_loss: 618.4927\n",
      "Epoch 2383/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.1228 - val_loss: 618.0877\n",
      "Epoch 2384/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.9747 - val_loss: 616.5431\n",
      "Epoch 2385/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.9792 - val_loss: 616.6407\n",
      "Epoch 2386/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.3686 - val_loss: 618.8978\n",
      "Epoch 2387/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.5077 - val_loss: 616.4303\n",
      "Epoch 2388/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.5086 - val_loss: 622.7150\n",
      "Epoch 2389/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.5141 - val_loss: 618.6966\n",
      "Epoch 2390/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.0758 - val_loss: 619.6294\n",
      "Epoch 2391/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.3376 - val_loss: 617.6810\n",
      "Epoch 2392/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.7314 - val_loss: 621.6779\n",
      "Epoch 2393/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.1034 - val_loss: 619.0517\n",
      "Epoch 2394/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.7319 - val_loss: 617.0435\n",
      "Epoch 2395/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.7653 - val_loss: 618.4325\n",
      "Epoch 2396/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 524.0097 - val_loss: 616.5604\n",
      "Epoch 2397/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.5667 - val_loss: 618.0549\n",
      "Epoch 2398/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.9620 - val_loss: 618.2391\n",
      "Epoch 2399/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.2143 - val_loss: 617.7322\n",
      "Epoch 2400/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.1204 - val_loss: 617.0756\n",
      "Epoch 2401/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.6799 - val_loss: 617.0303\n",
      "Epoch 2402/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.3839 - val_loss: 617.2674\n",
      "Epoch 2403/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.1279 - val_loss: 616.2041\n",
      "Epoch 2404/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.5682 - val_loss: 617.5981\n",
      "Epoch 2405/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.8597 - val_loss: 620.9628\n",
      "Epoch 2406/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.1721 - val_loss: 618.6114\n",
      "Epoch 2407/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.5384 - val_loss: 619.2757\n",
      "Epoch 2408/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.8718 - val_loss: 618.1619\n",
      "Epoch 2409/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.1787 - val_loss: 618.3621\n",
      "Epoch 2410/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.0720 - val_loss: 617.1845\n",
      "Epoch 2411/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.3148 - val_loss: 617.5094\n",
      "Epoch 2412/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.7330 - val_loss: 621.2847\n",
      "Epoch 2413/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.8189 - val_loss: 615.7631\n",
      "Epoch 2414/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.0387 - val_loss: 618.8078\n",
      "Epoch 2415/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.8937 - val_loss: 619.4339\n",
      "Epoch 2416/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.6012 - val_loss: 617.5022\n",
      "Epoch 2417/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.9416 - val_loss: 616.4350\n",
      "Epoch 2418/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.0910 - val_loss: 617.6777\n",
      "Epoch 2419/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 519.7533 - val_loss: 617.4313\n",
      "Epoch 2420/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.8642 - val_loss: 617.8964\n",
      "Epoch 2421/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.2576 - val_loss: 616.7640\n",
      "Epoch 2422/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 520.4948 - val_loss: 618.2384\n",
      "Epoch 2423/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.4749 - val_loss: 617.4898\n",
      "Epoch 2424/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 525.3686 - val_loss: 620.3858\n",
      "Epoch 2425/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.5360 - val_loss: 620.4438\n",
      "Epoch 2426/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.2000 - val_loss: 617.5772\n",
      "Epoch 2427/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.9556 - val_loss: 615.7431\n",
      "Epoch 2428/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.8403 - val_loss: 616.6372\n",
      "Epoch 2429/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.2076 - val_loss: 616.5655\n",
      "Epoch 2430/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.2110 - val_loss: 615.8955\n",
      "Epoch 2431/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.5323 - val_loss: 618.1695\n",
      "Epoch 2432/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.5069 - val_loss: 615.9239\n",
      "Epoch 2433/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.8906 - val_loss: 617.9150\n",
      "Epoch 2434/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.6266 - val_loss: 616.7901\n",
      "Epoch 2435/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.6009 - val_loss: 619.7701\n",
      "Epoch 2436/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.6466 - val_loss: 618.0833\n",
      "Epoch 2437/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.2324 - val_loss: 617.9480\n",
      "Epoch 2438/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.1692 - val_loss: 615.6918\n",
      "Epoch 2439/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.8116 - val_loss: 619.1351\n",
      "Epoch 2440/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.2233 - val_loss: 615.9818\n",
      "Epoch 2441/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.1991 - val_loss: 616.9633\n",
      "Epoch 2442/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.0219 - val_loss: 616.2369\n",
      "Epoch 2443/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 520.1800 - val_loss: 616.6103\n",
      "Epoch 2444/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.7360 - val_loss: 617.0204\n",
      "Epoch 2445/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.9477 - val_loss: 617.4454\n",
      "Epoch 2446/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.4379 - val_loss: 618.7398\n",
      "Epoch 2447/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.5231 - val_loss: 616.7845\n",
      "Epoch 2448/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 520.1926 - val_loss: 616.6761\n",
      "Epoch 2449/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 520.4482 - val_loss: 617.9181\n",
      "Epoch 2450/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.2946 - val_loss: 615.6276\n",
      "Epoch 2451/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.4175 - val_loss: 616.9235\n",
      "Epoch 2452/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.2224 - val_loss: 617.9786\n",
      "Epoch 2453/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 519.3241 - val_loss: 617.4425\n",
      "Epoch 2454/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.2671 - val_loss: 617.0026\n",
      "Epoch 2455/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.2356 - val_loss: 616.3544\n",
      "Epoch 2456/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.9689 - val_loss: 615.7222\n",
      "Epoch 2457/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 519.3953 - val_loss: 618.2435\n",
      "Epoch 2458/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 520.3516 - val_loss: 616.7552\n",
      "Epoch 2459/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.8166 - val_loss: 617.5532\n",
      "Epoch 2460/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.2561 - val_loss: 614.8313\n",
      "Epoch 2461/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.3369 - val_loss: 617.9994\n",
      "Epoch 2462/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.6989 - val_loss: 616.3758\n",
      "Epoch 2463/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.9476 - val_loss: 615.6634\n",
      "Epoch 2464/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.8161 - val_loss: 615.5940\n",
      "Epoch 2465/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.9039 - val_loss: 616.6171\n",
      "Epoch 2466/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.0186 - val_loss: 616.5811\n",
      "Epoch 2467/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.2069 - val_loss: 616.3807\n",
      "Epoch 2468/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.4967 - val_loss: 616.4276\n",
      "Epoch 2469/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.3181 - val_loss: 616.6541\n",
      "Epoch 2470/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.1114 - val_loss: 616.2490\n",
      "Epoch 2471/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.9589 - val_loss: 617.1775\n",
      "Epoch 2472/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.8380 - val_loss: 619.4488\n",
      "Epoch 2473/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.7211 - val_loss: 617.2833\n",
      "Epoch 2474/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.4608 - val_loss: 616.8521\n",
      "Epoch 2475/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.8536 - val_loss: 616.8349\n",
      "Epoch 2476/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.8571 - val_loss: 616.5155\n",
      "Epoch 2477/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.1844 - val_loss: 616.5795\n",
      "Epoch 2478/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.7935 - val_loss: 617.9257\n",
      "Epoch 2479/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.7233 - val_loss: 619.4544\n",
      "Epoch 2480/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.2912 - val_loss: 616.5030\n",
      "Epoch 2481/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.7050 - val_loss: 617.5687\n",
      "Epoch 2482/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.1674 - val_loss: 613.8355\n",
      "Epoch 2483/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.1704 - val_loss: 615.2736\n",
      "Epoch 2484/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.7205 - val_loss: 616.5695\n",
      "Epoch 2485/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.0150 - val_loss: 617.6287\n",
      "Epoch 2486/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.7542 - val_loss: 615.1698\n",
      "Epoch 2487/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.8638 - val_loss: 617.5632\n",
      "Epoch 2488/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.5438 - val_loss: 615.9318\n",
      "Epoch 2489/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.9967 - val_loss: 616.6330\n",
      "Epoch 2490/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.4467 - val_loss: 617.4551\n",
      "Epoch 2491/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.8984 - val_loss: 615.3873\n",
      "Epoch 2492/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.5095 - val_loss: 617.2267\n",
      "Epoch 2493/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.1845 - val_loss: 616.7721\n",
      "Epoch 2494/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.0512 - val_loss: 613.8992\n",
      "Epoch 2495/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.2462 - val_loss: 615.3940\n",
      "Epoch 2496/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.4088 - val_loss: 616.1038\n",
      "Epoch 2497/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.7370 - val_loss: 615.4126\n",
      "Epoch 2498/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.0546 - val_loss: 616.8390\n",
      "Epoch 2499/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.9820 - val_loss: 616.5219\n",
      "Epoch 2500/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 318.0287Epoch: 2500 - loss: 523.966156 - val_loss: 617.649748\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.9662 - val_loss: 617.6497\n",
      "Epoch 2501/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.7869 - val_loss: 616.5611\n",
      "Epoch 2502/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.0537 - val_loss: 615.6815\n",
      "Epoch 2503/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.2846 - val_loss: 616.4433\n",
      "Epoch 2504/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.8670 - val_loss: 619.0876\n",
      "Epoch 2505/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.9434 - val_loss: 617.0121\n",
      "Epoch 2506/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.4746 - val_loss: 615.0704\n",
      "Epoch 2507/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.8466 - val_loss: 616.5009\n",
      "Epoch 2508/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.4212 - val_loss: 615.2575\n",
      "Epoch 2509/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.8025 - val_loss: 617.7898\n",
      "Epoch 2510/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.6136 - val_loss: 618.0554\n",
      "Epoch 2511/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.4599 - val_loss: 617.5085\n",
      "Epoch 2512/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.3731 - val_loss: 616.0889\n",
      "Epoch 2513/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.0272 - val_loss: 616.2157\n",
      "Epoch 2514/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.3618 - val_loss: 616.0194\n",
      "Epoch 2515/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.7042 - val_loss: 615.6587\n",
      "Epoch 2516/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.2394 - val_loss: 616.9674\n",
      "Epoch 2517/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.3718 - val_loss: 614.9936\n",
      "Epoch 2518/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.8797 - val_loss: 619.2655\n",
      "Epoch 2519/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.5184 - val_loss: 614.1665\n",
      "Epoch 2520/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.0575 - val_loss: 616.6680\n",
      "Epoch 2521/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.8169 - val_loss: 616.9444\n",
      "Epoch 2522/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 522.2635 - val_loss: 614.7280\n",
      "Epoch 2523/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.5173 - val_loss: 615.6965\n",
      "Epoch 2524/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.5855 - val_loss: 617.1468\n",
      "Epoch 2525/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.4408 - val_loss: 614.2646\n",
      "Epoch 2526/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.0909 - val_loss: 614.6656\n",
      "Epoch 2527/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.2843 - val_loss: 615.2487\n",
      "Epoch 2528/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 518.2252 - val_loss: 615.0524\n",
      "Epoch 2529/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.0339 - val_loss: 617.3219\n",
      "Epoch 2530/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.4710 - val_loss: 614.6242\n",
      "Epoch 2531/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.2558 - val_loss: 613.8828\n",
      "Epoch 2532/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.2248 - val_loss: 617.6136\n",
      "Epoch 2533/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 523.8327 - val_loss: 616.3162\n",
      "Epoch 2534/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.1247 - val_loss: 613.8731\n",
      "Epoch 2535/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 518.5653 - val_loss: 614.8027\n",
      "Epoch 2536/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.4152 - val_loss: 616.1580\n",
      "Epoch 2537/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 520.1758 - val_loss: 616.3047\n",
      "Epoch 2538/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 517.6372 - val_loss: 614.5031\n",
      "Epoch 2539/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.6133 - val_loss: 617.7373\n",
      "Epoch 2540/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 520.9249 - val_loss: 615.4135\n",
      "Epoch 2541/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 518.4753 - val_loss: 615.2873\n",
      "Epoch 2542/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 519.8218 - val_loss: 616.7794\n",
      "Epoch 2543/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 517.1932 - val_loss: 615.1171\n",
      "Epoch 2544/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 520.0768 - val_loss: 616.9157\n",
      "Epoch 2545/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.4716 - val_loss: 613.7275\n",
      "Epoch 2546/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.0901 - val_loss: 613.5465\n",
      "Epoch 2547/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.0429 - val_loss: 613.3564\n",
      "Epoch 2548/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 518.1820 - val_loss: 613.1076\n",
      "Epoch 2549/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 518.2242 - val_loss: 614.2853\n",
      "Epoch 2550/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 517.5410 - val_loss: 613.8363\n",
      "Epoch 2551/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 518.4877 - val_loss: 614.9944\n",
      "Epoch 2552/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 518.0105 - val_loss: 614.2981\n",
      "Epoch 2553/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 518.6228 - val_loss: 612.3675\n",
      "Epoch 2554/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.8988 - val_loss: 613.3045\n",
      "Epoch 2555/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 11us/sample - loss: 518.6218 - val_loss: 615.2509\n",
      "Epoch 2556/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 518.2622 - val_loss: 614.3029\n",
      "Epoch 2557/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.5449 - val_loss: 617.7318\n",
      "Epoch 2558/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 518.6121 - val_loss: 615.1121\n",
      "Epoch 2559/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 520.3899 - val_loss: 615.7633\n",
      "Epoch 2560/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 522.5249 - val_loss: 616.6438\n",
      "Epoch 2561/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 517.6724 - val_loss: 616.3797\n",
      "Epoch 2562/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 519.2663 - val_loss: 616.6705\n",
      "Epoch 2563/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 520.6749 - val_loss: 618.4804\n",
      "Epoch 2564/10000\n",
      "3000/3000 [==============================] - 0s 14us/sample - loss: 520.4694 - val_loss: 614.0979\n",
      "Epoch 2565/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 520.0018 - val_loss: 616.6849\n",
      "Epoch 2566/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.7418 - val_loss: 613.8521\n",
      "Epoch 2567/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.2033 - val_loss: 613.8213\n",
      "Epoch 2568/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 518.3999 - val_loss: 614.2447\n",
      "Epoch 2569/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 518.9929 - val_loss: 613.7027\n",
      "Epoch 2570/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 518.3953 - val_loss: 615.8887\n",
      "Epoch 2571/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.7948 - val_loss: 611.1454\n",
      "Epoch 2572/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 518.4763 - val_loss: 615.7209\n",
      "Epoch 2573/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.1026 - val_loss: 614.0322\n",
      "Epoch 2574/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.2980 - val_loss: 612.1855\n",
      "Epoch 2575/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 516.6813 - val_loss: 614.8324\n",
      "Epoch 2576/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.1448 - val_loss: 616.4956\n",
      "Epoch 2577/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.7451 - val_loss: 613.7841\n",
      "Epoch 2578/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.4363 - val_loss: 612.3040\n",
      "Epoch 2579/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.7572 - val_loss: 613.8708\n",
      "Epoch 2580/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.8671 - val_loss: 614.4804\n",
      "Epoch 2581/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.6040 - val_loss: 615.5485\n",
      "Epoch 2582/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.8279 - val_loss: 613.9102\n",
      "Epoch 2583/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.8843 - val_loss: 617.0817\n",
      "Epoch 2584/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.1239 - val_loss: 612.4301\n",
      "Epoch 2585/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.5041 - val_loss: 614.5440\n",
      "Epoch 2586/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.1086 - val_loss: 616.5737\n",
      "Epoch 2587/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.6513 - val_loss: 617.2610\n",
      "Epoch 2588/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.6702 - val_loss: 615.1311\n",
      "Epoch 2589/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 518.4256 - val_loss: 612.3978\n",
      "Epoch 2590/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.4802 - val_loss: 615.2996\n",
      "Epoch 2591/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.9130 - val_loss: 616.8541\n",
      "Epoch 2592/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.4647 - val_loss: 613.8291\n",
      "Epoch 2593/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.1339 - val_loss: 612.7941\n",
      "Epoch 2594/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.0592 - val_loss: 614.6513\n",
      "Epoch 2595/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.1553 - val_loss: 612.3060\n",
      "Epoch 2596/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.4887 - val_loss: 614.7215\n",
      "Epoch 2597/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.3405 - val_loss: 614.1896\n",
      "Epoch 2598/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.0805 - val_loss: 615.1125\n",
      "Epoch 2599/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.1683 - val_loss: 615.2770\n",
      "Epoch 2600/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.3487 - val_loss: 613.0376\n",
      "Epoch 2601/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.1943 - val_loss: 613.9159\n",
      "Epoch 2602/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.0910 - val_loss: 615.7641\n",
      "Epoch 2603/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.1590 - val_loss: 613.0945\n",
      "Epoch 2604/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.3084 - val_loss: 615.3829\n",
      "Epoch 2605/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 520.2483 - val_loss: 613.3586\n",
      "Epoch 2606/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.9346 - val_loss: 615.5372\n",
      "Epoch 2607/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.5708 - val_loss: 614.9610\n",
      "Epoch 2608/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.1875 - val_loss: 613.9484\n",
      "Epoch 2609/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.6977 - val_loss: 613.3921\n",
      "Epoch 2610/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.1352 - val_loss: 611.0546\n",
      "Epoch 2611/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.4200 - val_loss: 614.6500\n",
      "Epoch 2612/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.1011 - val_loss: 615.0358\n",
      "Epoch 2613/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.2009 - val_loss: 615.6915\n",
      "Epoch 2614/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 521.1372 - val_loss: 613.4046\n",
      "Epoch 2615/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.8961 - val_loss: 613.7542\n",
      "Epoch 2616/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.5768 - val_loss: 616.4440\n",
      "Epoch 2617/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.4433 - val_loss: 611.7366\n",
      "Epoch 2618/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.5712 - val_loss: 613.1144\n",
      "Epoch 2619/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.1522 - val_loss: 613.3169\n",
      "Epoch 2620/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.8391 - val_loss: 613.6033\n",
      "Epoch 2621/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.2266 - val_loss: 614.4639\n",
      "Epoch 2622/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.8164 - val_loss: 615.3866\n",
      "Epoch 2623/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.6533 - val_loss: 614.4303\n",
      "Epoch 2624/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.2805 - val_loss: 614.6523\n",
      "Epoch 2625/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.2485 - val_loss: 616.2397\n",
      "Epoch 2626/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.6541 - val_loss: 615.5657\n",
      "Epoch 2627/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.9234 - val_loss: 611.7622\n",
      "Epoch 2628/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.9822 - val_loss: 614.7467\n",
      "Epoch 2629/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.8887 - val_loss: 612.3971\n",
      "Epoch 2630/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.7593 - val_loss: 613.6354\n",
      "Epoch 2631/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.5691 - val_loss: 614.1601\n",
      "Epoch 2632/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.2550 - val_loss: 613.4304\n",
      "Epoch 2633/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.0741 - val_loss: 613.3947\n",
      "Epoch 2634/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.0756 - val_loss: 616.6765\n",
      "Epoch 2635/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.8153 - val_loss: 612.6552\n",
      "Epoch 2636/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.0971 - val_loss: 613.4218\n",
      "Epoch 2637/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.6470 - val_loss: 613.1468\n",
      "Epoch 2638/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.7607 - val_loss: 615.5761\n",
      "Epoch 2639/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.4277 - val_loss: 611.8130\n",
      "Epoch 2640/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.3796 - val_loss: 615.9417\n",
      "Epoch 2641/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.3469 - val_loss: 614.6003\n",
      "Epoch 2642/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.5383 - val_loss: 615.5514\n",
      "Epoch 2643/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.0443 - val_loss: 614.7127\n",
      "Epoch 2644/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.1266 - val_loss: 613.0514\n",
      "Epoch 2645/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.4681 - val_loss: 612.9247\n",
      "Epoch 2646/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.2491 - val_loss: 614.2845\n",
      "Epoch 2647/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.6516 - val_loss: 612.4424\n",
      "Epoch 2648/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.0019 - val_loss: 613.1231\n",
      "Epoch 2649/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.4391 - val_loss: 612.1278\n",
      "Epoch 2650/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.9814 - val_loss: 614.3183\n",
      "Epoch 2651/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.5315 - val_loss: 617.3710\n",
      "Epoch 2652/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.0842 - val_loss: 612.9520\n",
      "Epoch 2653/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.2532 - val_loss: 613.9437\n",
      "Epoch 2654/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.2787 - val_loss: 614.3299\n",
      "Epoch 2655/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.3611 - val_loss: 614.1062\n",
      "Epoch 2656/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 515.4923 - val_loss: 613.1886\n",
      "Epoch 2657/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.6352 - val_loss: 613.3789\n",
      "Epoch 2658/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.0671 - val_loss: 612.5235\n",
      "Epoch 2659/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.6877 - val_loss: 613.2107\n",
      "Epoch 2660/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.3766 - val_loss: 613.1166\n",
      "Epoch 2661/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.1517 - val_loss: 615.3875\n",
      "Epoch 2662/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.1494 - val_loss: 614.0543\n",
      "Epoch 2663/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.4239 - val_loss: 613.3861\n",
      "Epoch 2664/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.5379 - val_loss: 614.4074\n",
      "Epoch 2665/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.2100 - val_loss: 615.1496\n",
      "Epoch 2666/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.2713 - val_loss: 615.0033\n",
      "Epoch 2667/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 519.0318 - val_loss: 614.3797\n",
      "Epoch 2668/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.4478 - val_loss: 612.0450\n",
      "Epoch 2669/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.5892 - val_loss: 612.9332\n",
      "Epoch 2670/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 516.4136 - val_loss: 614.0957\n",
      "Epoch 2671/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.3050 - val_loss: 611.2593\n",
      "Epoch 2672/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.3577 - val_loss: 612.0011\n",
      "Epoch 2673/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.9645 - val_loss: 612.0226\n",
      "Epoch 2674/10000\n",
      "3000/3000 [==============================] - 0s 17us/sample - loss: 516.8280 - val_loss: 612.4613\n",
      "Epoch 2675/10000\n",
      "3000/3000 [==============================] - 0s 17us/sample - loss: 515.1620 - val_loss: 615.5352\n",
      "Epoch 2676/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 518.2445 - val_loss: 613.4817\n",
      "Epoch 2677/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.2530 - val_loss: 611.3172\n",
      "Epoch 2678/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.1747 - val_loss: 613.0139\n",
      "Epoch 2679/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.2864 - val_loss: 609.8043\n",
      "Epoch 2680/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 519.9826 - val_loss: 613.4535\n",
      "Epoch 2681/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.8865 - val_loss: 611.0876\n",
      "Epoch 2682/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.2206 - val_loss: 612.2641\n",
      "Epoch 2683/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.7976 - val_loss: 611.4994\n",
      "Epoch 2684/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.8475 - val_loss: 611.6148\n",
      "Epoch 2685/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.8098 - val_loss: 612.3641\n",
      "Epoch 2686/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.5929 - val_loss: 612.5464\n",
      "Epoch 2687/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 515.0190 - val_loss: 612.9200\n",
      "Epoch 2688/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.5962 - val_loss: 613.1070\n",
      "Epoch 2689/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.7056 - val_loss: 613.5664\n",
      "Epoch 2690/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.2969 - val_loss: 609.9375\n",
      "Epoch 2691/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.8471 - val_loss: 612.1379\n",
      "Epoch 2692/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.5485 - val_loss: 612.2770\n",
      "Epoch 2693/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.3772 - val_loss: 612.3576\n",
      "Epoch 2694/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.1077 - val_loss: 610.3368\n",
      "Epoch 2695/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.5653 - val_loss: 612.7893\n",
      "Epoch 2696/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.9905 - val_loss: 614.1947\n",
      "Epoch 2697/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.8386 - val_loss: 613.1328\n",
      "Epoch 2698/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.3807 - val_loss: 610.8602\n",
      "Epoch 2699/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.1364 - val_loss: 614.7689\n",
      "Epoch 2700/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.8801 - val_loss: 610.3262\n",
      "Epoch 2701/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.5830 - val_loss: 614.1880\n",
      "Epoch 2702/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.8865 - val_loss: 611.7847\n",
      "Epoch 2703/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.6361 - val_loss: 614.2449\n",
      "Epoch 2704/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.8850 - val_loss: 612.9056\n",
      "Epoch 2705/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.6632 - val_loss: 612.9903\n",
      "Epoch 2706/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.4373 - val_loss: 612.3762\n",
      "Epoch 2707/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.1058 - val_loss: 612.2365\n",
      "Epoch 2708/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 515.3484 - val_loss: 612.0248\n",
      "Epoch 2709/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.8057 - val_loss: 611.3865\n",
      "Epoch 2710/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 516.7972 - val_loss: 612.5653\n",
      "Epoch 2711/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 516.1126 - val_loss: 612.7981\n",
      "Epoch 2712/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.2271 - val_loss: 611.7869\n",
      "Epoch 2713/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.5425 - val_loss: 611.5527\n",
      "Epoch 2714/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.9812 - val_loss: 610.0199\n",
      "Epoch 2715/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.2706 - val_loss: 611.6271\n",
      "Epoch 2716/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.7691 - val_loss: 611.2226\n",
      "Epoch 2717/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.4835 - val_loss: 611.2225\n",
      "Epoch 2718/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.5269 - val_loss: 612.3151\n",
      "Epoch 2719/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.2286 - val_loss: 612.3871\n",
      "Epoch 2720/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.7521 - val_loss: 614.8031\n",
      "Epoch 2721/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 517.0486 - val_loss: 612.1460\n",
      "Epoch 2722/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.0960 - val_loss: 612.0653\n",
      "Epoch 2723/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.1000 - val_loss: 611.4530\n",
      "Epoch 2724/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.1059 - val_loss: 612.4249\n",
      "Epoch 2725/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.8249 - val_loss: 612.2892\n",
      "Epoch 2726/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.4998 - val_loss: 612.0094\n",
      "Epoch 2727/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 514.6082 - val_loss: 611.6471\n",
      "Epoch 2728/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.2923 - val_loss: 610.5865\n",
      "Epoch 2729/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.1349 - val_loss: 612.4034\n",
      "Epoch 2730/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 515.3672 - val_loss: 611.9057\n",
      "Epoch 2731/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 515.9260 - val_loss: 610.8934\n",
      "Epoch 2732/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.2917 - val_loss: 613.1880\n",
      "Epoch 2733/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.2317 - val_loss: 613.3035\n",
      "Epoch 2734/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 514.5840 - val_loss: 610.2653\n",
      "Epoch 2735/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 514.4293 - val_loss: 612.4218\n",
      "Epoch 2736/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.0164 - val_loss: 612.5873\n",
      "Epoch 2737/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.6629 - val_loss: 612.5282\n",
      "Epoch 2738/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.7721 - val_loss: 611.7748\n",
      "Epoch 2739/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.8040 - val_loss: 610.1037\n",
      "Epoch 2740/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.6730 - val_loss: 611.5667\n",
      "Epoch 2741/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.6090 - val_loss: 614.9282\n",
      "Epoch 2742/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.0331 - val_loss: 610.8820\n",
      "Epoch 2743/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.5439 - val_loss: 610.7677\n",
      "Epoch 2744/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 518.5738 - val_loss: 611.5014\n",
      "Epoch 2745/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.0340 - val_loss: 611.2138\n",
      "Epoch 2746/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.2035 - val_loss: 610.7848\n",
      "Epoch 2747/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.4351 - val_loss: 611.6474\n",
      "Epoch 2748/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 517.1257 - val_loss: 610.6381\n",
      "Epoch 2749/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.5520 - val_loss: 612.4620\n",
      "Epoch 2750/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 334.8947Epoch: 2750 - loss: 516.707369 - val_loss: 612.146783\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.7074 - val_loss: 612.1468\n",
      "Epoch 2751/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.1750 - val_loss: 612.7474\n",
      "Epoch 2752/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.1000 - val_loss: 611.4144\n",
      "Epoch 2753/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.9748 - val_loss: 610.1708\n",
      "Epoch 2754/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.5031 - val_loss: 610.9357\n",
      "Epoch 2755/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.1999 - val_loss: 613.0518\n",
      "Epoch 2756/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.1141 - val_loss: 611.6539\n",
      "Epoch 2757/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.5761 - val_loss: 611.3855\n",
      "Epoch 2758/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.9392 - val_loss: 610.6489\n",
      "Epoch 2759/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.5540 - val_loss: 611.0670\n",
      "Epoch 2760/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.6119 - val_loss: 609.3231\n",
      "Epoch 2761/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 515.2485 - val_loss: 610.3645\n",
      "Epoch 2762/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.3898 - val_loss: 610.5862\n",
      "Epoch 2763/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.2244 - val_loss: 609.5125\n",
      "Epoch 2764/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.0979 - val_loss: 611.8062\n",
      "Epoch 2765/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 513.8226 - val_loss: 610.8636\n",
      "Epoch 2766/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.5500 - val_loss: 611.1207\n",
      "Epoch 2767/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.0150 - val_loss: 612.4400\n",
      "Epoch 2768/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.3660 - val_loss: 611.0929\n",
      "Epoch 2769/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.3944 - val_loss: 610.0539\n",
      "Epoch 2770/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.7379 - val_loss: 611.8734\n",
      "Epoch 2771/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.1879 - val_loss: 611.2547\n",
      "Epoch 2772/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 513.9153 - val_loss: 610.0747\n",
      "Epoch 2773/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.0332 - val_loss: 608.8258\n",
      "Epoch 2774/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.5710 - val_loss: 609.6963\n",
      "Epoch 2775/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.7646 - val_loss: 612.7060\n",
      "Epoch 2776/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.2329 - val_loss: 610.6662\n",
      "Epoch 2777/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.8012 - val_loss: 610.8613\n",
      "Epoch 2778/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.5629 - val_loss: 608.9347\n",
      "Epoch 2779/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.5551 - val_loss: 611.1331\n",
      "Epoch 2780/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 513.1502 - val_loss: 610.4040\n",
      "Epoch 2781/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.2797 - val_loss: 610.4550\n",
      "Epoch 2782/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.3118 - val_loss: 611.2555\n",
      "Epoch 2783/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.0348 - val_loss: 611.4901\n",
      "Epoch 2784/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.0385 - val_loss: 611.7605\n",
      "Epoch 2785/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.4993 - val_loss: 611.1169\n",
      "Epoch 2786/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 513.3685 - val_loss: 611.3640\n",
      "Epoch 2787/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.8093 - val_loss: 609.0952\n",
      "Epoch 2788/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 514.0503 - val_loss: 609.8750\n",
      "Epoch 2789/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.4411 - val_loss: 610.5398\n",
      "Epoch 2790/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.8262 - val_loss: 612.8213\n",
      "Epoch 2791/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.1756 - val_loss: 611.9523\n",
      "Epoch 2792/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.3959 - val_loss: 609.2070\n",
      "Epoch 2793/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.5901 - val_loss: 609.8267\n",
      "Epoch 2794/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.9723 - val_loss: 608.5694\n",
      "Epoch 2795/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.4515 - val_loss: 611.9200\n",
      "Epoch 2796/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.2938 - val_loss: 609.8908\n",
      "Epoch 2797/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.4398 - val_loss: 611.6084\n",
      "Epoch 2798/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 513.0339 - val_loss: 608.5479\n",
      "Epoch 2799/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 513.9555 - val_loss: 611.3659\n",
      "Epoch 2800/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 513.5336 - val_loss: 608.6356\n",
      "Epoch 2801/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.5785 - val_loss: 607.7353\n",
      "Epoch 2802/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.6004 - val_loss: 609.7371\n",
      "Epoch 2803/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 513.4532 - val_loss: 609.1969\n",
      "Epoch 2804/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.4780 - val_loss: 610.2852\n",
      "Epoch 2805/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 513.1312 - val_loss: 610.4505\n",
      "Epoch 2806/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 513.5251 - val_loss: 611.8864\n",
      "Epoch 2807/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.1892 - val_loss: 610.8906\n",
      "Epoch 2808/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.4952 - val_loss: 610.6276\n",
      "Epoch 2809/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 513.2101 - val_loss: 610.0756\n",
      "Epoch 2810/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.0537 - val_loss: 610.7685\n",
      "Epoch 2811/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.7945 - val_loss: 611.8564\n",
      "Epoch 2812/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 513.7902 - val_loss: 612.5417\n",
      "Epoch 2813/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.0448 - val_loss: 612.5729\n",
      "Epoch 2814/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.0176 - val_loss: 610.0749\n",
      "Epoch 2815/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.4420 - val_loss: 610.8247\n",
      "Epoch 2816/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.5997 - val_loss: 610.8101\n",
      "Epoch 2817/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.0000 - val_loss: 611.6462\n",
      "Epoch 2818/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.6999 - val_loss: 611.5250\n",
      "Epoch 2819/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.4146 - val_loss: 612.5049\n",
      "Epoch 2820/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.2741 - val_loss: 611.4075\n",
      "Epoch 2821/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 513.3672 - val_loss: 610.2600\n",
      "Epoch 2822/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.9732 - val_loss: 611.4684\n",
      "Epoch 2823/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.9274 - val_loss: 611.9632\n",
      "Epoch 2824/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.5385 - val_loss: 611.1480\n",
      "Epoch 2825/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.9070 - val_loss: 611.0781\n",
      "Epoch 2826/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.8484 - val_loss: 610.2015\n",
      "Epoch 2827/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.0715 - val_loss: 612.4337\n",
      "Epoch 2828/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 516.0820 - val_loss: 614.0541\n",
      "Epoch 2829/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.2246 - val_loss: 612.0507\n",
      "Epoch 2830/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.3198 - val_loss: 611.7107\n",
      "Epoch 2831/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 513.3978 - val_loss: 610.5970\n",
      "Epoch 2832/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.1337 - val_loss: 611.4801\n",
      "Epoch 2833/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.8731 - val_loss: 612.2416\n",
      "Epoch 2834/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.1948 - val_loss: 613.6974\n",
      "Epoch 2835/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 513.0343 - val_loss: 611.5978\n",
      "Epoch 2836/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.5715 - val_loss: 612.6757\n",
      "Epoch 2837/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.0612 - val_loss: 612.4078\n",
      "Epoch 2838/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 513.7524 - val_loss: 611.2861\n",
      "Epoch 2839/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.1819 - val_loss: 610.8057\n",
      "Epoch 2840/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 514.0634 - val_loss: 610.8157\n",
      "Epoch 2841/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 513.5651 - val_loss: 610.9045\n",
      "Epoch 2842/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 511.3864 - val_loss: 611.9920\n",
      "Epoch 2843/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.5572 - val_loss: 611.3487\n",
      "Epoch 2844/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.3820 - val_loss: 612.4975\n",
      "Epoch 2845/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 513.4988 - val_loss: 613.5558\n",
      "Epoch 2846/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 513.8995 - val_loss: 608.6169\n",
      "Epoch 2847/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 513.7560 - val_loss: 611.3190\n",
      "Epoch 2848/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.0530 - val_loss: 612.4047\n",
      "Epoch 2849/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 511.4718 - val_loss: 610.7912\n",
      "Epoch 2850/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 514.6464 - val_loss: 610.2751\n",
      "Epoch 2851/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.2712 - val_loss: 610.8996\n",
      "Epoch 2852/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.0208 - val_loss: 610.4983\n",
      "Epoch 2853/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.9266 - val_loss: 610.2996\n",
      "Epoch 2854/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 511.8680 - val_loss: 611.2134\n",
      "Epoch 2855/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 511.7062 - val_loss: 609.7696\n",
      "Epoch 2856/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 511.9753 - val_loss: 611.5171\n",
      "Epoch 2857/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 513.3722 - val_loss: 611.7407\n",
      "Epoch 2858/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 511.2183 - val_loss: 610.6104\n",
      "Epoch 2859/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 511.4459 - val_loss: 611.1178\n",
      "Epoch 2860/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.0955 - val_loss: 611.0761\n",
      "Epoch 2861/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.5008 - val_loss: 612.6696\n",
      "Epoch 2862/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.3068 - val_loss: 611.5577\n",
      "Epoch 2863/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 513.6107 - val_loss: 609.8922\n",
      "Epoch 2864/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 513.5151 - val_loss: 611.4830\n",
      "Epoch 2865/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 511.7845 - val_loss: 611.0094\n",
      "Epoch 2866/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.7568 - val_loss: 611.1136\n",
      "Epoch 2867/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.4354 - val_loss: 611.7613\n",
      "Epoch 2868/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.0374 - val_loss: 614.1309\n",
      "Epoch 2869/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 511.9407 - val_loss: 611.4971\n",
      "Epoch 2870/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 511.1918 - val_loss: 611.2471\n",
      "Epoch 2871/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 511.8504 - val_loss: 610.0541\n",
      "Epoch 2872/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.4161 - val_loss: 610.1368\n",
      "Epoch 2873/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.6492 - val_loss: 611.0653\n",
      "Epoch 2874/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.8519 - val_loss: 610.7955\n",
      "Epoch 2875/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 511.3113 - val_loss: 609.5318\n",
      "Epoch 2876/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.4164 - val_loss: 611.5713\n",
      "Epoch 2877/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 515.7978 - val_loss: 608.6362\n",
      "Epoch 2878/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.5220 - val_loss: 608.8572\n",
      "Epoch 2879/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 511.0655 - val_loss: 611.3409\n",
      "Epoch 2880/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 511.2152 - val_loss: 612.1280\n",
      "Epoch 2881/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.1448 - val_loss: 613.3880\n",
      "Epoch 2882/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.1873 - val_loss: 610.3260\n",
      "Epoch 2883/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 512.8071 - val_loss: 611.5352\n",
      "Epoch 2884/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.5340 - val_loss: 611.7101\n",
      "Epoch 2885/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.5291 - val_loss: 611.1724\n",
      "Epoch 2886/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.6301 - val_loss: 610.3816\n",
      "Epoch 2887/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.9589 - val_loss: 611.5566\n",
      "Epoch 2888/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.3949 - val_loss: 609.8155\n",
      "Epoch 2889/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 511.0807 - val_loss: 612.2538\n",
      "Epoch 2890/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 511.2879 - val_loss: 610.8271\n",
      "Epoch 2891/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.3249 - val_loss: 610.0597\n",
      "Epoch 2892/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 511.8960 - val_loss: 611.2683\n",
      "Epoch 2893/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.9435 - val_loss: 611.6565\n",
      "Epoch 2894/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.8316 - val_loss: 610.4358\n",
      "Epoch 2895/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.7201 - val_loss: 610.4577\n",
      "Epoch 2896/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.5439 - val_loss: 610.9696\n",
      "Epoch 2897/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.6303 - val_loss: 609.2280\n",
      "Epoch 2898/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 511.7921 - val_loss: 612.3627\n",
      "Epoch 2899/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 509.9423 - val_loss: 610.4449\n",
      "Epoch 2900/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.0464 - val_loss: 612.3359\n",
      "Epoch 2901/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.8975 - val_loss: 610.1954\n",
      "Epoch 2902/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.5524 - val_loss: 611.5668\n",
      "Epoch 2903/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 511.2335 - val_loss: 613.6517\n",
      "Epoch 2904/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 511.1877 - val_loss: 612.7352\n",
      "Epoch 2905/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.2951 - val_loss: 610.6105\n",
      "Epoch 2906/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.3439 - val_loss: 611.8065\n",
      "Epoch 2907/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.7638 - val_loss: 611.0635\n",
      "Epoch 2908/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.6297 - val_loss: 610.0456\n",
      "Epoch 2909/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.7669 - val_loss: 610.4903\n",
      "Epoch 2910/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.8435 - val_loss: 610.3969\n",
      "Epoch 2911/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.4023 - val_loss: 609.8342\n",
      "Epoch 2912/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.7792 - val_loss: 609.8303\n",
      "Epoch 2913/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.1631 - val_loss: 610.3210\n",
      "Epoch 2914/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.9087 - val_loss: 610.7692\n",
      "Epoch 2915/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.0545 - val_loss: 609.5692\n",
      "Epoch 2916/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.2245 - val_loss: 609.0547\n",
      "Epoch 2917/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 513.6610 - val_loss: 611.4590\n",
      "Epoch 2918/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.6762 - val_loss: 609.1964\n",
      "Epoch 2919/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.5586 - val_loss: 610.4568\n",
      "Epoch 2920/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.1563 - val_loss: 611.3307\n",
      "Epoch 2921/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.3360 - val_loss: 610.0106\n",
      "Epoch 2922/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.3600 - val_loss: 610.5626\n",
      "Epoch 2923/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 512.0224 - val_loss: 608.3824\n",
      "Epoch 2924/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 511.6253 - val_loss: 615.0963\n",
      "Epoch 2925/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.0748 - val_loss: 611.1964\n",
      "Epoch 2926/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.5253 - val_loss: 611.2278\n",
      "Epoch 2927/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 511.9452 - val_loss: 610.4646\n",
      "Epoch 2928/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.1751 - val_loss: 611.2455\n",
      "Epoch 2929/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.6603 - val_loss: 609.8406\n",
      "Epoch 2930/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.9992 - val_loss: 609.9854\n",
      "Epoch 2931/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 511.6749 - val_loss: 609.1614\n",
      "Epoch 2932/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.7492 - val_loss: 610.2753\n",
      "Epoch 2933/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 511.4215 - val_loss: 608.9995\n",
      "Epoch 2934/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.9451 - val_loss: 610.2350\n",
      "Epoch 2935/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.1278 - val_loss: 610.3936\n",
      "Epoch 2936/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.7583 - val_loss: 609.3844\n",
      "Epoch 2937/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.0612 - val_loss: 609.7232\n",
      "Epoch 2938/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.9864 - val_loss: 610.1781\n",
      "Epoch 2939/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.0808 - val_loss: 610.7872\n",
      "Epoch 2940/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.9727 - val_loss: 611.2849\n",
      "Epoch 2941/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.1500 - val_loss: 610.5546\n",
      "Epoch 2942/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.9574 - val_loss: 609.1000\n",
      "Epoch 2943/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.6493 - val_loss: 608.3256\n",
      "Epoch 2944/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.6301 - val_loss: 610.9039\n",
      "Epoch 2945/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.7372 - val_loss: 610.4056\n",
      "Epoch 2946/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.6485 - val_loss: 607.6161\n",
      "Epoch 2947/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.8669 - val_loss: 610.8690\n",
      "Epoch 2948/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.7483 - val_loss: 610.5286\n",
      "Epoch 2949/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.1487 - val_loss: 611.2101\n",
      "Epoch 2950/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.3777 - val_loss: 610.2199\n",
      "Epoch 2951/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.3667 - val_loss: 610.0653\n",
      "Epoch 2952/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.3666 - val_loss: 609.1688\n",
      "Epoch 2953/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.9642 - val_loss: 612.0378\n",
      "Epoch 2954/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.8549 - val_loss: 611.7215\n",
      "Epoch 2955/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 510.3200 - val_loss: 607.8484\n",
      "Epoch 2956/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.0131 - val_loss: 609.7097\n",
      "Epoch 2957/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.9928 - val_loss: 609.2812\n",
      "Epoch 2958/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.3423 - val_loss: 612.3277\n",
      "Epoch 2959/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.8480 - val_loss: 609.0955\n",
      "Epoch 2960/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.6067 - val_loss: 609.4639\n",
      "Epoch 2961/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.8999 - val_loss: 611.2661\n",
      "Epoch 2962/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 509.3354 - val_loss: 608.9895\n",
      "Epoch 2963/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 510.4476 - val_loss: 610.0712\n",
      "Epoch 2964/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.0077 - val_loss: 610.5198\n",
      "Epoch 2965/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 508.2978 - val_loss: 608.8265\n",
      "Epoch 2966/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 508.2202 - val_loss: 609.7586\n",
      "Epoch 2967/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 510.1093 - val_loss: 608.5874\n",
      "Epoch 2968/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 508.7657 - val_loss: 609.4573\n",
      "Epoch 2969/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 509.5956 - val_loss: 607.3168\n",
      "Epoch 2970/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.8403 - val_loss: 609.6798\n",
      "Epoch 2971/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.9308 - val_loss: 607.7170\n",
      "Epoch 2972/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.8524 - val_loss: 609.4493\n",
      "Epoch 2973/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.0380 - val_loss: 607.8936\n",
      "Epoch 2974/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.6988 - val_loss: 607.7301\n",
      "Epoch 2975/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.4651 - val_loss: 610.1601\n",
      "Epoch 2976/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.1272 - val_loss: 608.3946\n",
      "Epoch 2977/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.8499 - val_loss: 608.5175\n",
      "Epoch 2978/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.2698 - val_loss: 608.0770\n",
      "Epoch 2979/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.0005 - val_loss: 608.5137\n",
      "Epoch 2980/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.6891 - val_loss: 608.1039\n",
      "Epoch 2981/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.1911 - val_loss: 609.1488\n",
      "Epoch 2982/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.3465 - val_loss: 608.2817\n",
      "Epoch 2983/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.4235 - val_loss: 610.1281\n",
      "Epoch 2984/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.3608 - val_loss: 609.7317\n",
      "Epoch 2985/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.5768 - val_loss: 607.6831\n",
      "Epoch 2986/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.0651 - val_loss: 608.4847\n",
      "Epoch 2987/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.6561 - val_loss: 609.4304\n",
      "Epoch 2988/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.4551 - val_loss: 608.0657\n",
      "Epoch 2989/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.8908 - val_loss: 610.5980\n",
      "Epoch 2990/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 509.3513 - val_loss: 609.0165\n",
      "Epoch 2991/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.7331 - val_loss: 607.7698\n",
      "Epoch 2992/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.5486 - val_loss: 609.7998\n",
      "Epoch 2993/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.4012 - val_loss: 609.6445\n",
      "Epoch 2994/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.3241 - val_loss: 609.2814\n",
      "Epoch 2995/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.2006 - val_loss: 609.0942\n",
      "Epoch 2996/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.5907 - val_loss: 607.9192\n",
      "Epoch 2997/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.7757 - val_loss: 609.9307\n",
      "Epoch 2998/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.9466 - val_loss: 609.7598\n",
      "Epoch 2999/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.8443 - val_loss: 608.6114\n",
      "Epoch 3000/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 562.2183Epoch: 3000 - loss: 508.209159 - val_loss: 609.567002\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.2092 - val_loss: 609.5670\n",
      "Epoch 3001/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.5107 - val_loss: 608.1818\n",
      "Epoch 3002/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.3717 - val_loss: 608.5267\n",
      "Epoch 3003/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.9382 - val_loss: 609.0342\n",
      "Epoch 3004/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.0154 - val_loss: 609.8906\n",
      "Epoch 3005/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.0778 - val_loss: 608.2687\n",
      "Epoch 3006/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.3026 - val_loss: 609.1409\n",
      "Epoch 3007/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.6253 - val_loss: 608.3970\n",
      "Epoch 3008/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.1981 - val_loss: 609.1085\n",
      "Epoch 3009/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.1151 - val_loss: 609.5675\n",
      "Epoch 3010/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.1372 - val_loss: 608.8844\n",
      "Epoch 3011/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.1848 - val_loss: 608.5661\n",
      "Epoch 3012/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.2531 - val_loss: 609.0113\n",
      "Epoch 3013/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.1186 - val_loss: 609.5734\n",
      "Epoch 3014/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.7053 - val_loss: 608.0821\n",
      "Epoch 3015/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 511.1717 - val_loss: 612.4221\n",
      "Epoch 3016/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.2132 - val_loss: 609.2623\n",
      "Epoch 3017/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.6090 - val_loss: 610.6498\n",
      "Epoch 3018/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.0058 - val_loss: 608.1114\n",
      "Epoch 3019/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.0322 - val_loss: 609.6579\n",
      "Epoch 3020/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.7308 - val_loss: 609.3783\n",
      "Epoch 3021/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.3044 - val_loss: 609.5509\n",
      "Epoch 3022/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.2085 - val_loss: 609.2046\n",
      "Epoch 3023/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.5005 - val_loss: 607.9376\n",
      "Epoch 3024/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.3501 - val_loss: 608.5732\n",
      "Epoch 3025/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.7027 - val_loss: 608.0978\n",
      "Epoch 3026/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.9001 - val_loss: 609.6932\n",
      "Epoch 3027/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.8252 - val_loss: 607.7431\n",
      "Epoch 3028/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.3661 - val_loss: 607.8039\n",
      "Epoch 3029/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.8362 - val_loss: 610.4460\n",
      "Epoch 3030/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.6993 - val_loss: 609.2566\n",
      "Epoch 3031/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.7238 - val_loss: 608.5034\n",
      "Epoch 3032/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.3428 - val_loss: 609.5719\n",
      "Epoch 3033/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.7678 - val_loss: 608.2554\n",
      "Epoch 3034/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.8997 - val_loss: 610.3759\n",
      "Epoch 3035/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.5358 - val_loss: 606.9196\n",
      "Epoch 3036/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.8057 - val_loss: 610.0115\n",
      "Epoch 3037/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.3500 - val_loss: 610.1708\n",
      "Epoch 3038/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.9350 - val_loss: 608.8149\n",
      "Epoch 3039/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.7486 - val_loss: 611.3050\n",
      "Epoch 3040/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.6909 - val_loss: 609.4750\n",
      "Epoch 3041/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.0109 - val_loss: 608.2859\n",
      "Epoch 3042/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.3031 - val_loss: 608.3164\n",
      "Epoch 3043/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.5173 - val_loss: 609.2837\n",
      "Epoch 3044/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.5205 - val_loss: 609.2334\n",
      "Epoch 3045/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 507.3858 - val_loss: 609.0941\n",
      "Epoch 3046/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.0818 - val_loss: 608.3384\n",
      "Epoch 3047/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.4857 - val_loss: 607.2784\n",
      "Epoch 3048/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.4151 - val_loss: 608.3354\n",
      "Epoch 3049/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 509.1032 - val_loss: 610.6240\n",
      "Epoch 3050/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.4451 - val_loss: 608.4850\n",
      "Epoch 3051/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.8280 - val_loss: 608.7185\n",
      "Epoch 3052/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.2954 - val_loss: 608.2174\n",
      "Epoch 3053/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.7420 - val_loss: 608.8135\n",
      "Epoch 3054/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.3234 - val_loss: 607.2370\n",
      "Epoch 3055/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.9648 - val_loss: 608.2127\n",
      "Epoch 3056/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.6021 - val_loss: 608.1510\n",
      "Epoch 3057/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.5876 - val_loss: 609.4934\n",
      "Epoch 3058/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.8949 - val_loss: 607.8921\n",
      "Epoch 3059/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.5851 - val_loss: 607.7613\n",
      "Epoch 3060/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.2862 - val_loss: 606.3595\n",
      "Epoch 3061/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.2650 - val_loss: 607.3071\n",
      "Epoch 3062/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.6398 - val_loss: 607.6553\n",
      "Epoch 3063/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.1555 - val_loss: 609.1064\n",
      "Epoch 3064/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.5415 - val_loss: 608.9927\n",
      "Epoch 3065/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.4488 - val_loss: 607.3645\n",
      "Epoch 3066/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.0576 - val_loss: 608.4517\n",
      "Epoch 3067/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.6745 - val_loss: 608.3146\n",
      "Epoch 3068/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.9638 - val_loss: 607.8750\n",
      "Epoch 3069/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 507.6126 - val_loss: 606.6633\n",
      "Epoch 3070/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.3503 - val_loss: 610.3356\n",
      "Epoch 3071/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.1318 - val_loss: 608.4909\n",
      "Epoch 3072/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.3422 - val_loss: 607.8503\n",
      "Epoch 3073/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.6927 - val_loss: 607.4129\n",
      "Epoch 3074/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.1719 - val_loss: 605.7630\n",
      "Epoch 3075/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.9573 - val_loss: 607.0742\n",
      "Epoch 3076/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.7634 - val_loss: 608.1772\n",
      "Epoch 3077/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.8384 - val_loss: 607.6714\n",
      "Epoch 3078/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.2401 - val_loss: 608.5747\n",
      "Epoch 3079/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 506.9658 - val_loss: 605.5302\n",
      "Epoch 3080/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.0056 - val_loss: 606.8637\n",
      "Epoch 3081/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.1983 - val_loss: 606.4762\n",
      "Epoch 3082/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.2957 - val_loss: 606.9827\n",
      "Epoch 3083/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.5199 - val_loss: 606.9615\n",
      "Epoch 3084/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.1588 - val_loss: 607.0907\n",
      "Epoch 3085/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.0338 - val_loss: 608.5940\n",
      "Epoch 3086/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.8685 - val_loss: 606.6518\n",
      "Epoch 3087/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.5864 - val_loss: 606.8988\n",
      "Epoch 3088/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.3391 - val_loss: 607.3099\n",
      "Epoch 3089/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.1758 - val_loss: 609.1497\n",
      "Epoch 3090/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.0061 - val_loss: 607.1233\n",
      "Epoch 3091/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.6443 - val_loss: 608.2150\n",
      "Epoch 3092/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.6153 - val_loss: 607.6306\n",
      "Epoch 3093/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.3289 - val_loss: 609.5817\n",
      "Epoch 3094/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 508.6407 - val_loss: 607.5676\n",
      "Epoch 3095/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.2802 - val_loss: 608.6644\n",
      "Epoch 3096/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.0863 - val_loss: 607.8477\n",
      "Epoch 3097/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.7325 - val_loss: 606.5934\n",
      "Epoch 3098/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.5511 - val_loss: 607.0110\n",
      "Epoch 3099/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.5575 - val_loss: 608.5165\n",
      "Epoch 3100/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.5083 - val_loss: 607.0882\n",
      "Epoch 3101/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.6903 - val_loss: 606.1428\n",
      "Epoch 3102/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.7804 - val_loss: 608.7103\n",
      "Epoch 3103/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.7215 - val_loss: 608.4975\n",
      "Epoch 3104/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.1659 - val_loss: 607.9643\n",
      "Epoch 3105/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.2750 - val_loss: 607.9930\n",
      "Epoch 3106/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.3214 - val_loss: 607.5940\n",
      "Epoch 3107/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.2083 - val_loss: 607.7720\n",
      "Epoch 3108/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.8772 - val_loss: 607.3520\n",
      "Epoch 3109/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.6972 - val_loss: 608.0078\n",
      "Epoch 3110/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.7043 - val_loss: 606.6848\n",
      "Epoch 3111/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.1494 - val_loss: 607.3046\n",
      "Epoch 3112/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.2862 - val_loss: 607.5616\n",
      "Epoch 3113/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.3371 - val_loss: 607.0484\n",
      "Epoch 3114/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.7581 - val_loss: 607.2891\n",
      "Epoch 3115/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.7696 - val_loss: 607.5490\n",
      "Epoch 3116/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.0940 - val_loss: 606.9339\n",
      "Epoch 3117/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.8231 - val_loss: 606.9621\n",
      "Epoch 3118/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.2241 - val_loss: 606.1281\n",
      "Epoch 3119/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.3489 - val_loss: 605.8903\n",
      "Epoch 3120/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.5275 - val_loss: 607.4097\n",
      "Epoch 3121/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.6159 - val_loss: 607.9776\n",
      "Epoch 3122/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.5483 - val_loss: 607.1843\n",
      "Epoch 3123/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.3695 - val_loss: 606.2677\n",
      "Epoch 3124/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.6959 - val_loss: 609.3283\n",
      "Epoch 3125/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.3190 - val_loss: 606.7063\n",
      "Epoch 3126/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.4744 - val_loss: 607.4246\n",
      "Epoch 3127/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.7002 - val_loss: 605.6884\n",
      "Epoch 3128/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.6822 - val_loss: 607.1996\n",
      "Epoch 3129/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.6064 - val_loss: 607.4244\n",
      "Epoch 3130/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.8454 - val_loss: 605.9126\n",
      "Epoch 3131/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.6404 - val_loss: 606.5633\n",
      "Epoch 3132/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.0461 - val_loss: 606.5689\n",
      "Epoch 3133/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.0657 - val_loss: 606.2001\n",
      "Epoch 3134/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.6493 - val_loss: 605.8534\n",
      "Epoch 3135/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.0676 - val_loss: 606.7969\n",
      "Epoch 3136/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.9447 - val_loss: 609.7531\n",
      "Epoch 3137/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.2267 - val_loss: 607.3416\n",
      "Epoch 3138/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.5159 - val_loss: 609.1626\n",
      "Epoch 3139/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.3467 - val_loss: 607.0348\n",
      "Epoch 3140/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.7900 - val_loss: 608.7899\n",
      "Epoch 3141/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.3047 - val_loss: 608.1904\n",
      "Epoch 3142/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.2346 - val_loss: 608.1048\n",
      "Epoch 3143/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.2260 - val_loss: 607.2477\n",
      "Epoch 3144/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.9271 - val_loss: 607.0957\n",
      "Epoch 3145/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.9214 - val_loss: 606.3674\n",
      "Epoch 3146/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.9075 - val_loss: 607.3350\n",
      "Epoch 3147/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.5470 - val_loss: 609.1241\n",
      "Epoch 3148/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.8891 - val_loss: 608.3102\n",
      "Epoch 3149/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.5978 - val_loss: 607.9763\n",
      "Epoch 3150/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.4532 - val_loss: 606.7037\n",
      "Epoch 3151/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.0240 - val_loss: 606.3278\n",
      "Epoch 3152/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.6090 - val_loss: 607.2666\n",
      "Epoch 3153/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.2102 - val_loss: 604.9288\n",
      "Epoch 3154/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.4045 - val_loss: 607.1142\n",
      "Epoch 3155/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.3676 - val_loss: 607.8335\n",
      "Epoch 3156/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.0148 - val_loss: 607.8812\n",
      "Epoch 3157/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.3826 - val_loss: 607.6461\n",
      "Epoch 3158/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.1033 - val_loss: 605.8666\n",
      "Epoch 3159/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.3563 - val_loss: 606.6349\n",
      "Epoch 3160/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 507.2675 - val_loss: 606.8152\n",
      "Epoch 3161/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.2385 - val_loss: 606.4233\n",
      "Epoch 3162/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 505.0046 - val_loss: 606.7592\n",
      "Epoch 3163/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.5064 - val_loss: 604.6063\n",
      "Epoch 3164/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.8841 - val_loss: 607.2729\n",
      "Epoch 3165/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.2541 - val_loss: 606.1562\n",
      "Epoch 3166/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.0774 - val_loss: 605.5865\n",
      "Epoch 3167/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.3152 - val_loss: 606.3532\n",
      "Epoch 3168/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.0571 - val_loss: 605.8426\n",
      "Epoch 3169/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.2273 - val_loss: 605.3201\n",
      "Epoch 3170/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.4650 - val_loss: 606.6954\n",
      "Epoch 3171/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.2057 - val_loss: 607.7650\n",
      "Epoch 3172/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.9501 - val_loss: 607.3169\n",
      "Epoch 3173/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.5890 - val_loss: 606.6068\n",
      "Epoch 3174/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.9769 - val_loss: 605.0636\n",
      "Epoch 3175/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.6203 - val_loss: 605.7509\n",
      "Epoch 3176/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.1002 - val_loss: 605.0810\n",
      "Epoch 3177/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.2795 - val_loss: 605.7073\n",
      "Epoch 3178/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.7846 - val_loss: 605.8315\n",
      "Epoch 3179/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.3180 - val_loss: 606.8362\n",
      "Epoch 3180/10000\n",
      "3000/3000 [==============================] - 0s 15us/sample - loss: 504.5398 - val_loss: 605.3476\n",
      "Epoch 3181/10000\n",
      "3000/3000 [==============================] - 0s 17us/sample - loss: 504.3948 - val_loss: 605.5686\n",
      "Epoch 3182/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 504.1920 - val_loss: 605.3039\n",
      "Epoch 3183/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 504.0095 - val_loss: 606.2789\n",
      "Epoch 3184/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.6476 - val_loss: 606.3569\n",
      "Epoch 3185/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.4396 - val_loss: 605.3045\n",
      "Epoch 3186/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.8671 - val_loss: 604.9364\n",
      "Epoch 3187/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.0548 - val_loss: 606.2883\n",
      "Epoch 3188/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.0428 - val_loss: 604.8234\n",
      "Epoch 3189/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.2153 - val_loss: 604.4607\n",
      "Epoch 3190/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.7986 - val_loss: 607.4788\n",
      "Epoch 3191/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.7936 - val_loss: 605.9206\n",
      "Epoch 3192/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.1438 - val_loss: 606.3859\n",
      "Epoch 3193/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.3845 - val_loss: 606.7016\n",
      "Epoch 3194/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.5769 - val_loss: 606.5934\n",
      "Epoch 3195/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.0587 - val_loss: 605.8952\n",
      "Epoch 3196/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.4590 - val_loss: 605.8577\n",
      "Epoch 3197/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 506.2829 - val_loss: 607.9388\n",
      "Epoch 3198/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.8568 - val_loss: 606.1811\n",
      "Epoch 3199/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.4642 - val_loss: 605.4933\n",
      "Epoch 3200/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.0330 - val_loss: 605.2641\n",
      "Epoch 3201/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.2642 - val_loss: 605.6768\n",
      "Epoch 3202/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.6828 - val_loss: 604.3969\n",
      "Epoch 3203/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.8764 - val_loss: 605.6877\n",
      "Epoch 3204/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.0277 - val_loss: 606.1034\n",
      "Epoch 3205/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.2421 - val_loss: 605.5291\n",
      "Epoch 3206/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.5855 - val_loss: 604.2186\n",
      "Epoch 3207/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.1669 - val_loss: 605.3820\n",
      "Epoch 3208/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.1020 - val_loss: 604.3912\n",
      "Epoch 3209/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.5009 - val_loss: 603.7600\n",
      "Epoch 3210/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.0926 - val_loss: 605.5058\n",
      "Epoch 3211/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.8095 - val_loss: 605.8346\n",
      "Epoch 3212/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.7310 - val_loss: 605.7876\n",
      "Epoch 3213/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.3632 - val_loss: 605.2308\n",
      "Epoch 3214/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.0901 - val_loss: 605.3029\n",
      "Epoch 3215/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.0703 - val_loss: 605.8660\n",
      "Epoch 3216/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.2907 - val_loss: 605.0095\n",
      "Epoch 3217/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.3093 - val_loss: 605.3792\n",
      "Epoch 3218/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.3919 - val_loss: 605.5700\n",
      "Epoch 3219/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.0878 - val_loss: 604.8540\n",
      "Epoch 3220/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.6100 - val_loss: 605.6334\n",
      "Epoch 3221/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.2353 - val_loss: 606.1704\n",
      "Epoch 3222/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.8382 - val_loss: 604.4047\n",
      "Epoch 3223/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.2990 - val_loss: 604.8569\n",
      "Epoch 3224/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.9852 - val_loss: 605.1310\n",
      "Epoch 3225/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.6622 - val_loss: 604.4463\n",
      "Epoch 3226/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.2323 - val_loss: 604.0162\n",
      "Epoch 3227/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.2944 - val_loss: 603.6469\n",
      "Epoch 3228/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.6338 - val_loss: 604.9593\n",
      "Epoch 3229/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.2275 - val_loss: 603.9891\n",
      "Epoch 3230/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.2032 - val_loss: 604.8694\n",
      "Epoch 3231/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.0091 - val_loss: 604.5643\n",
      "Epoch 3232/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.5454 - val_loss: 605.8197\n",
      "Epoch 3233/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.2109 - val_loss: 604.8584\n",
      "Epoch 3234/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.3312 - val_loss: 606.3756\n",
      "Epoch 3235/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.4846 - val_loss: 603.7170\n",
      "Epoch 3236/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.9204 - val_loss: 606.7367\n",
      "Epoch 3237/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.6429 - val_loss: 604.3999\n",
      "Epoch 3238/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.9792 - val_loss: 602.8273\n",
      "Epoch 3239/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.4675 - val_loss: 605.9574\n",
      "Epoch 3240/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.0189 - val_loss: 606.3624\n",
      "Epoch 3241/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.5431 - val_loss: 603.9317\n",
      "Epoch 3242/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.4006 - val_loss: 603.2323\n",
      "Epoch 3243/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.7164 - val_loss: 603.7540\n",
      "Epoch 3244/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.5745 - val_loss: 604.8661\n",
      "Epoch 3245/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.2020 - val_loss: 602.5276\n",
      "Epoch 3246/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.9104 - val_loss: 602.7099\n",
      "Epoch 3247/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.9025 - val_loss: 604.4555\n",
      "Epoch 3248/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.6012 - val_loss: 603.6025\n",
      "Epoch 3249/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.5813 - val_loss: 602.9493\n",
      "Epoch 3250/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 403.6496Epoch: 3250 - loss: 504.247485 - val_loss: 605.279039\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 504.2475 - val_loss: 605.2790\n",
      "Epoch 3251/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.4486 - val_loss: 602.9016\n",
      "Epoch 3252/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.7293 - val_loss: 604.2088\n",
      "Epoch 3253/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.9291 - val_loss: 606.2887\n",
      "Epoch 3254/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.7781 - val_loss: 605.4890\n",
      "Epoch 3255/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.9953 - val_loss: 604.9497\n",
      "Epoch 3256/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.5382 - val_loss: 603.5727\n",
      "Epoch 3257/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.0248 - val_loss: 606.5829\n",
      "Epoch 3258/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.6370 - val_loss: 603.3028\n",
      "Epoch 3259/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.7288 - val_loss: 604.0041\n",
      "Epoch 3260/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.2475 - val_loss: 605.0985\n",
      "Epoch 3261/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.1654 - val_loss: 603.6519\n",
      "Epoch 3262/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.0369 - val_loss: 604.6886\n",
      "Epoch 3263/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.3604 - val_loss: 604.3237\n",
      "Epoch 3264/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 503.7440 - val_loss: 604.2730\n",
      "Epoch 3265/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.9588 - val_loss: 604.7669\n",
      "Epoch 3266/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.6602 - val_loss: 604.6257\n",
      "Epoch 3267/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.5407 - val_loss: 604.6288\n",
      "Epoch 3268/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.7723 - val_loss: 601.6317\n",
      "Epoch 3269/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.9311 - val_loss: 603.9918\n",
      "Epoch 3270/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.8743 - val_loss: 603.8826\n",
      "Epoch 3271/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.7119 - val_loss: 606.0635\n",
      "Epoch 3272/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.1973 - val_loss: 602.9910\n",
      "Epoch 3273/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.6745 - val_loss: 603.2829\n",
      "Epoch 3274/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.5311 - val_loss: 603.8292\n",
      "Epoch 3275/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.0633 - val_loss: 604.4487\n",
      "Epoch 3276/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.2869 - val_loss: 604.0083\n",
      "Epoch 3277/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.1952 - val_loss: 604.6267\n",
      "Epoch 3278/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 503.5619 - val_loss: 603.7712\n",
      "Epoch 3279/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.7088 - val_loss: 603.7519\n",
      "Epoch 3280/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.5956 - val_loss: 604.1159\n",
      "Epoch 3281/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.6362 - val_loss: 603.5427\n",
      "Epoch 3282/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.5450 - val_loss: 602.6271\n",
      "Epoch 3283/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.4139 - val_loss: 604.1174\n",
      "Epoch 3284/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.1604 - val_loss: 605.4192\n",
      "Epoch 3285/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 501.8790 - val_loss: 604.8779\n",
      "Epoch 3286/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.3621 - val_loss: 604.1170\n",
      "Epoch 3287/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.0714 - val_loss: 605.5817\n",
      "Epoch 3288/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.5693 - val_loss: 603.4979\n",
      "Epoch 3289/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.2266 - val_loss: 605.2685\n",
      "Epoch 3290/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.9844 - val_loss: 605.5501\n",
      "Epoch 3291/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.2463 - val_loss: 604.1967\n",
      "Epoch 3292/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.1785 - val_loss: 604.7936\n",
      "Epoch 3293/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.1092 - val_loss: 604.0507\n",
      "Epoch 3294/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.8834 - val_loss: 602.5926\n",
      "Epoch 3295/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.0923 - val_loss: 604.9284\n",
      "Epoch 3296/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.3536 - val_loss: 603.4141\n",
      "Epoch 3297/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.6881 - val_loss: 603.6157\n",
      "Epoch 3298/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.9769 - val_loss: 604.1625\n",
      "Epoch 3299/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.7631 - val_loss: 603.7559\n",
      "Epoch 3300/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.1436 - val_loss: 604.2239\n",
      "Epoch 3301/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.3875 - val_loss: 603.5377\n",
      "Epoch 3302/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.2757 - val_loss: 604.7916\n",
      "Epoch 3303/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.2455 - val_loss: 604.5672\n",
      "Epoch 3304/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 504.4504 - val_loss: 603.4096\n",
      "Epoch 3305/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.7547 - val_loss: 602.9985\n",
      "Epoch 3306/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.8602 - val_loss: 602.4236\n",
      "Epoch 3307/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.3169 - val_loss: 602.3089\n",
      "Epoch 3308/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.0969 - val_loss: 603.6490\n",
      "Epoch 3309/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.7936 - val_loss: 603.7529\n",
      "Epoch 3310/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.2128 - val_loss: 602.1507\n",
      "Epoch 3311/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.0025 - val_loss: 604.3414\n",
      "Epoch 3312/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.9332 - val_loss: 603.5218\n",
      "Epoch 3313/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.7143 - val_loss: 602.7000\n",
      "Epoch 3314/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.8045 - val_loss: 603.2074\n",
      "Epoch 3315/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.8111 - val_loss: 605.8858\n",
      "Epoch 3316/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.9512 - val_loss: 603.3581\n",
      "Epoch 3317/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.3138 - val_loss: 602.5973\n",
      "Epoch 3318/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.9879 - val_loss: 604.4157\n",
      "Epoch 3319/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.6482 - val_loss: 603.9985\n",
      "Epoch 3320/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.9053 - val_loss: 604.2657\n",
      "Epoch 3321/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.4532 - val_loss: 603.2806\n",
      "Epoch 3322/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.1819 - val_loss: 602.5915\n",
      "Epoch 3323/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.1010 - val_loss: 604.1068\n",
      "Epoch 3324/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.6024 - val_loss: 602.8769\n",
      "Epoch 3325/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.4037 - val_loss: 604.2322\n",
      "Epoch 3326/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.5285 - val_loss: 603.7004\n",
      "Epoch 3327/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.5280 - val_loss: 603.0281\n",
      "Epoch 3328/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.6651 - val_loss: 603.3825\n",
      "Epoch 3329/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.0537 - val_loss: 604.6924\n",
      "Epoch 3330/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.0284 - val_loss: 602.2624\n",
      "Epoch 3331/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.2855 - val_loss: 603.8056\n",
      "Epoch 3332/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.3820 - val_loss: 604.0176\n",
      "Epoch 3333/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.3141 - val_loss: 602.4704\n",
      "Epoch 3334/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.5521 - val_loss: 603.3606\n",
      "Epoch 3335/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.0619 - val_loss: 602.4777\n",
      "Epoch 3336/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.5900 - val_loss: 603.6097\n",
      "Epoch 3337/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.0717 - val_loss: 605.0982\n",
      "Epoch 3338/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.4609 - val_loss: 604.8478\n",
      "Epoch 3339/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.1679 - val_loss: 603.6383\n",
      "Epoch 3340/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.2165 - val_loss: 602.0289\n",
      "Epoch 3341/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.1447 - val_loss: 604.8955\n",
      "Epoch 3342/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.9392 - val_loss: 601.3955\n",
      "Epoch 3343/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.0105 - val_loss: 603.8397\n",
      "Epoch 3344/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.7254 - val_loss: 603.9811\n",
      "Epoch 3345/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.8368 - val_loss: 603.0048\n",
      "Epoch 3346/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.8005 - val_loss: 603.3730\n",
      "Epoch 3347/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.1318 - val_loss: 603.4556\n",
      "Epoch 3348/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.3758 - val_loss: 603.2262\n",
      "Epoch 3349/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.0009 - val_loss: 602.8199\n",
      "Epoch 3350/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.9015 - val_loss: 603.3915\n",
      "Epoch 3351/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.8110 - val_loss: 602.5169\n",
      "Epoch 3352/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.5292 - val_loss: 603.7271\n",
      "Epoch 3353/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.6770 - val_loss: 604.4800\n",
      "Epoch 3354/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.3115 - val_loss: 602.5739\n",
      "Epoch 3355/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.0054 - val_loss: 603.7282\n",
      "Epoch 3356/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.5039 - val_loss: 603.5949\n",
      "Epoch 3357/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.7836 - val_loss: 601.5773\n",
      "Epoch 3358/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.9311 - val_loss: 602.8762\n",
      "Epoch 3359/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.7221 - val_loss: 603.3153\n",
      "Epoch 3360/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.7685 - val_loss: 602.7454\n",
      "Epoch 3361/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.6011 - val_loss: 603.4895\n",
      "Epoch 3362/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.1302 - val_loss: 602.3820\n",
      "Epoch 3363/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.8109 - val_loss: 602.8397\n",
      "Epoch 3364/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.3544 - val_loss: 602.0962\n",
      "Epoch 3365/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.0802 - val_loss: 602.3110\n",
      "Epoch 3366/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.9623 - val_loss: 602.1449\n",
      "Epoch 3367/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.7464 - val_loss: 602.7774\n",
      "Epoch 3368/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.1207 - val_loss: 602.0308\n",
      "Epoch 3369/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.8112 - val_loss: 602.8246\n",
      "Epoch 3370/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.4393 - val_loss: 602.7388\n",
      "Epoch 3371/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.6333 - val_loss: 602.6715\n",
      "Epoch 3372/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.3328 - val_loss: 602.1781\n",
      "Epoch 3373/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 505.0551 - val_loss: 601.4338\n",
      "Epoch 3374/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.6046 - val_loss: 603.5171\n",
      "Epoch 3375/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 501.7132 - val_loss: 604.0748\n",
      "Epoch 3376/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 501.3777 - val_loss: 601.6179\n",
      "Epoch 3377/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 501.0786 - val_loss: 601.4258\n",
      "Epoch 3378/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 502.2989 - val_loss: 601.5448\n",
      "Epoch 3379/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 501.2477 - val_loss: 601.3028\n",
      "Epoch 3380/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 500.3049 - val_loss: 603.7469\n",
      "Epoch 3381/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 503.0472 - val_loss: 602.8961\n",
      "Epoch 3382/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 500.7245 - val_loss: 602.8407\n",
      "Epoch 3383/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 500.4896 - val_loss: 600.4843\n",
      "Epoch 3384/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.0961 - val_loss: 601.7993\n",
      "Epoch 3385/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.6102 - val_loss: 601.6619\n",
      "Epoch 3386/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.4679 - val_loss: 601.7060\n",
      "Epoch 3387/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 503.5725 - val_loss: 603.8064\n",
      "Epoch 3388/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.5417 - val_loss: 602.6001\n",
      "Epoch 3389/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 501.1461 - val_loss: 601.6823\n",
      "Epoch 3390/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 500.9541 - val_loss: 600.9397\n",
      "Epoch 3391/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 502.9630 - val_loss: 602.8109\n",
      "Epoch 3392/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 502.7032 - val_loss: 602.1369\n",
      "Epoch 3393/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 501.0411 - val_loss: 602.7268\n",
      "Epoch 3394/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 500.5983 - val_loss: 602.3919\n",
      "Epoch 3395/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.1133 - val_loss: 601.7511\n",
      "Epoch 3396/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.9137 - val_loss: 603.2108\n",
      "Epoch 3397/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 500.7523 - val_loss: 602.0360\n",
      "Epoch 3398/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 500.4493 - val_loss: 602.9580\n",
      "Epoch 3399/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.5798 - val_loss: 601.6564\n",
      "Epoch 3400/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 501.7599 - val_loss: 602.8876\n",
      "Epoch 3401/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 500.7202 - val_loss: 602.5399\n",
      "Epoch 3402/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 500.4742 - val_loss: 601.8675\n",
      "Epoch 3403/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.7092 - val_loss: 602.0592\n",
      "Epoch 3404/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.0294 - val_loss: 601.0667\n",
      "Epoch 3405/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.1673 - val_loss: 602.8643\n",
      "Epoch 3406/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.3552 - val_loss: 601.5552\n",
      "Epoch 3407/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.6883 - val_loss: 601.9588\n",
      "Epoch 3408/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.4149 - val_loss: 601.0541\n",
      "Epoch 3409/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.8909 - val_loss: 602.6889\n",
      "Epoch 3410/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.6265 - val_loss: 601.1798\n",
      "Epoch 3411/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.3629 - val_loss: 601.6278\n",
      "Epoch 3412/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 501.8335 - val_loss: 601.2369\n",
      "Epoch 3413/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.3509 - val_loss: 602.5553\n",
      "Epoch 3414/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.2252 - val_loss: 601.9264\n",
      "Epoch 3415/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.5066 - val_loss: 602.1710\n",
      "Epoch 3416/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.7165 - val_loss: 603.5363\n",
      "Epoch 3417/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.3375 - val_loss: 601.8013\n",
      "Epoch 3418/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.2731 - val_loss: 600.7937\n",
      "Epoch 3419/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.1569 - val_loss: 602.2617\n",
      "Epoch 3420/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 500.8728 - val_loss: 600.9667\n",
      "Epoch 3421/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 500.4354 - val_loss: 602.1446\n",
      "Epoch 3422/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 500.3643 - val_loss: 600.8637\n",
      "Epoch 3423/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 500.7254 - val_loss: 601.0615\n",
      "Epoch 3424/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 502.6596 - val_loss: 603.4471\n",
      "Epoch 3425/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 500.8692 - val_loss: 600.7197\n",
      "Epoch 3426/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 500.4529 - val_loss: 602.5247\n",
      "Epoch 3427/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.7418 - val_loss: 602.5270\n",
      "Epoch 3428/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.2265 - val_loss: 602.3995\n",
      "Epoch 3429/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.8217 - val_loss: 604.6860\n",
      "Epoch 3430/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.2971 - val_loss: 603.2498\n",
      "Epoch 3431/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.3406 - val_loss: 603.0121\n",
      "Epoch 3432/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.4401 - val_loss: 602.2400\n",
      "Epoch 3433/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 502.1410 - val_loss: 602.4593\n",
      "Epoch 3434/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.6638 - val_loss: 601.9023\n",
      "Epoch 3435/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.4490 - val_loss: 602.6394\n",
      "Epoch 3436/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.4753 - val_loss: 602.7014\n",
      "Epoch 3437/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.7549 - val_loss: 600.8455\n",
      "Epoch 3438/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.5272 - val_loss: 600.6020\n",
      "Epoch 3439/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.4028 - val_loss: 600.2195\n",
      "Epoch 3440/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.8289 - val_loss: 600.2375\n",
      "Epoch 3441/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.2035 - val_loss: 600.8496\n",
      "Epoch 3442/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.5128 - val_loss: 602.2487\n",
      "Epoch 3443/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.1258 - val_loss: 599.7189\n",
      "Epoch 3444/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.1751 - val_loss: 601.7698\n",
      "Epoch 3445/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.1230 - val_loss: 601.6910\n",
      "Epoch 3446/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.9054 - val_loss: 601.6556\n",
      "Epoch 3447/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.6099 - val_loss: 601.8597\n",
      "Epoch 3448/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.4894 - val_loss: 601.3580\n",
      "Epoch 3449/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.1760 - val_loss: 602.0092\n",
      "Epoch 3450/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.1375 - val_loss: 602.7350\n",
      "Epoch 3451/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.3975 - val_loss: 601.5673\n",
      "Epoch 3452/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.2206 - val_loss: 600.7818\n",
      "Epoch 3453/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.3987 - val_loss: 601.8386\n",
      "Epoch 3454/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.2276 - val_loss: 600.3693\n",
      "Epoch 3455/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 501.6826 - val_loss: 601.2306\n",
      "Epoch 3456/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 499.1497 - val_loss: 602.2973\n",
      "Epoch 3457/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 500.8777 - val_loss: 601.9677\n",
      "Epoch 3458/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 499.9544 - val_loss: 602.2533\n",
      "Epoch 3459/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 499.2860 - val_loss: 601.3064\n",
      "Epoch 3460/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 499.5167 - val_loss: 601.3173\n",
      "Epoch 3461/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.1811 - val_loss: 600.1728\n",
      "Epoch 3462/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.6946 - val_loss: 600.2622\n",
      "Epoch 3463/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 500.1855 - val_loss: 602.2541\n",
      "Epoch 3464/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.5841 - val_loss: 601.0998\n",
      "Epoch 3465/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.4986 - val_loss: 599.9054\n",
      "Epoch 3466/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.8367 - val_loss: 599.9139\n",
      "Epoch 3467/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.6675 - val_loss: 600.9266\n",
      "Epoch 3468/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.1130 - val_loss: 602.4366\n",
      "Epoch 3469/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.9528 - val_loss: 601.0308\n",
      "Epoch 3470/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.1817 - val_loss: 600.7587\n",
      "Epoch 3471/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.9317 - val_loss: 600.5717\n",
      "Epoch 3472/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.7259 - val_loss: 601.2186\n",
      "Epoch 3473/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.5886 - val_loss: 600.3158\n",
      "Epoch 3474/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.6525 - val_loss: 601.5422\n",
      "Epoch 3475/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.5649 - val_loss: 601.6810\n",
      "Epoch 3476/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.4106 - val_loss: 600.4211\n",
      "Epoch 3477/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 500.2805 - val_loss: 600.5777\n",
      "Epoch 3478/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.8686 - val_loss: 600.0817\n",
      "Epoch 3479/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.5923 - val_loss: 600.7566\n",
      "Epoch 3480/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.2070 - val_loss: 600.6239\n",
      "Epoch 3481/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.2072 - val_loss: 599.4561\n",
      "Epoch 3482/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.3556 - val_loss: 601.0763\n",
      "Epoch 3483/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.7941 - val_loss: 600.5410\n",
      "Epoch 3484/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.8987 - val_loss: 599.8142\n",
      "Epoch 3485/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.5910 - val_loss: 600.6404\n",
      "Epoch 3486/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.7382 - val_loss: 600.6262\n",
      "Epoch 3487/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.8131 - val_loss: 602.0236\n",
      "Epoch 3488/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.1160 - val_loss: 601.6206\n",
      "Epoch 3489/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 499.3476 - val_loss: 601.1694\n",
      "Epoch 3490/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 501.1285 - val_loss: 600.8990\n",
      "Epoch 3491/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 499.4254 - val_loss: 599.8757\n",
      "Epoch 3492/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.9102 - val_loss: 601.4841\n",
      "Epoch 3493/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 499.3015 - val_loss: 601.9104\n",
      "Epoch 3494/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.4774 - val_loss: 601.5439\n",
      "Epoch 3495/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.7258 - val_loss: 600.2482\n",
      "Epoch 3496/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.3313 - val_loss: 600.9552\n",
      "Epoch 3497/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.6199 - val_loss: 600.7471\n",
      "Epoch 3498/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.8844 - val_loss: 600.0256\n",
      "Epoch 3499/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.3600 - val_loss: 600.9361\n",
      "Epoch 3500/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 291.8310Epoch: 3500 - loss: 498.330158 - val_loss: 601.478660\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.3302 - val_loss: 601.4787\n",
      "Epoch 3501/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 499.1668 - val_loss: 600.5296\n",
      "Epoch 3502/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.4065 - val_loss: 601.4163\n",
      "Epoch 3503/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.0979 - val_loss: 601.7559\n",
      "Epoch 3504/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.9635 - val_loss: 602.0673\n",
      "Epoch 3505/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.1351 - val_loss: 602.0335\n",
      "Epoch 3506/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.4748 - val_loss: 600.3198\n",
      "Epoch 3507/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.3500 - val_loss: 601.0045\n",
      "Epoch 3508/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.2163 - val_loss: 601.6739\n",
      "Epoch 3509/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.6882 - val_loss: 601.5641\n",
      "Epoch 3510/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.2993 - val_loss: 600.4596\n",
      "Epoch 3511/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.1461 - val_loss: 602.3071\n",
      "Epoch 3512/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.0679 - val_loss: 601.4313\n",
      "Epoch 3513/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.3307 - val_loss: 599.5975\n",
      "Epoch 3514/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.2356 - val_loss: 600.5068\n",
      "Epoch 3515/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.1407 - val_loss: 601.4636\n",
      "Epoch 3516/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.4830 - val_loss: 601.2479\n",
      "Epoch 3517/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 499.1070 - val_loss: 601.1694\n",
      "Epoch 3518/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.8215 - val_loss: 598.4807\n",
      "Epoch 3519/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 498.7417 - val_loss: 599.1973\n",
      "Epoch 3520/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 500.3108 - val_loss: 599.4384\n",
      "Epoch 3521/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 498.7071 - val_loss: 601.8219\n",
      "Epoch 3522/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 499.0490 - val_loss: 600.0340\n",
      "Epoch 3523/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 501.6722 - val_loss: 601.2016\n",
      "Epoch 3524/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 497.8444 - val_loss: 600.9578\n",
      "Epoch 3525/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 499.7771 - val_loss: 599.3000\n",
      "Epoch 3526/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 499.3547 - val_loss: 600.3877\n",
      "Epoch 3527/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 499.8094 - val_loss: 601.2648\n",
      "Epoch 3528/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.6324 - val_loss: 598.7486\n",
      "Epoch 3529/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.0156 - val_loss: 600.6518\n",
      "Epoch 3530/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.3243 - val_loss: 600.5484\n",
      "Epoch 3531/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 499.1478 - val_loss: 599.7637\n",
      "Epoch 3532/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.1130 - val_loss: 601.4607\n",
      "Epoch 3533/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.9322 - val_loss: 599.4910\n",
      "Epoch 3534/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.5041 - val_loss: 599.9885\n",
      "Epoch 3535/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 499.3337 - val_loss: 601.0928\n",
      "Epoch 3536/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 500.0751 - val_loss: 598.2328\n",
      "Epoch 3537/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.2904 - val_loss: 601.5049\n",
      "Epoch 3538/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 501.5071 - val_loss: 597.9916\n",
      "Epoch 3539/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.6556 - val_loss: 600.1751\n",
      "Epoch 3540/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.0881 - val_loss: 600.5598\n",
      "Epoch 3541/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.9042 - val_loss: 599.9558\n",
      "Epoch 3542/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.3685 - val_loss: 599.9680\n",
      "Epoch 3543/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.3800 - val_loss: 599.5405\n",
      "Epoch 3544/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.3295 - val_loss: 599.1458\n",
      "Epoch 3545/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 11us/sample - loss: 498.8343 - val_loss: 600.8532\n",
      "Epoch 3546/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.7812 - val_loss: 599.1448\n",
      "Epoch 3547/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 498.3354 - val_loss: 599.7718\n",
      "Epoch 3548/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 498.8485 - val_loss: 600.3728\n",
      "Epoch 3549/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 499.0261 - val_loss: 600.0093\n",
      "Epoch 3550/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.1009 - val_loss: 598.9823\n",
      "Epoch 3551/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.5885 - val_loss: 600.6293\n",
      "Epoch 3552/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.9410 - val_loss: 600.1531\n",
      "Epoch 3553/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.7046 - val_loss: 599.6631\n",
      "Epoch 3554/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.6178 - val_loss: 600.5062\n",
      "Epoch 3555/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.3061 - val_loss: 601.8220\n",
      "Epoch 3556/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.0697 - val_loss: 600.7413\n",
      "Epoch 3557/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 498.4083 - val_loss: 599.7422\n",
      "Epoch 3558/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.2143 - val_loss: 600.2738\n",
      "Epoch 3559/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.8562 - val_loss: 599.8428\n",
      "Epoch 3560/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.1677 - val_loss: 600.6512\n",
      "Epoch 3561/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.2491 - val_loss: 599.7175\n",
      "Epoch 3562/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.7900 - val_loss: 599.2820\n",
      "Epoch 3563/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.2046 - val_loss: 599.9262\n",
      "Epoch 3564/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 499.3636 - val_loss: 600.9674\n",
      "Epoch 3565/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.5473 - val_loss: 600.8842\n",
      "Epoch 3566/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 499.5435 - val_loss: 601.7797\n",
      "Epoch 3567/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.1425 - val_loss: 599.1185\n",
      "Epoch 3568/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.5849 - val_loss: 599.8553\n",
      "Epoch 3569/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.4366 - val_loss: 599.9864\n",
      "Epoch 3570/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.7365 - val_loss: 602.1726\n",
      "Epoch 3571/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.6672 - val_loss: 598.7582\n",
      "Epoch 3572/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 498.2294 - val_loss: 600.3349\n",
      "Epoch 3573/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.0703 - val_loss: 600.2470\n",
      "Epoch 3574/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 498.2114 - val_loss: 599.5470\n",
      "Epoch 3575/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.4938 - val_loss: 599.8761\n",
      "Epoch 3576/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 498.7496 - val_loss: 599.5811\n",
      "Epoch 3577/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.5535 - val_loss: 597.8892\n",
      "Epoch 3578/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.8893 - val_loss: 599.3864\n",
      "Epoch 3579/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 498.2170 - val_loss: 598.6607\n",
      "Epoch 3580/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 497.8868 - val_loss: 599.7930\n",
      "Epoch 3581/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 499.8140 - val_loss: 599.8755\n",
      "Epoch 3582/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.8175 - val_loss: 600.5428\n",
      "Epoch 3583/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 498.7188 - val_loss: 599.8617\n",
      "Epoch 3584/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.4577 - val_loss: 598.9839\n",
      "Epoch 3585/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 499.2854 - val_loss: 598.6023\n",
      "Epoch 3586/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 497.9375 - val_loss: 600.2059\n",
      "Epoch 3587/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 499.4999 - val_loss: 599.3828\n",
      "Epoch 3588/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 498.3998 - val_loss: 600.3452\n",
      "Epoch 3589/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.6645 - val_loss: 598.2716\n",
      "Epoch 3590/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.5284 - val_loss: 598.6273\n",
      "Epoch 3591/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.0807 - val_loss: 600.2902\n",
      "Epoch 3592/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.0996 - val_loss: 600.2470\n",
      "Epoch 3593/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.3398 - val_loss: 599.5997\n",
      "Epoch 3594/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.7915 - val_loss: 598.3399\n",
      "Epoch 3595/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.4247 - val_loss: 598.6954\n",
      "Epoch 3596/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.2963 - val_loss: 599.2846\n",
      "Epoch 3597/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.1447 - val_loss: 599.2421\n",
      "Epoch 3598/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 500.2760 - val_loss: 596.5318\n",
      "Epoch 3599/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 497.2736 - val_loss: 600.0217\n",
      "Epoch 3600/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 497.9615 - val_loss: 599.9792\n",
      "Epoch 3601/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 500.2986 - val_loss: 600.1873\n",
      "Epoch 3602/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 498.9521 - val_loss: 598.6654\n",
      "Epoch 3603/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 497.7311 - val_loss: 599.0305\n",
      "Epoch 3604/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 498.0414 - val_loss: 597.8825\n",
      "Epoch 3605/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 498.0682 - val_loss: 597.3060\n",
      "Epoch 3606/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 498.2423 - val_loss: 599.6051\n",
      "Epoch 3607/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 499.1692 - val_loss: 598.5183\n",
      "Epoch 3608/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 498.5561 - val_loss: 598.1868\n",
      "Epoch 3609/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 498.2889 - val_loss: 599.1221\n",
      "Epoch 3610/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.6864 - val_loss: 599.6848\n",
      "Epoch 3611/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.4452 - val_loss: 600.0790\n",
      "Epoch 3612/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.9990 - val_loss: 598.8540\n",
      "Epoch 3613/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.7284 - val_loss: 598.8740\n",
      "Epoch 3614/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.6282 - val_loss: 597.4624\n",
      "Epoch 3615/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.7936 - val_loss: 599.1001\n",
      "Epoch 3616/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.9076 - val_loss: 598.7856\n",
      "Epoch 3617/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.0837 - val_loss: 598.6072\n",
      "Epoch 3618/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.6464 - val_loss: 600.1132\n",
      "Epoch 3619/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.0027 - val_loss: 599.2675\n",
      "Epoch 3620/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 498.1474 - val_loss: 597.4754\n",
      "Epoch 3621/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.4113 - val_loss: 597.7272\n",
      "Epoch 3622/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.7317 - val_loss: 596.8242\n",
      "Epoch 3623/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.2510 - val_loss: 598.8508\n",
      "Epoch 3624/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.3208 - val_loss: 599.1507\n",
      "Epoch 3625/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.0879 - val_loss: 598.5699\n",
      "Epoch 3626/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.5702 - val_loss: 597.9051\n",
      "Epoch 3627/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.5903 - val_loss: 597.7354\n",
      "Epoch 3628/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.9347 - val_loss: 599.9878\n",
      "Epoch 3629/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.0989 - val_loss: 599.1392\n",
      "Epoch 3630/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.3247 - val_loss: 600.5559\n",
      "Epoch 3631/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.8798 - val_loss: 599.3864\n",
      "Epoch 3632/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.9415 - val_loss: 597.9924\n",
      "Epoch 3633/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.1303 - val_loss: 598.1050\n",
      "Epoch 3634/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.4011 - val_loss: 598.6000\n",
      "Epoch 3635/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.0792 - val_loss: 599.8213\n",
      "Epoch 3636/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.1134 - val_loss: 598.2245\n",
      "Epoch 3637/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.5966 - val_loss: 599.3407\n",
      "Epoch 3638/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.7549 - val_loss: 599.4114\n",
      "Epoch 3639/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.1986 - val_loss: 597.2455\n",
      "Epoch 3640/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.6977 - val_loss: 597.7156\n",
      "Epoch 3641/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.4772 - val_loss: 598.8407\n",
      "Epoch 3642/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.1628 - val_loss: 597.4891\n",
      "Epoch 3643/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.1397 - val_loss: 598.6888\n",
      "Epoch 3644/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.4771 - val_loss: 597.6569\n",
      "Epoch 3645/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.3194 - val_loss: 597.6716\n",
      "Epoch 3646/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.0357 - val_loss: 597.0742\n",
      "Epoch 3647/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.8570 - val_loss: 597.8841\n",
      "Epoch 3648/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.1850 - val_loss: 598.4665\n",
      "Epoch 3649/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.5925 - val_loss: 598.7172\n",
      "Epoch 3650/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 499.8043 - val_loss: 598.8575\n",
      "Epoch 3651/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.9704 - val_loss: 598.5922\n",
      "Epoch 3652/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.5546 - val_loss: 598.4535\n",
      "Epoch 3653/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.5386 - val_loss: 598.4428\n",
      "Epoch 3654/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.0227 - val_loss: 598.6042\n",
      "Epoch 3655/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.9023 - val_loss: 596.8768\n",
      "Epoch 3656/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.1817 - val_loss: 598.3890\n",
      "Epoch 3657/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.4928 - val_loss: 597.8797\n",
      "Epoch 3658/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.8407 - val_loss: 596.2228\n",
      "Epoch 3659/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.1801 - val_loss: 597.4090\n",
      "Epoch 3660/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.1619 - val_loss: 598.0937\n",
      "Epoch 3661/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.0628 - val_loss: 597.2623\n",
      "Epoch 3662/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.8474 - val_loss: 598.5465\n",
      "Epoch 3663/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.2176 - val_loss: 596.9591\n",
      "Epoch 3664/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.9706 - val_loss: 598.1245\n",
      "Epoch 3665/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 497.3026 - val_loss: 597.3812\n",
      "Epoch 3666/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 496.5257 - val_loss: 597.4723\n",
      "Epoch 3667/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 496.6437 - val_loss: 597.2983\n",
      "Epoch 3668/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 496.6750 - val_loss: 597.5467\n",
      "Epoch 3669/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 498.9274 - val_loss: 596.5215\n",
      "Epoch 3670/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 497.5978 - val_loss: 598.9478\n",
      "Epoch 3671/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 497.0535 - val_loss: 597.1343\n",
      "Epoch 3672/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 497.9010 - val_loss: 597.1029\n",
      "Epoch 3673/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 497.2894 - val_loss: 597.3787\n",
      "Epoch 3674/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 498.3092 - val_loss: 596.6888\n",
      "Epoch 3675/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.5257 - val_loss: 596.2250\n",
      "Epoch 3676/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.5787 - val_loss: 596.7739\n",
      "Epoch 3677/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.6413 - val_loss: 596.1950\n",
      "Epoch 3678/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.2521 - val_loss: 598.0021\n",
      "Epoch 3679/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.0284 - val_loss: 596.0256\n",
      "Epoch 3680/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.0230 - val_loss: 597.1498\n",
      "Epoch 3681/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.6914 - val_loss: 595.7193\n",
      "Epoch 3682/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.0895 - val_loss: 597.2983\n",
      "Epoch 3683/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.8735 - val_loss: 597.8538\n",
      "Epoch 3684/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 496.8014 - val_loss: 597.2744\n",
      "Epoch 3685/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 498.0992 - val_loss: 597.4112\n",
      "Epoch 3686/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 497.6507 - val_loss: 597.0422\n",
      "Epoch 3687/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 11us/sample - loss: 498.7338 - val_loss: 596.1483\n",
      "Epoch 3688/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 497.4264 - val_loss: 598.2631\n",
      "Epoch 3689/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 498.2808 - val_loss: 597.4566\n",
      "Epoch 3690/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 497.1053 - val_loss: 597.1776\n",
      "Epoch 3691/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 498.9480 - val_loss: 597.1922\n",
      "Epoch 3692/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.3631 - val_loss: 596.5632\n",
      "Epoch 3693/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.7262 - val_loss: 597.9592\n",
      "Epoch 3694/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.3316 - val_loss: 597.7396\n",
      "Epoch 3695/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 496.5966 - val_loss: 597.2572\n",
      "Epoch 3696/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.8015 - val_loss: 597.6724\n",
      "Epoch 3697/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 496.2924 - val_loss: 598.4022\n",
      "Epoch 3698/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.4373 - val_loss: 595.6655\n",
      "Epoch 3699/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.3371 - val_loss: 596.2440\n",
      "Epoch 3700/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.6036 - val_loss: 597.1386\n",
      "Epoch 3701/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 496.8113 - val_loss: 597.0836\n",
      "Epoch 3702/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.0221 - val_loss: 598.5144\n",
      "Epoch 3703/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.5832 - val_loss: 597.9564\n",
      "Epoch 3704/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.4603 - val_loss: 597.2879\n",
      "Epoch 3705/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 496.5046 - val_loss: 596.3445\n",
      "Epoch 3706/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.7957 - val_loss: 597.2744\n",
      "Epoch 3707/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.2954 - val_loss: 597.9541\n",
      "Epoch 3708/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.3306 - val_loss: 597.8010\n",
      "Epoch 3709/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.0748 - val_loss: 596.5487\n",
      "Epoch 3710/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.1363 - val_loss: 598.1188\n",
      "Epoch 3711/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.4882 - val_loss: 597.7568\n",
      "Epoch 3712/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.9991 - val_loss: 598.5462\n",
      "Epoch 3713/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 496.2619 - val_loss: 596.9850\n",
      "Epoch 3714/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 495.9413 - val_loss: 598.0637\n",
      "Epoch 3715/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 496.7161 - val_loss: 597.9361\n",
      "Epoch 3716/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 496.6171 - val_loss: 596.8558\n",
      "Epoch 3717/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 496.4943 - val_loss: 597.8508\n",
      "Epoch 3718/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 496.9650 - val_loss: 596.8031\n",
      "Epoch 3719/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.8401 - val_loss: 597.5242\n",
      "Epoch 3720/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.8080 - val_loss: 597.3666\n",
      "Epoch 3721/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.6345 - val_loss: 596.7355\n",
      "Epoch 3722/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 497.1184 - val_loss: 596.6452\n",
      "Epoch 3723/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.2105 - val_loss: 596.3029\n",
      "Epoch 3724/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.8444 - val_loss: 596.1636\n",
      "Epoch 3725/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.1427 - val_loss: 595.9046\n",
      "Epoch 3726/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 496.3043 - val_loss: 597.7889\n",
      "Epoch 3727/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 496.4994 - val_loss: 597.8669\n",
      "Epoch 3728/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 496.7316 - val_loss: 597.3341\n",
      "Epoch 3729/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 497.2016 - val_loss: 598.2377\n",
      "Epoch 3730/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 496.2450 - val_loss: 596.4530\n",
      "Epoch 3731/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 496.6751 - val_loss: 596.7383\n",
      "Epoch 3732/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 497.1795 - val_loss: 598.7798\n",
      "Epoch 3733/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 495.8775 - val_loss: 596.5604\n",
      "Epoch 3734/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 496.5380 - val_loss: 596.2957\n",
      "Epoch 3735/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 496.1506 - val_loss: 597.1880\n",
      "Epoch 3736/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 496.5584 - val_loss: 595.8800\n",
      "Epoch 3737/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 497.2621 - val_loss: 598.1128\n",
      "Epoch 3738/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 498.5045 - val_loss: 595.7254\n",
      "Epoch 3739/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 496.4825 - val_loss: 595.9285\n",
      "Epoch 3740/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 496.8691 - val_loss: 596.9146\n",
      "Epoch 3741/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 496.0105 - val_loss: 595.9833\n",
      "Epoch 3742/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 496.2563 - val_loss: 596.9929\n",
      "Epoch 3743/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 496.5048 - val_loss: 595.5246\n",
      "Epoch 3744/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 497.3233 - val_loss: 597.7383\n",
      "Epoch 3745/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 495.8435 - val_loss: 597.4611\n",
      "Epoch 3746/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 496.9019 - val_loss: 596.0703\n",
      "Epoch 3747/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.2408 - val_loss: 595.1590\n",
      "Epoch 3748/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 496.2610 - val_loss: 595.6928\n",
      "Epoch 3749/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 496.2277 - val_loss: 596.2127\n",
      "Epoch 3750/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 643.0219Epoch: 3750 - loss: 497.648674 - val_loss: 595.542450\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 497.6487 - val_loss: 595.5425\n",
      "Epoch 3751/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 498.0048 - val_loss: 596.6783\n",
      "Epoch 3752/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 495.6618 - val_loss: 595.9016\n",
      "Epoch 3753/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.8063 - val_loss: 596.5548\n",
      "Epoch 3754/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.6475 - val_loss: 596.4527\n",
      "Epoch 3755/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.5538 - val_loss: 597.8850\n",
      "Epoch 3756/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.6152 - val_loss: 597.2197\n",
      "Epoch 3757/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 11us/sample - loss: 495.4813 - val_loss: 596.8978\n",
      "Epoch 3758/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.5510 - val_loss: 595.7358\n",
      "Epoch 3759/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.8228 - val_loss: 596.1648\n",
      "Epoch 3760/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.0768 - val_loss: 595.7415\n",
      "Epoch 3761/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.8235 - val_loss: 595.5292\n",
      "Epoch 3762/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.3829 - val_loss: 595.9521\n",
      "Epoch 3763/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 495.7351 - val_loss: 596.6468\n",
      "Epoch 3764/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.1834 - val_loss: 597.8404\n",
      "Epoch 3765/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.7457 - val_loss: 595.9832\n",
      "Epoch 3766/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.9212 - val_loss: 596.6282\n",
      "Epoch 3767/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.4226 - val_loss: 596.9071\n",
      "Epoch 3768/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 496.3034 - val_loss: 595.5359\n",
      "Epoch 3769/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.2651 - val_loss: 595.2452\n",
      "Epoch 3770/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.1678 - val_loss: 595.3258\n",
      "Epoch 3771/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.0330 - val_loss: 594.4880\n",
      "Epoch 3772/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.1824 - val_loss: 594.9736\n",
      "Epoch 3773/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.8007 - val_loss: 595.0069\n",
      "Epoch 3774/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.3138 - val_loss: 594.9369\n",
      "Epoch 3775/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.9438 - val_loss: 597.0568\n",
      "Epoch 3776/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.7093 - val_loss: 593.9367\n",
      "Epoch 3777/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.9118 - val_loss: 595.2102\n",
      "Epoch 3778/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.3050 - val_loss: 595.6485\n",
      "Epoch 3779/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.2537 - val_loss: 595.5746\n",
      "Epoch 3780/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 496.6780 - val_loss: 595.2077\n",
      "Epoch 3781/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.9079 - val_loss: 595.8869\n",
      "Epoch 3782/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.8697 - val_loss: 594.6220\n",
      "Epoch 3783/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.4806 - val_loss: 594.7281\n",
      "Epoch 3784/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.8276 - val_loss: 594.2614\n",
      "Epoch 3785/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.9060 - val_loss: 595.1580\n",
      "Epoch 3786/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.5478 - val_loss: 595.7163\n",
      "Epoch 3787/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.0643 - val_loss: 595.3274\n",
      "Epoch 3788/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.1787 - val_loss: 594.6153\n",
      "Epoch 3789/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.0594 - val_loss: 593.7241\n",
      "Epoch 3790/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.8094 - val_loss: 594.6977\n",
      "Epoch 3791/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.1267 - val_loss: 595.4704\n",
      "Epoch 3792/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.5174 - val_loss: 594.5132\n",
      "Epoch 3793/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.9875 - val_loss: 596.3427\n",
      "Epoch 3794/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.6155 - val_loss: 595.4698\n",
      "Epoch 3795/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.6431 - val_loss: 595.2002\n",
      "Epoch 3796/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.6349 - val_loss: 595.2474\n",
      "Epoch 3797/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.2956 - val_loss: 596.8168\n",
      "Epoch 3798/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.4648 - val_loss: 595.5117\n",
      "Epoch 3799/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.3215 - val_loss: 595.1318\n",
      "Epoch 3800/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.2917 - val_loss: 596.7459\n",
      "Epoch 3801/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.9063 - val_loss: 595.4586\n",
      "Epoch 3802/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.7823 - val_loss: 594.5961\n",
      "Epoch 3803/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.1404 - val_loss: 595.4275\n",
      "Epoch 3804/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.3796 - val_loss: 594.4669\n",
      "Epoch 3805/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.8892 - val_loss: 596.6597\n",
      "Epoch 3806/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.3037 - val_loss: 596.1315\n",
      "Epoch 3807/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.0736 - val_loss: 595.5534\n",
      "Epoch 3808/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.3464 - val_loss: 597.0955\n",
      "Epoch 3809/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.3047 - val_loss: 595.2421\n",
      "Epoch 3810/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.4838 - val_loss: 595.2571\n",
      "Epoch 3811/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 498.3518 - val_loss: 594.0337\n",
      "Epoch 3812/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.7964 - val_loss: 595.4023\n",
      "Epoch 3813/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.8755 - val_loss: 594.9859\n",
      "Epoch 3814/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.7992 - val_loss: 594.5434\n",
      "Epoch 3815/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.2298 - val_loss: 595.2584\n",
      "Epoch 3816/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.3808 - val_loss: 597.5082\n",
      "Epoch 3817/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.2811 - val_loss: 596.7280\n",
      "Epoch 3818/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.3330 - val_loss: 596.1486\n",
      "Epoch 3819/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.4079 - val_loss: 596.9406\n",
      "Epoch 3820/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.3776 - val_loss: 595.8134\n",
      "Epoch 3821/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.7859 - val_loss: 595.4750\n",
      "Epoch 3822/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.0021 - val_loss: 595.3275\n",
      "Epoch 3823/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.9338 - val_loss: 596.0178\n",
      "Epoch 3824/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.2385 - val_loss: 596.5230\n",
      "Epoch 3825/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.6293 - val_loss: 595.0482\n",
      "Epoch 3826/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.5572 - val_loss: 596.7081\n",
      "Epoch 3827/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.6568 - val_loss: 594.2855\n",
      "Epoch 3828/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.3499 - val_loss: 595.6003\n",
      "Epoch 3829/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 495.9203 - val_loss: 594.8025\n",
      "Epoch 3830/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.3855 - val_loss: 594.3921\n",
      "Epoch 3831/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.2345 - val_loss: 596.5891\n",
      "Epoch 3832/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.9982 - val_loss: 596.1534\n",
      "Epoch 3833/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.6915 - val_loss: 594.1752\n",
      "Epoch 3834/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.9414 - val_loss: 594.3260\n",
      "Epoch 3835/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.6327 - val_loss: 593.5574\n",
      "Epoch 3836/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.9136 - val_loss: 594.2348\n",
      "Epoch 3837/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.4287 - val_loss: 595.3903\n",
      "Epoch 3838/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.8957 - val_loss: 595.1340\n",
      "Epoch 3839/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.3030 - val_loss: 594.9607\n",
      "Epoch 3840/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.5047 - val_loss: 594.4934\n",
      "Epoch 3841/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.0196 - val_loss: 594.7651\n",
      "Epoch 3842/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.0137 - val_loss: 595.1506\n",
      "Epoch 3843/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.1396 - val_loss: 595.5919\n",
      "Epoch 3844/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.1749 - val_loss: 596.1772\n",
      "Epoch 3845/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.8820 - val_loss: 595.8378\n",
      "Epoch 3846/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 495.8945 - val_loss: 594.4667\n",
      "Epoch 3847/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.2650 - val_loss: 594.3011\n",
      "Epoch 3848/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.3074 - val_loss: 595.4392\n",
      "Epoch 3849/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.6996 - val_loss: 595.2959\n",
      "Epoch 3850/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.2117 - val_loss: 595.7259\n",
      "Epoch 3851/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.7367 - val_loss: 595.7363\n",
      "Epoch 3852/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.4610 - val_loss: 597.0993\n",
      "Epoch 3853/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.8206 - val_loss: 596.0765\n",
      "Epoch 3854/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.1832 - val_loss: 594.7457\n",
      "Epoch 3855/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.6187 - val_loss: 596.3088\n",
      "Epoch 3856/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.2017 - val_loss: 594.8171\n",
      "Epoch 3857/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 495.4592 - val_loss: 594.5161\n",
      "Epoch 3858/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.4691 - val_loss: 594.7024\n",
      "Epoch 3859/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.7927 - val_loss: 595.3647\n",
      "Epoch 3860/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.1751 - val_loss: 595.1229\n",
      "Epoch 3861/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.0935 - val_loss: 597.0194\n",
      "Epoch 3862/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.6225 - val_loss: 594.6142\n",
      "Epoch 3863/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.7849 - val_loss: 595.5593\n",
      "Epoch 3864/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.1323 - val_loss: 595.4087\n",
      "Epoch 3865/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.7860 - val_loss: 595.9535\n",
      "Epoch 3866/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.6820 - val_loss: 595.6606\n",
      "Epoch 3867/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.8442 - val_loss: 595.7642\n",
      "Epoch 3868/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.3192 - val_loss: 593.7241\n",
      "Epoch 3869/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.0252 - val_loss: 595.1092\n",
      "Epoch 3870/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.3235 - val_loss: 593.6789\n",
      "Epoch 3871/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.0412 - val_loss: 593.2552\n",
      "Epoch 3872/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.8921 - val_loss: 592.5025\n",
      "Epoch 3873/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.9926 - val_loss: 593.7555\n",
      "Epoch 3874/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.8231 - val_loss: 593.8567\n",
      "Epoch 3875/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.4007 - val_loss: 594.2130\n",
      "Epoch 3876/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.8150 - val_loss: 594.7416\n",
      "Epoch 3877/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.3574 - val_loss: 593.9908\n",
      "Epoch 3878/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.4491 - val_loss: 593.9756\n",
      "Epoch 3879/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.5687 - val_loss: 594.9531\n",
      "Epoch 3880/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.9246 - val_loss: 594.8510\n",
      "Epoch 3881/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.3772 - val_loss: 594.3137\n",
      "Epoch 3882/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.7770 - val_loss: 594.2052\n",
      "Epoch 3883/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.6236 - val_loss: 595.5923\n",
      "Epoch 3884/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.4702 - val_loss: 596.5558\n",
      "Epoch 3885/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.2705 - val_loss: 594.1423\n",
      "Epoch 3886/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.7272 - val_loss: 595.2605\n",
      "Epoch 3887/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.5735 - val_loss: 594.1182\n",
      "Epoch 3888/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.5527 - val_loss: 594.8776\n",
      "Epoch 3889/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.8909 - val_loss: 594.7320\n",
      "Epoch 3890/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 494.3540 - val_loss: 594.3921\n",
      "Epoch 3891/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.8264 - val_loss: 595.6213\n",
      "Epoch 3892/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.0196 - val_loss: 595.9462\n",
      "Epoch 3893/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.5759 - val_loss: 593.2071\n",
      "Epoch 3894/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.5781 - val_loss: 594.5098\n",
      "Epoch 3895/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.0334 - val_loss: 596.2181\n",
      "Epoch 3896/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.9504 - val_loss: 593.7990\n",
      "Epoch 3897/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.4471 - val_loss: 594.4575\n",
      "Epoch 3898/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.2798 - val_loss: 595.0997\n",
      "Epoch 3899/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.7503 - val_loss: 594.7007\n",
      "Epoch 3900/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.7732 - val_loss: 595.4954\n",
      "Epoch 3901/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.7259 - val_loss: 596.0529\n",
      "Epoch 3902/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.2473 - val_loss: 594.4631\n",
      "Epoch 3903/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.7164 - val_loss: 594.6133\n",
      "Epoch 3904/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.0565 - val_loss: 596.8273\n",
      "Epoch 3905/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.0205 - val_loss: 594.1329\n",
      "Epoch 3906/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.3878 - val_loss: 594.4393\n",
      "Epoch 3907/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.5872 - val_loss: 594.1811\n",
      "Epoch 3908/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.0033 - val_loss: 595.6145\n",
      "Epoch 3909/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.3233 - val_loss: 595.1612\n",
      "Epoch 3910/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.5477 - val_loss: 594.0588\n",
      "Epoch 3911/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.6155 - val_loss: 593.7421\n",
      "Epoch 3912/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.1558 - val_loss: 593.9800\n",
      "Epoch 3913/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.5068 - val_loss: 594.8050\n",
      "Epoch 3914/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.6403 - val_loss: 593.4359\n",
      "Epoch 3915/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.3286 - val_loss: 594.8947\n",
      "Epoch 3916/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.6805 - val_loss: 593.6693\n",
      "Epoch 3917/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.4245 - val_loss: 594.2658\n",
      "Epoch 3918/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.0543 - val_loss: 593.9587\n",
      "Epoch 3919/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.5886 - val_loss: 593.5748\n",
      "Epoch 3920/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.0888 - val_loss: 594.3813\n",
      "Epoch 3921/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.2104 - val_loss: 593.3197\n",
      "Epoch 3922/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.3557 - val_loss: 594.3761\n",
      "Epoch 3923/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.4118 - val_loss: 594.3538\n",
      "Epoch 3924/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.8025 - val_loss: 595.3227\n",
      "Epoch 3925/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.7746 - val_loss: 595.0326\n",
      "Epoch 3926/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.6152 - val_loss: 593.8520\n",
      "Epoch 3927/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.8218 - val_loss: 594.1874\n",
      "Epoch 3928/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.6507 - val_loss: 593.4256\n",
      "Epoch 3929/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.8573 - val_loss: 594.4244\n",
      "Epoch 3930/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.5234 - val_loss: 593.9998\n",
      "Epoch 3931/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.7259 - val_loss: 595.3234\n",
      "Epoch 3932/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.1164 - val_loss: 593.8677\n",
      "Epoch 3933/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.1242 - val_loss: 595.6754\n",
      "Epoch 3934/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.0552 - val_loss: 593.3931\n",
      "Epoch 3935/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.9376 - val_loss: 594.8086\n",
      "Epoch 3936/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.5882 - val_loss: 593.5776\n",
      "Epoch 3937/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.9407 - val_loss: 595.7978\n",
      "Epoch 3938/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.8745 - val_loss: 593.2341\n",
      "Epoch 3939/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.3833 - val_loss: 594.3330\n",
      "Epoch 3940/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.7228 - val_loss: 593.8291\n",
      "Epoch 3941/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.4657 - val_loss: 594.0470\n",
      "Epoch 3942/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.7888 - val_loss: 593.2207\n",
      "Epoch 3943/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.2786 - val_loss: 592.4282\n",
      "Epoch 3944/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.5690 - val_loss: 593.6430\n",
      "Epoch 3945/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.4909 - val_loss: 593.7265\n",
      "Epoch 3946/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 496.7125 - val_loss: 593.9665\n",
      "Epoch 3947/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.1299 - val_loss: 593.4954\n",
      "Epoch 3948/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.5425 - val_loss: 593.0727\n",
      "Epoch 3949/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.4467 - val_loss: 594.2703\n",
      "Epoch 3950/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 499.5558 - val_loss: 596.4224\n",
      "Epoch 3951/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.8541 - val_loss: 593.5714\n",
      "Epoch 3952/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.6073 - val_loss: 594.7465\n",
      "Epoch 3953/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.4284 - val_loss: 593.6252\n",
      "Epoch 3954/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.4060 - val_loss: 593.5866\n",
      "Epoch 3955/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.5712 - val_loss: 594.7453\n",
      "Epoch 3956/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.4279 - val_loss: 592.5466\n",
      "Epoch 3957/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.1320 - val_loss: 593.8757\n",
      "Epoch 3958/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.7484 - val_loss: 594.4071\n",
      "Epoch 3959/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.8181 - val_loss: 594.1931\n",
      "Epoch 3960/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.0408 - val_loss: 593.7753\n",
      "Epoch 3961/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.2898 - val_loss: 594.5449\n",
      "Epoch 3962/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.3647 - val_loss: 595.2573\n",
      "Epoch 3963/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.5253 - val_loss: 593.6952\n",
      "Epoch 3964/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.6061 - val_loss: 593.3209\n",
      "Epoch 3965/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.2770 - val_loss: 593.6798\n",
      "Epoch 3966/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.8010 - val_loss: 593.3081\n",
      "Epoch 3967/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.6139 - val_loss: 592.4083\n",
      "Epoch 3968/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.7467 - val_loss: 596.0887\n",
      "Epoch 3969/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.4527 - val_loss: 593.9326\n",
      "Epoch 3970/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.4995 - val_loss: 593.7103\n",
      "Epoch 3971/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.2342 - val_loss: 593.2633\n",
      "Epoch 3972/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.6286 - val_loss: 593.7831\n",
      "Epoch 3973/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.4672 - val_loss: 592.8705\n",
      "Epoch 3974/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.4932 - val_loss: 593.0507\n",
      "Epoch 3975/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.7559 - val_loss: 596.0265\n",
      "Epoch 3976/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.0539 - val_loss: 594.3506\n",
      "Epoch 3977/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.5275 - val_loss: 595.0992\n",
      "Epoch 3978/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.1110 - val_loss: 594.9062\n",
      "Epoch 3979/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.9652 - val_loss: 594.7175\n",
      "Epoch 3980/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.5510 - val_loss: 593.3820\n",
      "Epoch 3981/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.2252 - val_loss: 593.5229\n",
      "Epoch 3982/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.1261 - val_loss: 593.5701\n",
      "Epoch 3983/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.7816 - val_loss: 593.8333\n",
      "Epoch 3984/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.7812 - val_loss: 593.4264\n",
      "Epoch 3985/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.4012 - val_loss: 593.8046\n",
      "Epoch 3986/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.6899 - val_loss: 592.7785\n",
      "Epoch 3987/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.2270 - val_loss: 594.8752\n",
      "Epoch 3988/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.6433 - val_loss: 592.0790\n",
      "Epoch 3989/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.9656 - val_loss: 593.6033\n",
      "Epoch 3990/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.6216 - val_loss: 593.3649\n",
      "Epoch 3991/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.3504 - val_loss: 593.0445\n",
      "Epoch 3992/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.1500 - val_loss: 593.4021\n",
      "Epoch 3993/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.5438 - val_loss: 595.0916\n",
      "Epoch 3994/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.3368 - val_loss: 593.8222\n",
      "Epoch 3995/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.3142 - val_loss: 595.5603\n",
      "Epoch 3996/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.3801 - val_loss: 593.7089\n",
      "Epoch 3997/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.3448 - val_loss: 593.2976\n",
      "Epoch 3998/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 492.8654 - val_loss: 594.6798\n",
      "Epoch 3999/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.8314 - val_loss: 593.0137\n",
      "Epoch 4000/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 730.4507Epoch: 4000 - loss: 493.101966 - val_loss: 593.495647\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.1020 - val_loss: 593.4956\n",
      "Epoch 4001/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.5352 - val_loss: 594.0907\n",
      "Epoch 4002/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.6964 - val_loss: 592.5970\n",
      "Epoch 4003/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.5785 - val_loss: 594.3550\n",
      "Epoch 4004/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.7854 - val_loss: 592.8859\n",
      "Epoch 4005/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.9167 - val_loss: 591.8173\n",
      "Epoch 4006/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.5866 - val_loss: 594.3709\n",
      "Epoch 4007/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.0274 - val_loss: 592.5489\n",
      "Epoch 4008/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.3501 - val_loss: 593.1217\n",
      "Epoch 4009/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.0609 - val_loss: 592.7408\n",
      "Epoch 4010/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.6038 - val_loss: 591.6406\n",
      "Epoch 4011/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.7328 - val_loss: 593.0296\n",
      "Epoch 4012/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.6108 - val_loss: 594.0763\n",
      "Epoch 4013/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.8709 - val_loss: 593.0696\n",
      "Epoch 4014/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.7300 - val_loss: 592.8230\n",
      "Epoch 4015/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.7508 - val_loss: 592.9050\n",
      "Epoch 4016/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.0556 - val_loss: 592.4376\n",
      "Epoch 4017/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.8684 - val_loss: 592.6002\n",
      "Epoch 4018/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.4661 - val_loss: 591.8201\n",
      "Epoch 4019/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.5187 - val_loss: 593.5139\n",
      "Epoch 4020/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.1714 - val_loss: 593.2892\n",
      "Epoch 4021/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.2199 - val_loss: 594.4169\n",
      "Epoch 4022/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.1620 - val_loss: 592.4586\n",
      "Epoch 4023/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.1815 - val_loss: 593.5615\n",
      "Epoch 4024/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.1809 - val_loss: 593.9857\n",
      "Epoch 4025/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.6939 - val_loss: 593.9294\n",
      "Epoch 4026/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.9183 - val_loss: 593.9332\n",
      "Epoch 4027/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.3383 - val_loss: 594.5544\n",
      "Epoch 4028/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.6383 - val_loss: 593.6948\n",
      "Epoch 4029/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.8667 - val_loss: 593.9353\n",
      "Epoch 4030/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.7685 - val_loss: 593.7328\n",
      "Epoch 4031/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 497.0574 - val_loss: 593.7660\n",
      "Epoch 4032/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.4775 - val_loss: 594.7116\n",
      "Epoch 4033/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 493.7627 - val_loss: 594.4625\n",
      "Epoch 4034/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.1042 - val_loss: 592.5098\n",
      "Epoch 4035/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.2731 - val_loss: 593.5632\n",
      "Epoch 4036/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.0180 - val_loss: 593.7683\n",
      "Epoch 4037/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.6163 - val_loss: 593.2444\n",
      "Epoch 4038/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.9959 - val_loss: 592.3293\n",
      "Epoch 4039/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.2009 - val_loss: 592.1932\n",
      "Epoch 4040/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.0584 - val_loss: 593.9854\n",
      "Epoch 4041/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.0580 - val_loss: 592.9743\n",
      "Epoch 4042/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.2403 - val_loss: 594.0567\n",
      "Epoch 4043/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.0635 - val_loss: 593.3505\n",
      "Epoch 4044/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.4125 - val_loss: 594.2185\n",
      "Epoch 4045/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.5167 - val_loss: 593.1096\n",
      "Epoch 4046/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.1630 - val_loss: 593.2025\n",
      "Epoch 4047/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.2209 - val_loss: 592.6900\n",
      "Epoch 4048/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.0052 - val_loss: 593.3219\n",
      "Epoch 4049/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.5762 - val_loss: 593.3261\n",
      "Epoch 4050/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.3116 - val_loss: 594.0352\n",
      "Epoch 4051/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.7487 - val_loss: 591.2747\n",
      "Epoch 4052/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.6378 - val_loss: 592.6169\n",
      "Epoch 4053/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.9044 - val_loss: 592.0239\n",
      "Epoch 4054/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.3142 - val_loss: 591.9445\n",
      "Epoch 4055/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.6854 - val_loss: 592.3825\n",
      "Epoch 4056/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.4929 - val_loss: 592.1201\n",
      "Epoch 4057/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.1631 - val_loss: 592.1592\n",
      "Epoch 4058/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.4985 - val_loss: 591.8136\n",
      "Epoch 4059/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.0372 - val_loss: 593.0075\n",
      "Epoch 4060/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.5242 - val_loss: 593.2857\n",
      "Epoch 4061/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.0626 - val_loss: 594.3600\n",
      "Epoch 4062/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.7739 - val_loss: 594.0611\n",
      "Epoch 4063/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.6407 - val_loss: 591.8898\n",
      "Epoch 4064/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.3437 - val_loss: 591.7881\n",
      "Epoch 4065/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.3759 - val_loss: 592.1554\n",
      "Epoch 4066/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.4562 - val_loss: 593.8919\n",
      "Epoch 4067/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.3206 - val_loss: 591.6692\n",
      "Epoch 4068/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.6923 - val_loss: 593.5479\n",
      "Epoch 4069/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.9554 - val_loss: 591.9821\n",
      "Epoch 4070/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.9899 - val_loss: 592.9553\n",
      "Epoch 4071/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.3831 - val_loss: 592.6831\n",
      "Epoch 4072/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.3251 - val_loss: 594.0297\n",
      "Epoch 4073/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 492.2325 - val_loss: 593.4859\n",
      "Epoch 4074/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 493.5007 - val_loss: 594.1662\n",
      "Epoch 4075/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 493.4944 - val_loss: 592.5494\n",
      "Epoch 4076/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 492.7781 - val_loss: 592.0049\n",
      "Epoch 4077/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.3494 - val_loss: 592.2259\n",
      "Epoch 4078/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.2793 - val_loss: 592.3324\n",
      "Epoch 4079/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.2410 - val_loss: 592.8585\n",
      "Epoch 4080/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.7334 - val_loss: 593.6133\n",
      "Epoch 4081/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.8922 - val_loss: 592.4423\n",
      "Epoch 4082/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.6063 - val_loss: 593.0150\n",
      "Epoch 4083/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.7333 - val_loss: 591.4567\n",
      "Epoch 4084/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.9811 - val_loss: 593.2532\n",
      "Epoch 4085/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.7235 - val_loss: 592.3525\n",
      "Epoch 4086/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.9185 - val_loss: 593.5163\n",
      "Epoch 4087/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.8498 - val_loss: 593.4360\n",
      "Epoch 4088/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.7532 - val_loss: 592.0222\n",
      "Epoch 4089/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.4141 - val_loss: 592.6851\n",
      "Epoch 4090/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.1999 - val_loss: 592.0255\n",
      "Epoch 4091/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.8504 - val_loss: 592.7779\n",
      "Epoch 4092/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.5587 - val_loss: 591.3753\n",
      "Epoch 4093/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.6148 - val_loss: 591.5294\n",
      "Epoch 4094/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.3614 - val_loss: 590.7265\n",
      "Epoch 4095/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.2759 - val_loss: 592.6121\n",
      "Epoch 4096/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.1477 - val_loss: 592.3932\n",
      "Epoch 4097/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.1902 - val_loss: 592.1930\n",
      "Epoch 4098/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.6450 - val_loss: 593.0980\n",
      "Epoch 4099/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.8670 - val_loss: 592.1841\n",
      "Epoch 4100/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.5816 - val_loss: 592.1276\n",
      "Epoch 4101/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.9660 - val_loss: 591.2330\n",
      "Epoch 4102/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.0658 - val_loss: 590.7616\n",
      "Epoch 4103/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.0756 - val_loss: 593.7995\n",
      "Epoch 4104/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.6109 - val_loss: 592.2163\n",
      "Epoch 4105/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.4304 - val_loss: 591.9042\n",
      "Epoch 4106/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.4989 - val_loss: 592.2574\n",
      "Epoch 4107/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.4066 - val_loss: 591.9486\n",
      "Epoch 4108/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.6555 - val_loss: 591.9827\n",
      "Epoch 4109/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.0438 - val_loss: 593.6797\n",
      "Epoch 4110/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.1569 - val_loss: 591.9063\n",
      "Epoch 4111/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.0583 - val_loss: 592.9748\n",
      "Epoch 4112/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.1460 - val_loss: 592.4502\n",
      "Epoch 4113/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.8851 - val_loss: 592.5211\n",
      "Epoch 4114/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.4321 - val_loss: 592.6507\n",
      "Epoch 4115/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 495.0767 - val_loss: 591.3232\n",
      "Epoch 4116/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.2260 - val_loss: 591.4294\n",
      "Epoch 4117/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.9446 - val_loss: 592.1338\n",
      "Epoch 4118/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.0847 - val_loss: 592.8988\n",
      "Epoch 4119/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.0895 - val_loss: 591.5942\n",
      "Epoch 4120/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.3743 - val_loss: 592.3840\n",
      "Epoch 4121/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.1108 - val_loss: 591.7221\n",
      "Epoch 4122/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.7237 - val_loss: 591.2629\n",
      "Epoch 4123/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.3193 - val_loss: 591.8591\n",
      "Epoch 4124/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.5977 - val_loss: 592.7037\n",
      "Epoch 4125/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.4628 - val_loss: 592.2430\n",
      "Epoch 4126/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.2275 - val_loss: 591.4638\n",
      "Epoch 4127/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.2485 - val_loss: 591.5801\n",
      "Epoch 4128/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.1486 - val_loss: 591.4193\n",
      "Epoch 4129/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 491.5724 - val_loss: 590.9114\n",
      "Epoch 4130/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.8966 - val_loss: 591.3944\n",
      "Epoch 4131/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 492.5029 - val_loss: 591.9823\n",
      "Epoch 4132/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.2684 - val_loss: 592.9450\n",
      "Epoch 4133/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.3691 - val_loss: 593.2124\n",
      "Epoch 4134/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.0223 - val_loss: 592.9414\n",
      "Epoch 4135/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 491.6992 - val_loss: 592.8223\n",
      "Epoch 4136/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 493.4945 - val_loss: 591.8109\n",
      "Epoch 4137/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.3856 - val_loss: 592.0953\n",
      "Epoch 4138/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.8225 - val_loss: 592.3546\n",
      "Epoch 4139/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.1324 - val_loss: 592.5732\n",
      "Epoch 4140/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.9447 - val_loss: 591.9959\n",
      "Epoch 4141/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 494.7511 - val_loss: 591.8850\n",
      "Epoch 4142/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.2924 - val_loss: 590.9891\n",
      "Epoch 4143/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.8819 - val_loss: 590.9791\n",
      "Epoch 4144/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 494.1637 - val_loss: 591.9896\n",
      "Epoch 4145/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 492.5496 - val_loss: 593.1833\n",
      "Epoch 4146/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 492.1720 - val_loss: 591.9673\n",
      "Epoch 4147/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 493.0914 - val_loss: 592.8034\n",
      "Epoch 4148/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 494.9404 - val_loss: 592.0033\n",
      "Epoch 4149/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 492.1400 - val_loss: 590.6505\n",
      "Epoch 4150/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.2488 - val_loss: 591.1157\n",
      "Epoch 4151/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.0209 - val_loss: 593.5432\n",
      "Epoch 4152/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.4534 - val_loss: 591.4668\n",
      "Epoch 4153/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.7301 - val_loss: 591.8167\n",
      "Epoch 4154/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.1356 - val_loss: 591.8055\n",
      "Epoch 4155/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 492.3850 - val_loss: 593.1328\n",
      "Epoch 4156/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 491.3336 - val_loss: 592.6928\n",
      "Epoch 4157/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 491.8409 - val_loss: 592.8951\n",
      "Epoch 4158/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.5756 - val_loss: 592.4316\n",
      "Epoch 4159/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.5640 - val_loss: 591.8472\n",
      "Epoch 4160/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.5362 - val_loss: 592.3628\n",
      "Epoch 4161/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 491.3329 - val_loss: 591.9168\n",
      "Epoch 4162/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.1694 - val_loss: 591.6513\n",
      "Epoch 4163/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.5198 - val_loss: 591.9329\n",
      "Epoch 4164/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 491.3372 - val_loss: 591.1173\n",
      "Epoch 4165/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 492.1266 - val_loss: 591.6828\n",
      "Epoch 4166/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 491.9339 - val_loss: 590.2574\n",
      "Epoch 4167/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 492.2863 - val_loss: 590.1076\n",
      "Epoch 4168/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 492.0116 - val_loss: 591.5140\n",
      "Epoch 4169/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 494.3138 - val_loss: 590.0324\n",
      "Epoch 4170/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 491.5048 - val_loss: 591.6827\n",
      "Epoch 4171/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 493.5993 - val_loss: 591.6573\n",
      "Epoch 4172/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 492.1872 - val_loss: 591.8759\n",
      "Epoch 4173/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 491.4755 - val_loss: 591.9819\n",
      "Epoch 4174/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.1350 - val_loss: 592.0105\n",
      "Epoch 4175/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.2417 - val_loss: 592.0574\n",
      "Epoch 4176/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 491.9022 - val_loss: 592.4104\n",
      "Epoch 4177/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.2240 - val_loss: 592.0792\n",
      "Epoch 4178/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.8187 - val_loss: 591.2552\n",
      "Epoch 4179/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.9687 - val_loss: 591.5774\n",
      "Epoch 4180/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.5941 - val_loss: 591.7896\n",
      "Epoch 4181/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.7214 - val_loss: 590.6962\n",
      "Epoch 4182/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 11us/sample - loss: 492.1186 - val_loss: 591.4555\n",
      "Epoch 4183/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.9754 - val_loss: 591.3935\n",
      "Epoch 4184/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.1255 - val_loss: 590.6753\n",
      "Epoch 4185/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.1769 - val_loss: 591.5403\n",
      "Epoch 4186/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.9433 - val_loss: 589.9028\n",
      "Epoch 4187/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.1932 - val_loss: 592.5335\n",
      "Epoch 4188/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.6101 - val_loss: 590.2637\n",
      "Epoch 4189/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 491.2242 - val_loss: 591.2044\n",
      "Epoch 4190/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 492.0350 - val_loss: 593.2234\n",
      "Epoch 4191/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 491.0104 - val_loss: 591.1629\n",
      "Epoch 4192/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 492.0927 - val_loss: 590.2260\n",
      "Epoch 4193/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 492.3039 - val_loss: 590.4337\n",
      "Epoch 4194/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 492.2763 - val_loss: 590.8539\n",
      "Epoch 4195/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 492.1380 - val_loss: 590.5152\n",
      "Epoch 4196/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 493.1624 - val_loss: 589.4317\n",
      "Epoch 4197/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 491.7968 - val_loss: 591.5170\n",
      "Epoch 4198/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 491.6175 - val_loss: 591.9367\n",
      "Epoch 4199/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 492.6551 - val_loss: 591.2294\n",
      "Epoch 4200/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 491.8769 - val_loss: 590.0997\n",
      "Epoch 4201/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.2549 - val_loss: 591.8239\n",
      "Epoch 4202/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.7170 - val_loss: 591.9465\n",
      "Epoch 4203/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.7018 - val_loss: 590.9648\n",
      "Epoch 4204/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.1782 - val_loss: 591.0786\n",
      "Epoch 4205/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.0423 - val_loss: 590.8041\n",
      "Epoch 4206/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.3715 - val_loss: 591.4657\n",
      "Epoch 4207/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.4282 - val_loss: 591.3287\n",
      "Epoch 4208/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 491.0141 - val_loss: 590.9462\n",
      "Epoch 4209/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 492.1247 - val_loss: 591.0728\n",
      "Epoch 4210/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 490.9468 - val_loss: 590.8453\n",
      "Epoch 4211/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 491.1565 - val_loss: 590.8119\n",
      "Epoch 4212/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 491.5581 - val_loss: 590.6862\n",
      "Epoch 4213/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 490.7320 - val_loss: 590.2121\n",
      "Epoch 4214/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 491.3352 - val_loss: 589.3506\n",
      "Epoch 4215/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 490.8923 - val_loss: 589.8524\n",
      "Epoch 4216/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.6879 - val_loss: 590.6355\n",
      "Epoch 4217/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 491.1911 - val_loss: 590.0633\n",
      "Epoch 4218/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 492.9619 - val_loss: 591.3782\n",
      "Epoch 4219/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 492.0873 - val_loss: 591.1431\n",
      "Epoch 4220/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 490.7091 - val_loss: 590.5322\n",
      "Epoch 4221/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 490.8979 - val_loss: 591.3291\n",
      "Epoch 4222/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 491.3121 - val_loss: 591.8321\n",
      "Epoch 4223/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 491.1217 - val_loss: 589.9433\n",
      "Epoch 4224/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 491.2862 - val_loss: 590.4117\n",
      "Epoch 4225/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 492.7594 - val_loss: 591.0784\n",
      "Epoch 4226/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 490.8469 - val_loss: 591.5551\n",
      "Epoch 4227/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 493.0132 - val_loss: 592.1752\n",
      "Epoch 4228/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 491.4292 - val_loss: 592.0330\n",
      "Epoch 4229/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 491.0570 - val_loss: 590.9221\n",
      "Epoch 4230/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.4797 - val_loss: 589.8516\n",
      "Epoch 4231/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.4101 - val_loss: 591.2102\n",
      "Epoch 4232/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.1190 - val_loss: 591.1821\n",
      "Epoch 4233/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.4188 - val_loss: 590.8165\n",
      "Epoch 4234/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.7841 - val_loss: 590.5062\n",
      "Epoch 4235/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.2480 - val_loss: 591.5892\n",
      "Epoch 4236/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.6518 - val_loss: 591.2356\n",
      "Epoch 4237/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.6954 - val_loss: 591.2020\n",
      "Epoch 4238/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.0079 - val_loss: 591.6817\n",
      "Epoch 4239/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.8895 - val_loss: 591.0751\n",
      "Epoch 4240/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 491.3813 - val_loss: 591.8710\n",
      "Epoch 4241/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.3873 - val_loss: 590.4575\n",
      "Epoch 4242/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.8781 - val_loss: 591.5875\n",
      "Epoch 4243/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.4278 - val_loss: 590.5559\n",
      "Epoch 4244/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.7547 - val_loss: 590.6068\n",
      "Epoch 4245/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 490.5325 - val_loss: 591.8020\n",
      "Epoch 4246/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 490.6910 - val_loss: 590.9780\n",
      "Epoch 4247/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.0520 - val_loss: 590.8447\n",
      "Epoch 4248/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 490.7609 - val_loss: 591.5350\n",
      "Epoch 4249/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 491.5404 - val_loss: 590.6358\n",
      "Epoch 4250/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 479.1260Epoch: 4250 - loss: 491.067535 - val_loss: 592.361463\n",
      "3000/3000 [==============================] - 0s 14us/sample - loss: 491.0675 - val_loss: 592.3615\n",
      "Epoch 4251/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.0842 - val_loss: 589.7342\n",
      "Epoch 4252/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.5944 - val_loss: 589.8515\n",
      "Epoch 4253/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 491.9259 - val_loss: 591.0149\n",
      "Epoch 4254/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 490.8613 - val_loss: 590.7110\n",
      "Epoch 4255/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.9259 - val_loss: 591.2378\n",
      "Epoch 4256/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.3940 - val_loss: 590.5030\n",
      "Epoch 4257/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.1926 - val_loss: 591.1350\n",
      "Epoch 4258/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.0869 - val_loss: 591.0207\n",
      "Epoch 4259/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.6295 - val_loss: 591.5016\n",
      "Epoch 4260/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 492.3199 - val_loss: 588.9546\n",
      "Epoch 4261/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.7595 - val_loss: 590.2888\n",
      "Epoch 4262/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 490.8556 - val_loss: 590.4414\n",
      "Epoch 4263/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.5657 - val_loss: 592.6365\n",
      "Epoch 4264/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.6598 - val_loss: 591.6262\n",
      "Epoch 4265/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.9019 - val_loss: 591.5386\n",
      "Epoch 4266/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 491.6234 - val_loss: 590.9066\n",
      "Epoch 4267/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 490.1891 - val_loss: 590.5793\n",
      "Epoch 4268/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 490.8184 - val_loss: 590.7074\n",
      "Epoch 4269/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 492.6682 - val_loss: 590.7903\n",
      "Epoch 4270/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 492.1751 - val_loss: 590.7581\n",
      "Epoch 4271/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 491.0701 - val_loss: 590.6370\n",
      "Epoch 4272/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.5832 - val_loss: 590.9056\n",
      "Epoch 4273/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.8858 - val_loss: 591.2300\n",
      "Epoch 4274/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 493.7491 - val_loss: 589.7189\n",
      "Epoch 4275/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.9841 - val_loss: 591.4879\n",
      "Epoch 4276/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.1530 - val_loss: 589.8073\n",
      "Epoch 4277/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.7255 - val_loss: 591.8470\n",
      "Epoch 4278/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.8727 - val_loss: 590.9844\n",
      "Epoch 4279/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.5322 - val_loss: 591.3667\n",
      "Epoch 4280/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.9327 - val_loss: 591.1862\n",
      "Epoch 4281/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.6023 - val_loss: 590.5567\n",
      "Epoch 4282/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.9262 - val_loss: 590.9826\n",
      "Epoch 4283/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 490.9404 - val_loss: 591.0173\n",
      "Epoch 4284/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.0074 - val_loss: 590.3622\n",
      "Epoch 4285/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.3867 - val_loss: 590.7531\n",
      "Epoch 4286/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.3220 - val_loss: 590.1320\n",
      "Epoch 4287/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.8547 - val_loss: 591.2897\n",
      "Epoch 4288/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.4483 - val_loss: 590.2822\n",
      "Epoch 4289/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 491.7877 - val_loss: 590.2701\n",
      "Epoch 4290/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 493.3462 - val_loss: 590.6208\n",
      "Epoch 4291/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.4678 - val_loss: 589.8394\n",
      "Epoch 4292/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 490.5643 - val_loss: 592.1347\n",
      "Epoch 4293/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 490.0224 - val_loss: 590.2774\n",
      "Epoch 4294/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.5817 - val_loss: 590.4349\n",
      "Epoch 4295/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.4073 - val_loss: 590.5370\n",
      "Epoch 4296/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.0317 - val_loss: 589.2728\n",
      "Epoch 4297/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.1081 - val_loss: 590.8472\n",
      "Epoch 4298/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 490.7330 - val_loss: 590.0242\n",
      "Epoch 4299/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.1252 - val_loss: 590.8922\n",
      "Epoch 4300/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.7314 - val_loss: 591.4288\n",
      "Epoch 4301/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.8772 - val_loss: 589.8344\n",
      "Epoch 4302/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 490.3290 - val_loss: 589.7052\n",
      "Epoch 4303/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 490.8033 - val_loss: 590.6298\n",
      "Epoch 4304/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.2877 - val_loss: 589.1789\n",
      "Epoch 4305/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.2119 - val_loss: 590.3478\n",
      "Epoch 4306/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.3387 - val_loss: 589.4425\n",
      "Epoch 4307/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.9258 - val_loss: 590.9633\n",
      "Epoch 4308/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.7712 - val_loss: 589.9013\n",
      "Epoch 4309/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.0647 - val_loss: 589.9939\n",
      "Epoch 4310/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 490.4824 - val_loss: 589.3887\n",
      "Epoch 4311/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.1352 - val_loss: 591.4230\n",
      "Epoch 4312/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.2548 - val_loss: 589.5417\n",
      "Epoch 4313/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.9244 - val_loss: 588.9768\n",
      "Epoch 4314/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.6867 - val_loss: 590.1852\n",
      "Epoch 4315/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.1227 - val_loss: 590.9928\n",
      "Epoch 4316/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 491.4498 - val_loss: 590.3040\n",
      "Epoch 4317/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.6064 - val_loss: 589.8062\n",
      "Epoch 4318/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.3957 - val_loss: 590.6000\n",
      "Epoch 4319/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.7695 - val_loss: 590.0525\n",
      "Epoch 4320/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.6824 - val_loss: 590.9734\n",
      "Epoch 4321/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.7626 - val_loss: 589.3633\n",
      "Epoch 4322/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.2420 - val_loss: 590.3302\n",
      "Epoch 4323/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.3100 - val_loss: 590.7900\n",
      "Epoch 4324/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.4087 - val_loss: 590.2559\n",
      "Epoch 4325/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 491.3944 - val_loss: 590.9189\n",
      "Epoch 4326/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.1759 - val_loss: 590.8330\n",
      "Epoch 4327/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.8636 - val_loss: 590.3711\n",
      "Epoch 4328/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.7831 - val_loss: 590.2801\n",
      "Epoch 4329/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.5924 - val_loss: 590.5790\n",
      "Epoch 4330/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.8546 - val_loss: 590.5700\n",
      "Epoch 4331/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.0318 - val_loss: 590.0419\n",
      "Epoch 4332/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.9122 - val_loss: 588.8943\n",
      "Epoch 4333/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.2770 - val_loss: 588.8359\n",
      "Epoch 4334/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.7607 - val_loss: 589.5886\n",
      "Epoch 4335/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.0967 - val_loss: 589.6338\n",
      "Epoch 4336/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 490.5880 - val_loss: 590.0545\n",
      "Epoch 4337/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 489.7265 - val_loss: 591.0360\n",
      "Epoch 4338/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.5295 - val_loss: 590.2039\n",
      "Epoch 4339/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.3170 - val_loss: 589.3742\n",
      "Epoch 4340/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.4480 - val_loss: 591.2362\n",
      "Epoch 4341/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.1421 - val_loss: 590.5696\n",
      "Epoch 4342/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.4964 - val_loss: 590.8787\n",
      "Epoch 4343/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.9682 - val_loss: 589.3882\n",
      "Epoch 4344/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 489.7140 - val_loss: 589.4543\n",
      "Epoch 4345/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.2696 - val_loss: 591.2410\n",
      "Epoch 4346/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.6542 - val_loss: 589.0960\n",
      "Epoch 4347/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.8964 - val_loss: 591.4294\n",
      "Epoch 4348/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.2231 - val_loss: 588.8920\n",
      "Epoch 4349/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.4696 - val_loss: 589.5337\n",
      "Epoch 4350/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.6827 - val_loss: 590.4770\n",
      "Epoch 4351/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.0473 - val_loss: 588.7200\n",
      "Epoch 4352/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 490.6972 - val_loss: 588.9205\n",
      "Epoch 4353/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 490.3547 - val_loss: 590.4086\n",
      "Epoch 4354/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 490.6816 - val_loss: 589.5954\n",
      "Epoch 4355/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 490.1590 - val_loss: 588.6786\n",
      "Epoch 4356/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.7891 - val_loss: 590.7483\n",
      "Epoch 4357/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.4544 - val_loss: 588.5190\n",
      "Epoch 4358/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 491.1793 - val_loss: 590.2986\n",
      "Epoch 4359/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.8755 - val_loss: 589.7147\n",
      "Epoch 4360/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.9388 - val_loss: 587.9813\n",
      "Epoch 4361/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.9240 - val_loss: 588.5561\n",
      "Epoch 4362/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 490.9851 - val_loss: 589.1460\n",
      "Epoch 4363/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.9659 - val_loss: 589.3545\n",
      "Epoch 4364/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.2324 - val_loss: 588.9855\n",
      "Epoch 4365/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 490.3063 - val_loss: 589.0908\n",
      "Epoch 4366/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.2855 - val_loss: 587.6763\n",
      "Epoch 4367/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.8429 - val_loss: 588.0415\n",
      "Epoch 4368/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.9357 - val_loss: 589.7477\n",
      "Epoch 4369/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.5006 - val_loss: 588.5715\n",
      "Epoch 4370/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.0917 - val_loss: 589.0134\n",
      "Epoch 4371/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.6708 - val_loss: 590.2337\n",
      "Epoch 4372/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.7116 - val_loss: 589.1136\n",
      "Epoch 4373/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.5755 - val_loss: 589.1018\n",
      "Epoch 4374/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.7135 - val_loss: 588.9872\n",
      "Epoch 4375/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.8371 - val_loss: 589.5032\n",
      "Epoch 4376/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.1653 - val_loss: 588.3209\n",
      "Epoch 4377/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.9071 - val_loss: 588.9385\n",
      "Epoch 4378/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.9797 - val_loss: 588.4985\n",
      "Epoch 4379/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.2556 - val_loss: 587.2746\n",
      "Epoch 4380/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.1643 - val_loss: 588.0754\n",
      "Epoch 4381/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.2814 - val_loss: 589.7950\n",
      "Epoch 4382/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.1227 - val_loss: 590.1173\n",
      "Epoch 4383/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.3870 - val_loss: 588.1026\n",
      "Epoch 4384/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.3768 - val_loss: 588.9016\n",
      "Epoch 4385/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.9052 - val_loss: 587.6443\n",
      "Epoch 4386/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.3203 - val_loss: 588.3183\n",
      "Epoch 4387/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.2001 - val_loss: 590.1315\n",
      "Epoch 4388/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.1636 - val_loss: 587.9816\n",
      "Epoch 4389/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.2965 - val_loss: 588.3899\n",
      "Epoch 4390/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.3972 - val_loss: 588.2627\n",
      "Epoch 4391/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.6384 - val_loss: 589.6676\n",
      "Epoch 4392/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.4305 - val_loss: 588.7300\n",
      "Epoch 4393/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.5774 - val_loss: 588.7823\n",
      "Epoch 4394/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.7625 - val_loss: 590.2487\n",
      "Epoch 4395/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.2434 - val_loss: 590.1027\n",
      "Epoch 4396/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.3409 - val_loss: 589.0005\n",
      "Epoch 4397/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.7238 - val_loss: 590.2103\n",
      "Epoch 4398/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.0982 - val_loss: 588.6382\n",
      "Epoch 4399/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 490.9356 - val_loss: 589.6045\n",
      "Epoch 4400/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.2180 - val_loss: 588.1768\n",
      "Epoch 4401/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 489.0868 - val_loss: 587.3047\n",
      "Epoch 4402/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.9369 - val_loss: 588.5604\n",
      "Epoch 4403/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.3270 - val_loss: 588.3072\n",
      "Epoch 4404/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 489.0959 - val_loss: 588.9321\n",
      "Epoch 4405/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.4030 - val_loss: 588.9993\n",
      "Epoch 4406/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.3213 - val_loss: 587.5260\n",
      "Epoch 4407/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.3734 - val_loss: 589.1190\n",
      "Epoch 4408/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.9068 - val_loss: 590.1465\n",
      "Epoch 4409/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.1713 - val_loss: 588.1747\n",
      "Epoch 4410/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.2984 - val_loss: 589.0229\n",
      "Epoch 4411/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.9992 - val_loss: 588.5320\n",
      "Epoch 4412/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.7884 - val_loss: 587.8998\n",
      "Epoch 4413/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.1696 - val_loss: 590.7163\n",
      "Epoch 4414/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.8474 - val_loss: 589.4122\n",
      "Epoch 4415/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 490.2336 - val_loss: 588.8025\n",
      "Epoch 4416/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 489.4535 - val_loss: 588.8077\n",
      "Epoch 4417/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.0430 - val_loss: 588.9327\n",
      "Epoch 4418/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.6647 - val_loss: 589.9357\n",
      "Epoch 4419/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.9801 - val_loss: 587.8673\n",
      "Epoch 4420/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.3354 - val_loss: 587.7126\n",
      "Epoch 4421/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.3916 - val_loss: 588.1859\n",
      "Epoch 4422/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.3486 - val_loss: 588.3521\n",
      "Epoch 4423/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 489.2346 - val_loss: 590.1190\n",
      "Epoch 4424/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 489.3928 - val_loss: 588.7898\n",
      "Epoch 4425/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 489.6775 - val_loss: 588.2698\n",
      "Epoch 4426/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.6405 - val_loss: 588.2956\n",
      "Epoch 4427/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.9680 - val_loss: 589.6043\n",
      "Epoch 4428/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.1669 - val_loss: 587.3542\n",
      "Epoch 4429/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.4759 - val_loss: 588.7344\n",
      "Epoch 4430/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 489.6135 - val_loss: 588.6250\n",
      "Epoch 4431/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.5153 - val_loss: 587.3185\n",
      "Epoch 4432/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.1288 - val_loss: 587.8909\n",
      "Epoch 4433/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.6118 - val_loss: 587.0616\n",
      "Epoch 4434/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.0039 - val_loss: 588.1941\n",
      "Epoch 4435/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.1801 - val_loss: 589.0496\n",
      "Epoch 4436/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.3441 - val_loss: 589.4116\n",
      "Epoch 4437/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.9149 - val_loss: 588.3103\n",
      "Epoch 4438/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.6109 - val_loss: 588.7712\n",
      "Epoch 4439/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.6196 - val_loss: 587.9951\n",
      "Epoch 4440/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.1591 - val_loss: 588.2483\n",
      "Epoch 4441/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.8230 - val_loss: 588.5783\n",
      "Epoch 4442/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.2399 - val_loss: 588.3557\n",
      "Epoch 4443/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 489.4443 - val_loss: 588.3139\n",
      "Epoch 4444/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.7178 - val_loss: 589.1662\n",
      "Epoch 4445/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 489.8718 - val_loss: 588.1304\n",
      "Epoch 4446/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.8153 - val_loss: 587.6881\n",
      "Epoch 4447/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.6672 - val_loss: 588.8712\n",
      "Epoch 4448/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.8880 - val_loss: 587.7681\n",
      "Epoch 4449/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.4468 - val_loss: 588.3005\n",
      "Epoch 4450/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 488.9378 - val_loss: 589.5228\n",
      "Epoch 4451/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.6335 - val_loss: 588.6898\n",
      "Epoch 4452/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.6793 - val_loss: 587.9043\n",
      "Epoch 4453/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.4483 - val_loss: 589.3501\n",
      "Epoch 4454/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 492.6897 - val_loss: 589.9962\n",
      "Epoch 4455/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.9527 - val_loss: 588.8517\n",
      "Epoch 4456/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 489.2529 - val_loss: 587.8799\n",
      "Epoch 4457/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.7694 - val_loss: 588.0605\n",
      "Epoch 4458/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.6808 - val_loss: 587.5676\n",
      "Epoch 4459/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.1307 - val_loss: 586.6720\n",
      "Epoch 4460/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.2870 - val_loss: 588.0116\n",
      "Epoch 4461/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.3234 - val_loss: 588.7939\n",
      "Epoch 4462/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.3740 - val_loss: 588.3743\n",
      "Epoch 4463/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.7486 - val_loss: 587.9388\n",
      "Epoch 4464/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.3709 - val_loss: 586.4453\n",
      "Epoch 4465/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.0458 - val_loss: 587.9073\n",
      "Epoch 4466/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.5782 - val_loss: 587.9024\n",
      "Epoch 4467/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.2296 - val_loss: 588.1993\n",
      "Epoch 4468/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.6445 - val_loss: 588.5397\n",
      "Epoch 4469/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 489.0750 - val_loss: 588.3924\n",
      "Epoch 4470/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.2707 - val_loss: 588.4887\n",
      "Epoch 4471/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.9669 - val_loss: 587.7163\n",
      "Epoch 4472/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.6108 - val_loss: 588.2726\n",
      "Epoch 4473/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.7620 - val_loss: 587.6675\n",
      "Epoch 4474/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 490.6342 - val_loss: 588.5374\n",
      "Epoch 4475/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.5882 - val_loss: 590.0365\n",
      "Epoch 4476/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.8529 - val_loss: 587.1320\n",
      "Epoch 4477/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.2160 - val_loss: 588.0597\n",
      "Epoch 4478/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.5869 - val_loss: 588.3630\n",
      "Epoch 4479/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.7338 - val_loss: 587.1317\n",
      "Epoch 4480/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.9864 - val_loss: 587.3928\n",
      "Epoch 4481/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.0616 - val_loss: 588.1498\n",
      "Epoch 4482/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.9636 - val_loss: 588.2280\n",
      "Epoch 4483/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 488.3042 - val_loss: 586.3838\n",
      "Epoch 4484/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.1158 - val_loss: 586.6283\n",
      "Epoch 4485/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.5716 - val_loss: 587.1849\n",
      "Epoch 4486/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.3128 - val_loss: 587.4407\n",
      "Epoch 4487/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.3431 - val_loss: 586.7521\n",
      "Epoch 4488/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.3730 - val_loss: 587.4758\n",
      "Epoch 4489/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.3881 - val_loss: 587.1380\n",
      "Epoch 4490/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.5935 - val_loss: 588.6598\n",
      "Epoch 4491/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.9321 - val_loss: 587.5082\n",
      "Epoch 4492/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.7365 - val_loss: 587.1854\n",
      "Epoch 4493/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.3203 - val_loss: 587.0981\n",
      "Epoch 4494/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.4223 - val_loss: 588.5785\n",
      "Epoch 4495/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.6598 - val_loss: 587.1532\n",
      "Epoch 4496/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.4032 - val_loss: 585.9528\n",
      "Epoch 4497/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.0442 - val_loss: 587.2062\n",
      "Epoch 4498/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.3165 - val_loss: 586.3953\n",
      "Epoch 4499/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.5806 - val_loss: 586.7718\n",
      "Epoch 4500/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 161.7024Epoch: 4500 - loss: 488.401255 - val_loss: 587.314589\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 488.4013 - val_loss: 587.3146\n",
      "Epoch 4501/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.0697 - val_loss: 587.4155\n",
      "Epoch 4502/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.8257 - val_loss: 587.2319\n",
      "Epoch 4503/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.4887 - val_loss: 588.1551\n",
      "Epoch 4504/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 489.3954 - val_loss: 586.8002\n",
      "Epoch 4505/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.2194 - val_loss: 588.2408\n",
      "Epoch 4506/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.4544 - val_loss: 587.7082\n",
      "Epoch 4507/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.7425 - val_loss: 586.8338\n",
      "Epoch 4508/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 489.1845 - val_loss: 588.2451\n",
      "Epoch 4509/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 488.9376 - val_loss: 588.0732\n",
      "Epoch 4510/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.8193 - val_loss: 589.4192\n",
      "Epoch 4511/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.2995 - val_loss: 588.3852\n",
      "Epoch 4512/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.9973 - val_loss: 588.1924\n",
      "Epoch 4513/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.5021 - val_loss: 586.9068\n",
      "Epoch 4514/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.0547 - val_loss: 586.8884\n",
      "Epoch 4515/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.1660 - val_loss: 588.2153\n",
      "Epoch 4516/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.9857 - val_loss: 585.9578\n",
      "Epoch 4517/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 488.3709 - val_loss: 587.4866\n",
      "Epoch 4518/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.5929 - val_loss: 586.1376\n",
      "Epoch 4519/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.2297 - val_loss: 587.4796\n",
      "Epoch 4520/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.2576 - val_loss: 588.1763\n",
      "Epoch 4521/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.3625 - val_loss: 586.7712\n",
      "Epoch 4522/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.5390 - val_loss: 586.6926\n",
      "Epoch 4523/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.2163 - val_loss: 587.7403\n",
      "Epoch 4524/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.6140 - val_loss: 586.6559\n",
      "Epoch 4525/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 488.4856 - val_loss: 586.2814\n",
      "Epoch 4526/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 488.5024 - val_loss: 587.3590\n",
      "Epoch 4527/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.6485 - val_loss: 587.5731\n",
      "Epoch 4528/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.8543 - val_loss: 588.2132\n",
      "Epoch 4529/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.5216 - val_loss: 587.0667\n",
      "Epoch 4530/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.1961 - val_loss: 588.2109\n",
      "Epoch 4531/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.2926 - val_loss: 587.7947\n",
      "Epoch 4532/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.6253 - val_loss: 586.6718\n",
      "Epoch 4533/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.6446 - val_loss: 587.2514\n",
      "Epoch 4534/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.5429 - val_loss: 587.8912\n",
      "Epoch 4535/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.2669 - val_loss: 587.8990\n",
      "Epoch 4536/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 490.5937 - val_loss: 586.8660\n",
      "Epoch 4537/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.7264 - val_loss: 588.0802\n",
      "Epoch 4538/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.3840 - val_loss: 587.3320\n",
      "Epoch 4539/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.0341 - val_loss: 588.6944\n",
      "Epoch 4540/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 488.9069 - val_loss: 586.6063\n",
      "Epoch 4541/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.2281 - val_loss: 586.8424\n",
      "Epoch 4542/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.4289 - val_loss: 588.0131\n",
      "Epoch 4543/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.0989 - val_loss: 588.6419\n",
      "Epoch 4544/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.9009 - val_loss: 586.9403\n",
      "Epoch 4545/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.1747 - val_loss: 586.3523\n",
      "Epoch 4546/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 488.2106 - val_loss: 586.1531\n",
      "Epoch 4547/10000\n",
      "3000/3000 [==============================] - 0s 14us/sample - loss: 488.8791 - val_loss: 588.7712\n",
      "Epoch 4548/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 488.4875 - val_loss: 587.1188\n",
      "Epoch 4549/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 488.6257 - val_loss: 587.4182\n",
      "Epoch 4550/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.4491 - val_loss: 586.6650\n",
      "Epoch 4551/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.0450 - val_loss: 587.8280\n",
      "Epoch 4552/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 488.0699 - val_loss: 587.7767\n",
      "Epoch 4553/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.1596 - val_loss: 586.8929\n",
      "Epoch 4554/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.5430 - val_loss: 589.0027\n",
      "Epoch 4555/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.0083 - val_loss: 587.6641\n",
      "Epoch 4556/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.6478 - val_loss: 587.7758\n",
      "Epoch 4557/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.0927 - val_loss: 587.7257\n",
      "Epoch 4558/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.3372 - val_loss: 587.4402\n",
      "Epoch 4559/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.7506 - val_loss: 587.9088\n",
      "Epoch 4560/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.8650 - val_loss: 587.1216\n",
      "Epoch 4561/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.8336 - val_loss: 586.4376\n",
      "Epoch 4562/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 489.7527 - val_loss: 587.2952\n",
      "Epoch 4563/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.0038 - val_loss: 586.9653\n",
      "Epoch 4564/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.6587 - val_loss: 587.5955\n",
      "Epoch 4565/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.0624 - val_loss: 586.8971\n",
      "Epoch 4566/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 488.1686 - val_loss: 586.9037\n",
      "Epoch 4567/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.5048 - val_loss: 587.5738\n",
      "Epoch 4568/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.5834 - val_loss: 587.4695\n",
      "Epoch 4569/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.0568 - val_loss: 586.1985\n",
      "Epoch 4570/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.3254 - val_loss: 585.6467\n",
      "Epoch 4571/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.9923 - val_loss: 586.9214\n",
      "Epoch 4572/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.1505 - val_loss: 586.7660\n",
      "Epoch 4573/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 488.3466 - val_loss: 586.0425\n",
      "Epoch 4574/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.0842 - val_loss: 586.8415\n",
      "Epoch 4575/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.0377 - val_loss: 587.5221\n",
      "Epoch 4576/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.8014 - val_loss: 586.4273\n",
      "Epoch 4577/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.8791 - val_loss: 587.0910\n",
      "Epoch 4578/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.2130 - val_loss: 585.9984\n",
      "Epoch 4579/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.2735 - val_loss: 587.6213\n",
      "Epoch 4580/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.7290 - val_loss: 587.1568\n",
      "Epoch 4581/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.6110 - val_loss: 586.7698\n",
      "Epoch 4582/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.5014 - val_loss: 587.1177\n",
      "Epoch 4583/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 487.4558 - val_loss: 586.9870\n",
      "Epoch 4584/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.5106 - val_loss: 588.0921\n",
      "Epoch 4585/10000\n",
      "3000/3000 [==============================] - 0s 14us/sample - loss: 488.0469 - val_loss: 586.2171\n",
      "Epoch 4586/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 487.7638 - val_loss: 587.2671\n",
      "Epoch 4587/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.7579 - val_loss: 587.4657\n",
      "Epoch 4588/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 488.2773 - val_loss: 587.2329\n",
      "Epoch 4589/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.8144 - val_loss: 586.3529\n",
      "Epoch 4590/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 488.3821 - val_loss: 587.4886\n",
      "Epoch 4591/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 488.3568 - val_loss: 586.9429\n",
      "Epoch 4592/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 487.5920 - val_loss: 587.0227\n",
      "Epoch 4593/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 487.6549 - val_loss: 587.0379\n",
      "Epoch 4594/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.1844 - val_loss: 587.4931\n",
      "Epoch 4595/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.5144 - val_loss: 586.8849\n",
      "Epoch 4596/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.0970 - val_loss: 587.4063\n",
      "Epoch 4597/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.0241 - val_loss: 586.9740\n",
      "Epoch 4598/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.1546 - val_loss: 586.7890\n",
      "Epoch 4599/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 487.6085 - val_loss: 587.1947\n",
      "Epoch 4600/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.5149 - val_loss: 587.3231\n",
      "Epoch 4601/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 488.4787 - val_loss: 586.4335\n",
      "Epoch 4602/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.8029 - val_loss: 587.7010\n",
      "Epoch 4603/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.3231 - val_loss: 586.0717\n",
      "Epoch 4604/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.9560 - val_loss: 588.8907\n",
      "Epoch 4605/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.2127 - val_loss: 586.6801\n",
      "Epoch 4606/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 11us/sample - loss: 487.8229 - val_loss: 586.2345\n",
      "Epoch 4607/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.4938 - val_loss: 586.6074\n",
      "Epoch 4608/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.7972 - val_loss: 586.8726\n",
      "Epoch 4609/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 489.9579 - val_loss: 584.9832\n",
      "Epoch 4610/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.1347 - val_loss: 587.7549\n",
      "Epoch 4611/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.5420 - val_loss: 586.5314\n",
      "Epoch 4612/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.6770 - val_loss: 585.8607\n",
      "Epoch 4613/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 488.9769 - val_loss: 586.1151\n",
      "Epoch 4614/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.0742 - val_loss: 585.3940\n",
      "Epoch 4615/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 487.4515 - val_loss: 586.4706\n",
      "Epoch 4616/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 488.5254 - val_loss: 587.0849\n",
      "Epoch 4617/10000\n",
      "3000/3000 [==============================] - 0s 15us/sample - loss: 487.6865 - val_loss: 587.4334\n",
      "Epoch 4618/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 488.5115 - val_loss: 585.8735\n",
      "Epoch 4619/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.9243 - val_loss: 587.3783\n",
      "Epoch 4620/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.2188 - val_loss: 586.1431\n",
      "Epoch 4621/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.8558 - val_loss: 587.7545\n",
      "Epoch 4622/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.9628 - val_loss: 587.1664\n",
      "Epoch 4623/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.0040 - val_loss: 587.7485\n",
      "Epoch 4624/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.6965 - val_loss: 586.8883\n",
      "Epoch 4625/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.2595 - val_loss: 586.3442\n",
      "Epoch 4626/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.3911 - val_loss: 586.0461\n",
      "Epoch 4627/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 487.3628 - val_loss: 585.7830\n",
      "Epoch 4628/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.7375 - val_loss: 585.4101\n",
      "Epoch 4629/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.6008 - val_loss: 585.6341\n",
      "Epoch 4630/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.7144 - val_loss: 585.9161\n",
      "Epoch 4631/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.6987 - val_loss: 586.4558\n",
      "Epoch 4632/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 487.3095 - val_loss: 586.6356\n",
      "Epoch 4633/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.8243 - val_loss: 585.3527\n",
      "Epoch 4634/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.7204 - val_loss: 585.3190\n",
      "Epoch 4635/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.7259 - val_loss: 585.6053\n",
      "Epoch 4636/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 488.0141 - val_loss: 586.1731\n",
      "Epoch 4637/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.8285 - val_loss: 587.2356\n",
      "Epoch 4638/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 487.0296 - val_loss: 587.3688\n",
      "Epoch 4639/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.8469 - val_loss: 586.7848\n",
      "Epoch 4640/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.8331 - val_loss: 585.1492\n",
      "Epoch 4641/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.0057 - val_loss: 586.3670\n",
      "Epoch 4642/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 488.0734 - val_loss: 584.2964\n",
      "Epoch 4643/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.5034 - val_loss: 585.6006\n",
      "Epoch 4644/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.3309 - val_loss: 585.7125\n",
      "Epoch 4645/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.0644 - val_loss: 585.9094\n",
      "Epoch 4646/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.5064 - val_loss: 586.4976\n",
      "Epoch 4647/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.4529 - val_loss: 585.5685\n",
      "Epoch 4648/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.6935 - val_loss: 585.4970\n",
      "Epoch 4649/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.3490 - val_loss: 586.3178\n",
      "Epoch 4650/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.4210 - val_loss: 585.9994\n",
      "Epoch 4651/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.0032 - val_loss: 585.1114\n",
      "Epoch 4652/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.2423 - val_loss: 586.1205\n",
      "Epoch 4653/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 491.1800 - val_loss: 586.7780\n",
      "Epoch 4654/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.6345 - val_loss: 586.4915\n",
      "Epoch 4655/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.0163 - val_loss: 586.1666\n",
      "Epoch 4656/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.4495 - val_loss: 585.0097\n",
      "Epoch 4657/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.3091 - val_loss: 586.3539\n",
      "Epoch 4658/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 487.6926 - val_loss: 587.0229\n",
      "Epoch 4659/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.1870 - val_loss: 584.9253\n",
      "Epoch 4660/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.0669 - val_loss: 586.4277\n",
      "Epoch 4661/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.5446 - val_loss: 584.2446\n",
      "Epoch 4662/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.4943 - val_loss: 584.8146\n",
      "Epoch 4663/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.9468 - val_loss: 586.0076\n",
      "Epoch 4664/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.0049 - val_loss: 586.4546\n",
      "Epoch 4665/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 487.9001 - val_loss: 586.0630\n",
      "Epoch 4666/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.9875 - val_loss: 587.1024\n",
      "Epoch 4667/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.8240 - val_loss: 584.9317\n",
      "Epoch 4668/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 488.7187 - val_loss: 586.2656\n",
      "Epoch 4669/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 489.1767 - val_loss: 586.2969\n",
      "Epoch 4670/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 488.6837 - val_loss: 587.3148\n",
      "Epoch 4671/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.4706 - val_loss: 585.5033\n",
      "Epoch 4672/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.2708 - val_loss: 585.4914\n",
      "Epoch 4673/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.1796 - val_loss: 586.5351\n",
      "Epoch 4674/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.3684 - val_loss: 585.6654\n",
      "Epoch 4675/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.2722 - val_loss: 587.6890\n",
      "Epoch 4676/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.2338 - val_loss: 586.1848\n",
      "Epoch 4677/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.1255 - val_loss: 585.2073\n",
      "Epoch 4678/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.6209 - val_loss: 586.7484\n",
      "Epoch 4679/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.5610 - val_loss: 585.7351\n",
      "Epoch 4680/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 489.3055 - val_loss: 586.6420\n",
      "Epoch 4681/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.9456 - val_loss: 586.6410\n",
      "Epoch 4682/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 486.9821 - val_loss: 585.9878\n",
      "Epoch 4683/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.1928 - val_loss: 586.4315\n",
      "Epoch 4684/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.7830 - val_loss: 585.7579\n",
      "Epoch 4685/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 487.4190 - val_loss: 585.6359\n",
      "Epoch 4686/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.0410 - val_loss: 585.3108\n",
      "Epoch 4687/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 487.6299 - val_loss: 585.1488\n",
      "Epoch 4688/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.4990 - val_loss: 584.6169\n",
      "Epoch 4689/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.0668 - val_loss: 585.0086\n",
      "Epoch 4690/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.0771 - val_loss: 585.0904\n",
      "Epoch 4691/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.3043 - val_loss: 585.4638\n",
      "Epoch 4692/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.6855 - val_loss: 585.1044\n",
      "Epoch 4693/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.8687 - val_loss: 587.4372\n",
      "Epoch 4694/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 487.4309 - val_loss: 585.8217\n",
      "Epoch 4695/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.2684 - val_loss: 585.8310\n",
      "Epoch 4696/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 487.7433 - val_loss: 584.1970\n",
      "Epoch 4697/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.4748 - val_loss: 586.0466\n",
      "Epoch 4698/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.1833 - val_loss: 586.3254\n",
      "Epoch 4699/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 486.6188 - val_loss: 585.9429\n",
      "Epoch 4700/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.6770 - val_loss: 586.7947\n",
      "Epoch 4701/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.4121 - val_loss: 584.9206\n",
      "Epoch 4702/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.4055 - val_loss: 585.6328\n",
      "Epoch 4703/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 486.6350 - val_loss: 585.4708\n",
      "Epoch 4704/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.7644 - val_loss: 584.5711\n",
      "Epoch 4705/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.1579 - val_loss: 585.5120\n",
      "Epoch 4706/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.0884 - val_loss: 586.2562\n",
      "Epoch 4707/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.5589 - val_loss: 585.1905\n",
      "Epoch 4708/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.6598 - val_loss: 585.2941\n",
      "Epoch 4709/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.2168 - val_loss: 585.0650\n",
      "Epoch 4710/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.9939 - val_loss: 586.3827\n",
      "Epoch 4711/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 486.9001 - val_loss: 585.6345\n",
      "Epoch 4712/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 487.0837 - val_loss: 586.0843\n",
      "Epoch 4713/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 486.5529 - val_loss: 585.2541\n",
      "Epoch 4714/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 486.9217 - val_loss: 585.5321\n",
      "Epoch 4715/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.9182 - val_loss: 586.4679\n",
      "Epoch 4716/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.4657 - val_loss: 586.2828\n",
      "Epoch 4717/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 487.3412 - val_loss: 585.7207\n",
      "Epoch 4718/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.9329 - val_loss: 586.0486\n",
      "Epoch 4719/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.0766 - val_loss: 586.3479\n",
      "Epoch 4720/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.1861 - val_loss: 585.5174\n",
      "Epoch 4721/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.8770 - val_loss: 585.3718\n",
      "Epoch 4722/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 486.8761 - val_loss: 586.5557\n",
      "Epoch 4723/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 487.2935 - val_loss: 586.1757\n",
      "Epoch 4724/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.4412 - val_loss: 583.9455\n",
      "Epoch 4725/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.8616 - val_loss: 586.4496\n",
      "Epoch 4726/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 486.9083 - val_loss: 584.0141\n",
      "Epoch 4727/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.8339 - val_loss: 585.6729\n",
      "Epoch 4728/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.9666 - val_loss: 585.0584\n",
      "Epoch 4729/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.8796 - val_loss: 585.4023\n",
      "Epoch 4730/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.4948 - val_loss: 585.3488\n",
      "Epoch 4731/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 487.2668 - val_loss: 585.5628\n",
      "Epoch 4732/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.5690 - val_loss: 585.8953\n",
      "Epoch 4733/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.3376 - val_loss: 584.7416\n",
      "Epoch 4734/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 487.0506 - val_loss: 584.8633\n",
      "Epoch 4735/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.8885 - val_loss: 585.3707\n",
      "Epoch 4736/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.6760 - val_loss: 584.0203\n",
      "Epoch 4737/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.0749 - val_loss: 585.5028\n",
      "Epoch 4738/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.6005 - val_loss: 585.3185\n",
      "Epoch 4739/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.8992 - val_loss: 584.7891\n",
      "Epoch 4740/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.8397 - val_loss: 584.7406\n",
      "Epoch 4741/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.5090 - val_loss: 585.3935\n",
      "Epoch 4742/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 486.9267 - val_loss: 583.6224\n",
      "Epoch 4743/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.9179 - val_loss: 585.2481\n",
      "Epoch 4744/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.8426 - val_loss: 583.6698\n",
      "Epoch 4745/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.4014 - val_loss: 585.6884\n",
      "Epoch 4746/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.8753 - val_loss: 583.8736\n",
      "Epoch 4747/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.9176 - val_loss: 584.7144\n",
      "Epoch 4748/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 11us/sample - loss: 487.2043 - val_loss: 584.6939\n",
      "Epoch 4749/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 487.5775 - val_loss: 586.4148\n",
      "Epoch 4750/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 613.8811Epoch: 4750 - loss: 487.030687 - val_loss: 584.823592\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.0307 - val_loss: 584.8236\n",
      "Epoch 4751/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.7255 - val_loss: 584.8371\n",
      "Epoch 4752/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.7137 - val_loss: 585.0852\n",
      "Epoch 4753/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.6614 - val_loss: 585.3939\n",
      "Epoch 4754/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.2094 - val_loss: 585.2391\n",
      "Epoch 4755/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.5899 - val_loss: 585.5470\n",
      "Epoch 4756/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.5470 - val_loss: 585.7557\n",
      "Epoch 4757/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.7912 - val_loss: 585.4745\n",
      "Epoch 4758/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.6374 - val_loss: 586.1528\n",
      "Epoch 4759/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 486.7077 - val_loss: 585.4352\n",
      "Epoch 4760/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 487.3523 - val_loss: 585.2568\n",
      "Epoch 4761/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 486.7484 - val_loss: 584.3479\n",
      "Epoch 4762/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.8701 - val_loss: 584.9711\n",
      "Epoch 4763/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 486.7986 - val_loss: 585.0620\n",
      "Epoch 4764/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 486.7254 - val_loss: 585.2996\n",
      "Epoch 4765/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 487.5486 - val_loss: 585.5531\n",
      "Epoch 4766/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.7595 - val_loss: 586.7790\n",
      "Epoch 4767/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.2607 - val_loss: 584.8677\n",
      "Epoch 4768/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.5540 - val_loss: 586.2049\n",
      "Epoch 4769/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.0804 - val_loss: 586.3526\n",
      "Epoch 4770/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.3502 - val_loss: 585.2914\n",
      "Epoch 4771/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.7829 - val_loss: 585.7905\n",
      "Epoch 4772/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 486.1264 - val_loss: 585.6927\n",
      "Epoch 4773/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.1214 - val_loss: 586.3260\n",
      "Epoch 4774/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 486.3690 - val_loss: 585.0090\n",
      "Epoch 4775/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.2066 - val_loss: 584.8428\n",
      "Epoch 4776/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.7815 - val_loss: 586.4788\n",
      "Epoch 4777/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.8015 - val_loss: 585.5291\n",
      "Epoch 4778/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.6452 - val_loss: 585.1360\n",
      "Epoch 4779/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.0514 - val_loss: 585.8995\n",
      "Epoch 4780/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 488.1474 - val_loss: 584.8532\n",
      "Epoch 4781/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 487.0432 - val_loss: 585.6762\n",
      "Epoch 4782/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.4194 - val_loss: 584.6318\n",
      "Epoch 4783/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 487.1392 - val_loss: 584.8877\n",
      "Epoch 4784/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 489.0636 - val_loss: 585.3522\n",
      "Epoch 4785/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 486.8965 - val_loss: 584.5327\n",
      "Epoch 4786/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 487.3502 - val_loss: 584.0554\n",
      "Epoch 4787/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 487.0754 - val_loss: 584.5609\n",
      "Epoch 4788/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.9934 - val_loss: 584.2517\n",
      "Epoch 4789/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.4977 - val_loss: 585.6022\n",
      "Epoch 4790/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.8462 - val_loss: 584.2994\n",
      "Epoch 4791/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 486.9898 - val_loss: 585.6568\n",
      "Epoch 4792/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.8018 - val_loss: 584.9647\n",
      "Epoch 4793/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.3445 - val_loss: 583.6917\n",
      "Epoch 4794/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.2608 - val_loss: 584.0144\n",
      "Epoch 4795/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.2613 - val_loss: 584.8799\n",
      "Epoch 4796/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 486.7121 - val_loss: 584.5167\n",
      "Epoch 4797/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 486.7341 - val_loss: 584.7037\n",
      "Epoch 4798/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 486.4857 - val_loss: 585.0623\n",
      "Epoch 4799/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 486.5993 - val_loss: 582.8525\n",
      "Epoch 4800/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.9527 - val_loss: 583.4723\n",
      "Epoch 4801/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.1804 - val_loss: 583.7708\n",
      "Epoch 4802/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.8332 - val_loss: 583.7648\n",
      "Epoch 4803/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.2984 - val_loss: 584.4066\n",
      "Epoch 4804/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 487.2051 - val_loss: 584.0783\n",
      "Epoch 4805/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 487.2120 - val_loss: 585.4944\n",
      "Epoch 4806/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.1126 - val_loss: 584.5013\n",
      "Epoch 4807/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.9205 - val_loss: 583.8807\n",
      "Epoch 4808/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.0139 - val_loss: 585.9810\n",
      "Epoch 4809/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.8239 - val_loss: 583.6990\n",
      "Epoch 4810/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.3446 - val_loss: 584.7705\n",
      "Epoch 4811/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.7065 - val_loss: 582.9606\n",
      "Epoch 4812/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.7147 - val_loss: 585.0094\n",
      "Epoch 4813/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.1592 - val_loss: 584.3150\n",
      "Epoch 4814/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.2598 - val_loss: 584.5481\n",
      "Epoch 4815/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.9734 - val_loss: 583.8651\n",
      "Epoch 4816/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.2285 - val_loss: 583.7860\n",
      "Epoch 4817/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.2070 - val_loss: 584.0929\n",
      "Epoch 4818/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.8332 - val_loss: 585.0037\n",
      "Epoch 4819/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 486.8610 - val_loss: 584.7683\n",
      "Epoch 4820/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.3097 - val_loss: 584.4448\n",
      "Epoch 4821/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.5232 - val_loss: 586.1009\n",
      "Epoch 4822/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.5422 - val_loss: 585.0171\n",
      "Epoch 4823/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.8200 - val_loss: 583.8246\n",
      "Epoch 4824/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.0246 - val_loss: 584.4373\n",
      "Epoch 4825/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.3967 - val_loss: 584.5731\n",
      "Epoch 4826/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.1260 - val_loss: 584.9919\n",
      "Epoch 4827/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.4662 - val_loss: 583.9196\n",
      "Epoch 4828/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.9604 - val_loss: 584.2913\n",
      "Epoch 4829/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 486.3483 - val_loss: 584.0753\n",
      "Epoch 4830/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.4555 - val_loss: 583.8848\n",
      "Epoch 4831/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.0041 - val_loss: 582.7097\n",
      "Epoch 4832/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.8488 - val_loss: 583.7727\n",
      "Epoch 4833/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.8157 - val_loss: 584.4965\n",
      "Epoch 4834/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.3444 - val_loss: 584.3317\n",
      "Epoch 4835/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.9311 - val_loss: 583.9589\n",
      "Epoch 4836/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.1264 - val_loss: 584.2723\n",
      "Epoch 4837/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.1756 - val_loss: 584.0020\n",
      "Epoch 4838/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.7060 - val_loss: 583.6484\n",
      "Epoch 4839/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.8561 - val_loss: 583.0200\n",
      "Epoch 4840/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.4179 - val_loss: 583.3700\n",
      "Epoch 4841/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.2482 - val_loss: 583.6262\n",
      "Epoch 4842/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.0603 - val_loss: 584.6498\n",
      "Epoch 4843/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.7390 - val_loss: 583.9478\n",
      "Epoch 4844/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.3802 - val_loss: 583.5777\n",
      "Epoch 4845/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.3024 - val_loss: 583.5501\n",
      "Epoch 4846/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.6262 - val_loss: 583.2306\n",
      "Epoch 4847/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.7276 - val_loss: 585.2840\n",
      "Epoch 4848/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.9596 - val_loss: 583.0460\n",
      "Epoch 4849/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.1069 - val_loss: 585.2464\n",
      "Epoch 4850/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.9073 - val_loss: 584.6724\n",
      "Epoch 4851/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.7967 - val_loss: 582.7683\n",
      "Epoch 4852/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.0269 - val_loss: 584.2234\n",
      "Epoch 4853/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.8344 - val_loss: 583.3132\n",
      "Epoch 4854/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.6676 - val_loss: 583.4777\n",
      "Epoch 4855/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.8307 - val_loss: 583.1723\n",
      "Epoch 4856/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.0405 - val_loss: 583.4328\n",
      "Epoch 4857/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.1260 - val_loss: 583.6310\n",
      "Epoch 4858/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.6120 - val_loss: 584.1525\n",
      "Epoch 4859/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.6229 - val_loss: 583.1875\n",
      "Epoch 4860/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.0879 - val_loss: 582.7982\n",
      "Epoch 4861/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.1177 - val_loss: 585.3983\n",
      "Epoch 4862/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.9255 - val_loss: 582.3924\n",
      "Epoch 4863/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.1307 - val_loss: 583.1894\n",
      "Epoch 4864/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.2033 - val_loss: 584.2161\n",
      "Epoch 4865/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.5933 - val_loss: 584.7045\n",
      "Epoch 4866/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.4256 - val_loss: 583.8906\n",
      "Epoch 4867/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.6756 - val_loss: 584.0326\n",
      "Epoch 4868/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 486.4219 - val_loss: 584.2310\n",
      "Epoch 4869/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 486.0103 - val_loss: 584.9972\n",
      "Epoch 4870/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.3359 - val_loss: 583.7232\n",
      "Epoch 4871/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.7009 - val_loss: 583.3051\n",
      "Epoch 4872/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 487.0622 - val_loss: 583.2597\n",
      "Epoch 4873/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.0703 - val_loss: 583.3008\n",
      "Epoch 4874/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.0850 - val_loss: 582.7568\n",
      "Epoch 4875/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.9034 - val_loss: 582.6851\n",
      "Epoch 4876/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.5043 - val_loss: 583.1875\n",
      "Epoch 4877/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.3248 - val_loss: 583.7153\n",
      "Epoch 4878/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.7161 - val_loss: 582.9378\n",
      "Epoch 4879/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.8658 - val_loss: 583.2319\n",
      "Epoch 4880/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.8519 - val_loss: 583.8428\n",
      "Epoch 4881/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.3119 - val_loss: 583.3145\n",
      "Epoch 4882/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.8474 - val_loss: 584.0964\n",
      "Epoch 4883/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.1051 - val_loss: 583.1434\n",
      "Epoch 4884/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.3884 - val_loss: 583.4850\n",
      "Epoch 4885/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.3647 - val_loss: 584.6660\n",
      "Epoch 4886/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.3355 - val_loss: 584.0981\n",
      "Epoch 4887/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.6112 - val_loss: 583.0573\n",
      "Epoch 4888/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.4788 - val_loss: 583.6713\n",
      "Epoch 4889/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.6050 - val_loss: 584.9986\n",
      "Epoch 4890/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.7438 - val_loss: 582.5633\n",
      "Epoch 4891/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.5292 - val_loss: 583.2633\n",
      "Epoch 4892/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.8008 - val_loss: 583.1236\n",
      "Epoch 4893/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 486.0460 - val_loss: 582.2016\n",
      "Epoch 4894/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 486.2497 - val_loss: 583.5364\n",
      "Epoch 4895/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.8518 - val_loss: 583.6209\n",
      "Epoch 4896/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.3455 - val_loss: 584.1194\n",
      "Epoch 4897/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.9532 - val_loss: 583.1224\n",
      "Epoch 4898/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.8437 - val_loss: 583.4666\n",
      "Epoch 4899/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.5995 - val_loss: 583.4758\n",
      "Epoch 4900/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.7908 - val_loss: 583.6641\n",
      "Epoch 4901/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.9444 - val_loss: 583.3781\n",
      "Epoch 4902/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.7674 - val_loss: 582.7067\n",
      "Epoch 4903/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.4911 - val_loss: 583.2276\n",
      "Epoch 4904/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.5104 - val_loss: 583.3793\n",
      "Epoch 4905/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.7471 - val_loss: 584.0222\n",
      "Epoch 4906/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.4617 - val_loss: 584.1389\n",
      "Epoch 4907/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 486.2203 - val_loss: 583.5778\n",
      "Epoch 4908/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.2370 - val_loss: 584.3508\n",
      "Epoch 4909/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.7323 - val_loss: 583.4890\n",
      "Epoch 4910/10000\n",
      "3000/3000 [==============================] - 0s 15us/sample - loss: 485.4797 - val_loss: 583.6419\n",
      "Epoch 4911/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 486.0257 - val_loss: 583.3087\n",
      "Epoch 4912/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 485.2226 - val_loss: 582.2943\n",
      "Epoch 4913/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 485.6223 - val_loss: 583.1682\n",
      "Epoch 4914/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 487.2101 - val_loss: 582.2554\n",
      "Epoch 4915/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.2665 - val_loss: 583.3446\n",
      "Epoch 4916/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 486.9986 - val_loss: 584.2107\n",
      "Epoch 4917/10000\n",
      "3000/3000 [==============================] - 0s 14us/sample - loss: 485.5101 - val_loss: 583.4898\n",
      "Epoch 4918/10000\n",
      "3000/3000 [==============================] - 0s 15us/sample - loss: 485.8387 - val_loss: 582.3520\n",
      "Epoch 4919/10000\n",
      "3000/3000 [==============================] - 0s 16us/sample - loss: 486.0358 - val_loss: 584.4372\n",
      "Epoch 4920/10000\n",
      "3000/3000 [==============================] - 0s 14us/sample - loss: 485.7550 - val_loss: 583.1150\n",
      "Epoch 4921/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.2295 - val_loss: 584.3091\n",
      "Epoch 4922/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.4749 - val_loss: 584.1248\n",
      "Epoch 4923/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 485.6704 - val_loss: 582.6916\n",
      "Epoch 4924/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 485.6871 - val_loss: 583.5969\n",
      "Epoch 4925/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 485.2480 - val_loss: 584.4711\n",
      "Epoch 4926/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 486.0688 - val_loss: 584.0648\n",
      "Epoch 4927/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 485.8660 - val_loss: 583.3039\n",
      "Epoch 4928/10000\n",
      "3000/3000 [==============================] - 0s 14us/sample - loss: 485.1543 - val_loss: 583.1475\n",
      "Epoch 4929/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 485.3135 - val_loss: 584.3183\n",
      "Epoch 4930/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.2394 - val_loss: 583.3260\n",
      "Epoch 4931/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.7972 - val_loss: 582.9003\n",
      "Epoch 4932/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 485.6470 - val_loss: 582.7434\n",
      "Epoch 4933/10000\n",
      "3000/3000 [==============================] - 0s 14us/sample - loss: 485.9074 - val_loss: 584.0769\n",
      "Epoch 4934/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 486.1056 - val_loss: 582.9865\n",
      "Epoch 4935/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 485.8966 - val_loss: 584.0762\n",
      "Epoch 4936/10000\n",
      "3000/3000 [==============================] - 0s 14us/sample - loss: 486.7628 - val_loss: 582.1244\n",
      "Epoch 4937/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.4978 - val_loss: 584.5408\n",
      "Epoch 4938/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.4144 - val_loss: 584.4513\n",
      "Epoch 4939/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.0014 - val_loss: 584.4984\n",
      "Epoch 4940/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 486.1774 - val_loss: 583.1962\n",
      "Epoch 4941/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.3558 - val_loss: 584.6847\n",
      "Epoch 4942/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.2201 - val_loss: 583.1425\n",
      "Epoch 4943/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.2492 - val_loss: 583.3295\n",
      "Epoch 4944/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.6639 - val_loss: 584.2307\n",
      "Epoch 4945/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.7468 - val_loss: 583.6504\n",
      "Epoch 4946/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.2072 - val_loss: 584.1177\n",
      "Epoch 4947/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.6198 - val_loss: 584.2960\n",
      "Epoch 4948/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.3667 - val_loss: 582.6048\n",
      "Epoch 4949/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.8429 - val_loss: 583.6990\n",
      "Epoch 4950/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.8737 - val_loss: 583.3473\n",
      "Epoch 4951/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.1569 - val_loss: 582.8477\n",
      "Epoch 4952/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.6816 - val_loss: 583.2196\n",
      "Epoch 4953/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.5486 - val_loss: 583.6190\n",
      "Epoch 4954/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.9415 - val_loss: 583.4008\n",
      "Epoch 4955/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.2826 - val_loss: 583.1809\n",
      "Epoch 4956/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.3818 - val_loss: 583.8813\n",
      "Epoch 4957/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.2689 - val_loss: 584.0980\n",
      "Epoch 4958/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.3814 - val_loss: 582.8771\n",
      "Epoch 4959/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.6815 - val_loss: 584.7373\n",
      "Epoch 4960/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.1587 - val_loss: 582.8493\n",
      "Epoch 4961/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.3147 - val_loss: 582.7098\n",
      "Epoch 4962/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.1104 - val_loss: 582.9395\n",
      "Epoch 4963/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.2282 - val_loss: 583.4703\n",
      "Epoch 4964/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.5799 - val_loss: 583.6414\n",
      "Epoch 4965/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.6151 - val_loss: 583.6384\n",
      "Epoch 4966/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.6827 - val_loss: 583.4366\n",
      "Epoch 4967/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.7426 - val_loss: 583.2276\n",
      "Epoch 4968/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.7656 - val_loss: 583.1740\n",
      "Epoch 4969/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.3380 - val_loss: 583.3515\n",
      "Epoch 4970/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.0221 - val_loss: 584.2702\n",
      "Epoch 4971/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.2515 - val_loss: 584.4071\n",
      "Epoch 4972/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.8503 - val_loss: 583.3274\n",
      "Epoch 4973/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.2064 - val_loss: 582.5446\n",
      "Epoch 4974/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.6507 - val_loss: 583.8983\n",
      "Epoch 4975/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 486.3956 - val_loss: 582.6887\n",
      "Epoch 4976/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 484.7374 - val_loss: 584.1163\n",
      "Epoch 4977/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.8404 - val_loss: 583.5895\n",
      "Epoch 4978/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.8170 - val_loss: 584.2983\n",
      "Epoch 4979/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 484.7127 - val_loss: 583.1949\n",
      "Epoch 4980/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.7956 - val_loss: 582.5820\n",
      "Epoch 4981/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.1219 - val_loss: 582.2358\n",
      "Epoch 4982/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.4557 - val_loss: 584.1197\n",
      "Epoch 4983/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.6474 - val_loss: 583.6183\n",
      "Epoch 4984/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.6692 - val_loss: 582.1777\n",
      "Epoch 4985/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.3701 - val_loss: 583.7782\n",
      "Epoch 4986/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 484.8593 - val_loss: 582.5390\n",
      "Epoch 4987/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.4550 - val_loss: 582.9721\n",
      "Epoch 4988/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.4324 - val_loss: 584.0896\n",
      "Epoch 4989/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.9343 - val_loss: 583.3572\n",
      "Epoch 4990/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.3850 - val_loss: 583.2805\n",
      "Epoch 4991/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.6945 - val_loss: 583.6541\n",
      "Epoch 4992/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.2272 - val_loss: 583.7044\n",
      "Epoch 4993/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.6854 - val_loss: 583.8022\n",
      "Epoch 4994/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.8276 - val_loss: 582.3041\n",
      "Epoch 4995/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.7052 - val_loss: 583.8157\n",
      "Epoch 4996/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.0149 - val_loss: 583.5386\n",
      "Epoch 4997/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.9865 - val_loss: 583.1925\n",
      "Epoch 4998/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.0015 - val_loss: 583.7931\n",
      "Epoch 4999/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.9779 - val_loss: 583.7593\n",
      "Epoch 5000/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 411.7858Epoch: 5000 - loss: 485.397471 - val_loss: 582.978690\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.3975 - val_loss: 582.9787\n",
      "Epoch 5001/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.2110 - val_loss: 582.7143\n",
      "Epoch 5002/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.2109 - val_loss: 581.6663\n",
      "Epoch 5003/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.5568 - val_loss: 582.7524\n",
      "Epoch 5004/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.0870 - val_loss: 581.6837\n",
      "Epoch 5005/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.8678 - val_loss: 584.9243\n",
      "Epoch 5006/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.2104 - val_loss: 583.3105\n",
      "Epoch 5007/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.7215 - val_loss: 582.6828\n",
      "Epoch 5008/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.5188 - val_loss: 581.9331\n",
      "Epoch 5009/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 487.3779 - val_loss: 583.5181\n",
      "Epoch 5010/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.1241 - val_loss: 581.0049\n",
      "Epoch 5011/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.7410 - val_loss: 581.9921\n",
      "Epoch 5012/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.6472 - val_loss: 583.1377\n",
      "Epoch 5013/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.9685 - val_loss: 582.7419\n",
      "Epoch 5014/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.0483 - val_loss: 582.5786\n",
      "Epoch 5015/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.8959 - val_loss: 582.5918\n",
      "Epoch 5016/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.8485 - val_loss: 583.8403\n",
      "Epoch 5017/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.3719 - val_loss: 583.3766\n",
      "Epoch 5018/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.4707 - val_loss: 584.0304\n",
      "Epoch 5019/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.2135 - val_loss: 583.8136\n",
      "Epoch 5020/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 487.4348 - val_loss: 582.5538\n",
      "Epoch 5021/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 484.7540 - val_loss: 583.8901\n",
      "Epoch 5022/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.8678 - val_loss: 583.4458\n",
      "Epoch 5023/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 486.0934 - val_loss: 582.7298\n",
      "Epoch 5024/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.9021 - val_loss: 582.3005\n",
      "Epoch 5025/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.4340 - val_loss: 581.5627\n",
      "Epoch 5026/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.3371 - val_loss: 583.1630\n",
      "Epoch 5027/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.9160 - val_loss: 582.7826\n",
      "Epoch 5028/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.9830 - val_loss: 582.8528\n",
      "Epoch 5029/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.1603 - val_loss: 582.2331\n",
      "Epoch 5030/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.7335 - val_loss: 583.2899\n",
      "Epoch 5031/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.1981 - val_loss: 582.3417\n",
      "Epoch 5032/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.8863 - val_loss: 583.1035\n",
      "Epoch 5033/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.9875 - val_loss: 582.2522\n",
      "Epoch 5034/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.0364 - val_loss: 582.8478\n",
      "Epoch 5035/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.7922 - val_loss: 582.1507\n",
      "Epoch 5036/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.7656 - val_loss: 583.0433\n",
      "Epoch 5037/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.5015 - val_loss: 582.4148\n",
      "Epoch 5038/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.7757 - val_loss: 582.8315\n",
      "Epoch 5039/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.9157 - val_loss: 581.9929\n",
      "Epoch 5040/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.6668 - val_loss: 582.6096\n",
      "Epoch 5041/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.5900 - val_loss: 582.6666\n",
      "Epoch 5042/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.6026 - val_loss: 581.0827\n",
      "Epoch 5043/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.7944 - val_loss: 582.0234\n",
      "Epoch 5044/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.7089 - val_loss: 582.2481\n",
      "Epoch 5045/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.5812 - val_loss: 580.9540\n",
      "Epoch 5046/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.9305 - val_loss: 583.1864\n",
      "Epoch 5047/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.8296 - val_loss: 582.9545\n",
      "Epoch 5048/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.6118 - val_loss: 583.9977\n",
      "Epoch 5049/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.9444 - val_loss: 583.2742\n",
      "Epoch 5050/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.0900 - val_loss: 583.5152\n",
      "Epoch 5051/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.8317 - val_loss: 582.7514\n",
      "Epoch 5052/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.2650 - val_loss: 582.3724\n",
      "Epoch 5053/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.4048 - val_loss: 583.7192\n",
      "Epoch 5054/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.2741 - val_loss: 583.3299\n",
      "Epoch 5055/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.1351 - val_loss: 581.9926\n",
      "Epoch 5056/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.3429 - val_loss: 582.5131\n",
      "Epoch 5057/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.8451 - val_loss: 582.0919\n",
      "Epoch 5058/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.9936 - val_loss: 582.6894\n",
      "Epoch 5059/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.4471 - val_loss: 581.8043\n",
      "Epoch 5060/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.3394 - val_loss: 581.0935\n",
      "Epoch 5061/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.9466 - val_loss: 581.9504\n",
      "Epoch 5062/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.4517 - val_loss: 583.0186\n",
      "Epoch 5063/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.9595 - val_loss: 582.3543\n",
      "Epoch 5064/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.1899 - val_loss: 582.7977\n",
      "Epoch 5065/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.9939 - val_loss: 583.6815\n",
      "Epoch 5066/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.0183 - val_loss: 582.1943\n",
      "Epoch 5067/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.0537 - val_loss: 581.4838\n",
      "Epoch 5068/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.1543 - val_loss: 582.2014\n",
      "Epoch 5069/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.1174 - val_loss: 583.7759\n",
      "Epoch 5070/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.1399 - val_loss: 582.7497\n",
      "Epoch 5071/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.1568 - val_loss: 583.9910\n",
      "Epoch 5072/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.4729 - val_loss: 582.4551\n",
      "Epoch 5073/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.4293 - val_loss: 582.5734\n",
      "Epoch 5074/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.5666 - val_loss: 581.9438\n",
      "Epoch 5075/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.8981 - val_loss: 582.1829\n",
      "Epoch 5076/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.5014 - val_loss: 582.5422\n",
      "Epoch 5077/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.1236 - val_loss: 581.3692\n",
      "Epoch 5078/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.7181 - val_loss: 580.4788\n",
      "Epoch 5079/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.9413 - val_loss: 580.7889\n",
      "Epoch 5080/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.6842 - val_loss: 582.7394\n",
      "Epoch 5081/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.6614 - val_loss: 581.8210\n",
      "Epoch 5082/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.7982 - val_loss: 582.7067\n",
      "Epoch 5083/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.4164 - val_loss: 581.6792\n",
      "Epoch 5084/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 484.9672 - val_loss: 580.7332\n",
      "Epoch 5085/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.0015 - val_loss: 581.5864\n",
      "Epoch 5086/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.0997 - val_loss: 581.5581\n",
      "Epoch 5087/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 484.6282 - val_loss: 582.6703\n",
      "Epoch 5088/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.0230 - val_loss: 581.1048\n",
      "Epoch 5089/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.3640 - val_loss: 583.2965\n",
      "Epoch 5090/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.3239 - val_loss: 581.3537\n",
      "Epoch 5091/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.6423 - val_loss: 581.2385\n",
      "Epoch 5092/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.3325 - val_loss: 582.0130\n",
      "Epoch 5093/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 484.0786 - val_loss: 582.5911\n",
      "Epoch 5094/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.4746 - val_loss: 581.9540\n",
      "Epoch 5095/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.9531 - val_loss: 581.2557\n",
      "Epoch 5096/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.7339 - val_loss: 582.1284\n",
      "Epoch 5097/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.1333 - val_loss: 581.5879\n",
      "Epoch 5098/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.9484 - val_loss: 583.4387\n",
      "Epoch 5099/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.8478 - val_loss: 582.5731\n",
      "Epoch 5100/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.6464 - val_loss: 581.6416\n",
      "Epoch 5101/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.0303 - val_loss: 581.6029\n",
      "Epoch 5102/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.4207 - val_loss: 583.1603\n",
      "Epoch 5103/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.5054 - val_loss: 581.4502\n",
      "Epoch 5104/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.9448 - val_loss: 581.7123\n",
      "Epoch 5105/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.0864 - val_loss: 583.7591\n",
      "Epoch 5106/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 484.2165 - val_loss: 581.5113\n",
      "Epoch 5107/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.3063 - val_loss: 582.9635\n",
      "Epoch 5108/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.4731 - val_loss: 582.5231\n",
      "Epoch 5109/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.6665 - val_loss: 582.2849\n",
      "Epoch 5110/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.4382 - val_loss: 581.7836\n",
      "Epoch 5111/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.7167 - val_loss: 581.1376\n",
      "Epoch 5112/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.5809 - val_loss: 581.5937\n",
      "Epoch 5113/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.3756 - val_loss: 582.4388\n",
      "Epoch 5114/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.1456 - val_loss: 582.6925\n",
      "Epoch 5115/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.1544 - val_loss: 581.3104\n",
      "Epoch 5116/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.6489 - val_loss: 582.5362\n",
      "Epoch 5117/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.0538 - val_loss: 582.0075\n",
      "Epoch 5118/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.1114 - val_loss: 582.0235\n",
      "Epoch 5119/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.6151 - val_loss: 582.2842\n",
      "Epoch 5120/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.0821 - val_loss: 581.4463\n",
      "Epoch 5121/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.8447 - val_loss: 582.9991\n",
      "Epoch 5122/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.2592 - val_loss: 580.5411\n",
      "Epoch 5123/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.3321 - val_loss: 582.7881\n",
      "Epoch 5124/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.2157 - val_loss: 582.5137\n",
      "Epoch 5125/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.9033 - val_loss: 582.3949\n",
      "Epoch 5126/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.3670 - val_loss: 581.4480\n",
      "Epoch 5127/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.9222 - val_loss: 582.0725\n",
      "Epoch 5128/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.7820 - val_loss: 582.4699\n",
      "Epoch 5129/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.9457 - val_loss: 581.9890\n",
      "Epoch 5130/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.1066 - val_loss: 582.9420\n",
      "Epoch 5131/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.8064 - val_loss: 582.4203\n",
      "Epoch 5132/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 484.2004 - val_loss: 582.5145\n",
      "Epoch 5133/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.2817 - val_loss: 581.2548\n",
      "Epoch 5134/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.4380 - val_loss: 581.1615\n",
      "Epoch 5135/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.7245 - val_loss: 581.4311\n",
      "Epoch 5136/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.9268 - val_loss: 581.5638\n",
      "Epoch 5137/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.8843 - val_loss: 581.7102\n",
      "Epoch 5138/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.5919 - val_loss: 581.9872\n",
      "Epoch 5139/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.1493 - val_loss: 582.3417\n",
      "Epoch 5140/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.7252 - val_loss: 581.8664\n",
      "Epoch 5141/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.3809 - val_loss: 581.7161\n",
      "Epoch 5142/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.3320 - val_loss: 581.9270\n",
      "Epoch 5143/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.0183 - val_loss: 581.5643\n",
      "Epoch 5144/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.0757 - val_loss: 581.6435\n",
      "Epoch 5145/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.2199 - val_loss: 581.0846\n",
      "Epoch 5146/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.4490 - val_loss: 581.5958\n",
      "Epoch 5147/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.4176 - val_loss: 582.9139\n",
      "Epoch 5148/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.5827 - val_loss: 581.3558\n",
      "Epoch 5149/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.8379 - val_loss: 581.6106\n",
      "Epoch 5150/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.8776 - val_loss: 582.1144\n",
      "Epoch 5151/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.8300 - val_loss: 583.2796\n",
      "Epoch 5152/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.4452 - val_loss: 580.6930\n",
      "Epoch 5153/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.9228 - val_loss: 580.9224\n",
      "Epoch 5154/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.3313 - val_loss: 581.6578\n",
      "Epoch 5155/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.5468 - val_loss: 581.5520\n",
      "Epoch 5156/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.8868 - val_loss: 582.7563\n",
      "Epoch 5157/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.4996 - val_loss: 583.2268\n",
      "Epoch 5158/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.5571 - val_loss: 582.3756\n",
      "Epoch 5159/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.7274 - val_loss: 581.9529\n",
      "Epoch 5160/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.1095 - val_loss: 582.2591\n",
      "Epoch 5161/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.3359 - val_loss: 582.5664\n",
      "Epoch 5162/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.1956 - val_loss: 581.7739\n",
      "Epoch 5163/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.2125 - val_loss: 580.6512\n",
      "Epoch 5164/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.7711 - val_loss: 583.2864\n",
      "Epoch 5165/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.9675 - val_loss: 580.6211\n",
      "Epoch 5166/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.0220 - val_loss: 581.9454\n",
      "Epoch 5167/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.9399 - val_loss: 582.2702\n",
      "Epoch 5168/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.0488 - val_loss: 581.0285\n",
      "Epoch 5169/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.9471 - val_loss: 582.0289\n",
      "Epoch 5170/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.7975 - val_loss: 581.0761\n",
      "Epoch 5171/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.9389 - val_loss: 580.7308\n",
      "Epoch 5172/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.9924 - val_loss: 582.0070\n",
      "Epoch 5173/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.9816 - val_loss: 581.7610\n",
      "Epoch 5174/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 486.2393 - val_loss: 582.5695\n",
      "Epoch 5175/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.6824 - val_loss: 581.4679\n",
      "Epoch 5176/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.2757 - val_loss: 581.0993\n",
      "Epoch 5177/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.2894 - val_loss: 581.2204\n",
      "Epoch 5178/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.9216 - val_loss: 581.3973\n",
      "Epoch 5179/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.3787 - val_loss: 582.1915\n",
      "Epoch 5180/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.7642 - val_loss: 583.9770\n",
      "Epoch 5181/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.1085 - val_loss: 581.4897\n",
      "Epoch 5182/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 484.0147 - val_loss: 582.2391\n",
      "Epoch 5183/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.4020 - val_loss: 583.3036\n",
      "Epoch 5184/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.3230 - val_loss: 581.7124\n",
      "Epoch 5185/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.5895 - val_loss: 581.6058\n",
      "Epoch 5186/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.8613 - val_loss: 582.2778\n",
      "Epoch 5187/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.9541 - val_loss: 581.6743\n",
      "Epoch 5188/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.6044 - val_loss: 581.7637\n",
      "Epoch 5189/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.6875 - val_loss: 581.0754\n",
      "Epoch 5190/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.8944 - val_loss: 580.8628\n",
      "Epoch 5191/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.5969 - val_loss: 580.1582\n",
      "Epoch 5192/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.5132 - val_loss: 581.0053\n",
      "Epoch 5193/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.2520 - val_loss: 582.0603\n",
      "Epoch 5194/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.4635 - val_loss: 580.5255\n",
      "Epoch 5195/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.5425 - val_loss: 581.3790\n",
      "Epoch 5196/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.7943 - val_loss: 581.9741\n",
      "Epoch 5197/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.5204 - val_loss: 581.2163\n",
      "Epoch 5198/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.2693 - val_loss: 579.9876\n",
      "Epoch 5199/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.9566 - val_loss: 580.7344\n",
      "Epoch 5200/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.8934 - val_loss: 580.6570\n",
      "Epoch 5201/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.5981 - val_loss: 580.0885\n",
      "Epoch 5202/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.1752 - val_loss: 580.8305\n",
      "Epoch 5203/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.4881 - val_loss: 581.6843\n",
      "Epoch 5204/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.9948 - val_loss: 581.4738\n",
      "Epoch 5205/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.6359 - val_loss: 580.4756\n",
      "Epoch 5206/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.3564 - val_loss: 581.1599\n",
      "Epoch 5207/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.3728 - val_loss: 581.9420\n",
      "Epoch 5208/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.8287 - val_loss: 580.3417\n",
      "Epoch 5209/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.3055 - val_loss: 580.1507\n",
      "Epoch 5210/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.7078 - val_loss: 580.1367\n",
      "Epoch 5211/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.5300 - val_loss: 581.0131\n",
      "Epoch 5212/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.1531 - val_loss: 580.5456\n",
      "Epoch 5213/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.1633 - val_loss: 579.8465\n",
      "Epoch 5214/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.2044 - val_loss: 580.7420\n",
      "Epoch 5215/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.6031 - val_loss: 581.4687\n",
      "Epoch 5216/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.7803 - val_loss: 580.5708\n",
      "Epoch 5217/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.6838 - val_loss: 581.5639\n",
      "Epoch 5218/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.6009 - val_loss: 581.9020\n",
      "Epoch 5219/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 484.2348 - val_loss: 580.8046\n",
      "Epoch 5220/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 483.0123 - val_loss: 580.7948\n",
      "Epoch 5221/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.7968 - val_loss: 581.6048\n",
      "Epoch 5222/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.4509 - val_loss: 580.9284\n",
      "Epoch 5223/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.2651 - val_loss: 581.8254\n",
      "Epoch 5224/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 485.4656 - val_loss: 579.3347\n",
      "Epoch 5225/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.4938 - val_loss: 579.9994\n",
      "Epoch 5226/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.9129 - val_loss: 581.7478\n",
      "Epoch 5227/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.5989 - val_loss: 580.7094\n",
      "Epoch 5228/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.7259 - val_loss: 580.0451\n",
      "Epoch 5229/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.9080 - val_loss: 580.9290\n",
      "Epoch 5230/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.9847 - val_loss: 581.2003\n",
      "Epoch 5231/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.2601 - val_loss: 580.0007\n",
      "Epoch 5232/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.2905 - val_loss: 579.9303\n",
      "Epoch 5233/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.6039 - val_loss: 580.1003\n",
      "Epoch 5234/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.7432 - val_loss: 582.9499\n",
      "Epoch 5235/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.6249 - val_loss: 581.2067\n",
      "Epoch 5236/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.8665 - val_loss: 581.8585\n",
      "Epoch 5237/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.2860 - val_loss: 580.4548\n",
      "Epoch 5238/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.6253 - val_loss: 580.3177\n",
      "Epoch 5239/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.5150 - val_loss: 581.1230\n",
      "Epoch 5240/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.0584 - val_loss: 579.7355\n",
      "Epoch 5241/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 483.5290 - val_loss: 580.9676\n",
      "Epoch 5242/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 484.2219 - val_loss: 580.5095\n",
      "Epoch 5243/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 11us/sample - loss: 483.6982 - val_loss: 580.2885\n",
      "Epoch 5244/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 483.5782 - val_loss: 581.2944\n",
      "Epoch 5245/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.4571 - val_loss: 580.6139\n",
      "Epoch 5246/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.2006 - val_loss: 580.7624\n",
      "Epoch 5247/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.2556 - val_loss: 580.4496\n",
      "Epoch 5248/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.5024 - val_loss: 582.4710\n",
      "Epoch 5249/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.3998 - val_loss: 580.8066\n",
      "Epoch 5250/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 393.7761Epoch: 5250 - loss: 484.489104 - val_loss: 581.431584\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.4891 - val_loss: 581.4316\n",
      "Epoch 5251/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.3866 - val_loss: 580.2629\n",
      "Epoch 5252/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.0361 - val_loss: 579.4955\n",
      "Epoch 5253/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.1458 - val_loss: 580.6936\n",
      "Epoch 5254/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.4236 - val_loss: 581.0169\n",
      "Epoch 5255/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.5247 - val_loss: 580.0361\n",
      "Epoch 5256/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.3838 - val_loss: 580.8261\n",
      "Epoch 5257/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.2761 - val_loss: 581.0717\n",
      "Epoch 5258/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.1465 - val_loss: 580.3350\n",
      "Epoch 5259/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.8792 - val_loss: 580.2670\n",
      "Epoch 5260/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.1513 - val_loss: 579.1730\n",
      "Epoch 5261/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.7172 - val_loss: 580.2642\n",
      "Epoch 5262/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.2203 - val_loss: 580.2662\n",
      "Epoch 5263/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.5838 - val_loss: 580.7430\n",
      "Epoch 5264/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.2903 - val_loss: 580.1106\n",
      "Epoch 5265/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.1908 - val_loss: 580.7433\n",
      "Epoch 5266/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.8726 - val_loss: 581.1505\n",
      "Epoch 5267/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.6002 - val_loss: 579.6784\n",
      "Epoch 5268/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.1867 - val_loss: 581.1114\n",
      "Epoch 5269/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.1200 - val_loss: 580.8011\n",
      "Epoch 5270/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.8225 - val_loss: 581.3150\n",
      "Epoch 5271/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.1498 - val_loss: 582.3119\n",
      "Epoch 5272/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.0152 - val_loss: 579.8338\n",
      "Epoch 5273/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.1806 - val_loss: 579.5426\n",
      "Epoch 5274/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.6122 - val_loss: 580.2762\n",
      "Epoch 5275/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.8636 - val_loss: 579.9259\n",
      "Epoch 5276/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.4695 - val_loss: 580.9378\n",
      "Epoch 5277/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.6377 - val_loss: 581.3144\n",
      "Epoch 5278/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.3865 - val_loss: 580.5249\n",
      "Epoch 5279/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.0732 - val_loss: 580.4905\n",
      "Epoch 5280/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.3959 - val_loss: 580.9845\n",
      "Epoch 5281/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.2482 - val_loss: 580.8159\n",
      "Epoch 5282/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.9081 - val_loss: 580.8484\n",
      "Epoch 5283/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.5486 - val_loss: 581.5037\n",
      "Epoch 5284/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.6499 - val_loss: 581.2652\n",
      "Epoch 5285/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.7479 - val_loss: 580.4644\n",
      "Epoch 5286/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.2899 - val_loss: 580.8597\n",
      "Epoch 5287/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.9388 - val_loss: 580.5069\n",
      "Epoch 5288/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.3995 - val_loss: 579.5721\n",
      "Epoch 5289/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.8739 - val_loss: 580.4119\n",
      "Epoch 5290/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.6772 - val_loss: 579.9809\n",
      "Epoch 5291/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.4574 - val_loss: 581.0846\n",
      "Epoch 5292/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.8252 - val_loss: 580.3263\n",
      "Epoch 5293/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.7180 - val_loss: 580.5211\n",
      "Epoch 5294/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.7277 - val_loss: 581.2534\n",
      "Epoch 5295/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 483.4916 - val_loss: 580.6163\n",
      "Epoch 5296/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.9287 - val_loss: 580.8948\n",
      "Epoch 5297/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.8442 - val_loss: 580.7032\n",
      "Epoch 5298/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.0790 - val_loss: 579.9886\n",
      "Epoch 5299/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.3483 - val_loss: 579.8017\n",
      "Epoch 5300/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.9209 - val_loss: 580.4933\n",
      "Epoch 5301/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.0730 - val_loss: 581.3636\n",
      "Epoch 5302/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.0211 - val_loss: 580.9526\n",
      "Epoch 5303/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.6253 - val_loss: 579.9212\n",
      "Epoch 5304/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.6933 - val_loss: 579.0399\n",
      "Epoch 5305/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.0943 - val_loss: 580.5653\n",
      "Epoch 5306/10000\n",
      "3000/3000 [==============================] - 0s 18us/sample - loss: 483.0236 - val_loss: 580.4112\n",
      "Epoch 5307/10000\n",
      "3000/3000 [==============================] - 0s 15us/sample - loss: 483.2946 - val_loss: 580.8705\n",
      "Epoch 5308/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 482.8905 - val_loss: 579.8795\n",
      "Epoch 5309/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 485.1356 - val_loss: 580.3629\n",
      "Epoch 5310/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.9316 - val_loss: 580.7535\n",
      "Epoch 5311/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.7095 - val_loss: 581.2119\n",
      "Epoch 5312/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 483.3343 - val_loss: 580.8645\n",
      "Epoch 5313/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.0516 - val_loss: 579.6721\n",
      "Epoch 5314/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.5747 - val_loss: 581.2722\n",
      "Epoch 5315/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 483.2940 - val_loss: 580.7178\n",
      "Epoch 5316/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.3541 - val_loss: 581.0990\n",
      "Epoch 5317/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.5852 - val_loss: 580.6981\n",
      "Epoch 5318/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.3797 - val_loss: 579.7093\n",
      "Epoch 5319/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.9847 - val_loss: 579.5934\n",
      "Epoch 5320/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.4865 - val_loss: 580.4593\n",
      "Epoch 5321/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.6912 - val_loss: 580.4965\n",
      "Epoch 5322/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.2985 - val_loss: 578.9998\n",
      "Epoch 5323/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.9649 - val_loss: 580.1572\n",
      "Epoch 5324/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.6373 - val_loss: 580.4833\n",
      "Epoch 5325/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.6787 - val_loss: 580.1521\n",
      "Epoch 5326/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.9864 - val_loss: 580.5577\n",
      "Epoch 5327/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.4619 - val_loss: 579.9752\n",
      "Epoch 5328/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.8924 - val_loss: 580.1352\n",
      "Epoch 5329/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.7915 - val_loss: 579.7719\n",
      "Epoch 5330/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.2910 - val_loss: 580.5805\n",
      "Epoch 5331/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.2601 - val_loss: 582.0844\n",
      "Epoch 5332/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.0210 - val_loss: 580.1631\n",
      "Epoch 5333/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.6080 - val_loss: 580.7870\n",
      "Epoch 5334/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.7692 - val_loss: 580.6743\n",
      "Epoch 5335/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.6035 - val_loss: 579.9137\n",
      "Epoch 5336/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.3525 - val_loss: 581.0184\n",
      "Epoch 5337/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.9928 - val_loss: 580.6524\n",
      "Epoch 5338/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.9227 - val_loss: 580.6539\n",
      "Epoch 5339/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.4330 - val_loss: 580.9201\n",
      "Epoch 5340/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.7740 - val_loss: 580.1375\n",
      "Epoch 5341/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.4470 - val_loss: 580.2941\n",
      "Epoch 5342/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.8143 - val_loss: 580.8588\n",
      "Epoch 5343/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.3631 - val_loss: 581.1259\n",
      "Epoch 5344/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.9989 - val_loss: 580.2764\n",
      "Epoch 5345/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.0474 - val_loss: 579.6477\n",
      "Epoch 5346/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.5615 - val_loss: 581.4500\n",
      "Epoch 5347/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.2056 - val_loss: 580.3464\n",
      "Epoch 5348/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.4575 - val_loss: 580.1152\n",
      "Epoch 5349/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.2004 - val_loss: 580.3451\n",
      "Epoch 5350/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.8331 - val_loss: 581.2170\n",
      "Epoch 5351/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.0305 - val_loss: 580.0166\n",
      "Epoch 5352/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.3847 - val_loss: 581.2669\n",
      "Epoch 5353/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.5298 - val_loss: 580.7114\n",
      "Epoch 5354/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.2311 - val_loss: 579.8136\n",
      "Epoch 5355/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.0972 - val_loss: 579.2768\n",
      "Epoch 5356/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.0931 - val_loss: 579.3764\n",
      "Epoch 5357/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.4391 - val_loss: 579.9093\n",
      "Epoch 5358/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.3204 - val_loss: 580.2262\n",
      "Epoch 5359/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.4061 - val_loss: 581.0283\n",
      "Epoch 5360/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.9549 - val_loss: 579.5343\n",
      "Epoch 5361/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.6881 - val_loss: 581.0548\n",
      "Epoch 5362/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.7459 - val_loss: 580.2617\n",
      "Epoch 5363/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.3341 - val_loss: 579.6096\n",
      "Epoch 5364/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.7333 - val_loss: 579.6998\n",
      "Epoch 5365/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.6303 - val_loss: 579.5083\n",
      "Epoch 5366/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.8688 - val_loss: 580.0507\n",
      "Epoch 5367/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.5071 - val_loss: 578.9694\n",
      "Epoch 5368/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.0100 - val_loss: 579.0697\n",
      "Epoch 5369/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.5959 - val_loss: 579.1876\n",
      "Epoch 5370/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.1574 - val_loss: 579.6127\n",
      "Epoch 5371/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.7181 - val_loss: 579.2907\n",
      "Epoch 5372/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.7170 - val_loss: 579.1221\n",
      "Epoch 5373/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.8414 - val_loss: 578.7016\n",
      "Epoch 5374/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.9737 - val_loss: 579.2017\n",
      "Epoch 5375/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.4549 - val_loss: 579.3102\n",
      "Epoch 5376/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.8022 - val_loss: 580.0464\n",
      "Epoch 5377/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.8049 - val_loss: 578.5735\n",
      "Epoch 5378/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.9971 - val_loss: 579.6433\n",
      "Epoch 5379/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.2479 - val_loss: 580.4454\n",
      "Epoch 5380/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.9263 - val_loss: 579.9801\n",
      "Epoch 5381/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.3155 - val_loss: 579.8025\n",
      "Epoch 5382/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.0973 - val_loss: 579.6577\n",
      "Epoch 5383/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.1072 - val_loss: 580.4379\n",
      "Epoch 5384/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.5477 - val_loss: 579.2310\n",
      "Epoch 5385/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.3657 - val_loss: 580.2163\n",
      "Epoch 5386/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.0872 - val_loss: 579.3613\n",
      "Epoch 5387/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.0517 - val_loss: 578.9149\n",
      "Epoch 5388/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.3440 - val_loss: 579.8750\n",
      "Epoch 5389/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.1285 - val_loss: 578.5451\n",
      "Epoch 5390/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.5297 - val_loss: 578.8627\n",
      "Epoch 5391/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 483.0081 - val_loss: 579.2857\n",
      "Epoch 5392/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.1060 - val_loss: 579.9750\n",
      "Epoch 5393/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.6962 - val_loss: 579.8423\n",
      "Epoch 5394/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.1193 - val_loss: 579.3952\n",
      "Epoch 5395/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.0160 - val_loss: 579.7720\n",
      "Epoch 5396/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.3054 - val_loss: 579.7403\n",
      "Epoch 5397/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.6885 - val_loss: 579.1853\n",
      "Epoch 5398/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.2808 - val_loss: 580.3861\n",
      "Epoch 5399/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.3479 - val_loss: 579.6052\n",
      "Epoch 5400/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.2965 - val_loss: 580.2920\n",
      "Epoch 5401/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.4196 - val_loss: 580.6799\n",
      "Epoch 5402/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.6988 - val_loss: 579.9182\n",
      "Epoch 5403/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.9575 - val_loss: 580.1546\n",
      "Epoch 5404/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.6154 - val_loss: 579.4823\n",
      "Epoch 5405/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.0282 - val_loss: 580.7911\n",
      "Epoch 5406/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.8503 - val_loss: 579.4089\n",
      "Epoch 5407/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.7880 - val_loss: 579.9026\n",
      "Epoch 5408/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.5198 - val_loss: 580.3985\n",
      "Epoch 5409/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.7524 - val_loss: 579.9582\n",
      "Epoch 5410/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.2716 - val_loss: 579.5999\n",
      "Epoch 5411/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.1911 - val_loss: 579.5160\n",
      "Epoch 5412/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.1459 - val_loss: 578.6271\n",
      "Epoch 5413/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.9773 - val_loss: 580.2556\n",
      "Epoch 5414/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.1848 - val_loss: 579.6328\n",
      "Epoch 5415/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.8161 - val_loss: 579.1538\n",
      "Epoch 5416/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.9133 - val_loss: 580.0213\n",
      "Epoch 5417/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.2162 - val_loss: 579.7173\n",
      "Epoch 5418/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.4651 - val_loss: 579.6942\n",
      "Epoch 5419/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.1530 - val_loss: 579.7568\n",
      "Epoch 5420/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 482.7901 - val_loss: 579.6946\n",
      "Epoch 5421/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 483.8145 - val_loss: 580.4154\n",
      "Epoch 5422/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 482.2390 - val_loss: 580.2973\n",
      "Epoch 5423/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 482.7791 - val_loss: 580.4187\n",
      "Epoch 5424/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.1640 - val_loss: 579.4076\n",
      "Epoch 5425/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.1331 - val_loss: 580.7328\n",
      "Epoch 5426/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.1295 - val_loss: 580.3943\n",
      "Epoch 5427/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.0103 - val_loss: 578.6302\n",
      "Epoch 5428/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 482.4846 - val_loss: 578.2723\n",
      "Epoch 5429/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.2228 - val_loss: 578.2454\n",
      "Epoch 5430/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.6583 - val_loss: 580.3013\n",
      "Epoch 5431/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.4268 - val_loss: 579.8847\n",
      "Epoch 5432/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.9915 - val_loss: 579.3140\n",
      "Epoch 5433/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.1815 - val_loss: 578.7396\n",
      "Epoch 5434/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.0043 - val_loss: 579.6971\n",
      "Epoch 5435/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.9455 - val_loss: 578.7136\n",
      "Epoch 5436/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.6917 - val_loss: 579.0171\n",
      "Epoch 5437/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 482.4616 - val_loss: 579.6323\n",
      "Epoch 5438/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.0656 - val_loss: 579.0366\n",
      "Epoch 5439/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.9065 - val_loss: 578.0034\n",
      "Epoch 5440/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.9338 - val_loss: 578.4355\n",
      "Epoch 5441/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.3829 - val_loss: 579.7749\n",
      "Epoch 5442/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.4261 - val_loss: 578.8451\n",
      "Epoch 5443/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.5570 - val_loss: 579.0101\n",
      "Epoch 5444/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.0192 - val_loss: 579.0003\n",
      "Epoch 5445/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.0980 - val_loss: 579.1948\n",
      "Epoch 5446/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.5742 - val_loss: 579.3817\n",
      "Epoch 5447/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.4591 - val_loss: 579.0041\n",
      "Epoch 5448/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.4641 - val_loss: 578.9568\n",
      "Epoch 5449/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.3556 - val_loss: 579.3974\n",
      "Epoch 5450/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.8178 - val_loss: 579.0858\n",
      "Epoch 5451/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.5979 - val_loss: 578.9207\n",
      "Epoch 5452/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.8834 - val_loss: 578.5221\n",
      "Epoch 5453/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.3335 - val_loss: 579.9927\n",
      "Epoch 5454/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.5185 - val_loss: 579.0912\n",
      "Epoch 5455/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.3275 - val_loss: 580.1579\n",
      "Epoch 5456/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.1829 - val_loss: 579.6406\n",
      "Epoch 5457/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.3603 - val_loss: 579.7850\n",
      "Epoch 5458/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.2676 - val_loss: 579.2376\n",
      "Epoch 5459/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.7789 - val_loss: 578.4120\n",
      "Epoch 5460/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.9752 - val_loss: 580.5260\n",
      "Epoch 5461/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.6332 - val_loss: 580.3081\n",
      "Epoch 5462/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.9234 - val_loss: 579.3182\n",
      "Epoch 5463/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.6061 - val_loss: 579.3783\n",
      "Epoch 5464/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.2887 - val_loss: 580.6861\n",
      "Epoch 5465/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.7352 - val_loss: 579.6873\n",
      "Epoch 5466/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.7826 - val_loss: 579.6226\n",
      "Epoch 5467/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 482.0381 - val_loss: 579.0474\n",
      "Epoch 5468/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.5266 - val_loss: 578.8227\n",
      "Epoch 5469/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.3950 - val_loss: 578.5790\n",
      "Epoch 5470/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.7497 - val_loss: 579.4461\n",
      "Epoch 5471/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.0926 - val_loss: 578.0441\n",
      "Epoch 5472/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.0688 - val_loss: 579.1673\n",
      "Epoch 5473/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.3428 - val_loss: 579.8402\n",
      "Epoch 5474/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.6822 - val_loss: 578.9876\n",
      "Epoch 5475/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.9403 - val_loss: 579.6514\n",
      "Epoch 5476/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.0203 - val_loss: 579.1632\n",
      "Epoch 5477/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.1070 - val_loss: 580.0811\n",
      "Epoch 5478/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.0413 - val_loss: 579.4578\n",
      "Epoch 5479/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.4239 - val_loss: 579.0315\n",
      "Epoch 5480/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.0398 - val_loss: 580.2151\n",
      "Epoch 5481/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.3968 - val_loss: 578.9861\n",
      "Epoch 5482/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.8035 - val_loss: 578.4038\n",
      "Epoch 5483/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.2857 - val_loss: 579.1681\n",
      "Epoch 5484/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.9101 - val_loss: 579.8750\n",
      "Epoch 5485/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.9226 - val_loss: 579.3878\n",
      "Epoch 5486/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.1982 - val_loss: 579.4254\n",
      "Epoch 5487/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.1508 - val_loss: 579.6714\n",
      "Epoch 5488/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.2076 - val_loss: 578.8347\n",
      "Epoch 5489/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.9783 - val_loss: 580.7399\n",
      "Epoch 5490/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.0682 - val_loss: 580.2947\n",
      "Epoch 5491/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.4123 - val_loss: 579.6353\n",
      "Epoch 5492/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.1986 - val_loss: 579.6625\n",
      "Epoch 5493/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.3907 - val_loss: 579.7441\n",
      "Epoch 5494/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.7029 - val_loss: 578.9087\n",
      "Epoch 5495/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.4531 - val_loss: 579.2731\n",
      "Epoch 5496/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.2365 - val_loss: 580.5039\n",
      "Epoch 5497/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.7527 - val_loss: 578.8299\n",
      "Epoch 5498/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.2522 - val_loss: 579.6512\n",
      "Epoch 5499/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.9117 - val_loss: 578.5311\n",
      "Epoch 5500/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 414.6805Epoch: 5500 - loss: 481.963022 - val_loss: 578.612129\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.9630 - val_loss: 578.6121\n",
      "Epoch 5501/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.7143 - val_loss: 579.8335\n",
      "Epoch 5502/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.0226 - val_loss: 579.4263\n",
      "Epoch 5503/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.1667 - val_loss: 579.8354\n",
      "Epoch 5504/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.0324 - val_loss: 578.4722\n",
      "Epoch 5505/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.0125 - val_loss: 578.7714\n",
      "Epoch 5506/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.4830 - val_loss: 579.4839\n",
      "Epoch 5507/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.2702 - val_loss: 578.2033\n",
      "Epoch 5508/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.1547 - val_loss: 578.6096\n",
      "Epoch 5509/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.7788 - val_loss: 579.2565\n",
      "Epoch 5510/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.7246 - val_loss: 579.9006\n",
      "Epoch 5511/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 482.1677 - val_loss: 579.4820\n",
      "Epoch 5512/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.7410 - val_loss: 577.8869\n",
      "Epoch 5513/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.9446 - val_loss: 578.4574\n",
      "Epoch 5514/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.9172 - val_loss: 578.3091\n",
      "Epoch 5515/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.0583 - val_loss: 578.9462\n",
      "Epoch 5516/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.4492 - val_loss: 579.3003\n",
      "Epoch 5517/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.6062 - val_loss: 580.0808\n",
      "Epoch 5518/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.0774 - val_loss: 579.3993\n",
      "Epoch 5519/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.8121 - val_loss: 579.0238\n",
      "Epoch 5520/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.0624 - val_loss: 579.5833\n",
      "Epoch 5521/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.8790 - val_loss: 578.0677\n",
      "Epoch 5522/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.6917 - val_loss: 579.6401\n",
      "Epoch 5523/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.8899 - val_loss: 580.3709\n",
      "Epoch 5524/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.8338 - val_loss: 579.2510\n",
      "Epoch 5525/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.8237 - val_loss: 578.4146\n",
      "Epoch 5526/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.6790 - val_loss: 578.9467\n",
      "Epoch 5527/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.9545 - val_loss: 578.9349\n",
      "Epoch 5528/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.0823 - val_loss: 578.3517\n",
      "Epoch 5529/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 482.6263 - val_loss: 577.9910\n",
      "Epoch 5530/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.8811 - val_loss: 577.5914\n",
      "Epoch 5531/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.5388 - val_loss: 578.3086\n",
      "Epoch 5532/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.2454 - val_loss: 577.5921\n",
      "Epoch 5533/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.8163 - val_loss: 579.2951\n",
      "Epoch 5534/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.8782 - val_loss: 579.3494\n",
      "Epoch 5535/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 482.0668 - val_loss: 579.2573\n",
      "Epoch 5536/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 484.0147 - val_loss: 578.2818\n",
      "Epoch 5537/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.7318 - val_loss: 579.0420\n",
      "Epoch 5538/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.6174 - val_loss: 578.3683\n",
      "Epoch 5539/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.1864 - val_loss: 578.7090\n",
      "Epoch 5540/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.6849 - val_loss: 577.7390\n",
      "Epoch 5541/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.0428 - val_loss: 578.1062\n",
      "Epoch 5542/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.4069 - val_loss: 578.4151\n",
      "Epoch 5543/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.5390 - val_loss: 579.0232\n",
      "Epoch 5544/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.4169 - val_loss: 579.0378\n",
      "Epoch 5545/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.5012 - val_loss: 579.0440\n",
      "Epoch 5546/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.5152 - val_loss: 578.4221\n",
      "Epoch 5547/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.8057 - val_loss: 578.9709\n",
      "Epoch 5548/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 481.5068 - val_loss: 578.5855\n",
      "Epoch 5549/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.8285 - val_loss: 579.1368\n",
      "Epoch 5550/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.0695 - val_loss: 578.6389\n",
      "Epoch 5551/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.6477 - val_loss: 579.8856\n",
      "Epoch 5552/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.1543 - val_loss: 579.4103\n",
      "Epoch 5553/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.0015 - val_loss: 578.3919\n",
      "Epoch 5554/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.2527 - val_loss: 579.4475\n",
      "Epoch 5555/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.6969 - val_loss: 578.7886\n",
      "Epoch 5556/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.2411 - val_loss: 579.7934\n",
      "Epoch 5557/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.5443 - val_loss: 577.1839\n",
      "Epoch 5558/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.7539 - val_loss: 578.4316\n",
      "Epoch 5559/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.7334 - val_loss: 579.5004\n",
      "Epoch 5560/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.2608 - val_loss: 578.4969\n",
      "Epoch 5561/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.6471 - val_loss: 579.7252\n",
      "Epoch 5562/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.4069 - val_loss: 579.7611\n",
      "Epoch 5563/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.2428 - val_loss: 579.5254\n",
      "Epoch 5564/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.6044 - val_loss: 578.7262\n",
      "Epoch 5565/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.0771 - val_loss: 579.6812\n",
      "Epoch 5566/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.6011 - val_loss: 579.4472\n",
      "Epoch 5567/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 481.8715 - val_loss: 579.6509\n",
      "Epoch 5568/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.4012 - val_loss: 579.6937\n",
      "Epoch 5569/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.6012 - val_loss: 579.0066\n",
      "Epoch 5570/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.9812 - val_loss: 579.1248\n",
      "Epoch 5571/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.3602 - val_loss: 578.6855\n",
      "Epoch 5572/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.0667 - val_loss: 578.8532\n",
      "Epoch 5573/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.3395 - val_loss: 579.4260\n",
      "Epoch 5574/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.7757 - val_loss: 578.5959\n",
      "Epoch 5575/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.0946 - val_loss: 578.9365\n",
      "Epoch 5576/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.8036 - val_loss: 578.1644\n",
      "Epoch 5577/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.0044 - val_loss: 578.2203\n",
      "Epoch 5578/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.8092 - val_loss: 579.3275\n",
      "Epoch 5579/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.2021 - val_loss: 579.3055\n",
      "Epoch 5580/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.3344 - val_loss: 578.0336\n",
      "Epoch 5581/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.2196 - val_loss: 578.3275\n",
      "Epoch 5582/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.6899 - val_loss: 578.9360\n",
      "Epoch 5583/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.0662 - val_loss: 577.5978\n",
      "Epoch 5584/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.1422 - val_loss: 576.9163\n",
      "Epoch 5585/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.4372 - val_loss: 578.6835\n",
      "Epoch 5586/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.9542 - val_loss: 577.3713\n",
      "Epoch 5587/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.6575 - val_loss: 577.9976\n",
      "Epoch 5588/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.5060 - val_loss: 578.1896\n",
      "Epoch 5589/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.7282 - val_loss: 578.6909\n",
      "Epoch 5590/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.7515 - val_loss: 578.0391\n",
      "Epoch 5591/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.9504 - val_loss: 578.3674\n",
      "Epoch 5592/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.3894 - val_loss: 578.3949\n",
      "Epoch 5593/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.0090 - val_loss: 578.3201\n",
      "Epoch 5594/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.6697 - val_loss: 578.4924\n",
      "Epoch 5595/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.6035 - val_loss: 577.9602\n",
      "Epoch 5596/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.8037 - val_loss: 578.1756\n",
      "Epoch 5597/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.5398 - val_loss: 578.8866\n",
      "Epoch 5598/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.5851 - val_loss: 579.7376\n",
      "Epoch 5599/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.5065 - val_loss: 579.2888\n",
      "Epoch 5600/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.8122 - val_loss: 578.5829\n",
      "Epoch 5601/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.6840 - val_loss: 579.4393\n",
      "Epoch 5602/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.8310 - val_loss: 579.6061\n",
      "Epoch 5603/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.9472 - val_loss: 578.5485\n",
      "Epoch 5604/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.4145 - val_loss: 578.2763\n",
      "Epoch 5605/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.7435 - val_loss: 578.0037\n",
      "Epoch 5606/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.4207 - val_loss: 578.7036\n",
      "Epoch 5607/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.5202 - val_loss: 578.5291\n",
      "Epoch 5608/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.0325 - val_loss: 577.9834\n",
      "Epoch 5609/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.4231 - val_loss: 578.2091\n",
      "Epoch 5610/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.3254 - val_loss: 577.4869\n",
      "Epoch 5611/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.1102 - val_loss: 578.0156\n",
      "Epoch 5612/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.6108 - val_loss: 578.3848\n",
      "Epoch 5613/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.3003 - val_loss: 578.6935\n",
      "Epoch 5614/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.1481 - val_loss: 578.7037\n",
      "Epoch 5615/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.6728 - val_loss: 579.0752\n",
      "Epoch 5616/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.4340 - val_loss: 578.6014\n",
      "Epoch 5617/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.2090 - val_loss: 578.7233\n",
      "Epoch 5618/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.1139 - val_loss: 578.5509\n",
      "Epoch 5619/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.1232 - val_loss: 579.1452\n",
      "Epoch 5620/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.8433 - val_loss: 579.5096\n",
      "Epoch 5621/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.3644 - val_loss: 579.1398\n",
      "Epoch 5622/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.1768 - val_loss: 579.4532\n",
      "Epoch 5623/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.3481 - val_loss: 579.8496\n",
      "Epoch 5624/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.9416 - val_loss: 579.4195\n",
      "Epoch 5625/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.1875 - val_loss: 578.3851\n",
      "Epoch 5626/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.8528 - val_loss: 579.9654\n",
      "Epoch 5627/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.1268 - val_loss: 577.7912\n",
      "Epoch 5628/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.2996 - val_loss: 579.0723\n",
      "Epoch 5629/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.0648 - val_loss: 579.9405\n",
      "Epoch 5630/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.5075 - val_loss: 578.4117\n",
      "Epoch 5631/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.7323 - val_loss: 579.1227\n",
      "Epoch 5632/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.5276 - val_loss: 579.1866\n",
      "Epoch 5633/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.9418 - val_loss: 578.2084\n",
      "Epoch 5634/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.4647 - val_loss: 578.2738\n",
      "Epoch 5635/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.1060 - val_loss: 578.8209\n",
      "Epoch 5636/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.2894 - val_loss: 578.6031\n",
      "Epoch 5637/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.3749 - val_loss: 578.6197\n",
      "Epoch 5638/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.7454 - val_loss: 578.0696\n",
      "Epoch 5639/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.8654 - val_loss: 578.9987\n",
      "Epoch 5640/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.4740 - val_loss: 578.7631\n",
      "Epoch 5641/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.4405 - val_loss: 577.7489\n",
      "Epoch 5642/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.0331 - val_loss: 578.9053\n",
      "Epoch 5643/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.3434 - val_loss: 577.1125\n",
      "Epoch 5644/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.3414 - val_loss: 576.8403\n",
      "Epoch 5645/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.3950 - val_loss: 576.8263\n",
      "Epoch 5646/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.1007 - val_loss: 577.4479\n",
      "Epoch 5647/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.3981 - val_loss: 578.3716\n",
      "Epoch 5648/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.9895 - val_loss: 578.1105\n",
      "Epoch 5649/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.8494 - val_loss: 577.5054\n",
      "Epoch 5650/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.6504 - val_loss: 577.2193\n",
      "Epoch 5651/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.8314 - val_loss: 578.5311\n",
      "Epoch 5652/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.8158 - val_loss: 577.6762\n",
      "Epoch 5653/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.3071 - val_loss: 578.0155\n",
      "Epoch 5654/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.2650 - val_loss: 577.7917\n",
      "Epoch 5655/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.5631 - val_loss: 578.3943\n",
      "Epoch 5656/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.6599 - val_loss: 578.2652\n",
      "Epoch 5657/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.2484 - val_loss: 578.7725\n",
      "Epoch 5658/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.3719 - val_loss: 579.0421\n",
      "Epoch 5659/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.1736 - val_loss: 579.0497\n",
      "Epoch 5660/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.1560 - val_loss: 579.2286\n",
      "Epoch 5661/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.4821 - val_loss: 579.0185\n",
      "Epoch 5662/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.3350 - val_loss: 577.8448\n",
      "Epoch 5663/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.0707 - val_loss: 578.6182\n",
      "Epoch 5664/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.0791 - val_loss: 578.0655\n",
      "Epoch 5665/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.1675 - val_loss: 578.5369\n",
      "Epoch 5666/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.5253 - val_loss: 577.7204\n",
      "Epoch 5667/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.2208 - val_loss: 577.9619\n",
      "Epoch 5668/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.1977 - val_loss: 578.4605\n",
      "Epoch 5669/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.0596 - val_loss: 578.5840\n",
      "Epoch 5670/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.2569 - val_loss: 577.9770\n",
      "Epoch 5671/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.1207 - val_loss: 578.1717\n",
      "Epoch 5672/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.7106 - val_loss: 579.4318\n",
      "Epoch 5673/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.0424 - val_loss: 578.6322\n",
      "Epoch 5674/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.0213 - val_loss: 578.2565\n",
      "Epoch 5675/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 483.1735 - val_loss: 577.7835\n",
      "Epoch 5676/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.7611 - val_loss: 578.2656\n",
      "Epoch 5677/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.2579 - val_loss: 578.0677\n",
      "Epoch 5678/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.0306 - val_loss: 578.1494\n",
      "Epoch 5679/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.4555 - val_loss: 578.1813\n",
      "Epoch 5680/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.4582 - val_loss: 578.6772\n",
      "Epoch 5681/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.0553 - val_loss: 578.3580\n",
      "Epoch 5682/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.0515 - val_loss: 578.4802\n",
      "Epoch 5683/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.0242 - val_loss: 577.0596\n",
      "Epoch 5684/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.4134 - val_loss: 576.6544\n",
      "Epoch 5685/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.7713 - val_loss: 579.0128\n",
      "Epoch 5686/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.2210 - val_loss: 577.0743\n",
      "Epoch 5687/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.7454 - val_loss: 578.6807\n",
      "Epoch 5688/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.9523 - val_loss: 578.5360\n",
      "Epoch 5689/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 481.2271 - val_loss: 578.3048\n",
      "Epoch 5690/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.3109 - val_loss: 578.1444\n",
      "Epoch 5691/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.5550 - val_loss: 578.4451\n",
      "Epoch 5692/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.9014 - val_loss: 577.8145\n",
      "Epoch 5693/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.0921 - val_loss: 578.3141\n",
      "Epoch 5694/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.3131 - val_loss: 577.6944\n",
      "Epoch 5695/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 481.0786 - val_loss: 577.3475\n",
      "Epoch 5696/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.0172 - val_loss: 578.7230\n",
      "Epoch 5697/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.5859 - val_loss: 577.4080\n",
      "Epoch 5698/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.9300 - val_loss: 579.5507\n",
      "Epoch 5699/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.4093 - val_loss: 578.8935\n",
      "Epoch 5700/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.4498 - val_loss: 578.3147\n",
      "Epoch 5701/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.3390 - val_loss: 577.1888\n",
      "Epoch 5702/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.6371 - val_loss: 578.1978\n",
      "Epoch 5703/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.5464 - val_loss: 578.5523\n",
      "Epoch 5704/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.8698 - val_loss: 578.8307\n",
      "Epoch 5705/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.0035 - val_loss: 577.6613\n",
      "Epoch 5706/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.7898 - val_loss: 578.6330\n",
      "Epoch 5707/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.9071 - val_loss: 577.5983\n",
      "Epoch 5708/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.8412 - val_loss: 577.4735\n",
      "Epoch 5709/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.9997 - val_loss: 577.6407\n",
      "Epoch 5710/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.2520 - val_loss: 579.1881\n",
      "Epoch 5711/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.0830 - val_loss: 577.7444\n",
      "Epoch 5712/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.7403 - val_loss: 577.7084\n",
      "Epoch 5713/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.7492 - val_loss: 577.3887\n",
      "Epoch 5714/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.8115 - val_loss: 577.3880\n",
      "Epoch 5715/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.1784 - val_loss: 577.7237\n",
      "Epoch 5716/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.1411 - val_loss: 577.4371\n",
      "Epoch 5717/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.4787 - val_loss: 578.5035\n",
      "Epoch 5718/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.7759 - val_loss: 577.9899\n",
      "Epoch 5719/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.2536 - val_loss: 577.2056\n",
      "Epoch 5720/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.2781 - val_loss: 576.9590\n",
      "Epoch 5721/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.7305 - val_loss: 578.6995\n",
      "Epoch 5722/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.1464 - val_loss: 577.2802\n",
      "Epoch 5723/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.1472 - val_loss: 578.4873\n",
      "Epoch 5724/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.6542 - val_loss: 577.8024\n",
      "Epoch 5725/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.5819 - val_loss: 577.6629\n",
      "Epoch 5726/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.6486 - val_loss: 577.3108\n",
      "Epoch 5727/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.1506 - val_loss: 577.3186\n",
      "Epoch 5728/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.9586 - val_loss: 578.1134\n",
      "Epoch 5729/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.9776 - val_loss: 577.3510\n",
      "Epoch 5730/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.0925 - val_loss: 578.0539\n",
      "Epoch 5731/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.5737 - val_loss: 577.7058\n",
      "Epoch 5732/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.5201 - val_loss: 577.2370\n",
      "Epoch 5733/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.9523 - val_loss: 577.2597\n",
      "Epoch 5734/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.4967 - val_loss: 577.0912\n",
      "Epoch 5735/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.4029 - val_loss: 576.3135\n",
      "Epoch 5736/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.7388 - val_loss: 577.7835\n",
      "Epoch 5737/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.1133 - val_loss: 577.1345\n",
      "Epoch 5738/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.5824 - val_loss: 577.6737\n",
      "Epoch 5739/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.2110 - val_loss: 577.6305\n",
      "Epoch 5740/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 481.5700 - val_loss: 579.4213\n",
      "Epoch 5741/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.8469 - val_loss: 578.1489\n",
      "Epoch 5742/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.9699 - val_loss: 578.2853\n",
      "Epoch 5743/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.6029 - val_loss: 578.6175\n",
      "Epoch 5744/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.6977 - val_loss: 578.2978\n",
      "Epoch 5745/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 482.4878 - val_loss: 578.1083\n",
      "Epoch 5746/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.4020 - val_loss: 577.9855\n",
      "Epoch 5747/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.9837 - val_loss: 577.8887\n",
      "Epoch 5748/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.3057 - val_loss: 576.7418\n",
      "Epoch 5749/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.4723 - val_loss: 579.2342\n",
      "Epoch 5750/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 605.1511Epoch: 5750 - loss: 481.181827 - val_loss: 577.408781\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.1818 - val_loss: 577.4088\n",
      "Epoch 5751/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.7413 - val_loss: 578.1121\n",
      "Epoch 5752/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.6789 - val_loss: 578.4020\n",
      "Epoch 5753/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.7041 - val_loss: 577.3311\n",
      "Epoch 5754/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.9405 - val_loss: 577.2579\n",
      "Epoch 5755/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.0638 - val_loss: 577.0997\n",
      "Epoch 5756/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.3897 - val_loss: 578.5138\n",
      "Epoch 5757/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.4550 - val_loss: 577.7122\n",
      "Epoch 5758/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 480.6686 - val_loss: 577.9627\n",
      "Epoch 5759/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.4148 - val_loss: 577.9556\n",
      "Epoch 5760/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.6551 - val_loss: 577.8841\n",
      "Epoch 5761/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.6128 - val_loss: 577.2795\n",
      "Epoch 5762/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.3778 - val_loss: 577.8121\n",
      "Epoch 5763/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.6747 - val_loss: 579.0613\n",
      "Epoch 5764/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.7620 - val_loss: 577.8219\n",
      "Epoch 5765/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.6694 - val_loss: 577.6683\n",
      "Epoch 5766/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.5314 - val_loss: 577.6784\n",
      "Epoch 5767/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.8416 - val_loss: 576.9845\n",
      "Epoch 5768/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.4991 - val_loss: 578.2016\n",
      "Epoch 5769/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.7978 - val_loss: 578.3045\n",
      "Epoch 5770/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.2543 - val_loss: 578.2230\n",
      "Epoch 5771/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.9670 - val_loss: 578.2675\n",
      "Epoch 5772/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.4803 - val_loss: 577.9434\n",
      "Epoch 5773/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.4695 - val_loss: 578.5067\n",
      "Epoch 5774/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.6740 - val_loss: 577.2945\n",
      "Epoch 5775/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.7341 - val_loss: 577.9827\n",
      "Epoch 5776/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.5854 - val_loss: 577.7479\n",
      "Epoch 5777/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.7407 - val_loss: 578.1167\n",
      "Epoch 5778/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.3209 - val_loss: 578.0728\n",
      "Epoch 5779/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.3795 - val_loss: 578.0210\n",
      "Epoch 5780/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.5857 - val_loss: 578.1335\n",
      "Epoch 5781/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.2820 - val_loss: 578.1051\n",
      "Epoch 5782/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.4335 - val_loss: 577.1476\n",
      "Epoch 5783/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.8349 - val_loss: 578.7210\n",
      "Epoch 5784/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.3100 - val_loss: 577.5737\n",
      "Epoch 5785/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.8651 - val_loss: 577.5243\n",
      "Epoch 5786/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.3750 - val_loss: 578.4936\n",
      "Epoch 5787/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.4466 - val_loss: 578.7901\n",
      "Epoch 5788/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.6281 - val_loss: 578.3926\n",
      "Epoch 5789/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.8956 - val_loss: 578.6893\n",
      "Epoch 5790/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.5770 - val_loss: 578.2168\n",
      "Epoch 5791/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.9441 - val_loss: 576.9549\n",
      "Epoch 5792/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.9751 - val_loss: 577.1319\n",
      "Epoch 5793/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.1810 - val_loss: 576.9227\n",
      "Epoch 5794/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.4306 - val_loss: 578.2521\n",
      "Epoch 5795/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.5855 - val_loss: 579.6743\n",
      "Epoch 5796/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.3110 - val_loss: 578.2778\n",
      "Epoch 5797/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.4647 - val_loss: 577.7855\n",
      "Epoch 5798/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.4968 - val_loss: 578.3211\n",
      "Epoch 5799/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.0098 - val_loss: 578.2371\n",
      "Epoch 5800/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 482.1272 - val_loss: 577.2593\n",
      "Epoch 5801/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.5629 - val_loss: 577.1017\n",
      "Epoch 5802/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.0831 - val_loss: 577.1253\n",
      "Epoch 5803/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.6986 - val_loss: 577.8880\n",
      "Epoch 5804/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.2906 - val_loss: 577.5230\n",
      "Epoch 5805/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.2980 - val_loss: 578.5602\n",
      "Epoch 5806/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.6768 - val_loss: 577.8268\n",
      "Epoch 5807/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.2324 - val_loss: 577.9429\n",
      "Epoch 5808/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.5360 - val_loss: 577.1970\n",
      "Epoch 5809/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.8356 - val_loss: 577.4745\n",
      "Epoch 5810/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.1061 - val_loss: 577.3137\n",
      "Epoch 5811/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.1320 - val_loss: 577.4896\n",
      "Epoch 5812/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.5189 - val_loss: 578.2862\n",
      "Epoch 5813/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.4053 - val_loss: 577.3285\n",
      "Epoch 5814/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.1494 - val_loss: 577.9612\n",
      "Epoch 5815/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.1798 - val_loss: 580.2106\n",
      "Epoch 5816/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.1210 - val_loss: 577.8029\n",
      "Epoch 5817/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.3555 - val_loss: 578.4336\n",
      "Epoch 5818/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.5416 - val_loss: 578.3640\n",
      "Epoch 5819/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.6931 - val_loss: 579.5287\n",
      "Epoch 5820/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.4682 - val_loss: 577.4515\n",
      "Epoch 5821/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.9177 - val_loss: 579.1456\n",
      "Epoch 5822/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.0435 - val_loss: 578.4008\n",
      "Epoch 5823/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.5339 - val_loss: 577.6108\n",
      "Epoch 5824/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.2363 - val_loss: 578.7210\n",
      "Epoch 5825/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.4184 - val_loss: 578.3824\n",
      "Epoch 5826/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.5187 - val_loss: 578.4950\n",
      "Epoch 5827/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.6336 - val_loss: 578.4423\n",
      "Epoch 5828/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.7076 - val_loss: 577.9231\n",
      "Epoch 5829/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.1827 - val_loss: 579.2330\n",
      "Epoch 5830/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.8907 - val_loss: 578.7146\n",
      "Epoch 5831/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.5280 - val_loss: 576.7655\n",
      "Epoch 5832/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.0562 - val_loss: 577.9689\n",
      "Epoch 5833/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.6310 - val_loss: 578.6936\n",
      "Epoch 5834/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.6021 - val_loss: 577.8699\n",
      "Epoch 5835/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.4634 - val_loss: 576.9971\n",
      "Epoch 5836/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.3668 - val_loss: 578.3268\n",
      "Epoch 5837/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.6142 - val_loss: 577.7290\n",
      "Epoch 5838/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.3405 - val_loss: 576.8828\n",
      "Epoch 5839/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.6032 - val_loss: 576.9203\n",
      "Epoch 5840/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.2169 - val_loss: 576.3109\n",
      "Epoch 5841/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.8687 - val_loss: 577.5166\n",
      "Epoch 5842/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.8755 - val_loss: 577.8896\n",
      "Epoch 5843/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.0951 - val_loss: 577.2163\n",
      "Epoch 5844/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.9502 - val_loss: 578.0142\n",
      "Epoch 5845/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.2462 - val_loss: 578.4615\n",
      "Epoch 5846/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.2348 - val_loss: 576.7811\n",
      "Epoch 5847/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.1871 - val_loss: 577.7273\n",
      "Epoch 5848/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.0236 - val_loss: 578.8831\n",
      "Epoch 5849/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.8727 - val_loss: 577.3993\n",
      "Epoch 5850/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.4564 - val_loss: 578.0216\n",
      "Epoch 5851/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.2072 - val_loss: 577.4015\n",
      "Epoch 5852/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.9938 - val_loss: 577.0209\n",
      "Epoch 5853/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.0820 - val_loss: 577.1655\n",
      "Epoch 5854/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.9579 - val_loss: 577.0875\n",
      "Epoch 5855/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.2112 - val_loss: 577.5940\n",
      "Epoch 5856/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.5232 - val_loss: 577.4628\n",
      "Epoch 5857/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.7106 - val_loss: 575.8014\n",
      "Epoch 5858/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.7461 - val_loss: 577.0018\n",
      "Epoch 5859/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.4703 - val_loss: 577.2141\n",
      "Epoch 5860/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 481.2789 - val_loss: 576.1834\n",
      "Epoch 5861/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.0720 - val_loss: 576.8025\n",
      "Epoch 5862/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.5456 - val_loss: 577.2643\n",
      "Epoch 5863/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.9712 - val_loss: 577.6520\n",
      "Epoch 5864/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.8782 - val_loss: 577.1652\n",
      "Epoch 5865/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.0273 - val_loss: 577.6909\n",
      "Epoch 5866/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.5151 - val_loss: 576.9765\n",
      "Epoch 5867/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.1748 - val_loss: 577.3619\n",
      "Epoch 5868/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.7896 - val_loss: 578.1936\n",
      "Epoch 5869/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.1443 - val_loss: 576.9437\n",
      "Epoch 5870/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.0468 - val_loss: 577.0132\n",
      "Epoch 5871/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.1211 - val_loss: 577.5211\n",
      "Epoch 5872/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.3537 - val_loss: 577.7789\n",
      "Epoch 5873/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.8686 - val_loss: 578.5307\n",
      "Epoch 5874/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.2920 - val_loss: 577.1500\n",
      "Epoch 5875/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.5686 - val_loss: 576.8719\n",
      "Epoch 5876/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.0836 - val_loss: 576.5533\n",
      "Epoch 5877/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.5692 - val_loss: 577.3680\n",
      "Epoch 5878/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.8505 - val_loss: 577.5182\n",
      "Epoch 5879/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.7132 - val_loss: 577.5422\n",
      "Epoch 5880/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.7406 - val_loss: 577.2633\n",
      "Epoch 5881/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.8412 - val_loss: 576.2935\n",
      "Epoch 5882/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.7801 - val_loss: 578.5017\n",
      "Epoch 5883/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.2440 - val_loss: 576.7129\n",
      "Epoch 5884/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 480.1769 - val_loss: 578.0774\n",
      "Epoch 5885/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.4234 - val_loss: 578.0482\n",
      "Epoch 5886/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.8733 - val_loss: 577.4450\n",
      "Epoch 5887/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.4142 - val_loss: 576.6512\n",
      "Epoch 5888/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.3665 - val_loss: 576.5637\n",
      "Epoch 5889/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.7615 - val_loss: 578.3305\n",
      "Epoch 5890/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.0353 - val_loss: 577.5597\n",
      "Epoch 5891/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.7845 - val_loss: 577.1241\n",
      "Epoch 5892/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.7984 - val_loss: 577.4960\n",
      "Epoch 5893/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.0181 - val_loss: 577.2137\n",
      "Epoch 5894/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.0985 - val_loss: 576.7801\n",
      "Epoch 5895/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.5418 - val_loss: 578.1351\n",
      "Epoch 5896/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.9873 - val_loss: 576.8747\n",
      "Epoch 5897/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 479.6163 - val_loss: 578.0105\n",
      "Epoch 5898/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.8461 - val_loss: 577.4475\n",
      "Epoch 5899/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.6074 - val_loss: 577.8897\n",
      "Epoch 5900/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.0917 - val_loss: 577.1701\n",
      "Epoch 5901/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.9472 - val_loss: 577.2878\n",
      "Epoch 5902/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 480.1496 - val_loss: 577.0255\n",
      "Epoch 5903/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.9280 - val_loss: 576.2288\n",
      "Epoch 5904/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.5125 - val_loss: 577.5998\n",
      "Epoch 5905/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.7578 - val_loss: 578.2188\n",
      "Epoch 5906/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.9751 - val_loss: 578.2714\n",
      "Epoch 5907/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.4358 - val_loss: 576.6230\n",
      "Epoch 5908/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.2631 - val_loss: 577.0566\n",
      "Epoch 5909/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.3772 - val_loss: 576.9942\n",
      "Epoch 5910/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.6947 - val_loss: 576.7486\n",
      "Epoch 5911/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.5460 - val_loss: 577.0677\n",
      "Epoch 5912/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.8471 - val_loss: 577.8500\n",
      "Epoch 5913/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.8287 - val_loss: 576.5026\n",
      "Epoch 5914/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.9417 - val_loss: 576.2975\n",
      "Epoch 5915/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.5666 - val_loss: 577.5863\n",
      "Epoch 5916/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.3089 - val_loss: 577.1262\n",
      "Epoch 5917/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.7604 - val_loss: 576.9350\n",
      "Epoch 5918/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.5936 - val_loss: 577.1655\n",
      "Epoch 5919/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.7973 - val_loss: 577.8425\n",
      "Epoch 5920/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.1057 - val_loss: 577.0354\n",
      "Epoch 5921/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.2807 - val_loss: 576.9402\n",
      "Epoch 5922/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.8080 - val_loss: 577.3948\n",
      "Epoch 5923/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.6922 - val_loss: 576.7299\n",
      "Epoch 5924/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.7637 - val_loss: 576.3357\n",
      "Epoch 5925/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.2319 - val_loss: 576.9806\n",
      "Epoch 5926/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.3571 - val_loss: 576.4533\n",
      "Epoch 5927/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.9714 - val_loss: 577.2042\n",
      "Epoch 5928/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.2643 - val_loss: 577.0056\n",
      "Epoch 5929/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.4623 - val_loss: 576.7592\n",
      "Epoch 5930/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.3535 - val_loss: 576.7233\n",
      "Epoch 5931/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.7980 - val_loss: 577.0849\n",
      "Epoch 5932/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.8328 - val_loss: 576.8398\n",
      "Epoch 5933/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.5015 - val_loss: 576.6011\n",
      "Epoch 5934/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.6102 - val_loss: 576.9546\n",
      "Epoch 5935/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.5251 - val_loss: 577.4237\n",
      "Epoch 5936/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.6936 - val_loss: 577.9859\n",
      "Epoch 5937/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.5013 - val_loss: 576.9641\n",
      "Epoch 5938/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.0528 - val_loss: 576.6550\n",
      "Epoch 5939/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.2082 - val_loss: 576.4460\n",
      "Epoch 5940/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.9943 - val_loss: 578.3389\n",
      "Epoch 5941/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.3406 - val_loss: 577.0948\n",
      "Epoch 5942/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.9672 - val_loss: 577.2064\n",
      "Epoch 5943/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.5067 - val_loss: 577.8220\n",
      "Epoch 5944/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.1549 - val_loss: 577.9645\n",
      "Epoch 5945/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.0001 - val_loss: 577.1175\n",
      "Epoch 5946/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.2937 - val_loss: 577.1367\n",
      "Epoch 5947/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.7590 - val_loss: 577.5736\n",
      "Epoch 5948/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.2851 - val_loss: 576.3211\n",
      "Epoch 5949/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.3476 - val_loss: 577.7562\n",
      "Epoch 5950/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.1648 - val_loss: 576.3212\n",
      "Epoch 5951/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.2067 - val_loss: 577.9838\n",
      "Epoch 5952/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.6783 - val_loss: 577.1419\n",
      "Epoch 5953/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.4707 - val_loss: 577.6757\n",
      "Epoch 5954/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.6272 - val_loss: 578.1992\n",
      "Epoch 5955/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.8847 - val_loss: 578.2352\n",
      "Epoch 5956/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.5289 - val_loss: 577.0622\n",
      "Epoch 5957/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.9115 - val_loss: 577.3025\n",
      "Epoch 5958/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.6022 - val_loss: 576.7653\n",
      "Epoch 5959/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.6147 - val_loss: 577.1536\n",
      "Epoch 5960/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.6956 - val_loss: 577.3127\n",
      "Epoch 5961/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.1486 - val_loss: 576.6865\n",
      "Epoch 5962/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.7925 - val_loss: 578.0129\n",
      "Epoch 5963/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 479.9105 - val_loss: 576.5646\n",
      "Epoch 5964/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.8362 - val_loss: 577.4173\n",
      "Epoch 5965/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.6556 - val_loss: 577.2893\n",
      "Epoch 5966/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.8697 - val_loss: 577.3079\n",
      "Epoch 5967/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.4596 - val_loss: 577.9854\n",
      "Epoch 5968/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.2723 - val_loss: 577.2896\n",
      "Epoch 5969/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.3971 - val_loss: 576.8510\n",
      "Epoch 5970/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.2570 - val_loss: 577.2890\n",
      "Epoch 5971/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.0694 - val_loss: 576.9429\n",
      "Epoch 5972/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.3292 - val_loss: 576.7483\n",
      "Epoch 5973/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.5360 - val_loss: 576.5061\n",
      "Epoch 5974/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.6355 - val_loss: 578.0988\n",
      "Epoch 5975/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.8984 - val_loss: 577.7056\n",
      "Epoch 5976/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.4253 - val_loss: 577.4382\n",
      "Epoch 5977/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.3884 - val_loss: 578.1548\n",
      "Epoch 5978/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 481.3211 - val_loss: 577.6092\n",
      "Epoch 5979/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.2814 - val_loss: 576.5122\n",
      "Epoch 5980/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.5926 - val_loss: 577.0525\n",
      "Epoch 5981/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.3316 - val_loss: 576.8660\n",
      "Epoch 5982/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.8897 - val_loss: 577.2789\n",
      "Epoch 5983/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.0604 - val_loss: 577.7399\n",
      "Epoch 5984/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.6906 - val_loss: 576.6788\n",
      "Epoch 5985/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.7986 - val_loss: 577.2194\n",
      "Epoch 5986/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.2232 - val_loss: 578.1254\n",
      "Epoch 5987/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.2249 - val_loss: 576.4137\n",
      "Epoch 5988/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.9765 - val_loss: 576.6912\n",
      "Epoch 5989/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.7035 - val_loss: 577.0638\n",
      "Epoch 5990/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.6539 - val_loss: 576.6087\n",
      "Epoch 5991/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.5572 - val_loss: 576.5190\n",
      "Epoch 5992/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.6628 - val_loss: 578.2072\n",
      "Epoch 5993/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.0989 - val_loss: 576.3805\n",
      "Epoch 5994/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.6593 - val_loss: 576.1114\n",
      "Epoch 5995/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.8301 - val_loss: 577.3712\n",
      "Epoch 5996/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.5931 - val_loss: 577.5046\n",
      "Epoch 5997/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.2967 - val_loss: 576.9379\n",
      "Epoch 5998/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.3670 - val_loss: 577.0453\n",
      "Epoch 5999/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.0613 - val_loss: 576.5749\n",
      "Epoch 6000/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 608.5862Epoch: 6000 - loss: 479.633576 - val_loss: 577.314599\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.6336 - val_loss: 577.3146\n",
      "Epoch 6001/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.6214 - val_loss: 577.4027\n",
      "Epoch 6002/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.4765 - val_loss: 577.1475\n",
      "Epoch 6003/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.0335 - val_loss: 578.0494\n",
      "Epoch 6004/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.8615 - val_loss: 577.8353\n",
      "Epoch 6005/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.1917 - val_loss: 576.5971\n",
      "Epoch 6006/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.6701 - val_loss: 576.2399\n",
      "Epoch 6007/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.2536 - val_loss: 577.0122\n",
      "Epoch 6008/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.7105 - val_loss: 577.2843\n",
      "Epoch 6009/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.6891 - val_loss: 576.5671\n",
      "Epoch 6010/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.5483 - val_loss: 578.1864\n",
      "Epoch 6011/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.3993 - val_loss: 577.9339\n",
      "Epoch 6012/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.1323 - val_loss: 576.1644\n",
      "Epoch 6013/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.3692 - val_loss: 576.7310\n",
      "Epoch 6014/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.1533 - val_loss: 576.7884\n",
      "Epoch 6015/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.4962 - val_loss: 576.7340\n",
      "Epoch 6016/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.6406 - val_loss: 576.5682\n",
      "Epoch 6017/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.4022 - val_loss: 575.7169\n",
      "Epoch 6018/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.2645 - val_loss: 577.2435\n",
      "Epoch 6019/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.3425 - val_loss: 576.5247\n",
      "Epoch 6020/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.2545 - val_loss: 575.9484\n",
      "Epoch 6021/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 478.9651 - val_loss: 576.6539\n",
      "Epoch 6022/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.0246 - val_loss: 576.5592\n",
      "Epoch 6023/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.8540 - val_loss: 577.7472\n",
      "Epoch 6024/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.9378 - val_loss: 577.5765\n",
      "Epoch 6025/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.0673 - val_loss: 576.2488\n",
      "Epoch 6026/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.7448 - val_loss: 576.2943\n",
      "Epoch 6027/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.2074 - val_loss: 577.0600\n",
      "Epoch 6028/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.0078 - val_loss: 576.8309\n",
      "Epoch 6029/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.9691 - val_loss: 576.6101\n",
      "Epoch 6030/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.2555 - val_loss: 577.1987\n",
      "Epoch 6031/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.8429 - val_loss: 577.4359\n",
      "Epoch 6032/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.3157 - val_loss: 577.1041\n",
      "Epoch 6033/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.3820 - val_loss: 578.1150\n",
      "Epoch 6034/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.0608 - val_loss: 577.2109\n",
      "Epoch 6035/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.1695 - val_loss: 576.8916\n",
      "Epoch 6036/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.8020 - val_loss: 576.6813\n",
      "Epoch 6037/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.7123 - val_loss: 576.5282\n",
      "Epoch 6038/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.9943 - val_loss: 576.2653\n",
      "Epoch 6039/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.2397 - val_loss: 576.3725\n",
      "Epoch 6040/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.9407 - val_loss: 577.5574\n",
      "Epoch 6041/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.0003 - val_loss: 577.3140\n",
      "Epoch 6042/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.8803 - val_loss: 576.5080\n",
      "Epoch 6043/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.9901 - val_loss: 576.4661\n",
      "Epoch 6044/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.3974 - val_loss: 575.8666\n",
      "Epoch 6045/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.0548 - val_loss: 577.2104\n",
      "Epoch 6046/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.4942 - val_loss: 577.0018\n",
      "Epoch 6047/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.0721 - val_loss: 576.3843\n",
      "Epoch 6048/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.1941 - val_loss: 577.7751\n",
      "Epoch 6049/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.2424 - val_loss: 577.2522\n",
      "Epoch 6050/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.8420 - val_loss: 576.5802\n",
      "Epoch 6051/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.8168 - val_loss: 577.1054\n",
      "Epoch 6052/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.8499 - val_loss: 575.9711\n",
      "Epoch 6053/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.9976 - val_loss: 576.5670\n",
      "Epoch 6054/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.8240 - val_loss: 576.2298\n",
      "Epoch 6055/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.7918 - val_loss: 576.6124\n",
      "Epoch 6056/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.0256 - val_loss: 577.6421\n",
      "Epoch 6057/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.8030 - val_loss: 577.7080\n",
      "Epoch 6058/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.7655 - val_loss: 576.3022\n",
      "Epoch 6059/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.3308 - val_loss: 577.2570\n",
      "Epoch 6060/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.8805 - val_loss: 577.2470\n",
      "Epoch 6061/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.2355 - val_loss: 575.8665\n",
      "Epoch 6062/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.0292 - val_loss: 575.9599\n",
      "Epoch 6063/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.3739 - val_loss: 577.0151\n",
      "Epoch 6064/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.0397 - val_loss: 577.3580\n",
      "Epoch 6065/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.9032 - val_loss: 577.7151\n",
      "Epoch 6066/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.8812 - val_loss: 577.2995\n",
      "Epoch 6067/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.0394 - val_loss: 576.4967\n",
      "Epoch 6068/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.1635 - val_loss: 576.9476\n",
      "Epoch 6069/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.5769 - val_loss: 577.7380\n",
      "Epoch 6070/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.3312 - val_loss: 576.5190\n",
      "Epoch 6071/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.7255 - val_loss: 577.4456\n",
      "Epoch 6072/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.4224 - val_loss: 576.8594\n",
      "Epoch 6073/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.8010 - val_loss: 576.1893\n",
      "Epoch 6074/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.6432 - val_loss: 576.2081\n",
      "Epoch 6075/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 479.3844 - val_loss: 575.8846\n",
      "Epoch 6076/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.7982 - val_loss: 577.5625\n",
      "Epoch 6077/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.3951 - val_loss: 577.7312\n",
      "Epoch 6078/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.5787 - val_loss: 576.6769\n",
      "Epoch 6079/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.6048 - val_loss: 577.8650\n",
      "Epoch 6080/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.7918 - val_loss: 576.9544\n",
      "Epoch 6081/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.6217 - val_loss: 576.4324\n",
      "Epoch 6082/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.9992 - val_loss: 576.4597\n",
      "Epoch 6083/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.8995 - val_loss: 575.9925\n",
      "Epoch 6084/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.7305 - val_loss: 576.6616\n",
      "Epoch 6085/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.7875 - val_loss: 576.6202\n",
      "Epoch 6086/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.3712 - val_loss: 575.9403\n",
      "Epoch 6087/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.9830 - val_loss: 576.2589\n",
      "Epoch 6088/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.5574 - val_loss: 576.6363\n",
      "Epoch 6089/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.6577 - val_loss: 576.8682\n",
      "Epoch 6090/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.2932 - val_loss: 576.2658\n",
      "Epoch 6091/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.9191 - val_loss: 576.7411\n",
      "Epoch 6092/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.6690 - val_loss: 576.2668\n",
      "Epoch 6093/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 478.7034 - val_loss: 577.2881\n",
      "Epoch 6094/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.6664 - val_loss: 576.9822\n",
      "Epoch 6095/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.0292 - val_loss: 577.5023\n",
      "Epoch 6096/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.2621 - val_loss: 577.4098\n",
      "Epoch 6097/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.7079 - val_loss: 576.4745\n",
      "Epoch 6098/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.7900 - val_loss: 576.0612\n",
      "Epoch 6099/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.8962 - val_loss: 575.8644\n",
      "Epoch 6100/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.4279 - val_loss: 576.4756\n",
      "Epoch 6101/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.5923 - val_loss: 576.0242\n",
      "Epoch 6102/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.1947 - val_loss: 575.8489\n",
      "Epoch 6103/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.7234 - val_loss: 577.3551\n",
      "Epoch 6104/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.1330 - val_loss: 575.8479\n",
      "Epoch 6105/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.0162 - val_loss: 577.0086\n",
      "Epoch 6106/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.6435 - val_loss: 576.6170\n",
      "Epoch 6107/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.9502 - val_loss: 575.1070\n",
      "Epoch 6108/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.1797 - val_loss: 576.5252\n",
      "Epoch 6109/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.7606 - val_loss: 575.7202\n",
      "Epoch 6110/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.8587 - val_loss: 575.5191\n",
      "Epoch 6111/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.7717 - val_loss: 576.1847\n",
      "Epoch 6112/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.9543 - val_loss: 575.5818\n",
      "Epoch 6113/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 480.2072 - val_loss: 574.6301\n",
      "Epoch 6114/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.3446 - val_loss: 576.8406\n",
      "Epoch 6115/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.1646 - val_loss: 575.4873\n",
      "Epoch 6116/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.4535 - val_loss: 575.5923\n",
      "Epoch 6117/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.7769 - val_loss: 577.1852\n",
      "Epoch 6118/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.3685 - val_loss: 575.8942\n",
      "Epoch 6119/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.4700 - val_loss: 576.7452\n",
      "Epoch 6120/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.1331 - val_loss: 576.4761\n",
      "Epoch 6121/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 479.2910 - val_loss: 575.0625\n",
      "Epoch 6122/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.8218 - val_loss: 576.8678\n",
      "Epoch 6123/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.8644 - val_loss: 576.7682\n",
      "Epoch 6124/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.6343 - val_loss: 576.0287\n",
      "Epoch 6125/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.4549 - val_loss: 576.9705\n",
      "Epoch 6126/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.8854 - val_loss: 576.5406\n",
      "Epoch 6127/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.4028 - val_loss: 576.6944\n",
      "Epoch 6128/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.7877 - val_loss: 576.6335\n",
      "Epoch 6129/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.1095 - val_loss: 576.4701\n",
      "Epoch 6130/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.6269 - val_loss: 576.0357\n",
      "Epoch 6131/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.4602 - val_loss: 577.3360\n",
      "Epoch 6132/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.1432 - val_loss: 576.7644\n",
      "Epoch 6133/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.8299 - val_loss: 576.9735\n",
      "Epoch 6134/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.8052 - val_loss: 577.4197\n",
      "Epoch 6135/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.9669 - val_loss: 577.6751\n",
      "Epoch 6136/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.6346 - val_loss: 577.3167\n",
      "Epoch 6137/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.9778 - val_loss: 576.4622\n",
      "Epoch 6138/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.3878 - val_loss: 575.8165\n",
      "Epoch 6139/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.9560 - val_loss: 577.1215\n",
      "Epoch 6140/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.2912 - val_loss: 576.4235\n",
      "Epoch 6141/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.4031 - val_loss: 576.8488\n",
      "Epoch 6142/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.0434 - val_loss: 575.9061\n",
      "Epoch 6143/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.5724 - val_loss: 576.3625\n",
      "Epoch 6144/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.8225 - val_loss: 575.2701\n",
      "Epoch 6145/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.3713 - val_loss: 575.9741\n",
      "Epoch 6146/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.9432 - val_loss: 576.4654\n",
      "Epoch 6147/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.2343 - val_loss: 575.6943\n",
      "Epoch 6148/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.2760 - val_loss: 576.6171\n",
      "Epoch 6149/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.8294 - val_loss: 577.0604\n",
      "Epoch 6150/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.7917 - val_loss: 575.7660\n",
      "Epoch 6151/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.7800 - val_loss: 575.4796\n",
      "Epoch 6152/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.3393 - val_loss: 576.7903\n",
      "Epoch 6153/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.3374 - val_loss: 576.5254\n",
      "Epoch 6154/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.6150 - val_loss: 576.4363\n",
      "Epoch 6155/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.6849 - val_loss: 576.6758\n",
      "Epoch 6156/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.3227 - val_loss: 575.5861\n",
      "Epoch 6157/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.5701 - val_loss: 576.6377\n",
      "Epoch 6158/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.3594 - val_loss: 575.7935\n",
      "Epoch 6159/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.5864 - val_loss: 575.8494\n",
      "Epoch 6160/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.5944 - val_loss: 576.2579\n",
      "Epoch 6161/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.5572 - val_loss: 575.8856\n",
      "Epoch 6162/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.2803 - val_loss: 575.8530\n",
      "Epoch 6163/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.3168 - val_loss: 576.4234\n",
      "Epoch 6164/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.0765 - val_loss: 577.3893\n",
      "Epoch 6165/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.4775 - val_loss: 577.0166\n",
      "Epoch 6166/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.7579 - val_loss: 574.8271\n",
      "Epoch 6167/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.8096 - val_loss: 575.4190\n",
      "Epoch 6168/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.6110 - val_loss: 575.6193\n",
      "Epoch 6169/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.6087 - val_loss: 575.1632\n",
      "Epoch 6170/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.6566 - val_loss: 575.9140\n",
      "Epoch 6171/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.5565 - val_loss: 575.5618\n",
      "Epoch 6172/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.8411 - val_loss: 575.5103\n",
      "Epoch 6173/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.4568 - val_loss: 574.9562\n",
      "Epoch 6174/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.2186 - val_loss: 575.2589\n",
      "Epoch 6175/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.4664 - val_loss: 576.1591\n",
      "Epoch 6176/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.1898 - val_loss: 576.1039\n",
      "Epoch 6177/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.9163 - val_loss: 576.8543\n",
      "Epoch 6178/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.9467 - val_loss: 576.5145\n",
      "Epoch 6179/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.4626 - val_loss: 576.2482\n",
      "Epoch 6180/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.3666 - val_loss: 575.7840\n",
      "Epoch 6181/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.3698 - val_loss: 575.9461\n",
      "Epoch 6182/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.6756 - val_loss: 576.2502\n",
      "Epoch 6183/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.2122 - val_loss: 576.2202\n",
      "Epoch 6184/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.3470 - val_loss: 576.4699\n",
      "Epoch 6185/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.7639 - val_loss: 576.0842\n",
      "Epoch 6186/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.3121 - val_loss: 576.7179\n",
      "Epoch 6187/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.3241 - val_loss: 575.6983\n",
      "Epoch 6188/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.1503 - val_loss: 576.5363\n",
      "Epoch 6189/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.9209 - val_loss: 577.4746\n",
      "Epoch 6190/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 478.1710 - val_loss: 576.0343\n",
      "Epoch 6191/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.7898 - val_loss: 575.5687\n",
      "Epoch 6192/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.5206 - val_loss: 576.7338\n",
      "Epoch 6193/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.4718 - val_loss: 575.6108\n",
      "Epoch 6194/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.1305 - val_loss: 575.5086\n",
      "Epoch 6195/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.5769 - val_loss: 575.5738\n",
      "Epoch 6196/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.4205 - val_loss: 575.6433\n",
      "Epoch 6197/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.4429 - val_loss: 576.5210\n",
      "Epoch 6198/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.1959 - val_loss: 575.5458\n",
      "Epoch 6199/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.9283 - val_loss: 575.5785\n",
      "Epoch 6200/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.2403 - val_loss: 575.3931\n",
      "Epoch 6201/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.8652 - val_loss: 576.0386\n",
      "Epoch 6202/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.2357 - val_loss: 576.7826\n",
      "Epoch 6203/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.2411 - val_loss: 576.4966\n",
      "Epoch 6204/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.1003 - val_loss: 576.1615\n",
      "Epoch 6205/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.9190 - val_loss: 576.1862\n",
      "Epoch 6206/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.1522 - val_loss: 575.2155\n",
      "Epoch 6207/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.3257 - val_loss: 577.0251\n",
      "Epoch 6208/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.5771 - val_loss: 576.5173\n",
      "Epoch 6209/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.0376 - val_loss: 575.6819\n",
      "Epoch 6210/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.8748 - val_loss: 576.9578\n",
      "Epoch 6211/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.7918 - val_loss: 576.6024\n",
      "Epoch 6212/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.1891 - val_loss: 576.8006\n",
      "Epoch 6213/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.4316 - val_loss: 576.5780\n",
      "Epoch 6214/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.9586 - val_loss: 575.6765\n",
      "Epoch 6215/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.6944 - val_loss: 576.5201\n",
      "Epoch 6216/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.3106 - val_loss: 575.9203\n",
      "Epoch 6217/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.5674 - val_loss: 576.4459\n",
      "Epoch 6218/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.7723 - val_loss: 575.7804\n",
      "Epoch 6219/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.9260 - val_loss: 575.2488\n",
      "Epoch 6220/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.6173 - val_loss: 574.9949\n",
      "Epoch 6221/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.1312 - val_loss: 575.3100\n",
      "Epoch 6222/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.8404 - val_loss: 576.7500\n",
      "Epoch 6223/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.4785 - val_loss: 575.1684\n",
      "Epoch 6224/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.1096 - val_loss: 575.5570\n",
      "Epoch 6225/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.1495 - val_loss: 576.2860\n",
      "Epoch 6226/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.7280 - val_loss: 576.3555\n",
      "Epoch 6227/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.8656 - val_loss: 574.7485\n",
      "Epoch 6228/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.9483 - val_loss: 577.0708\n",
      "Epoch 6229/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.3127 - val_loss: 576.1648\n",
      "Epoch 6230/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.9598 - val_loss: 576.5485\n",
      "Epoch 6231/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.8218 - val_loss: 576.1336\n",
      "Epoch 6232/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.9056 - val_loss: 575.7863\n",
      "Epoch 6233/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.1273 - val_loss: 575.2482\n",
      "Epoch 6234/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.4162 - val_loss: 575.6853\n",
      "Epoch 6235/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.6655 - val_loss: 575.6181\n",
      "Epoch 6236/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.6363 - val_loss: 576.1914\n",
      "Epoch 6237/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.1490 - val_loss: 574.9278\n",
      "Epoch 6238/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.9292 - val_loss: 575.9024\n",
      "Epoch 6239/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.2410 - val_loss: 576.3824\n",
      "Epoch 6240/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.3271 - val_loss: 575.7131\n",
      "Epoch 6241/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.1089 - val_loss: 575.7449\n",
      "Epoch 6242/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.0392 - val_loss: 575.5046\n",
      "Epoch 6243/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.0810 - val_loss: 575.8924\n",
      "Epoch 6244/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.8998 - val_loss: 574.9777\n",
      "Epoch 6245/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 478.4944 - val_loss: 575.1304\n",
      "Epoch 6246/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.0394 - val_loss: 574.3641\n",
      "Epoch 6247/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.2032 - val_loss: 575.8155\n",
      "Epoch 6248/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.9524 - val_loss: 575.2308\n",
      "Epoch 6249/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.1104 - val_loss: 577.0470\n",
      "Epoch 6250/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 346.5399Epoch: 6250 - loss: 478.210230 - val_loss: 574.936589\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.2102 - val_loss: 574.9366\n",
      "Epoch 6251/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 478.0689 - val_loss: 575.9738\n",
      "Epoch 6252/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 479.0522 - val_loss: 575.3229\n",
      "Epoch 6253/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.9302 - val_loss: 574.3830\n",
      "Epoch 6254/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.2178 - val_loss: 575.9103\n",
      "Epoch 6255/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.6486 - val_loss: 575.2503\n",
      "Epoch 6256/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.6656 - val_loss: 575.1959\n",
      "Epoch 6257/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.9057 - val_loss: 575.2961\n",
      "Epoch 6258/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.0292 - val_loss: 575.3173\n",
      "Epoch 6259/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.0998 - val_loss: 574.8366\n",
      "Epoch 6260/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.0409 - val_loss: 575.6463\n",
      "Epoch 6261/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.4677 - val_loss: 575.2937\n",
      "Epoch 6262/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.9815 - val_loss: 575.4246\n",
      "Epoch 6263/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.6247 - val_loss: 574.5674\n",
      "Epoch 6264/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.9395 - val_loss: 575.4817\n",
      "Epoch 6265/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.1536 - val_loss: 575.2182\n",
      "Epoch 6266/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.1212 - val_loss: 575.1141\n",
      "Epoch 6267/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.2361 - val_loss: 576.7063\n",
      "Epoch 6268/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.7801 - val_loss: 575.0752\n",
      "Epoch 6269/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.6069 - val_loss: 575.7166\n",
      "Epoch 6270/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.8352 - val_loss: 576.1161\n",
      "Epoch 6271/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.8529 - val_loss: 575.5910\n",
      "Epoch 6272/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.3188 - val_loss: 575.1797\n",
      "Epoch 6273/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.8005 - val_loss: 576.6488\n",
      "Epoch 6274/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.6871 - val_loss: 574.5478\n",
      "Epoch 6275/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.6380 - val_loss: 576.4854\n",
      "Epoch 6276/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.5778 - val_loss: 575.0401\n",
      "Epoch 6277/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.8504 - val_loss: 575.3271\n",
      "Epoch 6278/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.7188 - val_loss: 575.0142\n",
      "Epoch 6279/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.2770 - val_loss: 573.8836\n",
      "Epoch 6280/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.4752 - val_loss: 576.1341\n",
      "Epoch 6281/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.8384 - val_loss: 575.0342\n",
      "Epoch 6282/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.1949 - val_loss: 576.2684\n",
      "Epoch 6283/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.0349 - val_loss: 575.7872\n",
      "Epoch 6284/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.7461 - val_loss: 575.4951\n",
      "Epoch 6285/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.9423 - val_loss: 575.1322\n",
      "Epoch 6286/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.4300 - val_loss: 574.8898\n",
      "Epoch 6287/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 477.8887 - val_loss: 575.6241\n",
      "Epoch 6288/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.7427 - val_loss: 575.7936\n",
      "Epoch 6289/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.1928 - val_loss: 574.6330\n",
      "Epoch 6290/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.1548 - val_loss: 574.4275\n",
      "Epoch 6291/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.8608 - val_loss: 575.0520\n",
      "Epoch 6292/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.2964 - val_loss: 575.8371\n",
      "Epoch 6293/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.5791 - val_loss: 574.8324\n",
      "Epoch 6294/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.8713 - val_loss: 574.6020\n",
      "Epoch 6295/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.1487 - val_loss: 574.0386\n",
      "Epoch 6296/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.8764 - val_loss: 574.8730\n",
      "Epoch 6297/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 477.6158 - val_loss: 575.1723\n",
      "Epoch 6298/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.5731 - val_loss: 574.4217\n",
      "Epoch 6299/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.4906 - val_loss: 574.5167\n",
      "Epoch 6300/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.7381 - val_loss: 575.2559\n",
      "Epoch 6301/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.3695 - val_loss: 575.8157\n",
      "Epoch 6302/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.8359 - val_loss: 574.9077\n",
      "Epoch 6303/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.7276 - val_loss: 574.9450\n",
      "Epoch 6304/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.5215 - val_loss: 575.6071\n",
      "Epoch 6305/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.7870 - val_loss: 575.4362\n",
      "Epoch 6306/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.8889 - val_loss: 574.9319\n",
      "Epoch 6307/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.9557 - val_loss: 574.3382\n",
      "Epoch 6308/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.5831 - val_loss: 576.9333\n",
      "Epoch 6309/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.5869 - val_loss: 575.0306\n",
      "Epoch 6310/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.8584 - val_loss: 574.6412\n",
      "Epoch 6311/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.4207 - val_loss: 574.9480\n",
      "Epoch 6312/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.5065 - val_loss: 574.3686\n",
      "Epoch 6313/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.3971 - val_loss: 574.8315\n",
      "Epoch 6314/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.8206 - val_loss: 576.9361\n",
      "Epoch 6315/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.6188 - val_loss: 574.7984\n",
      "Epoch 6316/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.7721 - val_loss: 574.0187\n",
      "Epoch 6317/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 477.6729 - val_loss: 575.0050\n",
      "Epoch 6318/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.3367 - val_loss: 574.6553\n",
      "Epoch 6319/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.9818 - val_loss: 575.2085\n",
      "Epoch 6320/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.9214 - val_loss: 574.4385\n",
      "Epoch 6321/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.9133 - val_loss: 574.8541\n",
      "Epoch 6322/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.7471 - val_loss: 575.1954\n",
      "Epoch 6323/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.3609 - val_loss: 574.9510\n",
      "Epoch 6324/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.9738 - val_loss: 575.4517\n",
      "Epoch 6325/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.5418 - val_loss: 575.1848\n",
      "Epoch 6326/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.7474 - val_loss: 574.8558\n",
      "Epoch 6327/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.0378 - val_loss: 575.9420\n",
      "Epoch 6328/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.8085 - val_loss: 574.9983\n",
      "Epoch 6329/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.5204 - val_loss: 574.8178\n",
      "Epoch 6330/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.6854 - val_loss: 574.6108\n",
      "Epoch 6331/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.4396 - val_loss: 575.9105\n",
      "Epoch 6332/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.8178 - val_loss: 575.2766\n",
      "Epoch 6333/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.0070 - val_loss: 575.5444\n",
      "Epoch 6334/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.5162 - val_loss: 575.8703\n",
      "Epoch 6335/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.0686 - val_loss: 576.5734\n",
      "Epoch 6336/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.7894 - val_loss: 574.6867\n",
      "Epoch 6337/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.6575 - val_loss: 575.0118\n",
      "Epoch 6338/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.0713 - val_loss: 576.3658\n",
      "Epoch 6339/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.0432 - val_loss: 575.6234\n",
      "Epoch 6340/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.0637 - val_loss: 575.3599\n",
      "Epoch 6341/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.8952 - val_loss: 574.6334\n",
      "Epoch 6342/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.3660 - val_loss: 575.4885\n",
      "Epoch 6343/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.7506 - val_loss: 575.6589\n",
      "Epoch 6344/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.4906 - val_loss: 574.7388\n",
      "Epoch 6345/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.5456 - val_loss: 575.2924\n",
      "Epoch 6346/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.8507 - val_loss: 575.1261\n",
      "Epoch 6347/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.4059 - val_loss: 575.9712\n",
      "Epoch 6348/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.4767 - val_loss: 575.8912\n",
      "Epoch 6349/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.3987 - val_loss: 574.6597\n",
      "Epoch 6350/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.5300 - val_loss: 575.9479\n",
      "Epoch 6351/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.6019 - val_loss: 574.8903\n",
      "Epoch 6352/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.4629 - val_loss: 575.3269\n",
      "Epoch 6353/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.3656 - val_loss: 576.5327\n",
      "Epoch 6354/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.3455 - val_loss: 575.4301\n",
      "Epoch 6355/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.7546 - val_loss: 576.0585\n",
      "Epoch 6356/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.0583 - val_loss: 575.8376\n",
      "Epoch 6357/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.8989 - val_loss: 575.4245\n",
      "Epoch 6358/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.4678 - val_loss: 574.4604\n",
      "Epoch 6359/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.4544 - val_loss: 574.9720\n",
      "Epoch 6360/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.4645 - val_loss: 575.4845\n",
      "Epoch 6361/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.7088 - val_loss: 575.8039\n",
      "Epoch 6362/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.2819 - val_loss: 574.4234\n",
      "Epoch 6363/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.5510 - val_loss: 575.0463\n",
      "Epoch 6364/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.1576 - val_loss: 574.9472\n",
      "Epoch 6365/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.3107 - val_loss: 574.8298\n",
      "Epoch 6366/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.7647 - val_loss: 575.4051\n",
      "Epoch 6367/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.2664 - val_loss: 575.5684\n",
      "Epoch 6368/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.3220 - val_loss: 574.9344\n",
      "Epoch 6369/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.3290 - val_loss: 574.0485\n",
      "Epoch 6370/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.3078 - val_loss: 574.7386\n",
      "Epoch 6371/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.1757 - val_loss: 573.9322\n",
      "Epoch 6372/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.6851 - val_loss: 574.4962\n",
      "Epoch 6373/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.5414 - val_loss: 574.6082\n",
      "Epoch 6374/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.4879 - val_loss: 574.5300\n",
      "Epoch 6375/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.3868 - val_loss: 575.7669\n",
      "Epoch 6376/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.8102 - val_loss: 575.2419\n",
      "Epoch 6377/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.8391 - val_loss: 574.9900\n",
      "Epoch 6378/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.5750 - val_loss: 574.8299\n",
      "Epoch 6379/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.3208 - val_loss: 574.9340\n",
      "Epoch 6380/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.1869 - val_loss: 575.2075\n",
      "Epoch 6381/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.3967 - val_loss: 574.7652\n",
      "Epoch 6382/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.4794 - val_loss: 575.4552\n",
      "Epoch 6383/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.2778 - val_loss: 574.3160\n",
      "Epoch 6384/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.6730 - val_loss: 573.8783\n",
      "Epoch 6385/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.1319 - val_loss: 574.5103\n",
      "Epoch 6386/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.6302 - val_loss: 575.4340\n",
      "Epoch 6387/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.3148 - val_loss: 574.8672\n",
      "Epoch 6388/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.3893 - val_loss: 576.0628\n",
      "Epoch 6389/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.9809 - val_loss: 574.6728\n",
      "Epoch 6390/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.2022 - val_loss: 576.8520\n",
      "Epoch 6391/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.5640 - val_loss: 575.0148\n",
      "Epoch 6392/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.7810 - val_loss: 575.2473\n",
      "Epoch 6393/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.7273 - val_loss: 575.8384\n",
      "Epoch 6394/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.5727 - val_loss: 575.7535\n",
      "Epoch 6395/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.5891 - val_loss: 574.9747\n",
      "Epoch 6396/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 477.2786 - val_loss: 575.1215\n",
      "Epoch 6397/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 477.0580 - val_loss: 574.6572\n",
      "Epoch 6398/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.3134 - val_loss: 574.5440\n",
      "Epoch 6399/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 477.8547 - val_loss: 574.4443\n",
      "Epoch 6400/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.8561 - val_loss: 576.2313\n",
      "Epoch 6401/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.7270 - val_loss: 575.3583\n",
      "Epoch 6402/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.2936 - val_loss: 575.0938\n",
      "Epoch 6403/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 477.3537 - val_loss: 575.2509\n",
      "Epoch 6404/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.2683 - val_loss: 574.4360\n",
      "Epoch 6405/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.1009 - val_loss: 575.4554\n",
      "Epoch 6406/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.3235 - val_loss: 575.0262\n",
      "Epoch 6407/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.0272 - val_loss: 575.3306\n",
      "Epoch 6408/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.7002 - val_loss: 574.9628\n",
      "Epoch 6409/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.2176 - val_loss: 574.2054\n",
      "Epoch 6410/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.9939 - val_loss: 574.5697\n",
      "Epoch 6411/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.0982 - val_loss: 575.6019\n",
      "Epoch 6412/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.7172 - val_loss: 574.4201\n",
      "Epoch 6413/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.0444 - val_loss: 576.0369\n",
      "Epoch 6414/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.4859 - val_loss: 574.3452\n",
      "Epoch 6415/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.8039 - val_loss: 574.6875\n",
      "Epoch 6416/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.0979 - val_loss: 575.8040\n",
      "Epoch 6417/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.1018 - val_loss: 574.6950\n",
      "Epoch 6418/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.5608 - val_loss: 574.7959\n",
      "Epoch 6419/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.0391 - val_loss: 575.7982\n",
      "Epoch 6420/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.5275 - val_loss: 575.8061\n",
      "Epoch 6421/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.4562 - val_loss: 575.5496\n",
      "Epoch 6422/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.5922 - val_loss: 574.7057\n",
      "Epoch 6423/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.7716 - val_loss: 575.2871\n",
      "Epoch 6424/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.0867 - val_loss: 575.6125\n",
      "Epoch 6425/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.9159 - val_loss: 574.6798\n",
      "Epoch 6426/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.9726 - val_loss: 575.7764\n",
      "Epoch 6427/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.3664 - val_loss: 575.9234\n",
      "Epoch 6428/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.3628 - val_loss: 575.0168\n",
      "Epoch 6429/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.3461 - val_loss: 574.4742\n",
      "Epoch 6430/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 477.6635 - val_loss: 575.3754\n",
      "Epoch 6431/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.5028 - val_loss: 576.1457\n",
      "Epoch 6432/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.3327 - val_loss: 575.9746\n",
      "Epoch 6433/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.7184 - val_loss: 574.9129\n",
      "Epoch 6434/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.8467 - val_loss: 575.0540\n",
      "Epoch 6435/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.4502 - val_loss: 574.9930\n",
      "Epoch 6436/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.9604 - val_loss: 574.9032\n",
      "Epoch 6437/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.2294 - val_loss: 573.8932\n",
      "Epoch 6438/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.3043 - val_loss: 574.4026\n",
      "Epoch 6439/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.6280 - val_loss: 574.9929\n",
      "Epoch 6440/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.2526 - val_loss: 574.8251\n",
      "Epoch 6441/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.5861 - val_loss: 575.0790\n",
      "Epoch 6442/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.3345 - val_loss: 574.9526\n",
      "Epoch 6443/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.0962 - val_loss: 574.6469\n",
      "Epoch 6444/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.2230 - val_loss: 574.9940\n",
      "Epoch 6445/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.9511 - val_loss: 574.3132\n",
      "Epoch 6446/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.8418 - val_loss: 573.8631\n",
      "Epoch 6447/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.4575 - val_loss: 574.0695\n",
      "Epoch 6448/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.8302 - val_loss: 574.5031\n",
      "Epoch 6449/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.9831 - val_loss: 575.4240\n",
      "Epoch 6450/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.6632 - val_loss: 573.8567\n",
      "Epoch 6451/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.2581 - val_loss: 574.9196\n",
      "Epoch 6452/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.4392 - val_loss: 575.1656\n",
      "Epoch 6453/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.0922 - val_loss: 574.4292\n",
      "Epoch 6454/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.9742 - val_loss: 575.6261\n",
      "Epoch 6455/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.9533 - val_loss: 574.7036\n",
      "Epoch 6456/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.8373 - val_loss: 576.4914\n",
      "Epoch 6457/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.0339 - val_loss: 575.3242\n",
      "Epoch 6458/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.6311 - val_loss: 574.8519\n",
      "Epoch 6459/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.5571 - val_loss: 574.5968\n",
      "Epoch 6460/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.7880 - val_loss: 576.5958\n",
      "Epoch 6461/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.8796 - val_loss: 575.0238\n",
      "Epoch 6462/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.7252 - val_loss: 575.9862\n",
      "Epoch 6463/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.9437 - val_loss: 574.9131\n",
      "Epoch 6464/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.0638 - val_loss: 575.6724\n",
      "Epoch 6465/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.3623 - val_loss: 574.7326\n",
      "Epoch 6466/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.8993 - val_loss: 573.4249\n",
      "Epoch 6467/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.8781 - val_loss: 573.8890\n",
      "Epoch 6468/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.5425 - val_loss: 574.2735\n",
      "Epoch 6469/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.4450 - val_loss: 575.2083\n",
      "Epoch 6470/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.9634 - val_loss: 575.1685\n",
      "Epoch 6471/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.9664 - val_loss: 575.0804\n",
      "Epoch 6472/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.0202 - val_loss: 574.5954\n",
      "Epoch 6473/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.1245 - val_loss: 574.1285\n",
      "Epoch 6474/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.6748 - val_loss: 575.6327\n",
      "Epoch 6475/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.0407 - val_loss: 574.7727\n",
      "Epoch 6476/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.7599 - val_loss: 574.8005\n",
      "Epoch 6477/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.5456 - val_loss: 573.6186\n",
      "Epoch 6478/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.9500 - val_loss: 573.4643\n",
      "Epoch 6479/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.0158 - val_loss: 573.3541\n",
      "Epoch 6480/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.3855 - val_loss: 575.0772\n",
      "Epoch 6481/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.2811 - val_loss: 573.7363\n",
      "Epoch 6482/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.0540 - val_loss: 573.9230\n",
      "Epoch 6483/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.0127 - val_loss: 572.9024\n",
      "Epoch 6484/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 478.0421 - val_loss: 575.0836\n",
      "Epoch 6485/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.8823 - val_loss: 574.7222\n",
      "Epoch 6486/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.2501 - val_loss: 574.0047\n",
      "Epoch 6487/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.3820 - val_loss: 573.3976\n",
      "Epoch 6488/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.5800 - val_loss: 573.5375\n",
      "Epoch 6489/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.5935 - val_loss: 574.3893\n",
      "Epoch 6490/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.1270 - val_loss: 574.9328\n",
      "Epoch 6491/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.8710 - val_loss: 575.4508\n",
      "Epoch 6492/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.7713 - val_loss: 574.3733\n",
      "Epoch 6493/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.5307 - val_loss: 574.5992\n",
      "Epoch 6494/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.9166 - val_loss: 574.6727\n",
      "Epoch 6495/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.4839 - val_loss: 574.5063\n",
      "Epoch 6496/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.6369 - val_loss: 574.0953\n",
      "Epoch 6497/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.8080 - val_loss: 573.7336\n",
      "Epoch 6498/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 477.0718 - val_loss: 574.4282\n",
      "Epoch 6499/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.9160 - val_loss: 574.1740\n",
      "Epoch 6500/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 337.6676Epoch: 6500 - loss: 477.052687 - val_loss: 575.483433\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.0527 - val_loss: 575.4834\n",
      "Epoch 6501/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 477.0546 - val_loss: 574.7239\n",
      "Epoch 6502/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 477.2125 - val_loss: 574.6118\n",
      "Epoch 6503/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.8530 - val_loss: 574.9742\n",
      "Epoch 6504/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.5783 - val_loss: 574.3191\n",
      "Epoch 6505/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.8685 - val_loss: 575.1653\n",
      "Epoch 6506/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.6724 - val_loss: 574.3549\n",
      "Epoch 6507/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.1266 - val_loss: 574.2711\n",
      "Epoch 6508/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 476.8314 - val_loss: 574.6663\n",
      "Epoch 6509/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.8572 - val_loss: 574.1376\n",
      "Epoch 6510/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.9672 - val_loss: 573.7415\n",
      "Epoch 6511/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.2949 - val_loss: 574.4248\n",
      "Epoch 6512/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.8329 - val_loss: 574.4643\n",
      "Epoch 6513/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.8271 - val_loss: 574.1977\n",
      "Epoch 6514/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.9697 - val_loss: 574.5446\n",
      "Epoch 6515/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.7384 - val_loss: 574.7833\n",
      "Epoch 6516/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.1810 - val_loss: 575.2317\n",
      "Epoch 6517/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.6399 - val_loss: 574.2787\n",
      "Epoch 6518/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.4777 - val_loss: 573.5091\n",
      "Epoch 6519/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.2569 - val_loss: 574.4407\n",
      "Epoch 6520/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.0222 - val_loss: 575.8025\n",
      "Epoch 6521/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 476.7000 - val_loss: 574.5715\n",
      "Epoch 6522/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.3530 - val_loss: 574.0907\n",
      "Epoch 6523/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.9296 - val_loss: 574.8918\n",
      "Epoch 6524/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.6994 - val_loss: 575.6635\n",
      "Epoch 6525/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.0771 - val_loss: 575.3816\n",
      "Epoch 6526/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.9228 - val_loss: 575.1787\n",
      "Epoch 6527/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 476.7660 - val_loss: 574.1597\n",
      "Epoch 6528/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.3952 - val_loss: 574.3561\n",
      "Epoch 6529/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.5883 - val_loss: 574.9343\n",
      "Epoch 6530/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.6304 - val_loss: 572.9965\n",
      "Epoch 6531/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.8904 - val_loss: 574.7721\n",
      "Epoch 6532/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.6662 - val_loss: 573.5825\n",
      "Epoch 6533/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.2883 - val_loss: 574.7927\n",
      "Epoch 6534/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.1074 - val_loss: 574.0897\n",
      "Epoch 6535/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.8661 - val_loss: 574.3726\n",
      "Epoch 6536/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.4865 - val_loss: 573.1658\n",
      "Epoch 6537/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.0617 - val_loss: 574.4932\n",
      "Epoch 6538/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.6614 - val_loss: 573.6837\n",
      "Epoch 6539/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.2959 - val_loss: 573.6719\n",
      "Epoch 6540/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.5029 - val_loss: 574.4006\n",
      "Epoch 6541/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.3927 - val_loss: 574.4018\n",
      "Epoch 6542/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.4866 - val_loss: 573.7041\n",
      "Epoch 6543/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.2648 - val_loss: 573.6837\n",
      "Epoch 6544/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.7242 - val_loss: 575.4576\n",
      "Epoch 6545/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.7211 - val_loss: 574.7790\n",
      "Epoch 6546/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.2221 - val_loss: 574.2182\n",
      "Epoch 6547/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.5251 - val_loss: 574.2843\n",
      "Epoch 6548/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.6437 - val_loss: 574.6025\n",
      "Epoch 6549/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.1572 - val_loss: 573.4701\n",
      "Epoch 6550/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.4333 - val_loss: 574.0559\n",
      "Epoch 6551/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.7629 - val_loss: 573.9408\n",
      "Epoch 6552/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.5418 - val_loss: 574.9176\n",
      "Epoch 6553/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.4852 - val_loss: 574.7286\n",
      "Epoch 6554/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.7014 - val_loss: 575.1634\n",
      "Epoch 6555/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.9389 - val_loss: 573.9985\n",
      "Epoch 6556/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.2426 - val_loss: 574.6188\n",
      "Epoch 6557/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.5332 - val_loss: 574.4006\n",
      "Epoch 6558/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.2965 - val_loss: 574.1440\n",
      "Epoch 6559/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.4475 - val_loss: 574.6865\n",
      "Epoch 6560/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.7799 - val_loss: 574.9370\n",
      "Epoch 6561/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.8948 - val_loss: 573.4688\n",
      "Epoch 6562/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.7485 - val_loss: 574.8397\n",
      "Epoch 6563/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.0932 - val_loss: 574.4042\n",
      "Epoch 6564/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.8220 - val_loss: 574.3778\n",
      "Epoch 6565/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.1826 - val_loss: 574.3834\n",
      "Epoch 6566/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.4122 - val_loss: 574.9235\n",
      "Epoch 6567/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.9787 - val_loss: 574.5223\n",
      "Epoch 6568/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.3421 - val_loss: 574.5743\n",
      "Epoch 6569/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.9728 - val_loss: 575.4650\n",
      "Epoch 6570/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.7986 - val_loss: 574.8489\n",
      "Epoch 6571/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.7195 - val_loss: 575.0900\n",
      "Epoch 6572/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.9362 - val_loss: 574.0766\n",
      "Epoch 6573/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.3303 - val_loss: 574.4749\n",
      "Epoch 6574/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.1776 - val_loss: 575.1595\n",
      "Epoch 6575/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.7859 - val_loss: 574.6263\n",
      "Epoch 6576/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.7150 - val_loss: 575.3461\n",
      "Epoch 6577/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.7618 - val_loss: 574.1350\n",
      "Epoch 6578/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.4351 - val_loss: 574.2207\n",
      "Epoch 6579/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.4529 - val_loss: 574.2967\n",
      "Epoch 6580/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.2741 - val_loss: 574.3170\n",
      "Epoch 6581/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.3965 - val_loss: 574.6874\n",
      "Epoch 6582/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.6446 - val_loss: 573.3795\n",
      "Epoch 6583/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.9731 - val_loss: 574.2598\n",
      "Epoch 6584/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.8415 - val_loss: 574.9465\n",
      "Epoch 6585/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.9796 - val_loss: 574.3383\n",
      "Epoch 6586/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.5537 - val_loss: 573.7160\n",
      "Epoch 6587/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.5716 - val_loss: 574.4981\n",
      "Epoch 6588/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.8864 - val_loss: 574.8387\n",
      "Epoch 6589/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 476.3212 - val_loss: 573.5353\n",
      "Epoch 6590/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.3510 - val_loss: 574.0151\n",
      "Epoch 6591/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.2958 - val_loss: 574.4369\n",
      "Epoch 6592/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.1230 - val_loss: 573.9132\n",
      "Epoch 6593/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.1357 - val_loss: 574.4094\n",
      "Epoch 6594/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.4191 - val_loss: 573.7813\n",
      "Epoch 6595/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.0972 - val_loss: 572.8295\n",
      "Epoch 6596/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.9635 - val_loss: 574.4163\n",
      "Epoch 6597/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.0925 - val_loss: 574.4693\n",
      "Epoch 6598/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.1977 - val_loss: 573.2280\n",
      "Epoch 6599/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.7068 - val_loss: 574.3325\n",
      "Epoch 6600/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.6954 - val_loss: 574.5802\n",
      "Epoch 6601/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.5424 - val_loss: 575.0716\n",
      "Epoch 6602/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.2355 - val_loss: 573.6847\n",
      "Epoch 6603/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.5058 - val_loss: 574.3190\n",
      "Epoch 6604/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.0001 - val_loss: 573.6087\n",
      "Epoch 6605/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.7843 - val_loss: 573.8503\n",
      "Epoch 6606/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.1270 - val_loss: 573.0393\n",
      "Epoch 6607/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.7932 - val_loss: 574.8022\n",
      "Epoch 6608/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.6966 - val_loss: 573.4483\n",
      "Epoch 6609/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.4813 - val_loss: 574.4239\n",
      "Epoch 6610/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.3762 - val_loss: 572.7076\n",
      "Epoch 6611/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.1929 - val_loss: 573.0708\n",
      "Epoch 6612/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.3632 - val_loss: 572.7412\n",
      "Epoch 6613/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.3956 - val_loss: 573.3136\n",
      "Epoch 6614/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.6473 - val_loss: 572.6019\n",
      "Epoch 6615/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.2654 - val_loss: 572.5760\n",
      "Epoch 6616/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.1898 - val_loss: 572.9459\n",
      "Epoch 6617/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.9759 - val_loss: 572.4085\n",
      "Epoch 6618/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.1791 - val_loss: 573.3908\n",
      "Epoch 6619/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.1866 - val_loss: 574.4714\n",
      "Epoch 6620/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.1395 - val_loss: 572.9312\n",
      "Epoch 6621/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.5243 - val_loss: 572.9864\n",
      "Epoch 6622/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.9737 - val_loss: 573.0176\n",
      "Epoch 6623/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.3515 - val_loss: 573.3423\n",
      "Epoch 6624/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.1473 - val_loss: 574.1250\n",
      "Epoch 6625/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.6857 - val_loss: 575.0786\n",
      "Epoch 6626/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.1666 - val_loss: 573.8941\n",
      "Epoch 6627/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.0695 - val_loss: 573.4980\n",
      "Epoch 6628/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.1635 - val_loss: 573.3296\n",
      "Epoch 6629/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.5735 - val_loss: 573.7755\n",
      "Epoch 6630/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.1517 - val_loss: 574.2388\n",
      "Epoch 6631/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.1469 - val_loss: 573.8650\n",
      "Epoch 6632/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.2901 - val_loss: 573.6500\n",
      "Epoch 6633/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.7186 - val_loss: 574.2733\n",
      "Epoch 6634/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.3297 - val_loss: 574.3969\n",
      "Epoch 6635/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.2064 - val_loss: 573.7543\n",
      "Epoch 6636/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.0518 - val_loss: 572.1764\n",
      "Epoch 6637/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.5999 - val_loss: 573.5550\n",
      "Epoch 6638/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.2419 - val_loss: 573.9916\n",
      "Epoch 6639/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.5350 - val_loss: 573.6643\n",
      "Epoch 6640/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.0335 - val_loss: 573.0635\n",
      "Epoch 6641/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.9649 - val_loss: 573.0576\n",
      "Epoch 6642/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.2306 - val_loss: 573.9460\n",
      "Epoch 6643/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.2724 - val_loss: 573.1968\n",
      "Epoch 6644/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.0583 - val_loss: 573.6421\n",
      "Epoch 6645/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.9850 - val_loss: 574.3118\n",
      "Epoch 6646/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.2687 - val_loss: 574.1619\n",
      "Epoch 6647/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.1919 - val_loss: 573.4936\n",
      "Epoch 6648/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 475.9836 - val_loss: 573.5840\n",
      "Epoch 6649/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.5715 - val_loss: 573.6137\n",
      "Epoch 6650/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.9312 - val_loss: 573.9123\n",
      "Epoch 6651/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.0864 - val_loss: 573.4914\n",
      "Epoch 6652/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.3920 - val_loss: 573.1879\n",
      "Epoch 6653/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 476.7433 - val_loss: 573.6013\n",
      "Epoch 6654/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.8738 - val_loss: 574.4584\n",
      "Epoch 6655/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.4844 - val_loss: 574.3937\n",
      "Epoch 6656/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.8683 - val_loss: 574.6345\n",
      "Epoch 6657/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.5624 - val_loss: 573.5715\n",
      "Epoch 6658/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.2093 - val_loss: 574.0549\n",
      "Epoch 6659/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.2930 - val_loss: 573.7142\n",
      "Epoch 6660/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.3961 - val_loss: 572.7434\n",
      "Epoch 6661/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.9590 - val_loss: 573.4753\n",
      "Epoch 6662/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.4191 - val_loss: 573.7235\n",
      "Epoch 6663/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.1672 - val_loss: 572.8112\n",
      "Epoch 6664/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.0080 - val_loss: 574.0205\n",
      "Epoch 6665/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.4645 - val_loss: 573.8951\n",
      "Epoch 6666/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.7169 - val_loss: 573.5436\n",
      "Epoch 6667/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.3496 - val_loss: 572.6577\n",
      "Epoch 6668/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.8992 - val_loss: 573.2168\n",
      "Epoch 6669/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.8461 - val_loss: 575.4264\n",
      "Epoch 6670/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.1862 - val_loss: 573.5735\n",
      "Epoch 6671/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.1470 - val_loss: 573.0669\n",
      "Epoch 6672/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.4455 - val_loss: 574.5976\n",
      "Epoch 6673/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.8159 - val_loss: 573.1973\n",
      "Epoch 6674/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.9719 - val_loss: 573.7106\n",
      "Epoch 6675/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.3931 - val_loss: 573.3211\n",
      "Epoch 6676/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.1404 - val_loss: 573.6224\n",
      "Epoch 6677/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.0152 - val_loss: 573.8758\n",
      "Epoch 6678/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.6938 - val_loss: 572.3121\n",
      "Epoch 6679/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.6919 - val_loss: 573.2730\n",
      "Epoch 6680/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.0201 - val_loss: 573.7242\n",
      "Epoch 6681/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.9835 - val_loss: 574.3918\n",
      "Epoch 6682/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.8092 - val_loss: 573.5205\n",
      "Epoch 6683/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.4578 - val_loss: 572.8084\n",
      "Epoch 6684/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.1035 - val_loss: 573.6794\n",
      "Epoch 6685/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.8324 - val_loss: 573.3418\n",
      "Epoch 6686/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 476.2781 - val_loss: 573.7576\n",
      "Epoch 6687/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.2950 - val_loss: 573.1679\n",
      "Epoch 6688/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.3009 - val_loss: 573.4854\n",
      "Epoch 6689/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.0367 - val_loss: 574.1981\n",
      "Epoch 6690/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.4180 - val_loss: 573.5633\n",
      "Epoch 6691/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.5720 - val_loss: 573.4281\n",
      "Epoch 6692/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.1755 - val_loss: 573.5112\n",
      "Epoch 6693/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.2019 - val_loss: 574.0481\n",
      "Epoch 6694/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.9506 - val_loss: 573.8046\n",
      "Epoch 6695/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.0788 - val_loss: 572.8465\n",
      "Epoch 6696/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.8177 - val_loss: 574.6543\n",
      "Epoch 6697/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.9162 - val_loss: 573.7498\n",
      "Epoch 6698/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.8093 - val_loss: 572.7683\n",
      "Epoch 6699/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.7257 - val_loss: 573.6390\n",
      "Epoch 6700/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.7678 - val_loss: 573.0208\n",
      "Epoch 6701/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.4719 - val_loss: 574.1492\n",
      "Epoch 6702/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.5264 - val_loss: 574.2037\n",
      "Epoch 6703/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.9323 - val_loss: 573.5165\n",
      "Epoch 6704/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.1052 - val_loss: 573.5915\n",
      "Epoch 6705/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.1438 - val_loss: 572.8856\n",
      "Epoch 6706/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.6418 - val_loss: 574.6096\n",
      "Epoch 6707/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.7632 - val_loss: 574.1210\n",
      "Epoch 6708/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.0800 - val_loss: 573.3835\n",
      "Epoch 6709/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.1825 - val_loss: 574.5147\n",
      "Epoch 6710/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.0162 - val_loss: 573.6014\n",
      "Epoch 6711/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.6770 - val_loss: 573.8196\n",
      "Epoch 6712/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.0475 - val_loss: 574.0914\n",
      "Epoch 6713/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.4483 - val_loss: 572.9211\n",
      "Epoch 6714/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.1422 - val_loss: 574.4133\n",
      "Epoch 6715/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.8582 - val_loss: 575.1177\n",
      "Epoch 6716/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.9112 - val_loss: 573.8459\n",
      "Epoch 6717/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.8975 - val_loss: 574.8484\n",
      "Epoch 6718/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.3587 - val_loss: 573.9378\n",
      "Epoch 6719/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.8076 - val_loss: 573.1301\n",
      "Epoch 6720/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.0152 - val_loss: 573.2813\n",
      "Epoch 6721/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.7576 - val_loss: 572.9689\n",
      "Epoch 6722/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.8861 - val_loss: 573.3850\n",
      "Epoch 6723/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 475.7139 - val_loss: 574.2782\n",
      "Epoch 6724/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.0226 - val_loss: 573.1572\n",
      "Epoch 6725/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.0479 - val_loss: 573.1146\n",
      "Epoch 6726/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.1356 - val_loss: 574.5496\n",
      "Epoch 6727/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.3355 - val_loss: 573.5042\n",
      "Epoch 6728/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.6323 - val_loss: 573.2704\n",
      "Epoch 6729/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.6672 - val_loss: 573.4723\n",
      "Epoch 6730/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.2755 - val_loss: 573.5095\n",
      "Epoch 6731/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.8473 - val_loss: 574.0184\n",
      "Epoch 6732/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.6302 - val_loss: 572.3068\n",
      "Epoch 6733/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.7549 - val_loss: 573.2955\n",
      "Epoch 6734/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.7818 - val_loss: 572.7666\n",
      "Epoch 6735/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.8485 - val_loss: 572.4915\n",
      "Epoch 6736/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.7608 - val_loss: 572.6788\n",
      "Epoch 6737/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.4906 - val_loss: 572.9646\n",
      "Epoch 6738/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.5434 - val_loss: 573.3568\n",
      "Epoch 6739/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.9103 - val_loss: 574.0994\n",
      "Epoch 6740/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.1491 - val_loss: 573.8601\n",
      "Epoch 6741/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.7081 - val_loss: 573.0609\n",
      "Epoch 6742/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.8819 - val_loss: 573.3572\n",
      "Epoch 6743/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.5575 - val_loss: 572.1648\n",
      "Epoch 6744/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.0929 - val_loss: 572.8285\n",
      "Epoch 6745/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.8426 - val_loss: 572.2634\n",
      "Epoch 6746/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.7422 - val_loss: 573.7871\n",
      "Epoch 6747/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.1539 - val_loss: 572.9902\n",
      "Epoch 6748/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.2373 - val_loss: 572.7918\n",
      "Epoch 6749/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.6850 - val_loss: 572.5677\n",
      "Epoch 6750/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 359.0191Epoch: 6750 - loss: 475.852383 - val_loss: 572.842196\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.8524 - val_loss: 572.8422\n",
      "Epoch 6751/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.8269 - val_loss: 573.2409\n",
      "Epoch 6752/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.8308 - val_loss: 572.7919\n",
      "Epoch 6753/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.7132 - val_loss: 572.6810\n",
      "Epoch 6754/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.4319 - val_loss: 572.3876\n",
      "Epoch 6755/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.0922 - val_loss: 572.9263\n",
      "Epoch 6756/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.4389 - val_loss: 572.8812\n",
      "Epoch 6757/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.6359 - val_loss: 572.5172\n",
      "Epoch 6758/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.5116 - val_loss: 572.4342\n",
      "Epoch 6759/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.7994 - val_loss: 573.6712\n",
      "Epoch 6760/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.1565 - val_loss: 572.3495\n",
      "Epoch 6761/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.7122 - val_loss: 572.6798\n",
      "Epoch 6762/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.5643 - val_loss: 572.1556\n",
      "Epoch 6763/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.4678 - val_loss: 571.7321\n",
      "Epoch 6764/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.6506 - val_loss: 572.1404\n",
      "Epoch 6765/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.7621 - val_loss: 571.6245\n",
      "Epoch 6766/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.3574 - val_loss: 572.8353\n",
      "Epoch 6767/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.9054 - val_loss: 572.6760\n",
      "Epoch 6768/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.9256 - val_loss: 572.2090\n",
      "Epoch 6769/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 477.0221 - val_loss: 573.5880\n",
      "Epoch 6770/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 476.1744 - val_loss: 573.3099\n",
      "Epoch 6771/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.0413 - val_loss: 574.1255\n",
      "Epoch 6772/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.4091 - val_loss: 572.4127\n",
      "Epoch 6773/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.9225 - val_loss: 574.1028\n",
      "Epoch 6774/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.4332 - val_loss: 573.6882\n",
      "Epoch 6775/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.4265 - val_loss: 573.3515\n",
      "Epoch 6776/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.8322 - val_loss: 572.7446\n",
      "Epoch 6777/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.6312 - val_loss: 573.1002\n",
      "Epoch 6778/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.5987 - val_loss: 572.3049\n",
      "Epoch 6779/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.4813 - val_loss: 573.1821\n",
      "Epoch 6780/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.0095 - val_loss: 573.3321\n",
      "Epoch 6781/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.5304 - val_loss: 573.1998\n",
      "Epoch 6782/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.6149 - val_loss: 572.6088\n",
      "Epoch 6783/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.6070 - val_loss: 573.4620\n",
      "Epoch 6784/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.8822 - val_loss: 572.5524\n",
      "Epoch 6785/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.5801 - val_loss: 572.5713\n",
      "Epoch 6786/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.3240 - val_loss: 572.2886\n",
      "Epoch 6787/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.5903 - val_loss: 573.0329\n",
      "Epoch 6788/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.6831 - val_loss: 572.4832\n",
      "Epoch 6789/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.1372 - val_loss: 573.5276\n",
      "Epoch 6790/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.3118 - val_loss: 573.4961\n",
      "Epoch 6791/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.7023 - val_loss: 572.2092\n",
      "Epoch 6792/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.4678 - val_loss: 572.7334\n",
      "Epoch 6793/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.4825 - val_loss: 572.5867\n",
      "Epoch 6794/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.7271 - val_loss: 573.0070\n",
      "Epoch 6795/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.5629 - val_loss: 572.5788\n",
      "Epoch 6796/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.8595 - val_loss: 572.2610\n",
      "Epoch 6797/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.6101 - val_loss: 572.3878\n",
      "Epoch 6798/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.5374 - val_loss: 572.1865\n",
      "Epoch 6799/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.8110 - val_loss: 572.9778\n",
      "Epoch 6800/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.6625 - val_loss: 572.9192\n",
      "Epoch 6801/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.6535 - val_loss: 572.7297\n",
      "Epoch 6802/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.5404 - val_loss: 573.1377\n",
      "Epoch 6803/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.2882 - val_loss: 572.4439\n",
      "Epoch 6804/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.4027 - val_loss: 571.9460\n",
      "Epoch 6805/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.6992 - val_loss: 573.7534\n",
      "Epoch 6806/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 475.4565 - val_loss: 572.2162\n",
      "Epoch 6807/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.1677 - val_loss: 572.0656\n",
      "Epoch 6808/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.7832 - val_loss: 573.2987\n",
      "Epoch 6809/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.5156 - val_loss: 572.4129\n",
      "Epoch 6810/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.0998 - val_loss: 573.1664\n",
      "Epoch 6811/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.7023 - val_loss: 571.3069\n",
      "Epoch 6812/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.5240 - val_loss: 572.4073\n",
      "Epoch 6813/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.7830 - val_loss: 572.9134\n",
      "Epoch 6814/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.1158 - val_loss: 572.8810\n",
      "Epoch 6815/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.3721 - val_loss: 573.0896\n",
      "Epoch 6816/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.2122 - val_loss: 571.7570\n",
      "Epoch 6817/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.5519 - val_loss: 573.2838\n",
      "Epoch 6818/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.5779 - val_loss: 571.9450\n",
      "Epoch 6819/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.4405 - val_loss: 572.0628\n",
      "Epoch 6820/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.7646 - val_loss: 573.2410\n",
      "Epoch 6821/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.0261 - val_loss: 573.0560\n",
      "Epoch 6822/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.9993 - val_loss: 572.3591\n",
      "Epoch 6823/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.6324 - val_loss: 571.5051\n",
      "Epoch 6824/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.3512 - val_loss: 572.9083\n",
      "Epoch 6825/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.6251 - val_loss: 573.1018\n",
      "Epoch 6826/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.6093 - val_loss: 573.2730\n",
      "Epoch 6827/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.6756 - val_loss: 573.4113\n",
      "Epoch 6828/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.9447 - val_loss: 572.3690\n",
      "Epoch 6829/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.3803 - val_loss: 574.2826\n",
      "Epoch 6830/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.4163 - val_loss: 573.8962\n",
      "Epoch 6831/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.9408 - val_loss: 572.4769\n",
      "Epoch 6832/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.9068 - val_loss: 573.0350\n",
      "Epoch 6833/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.5068 - val_loss: 572.7903\n",
      "Epoch 6834/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.8042 - val_loss: 572.2508\n",
      "Epoch 6835/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.7386 - val_loss: 573.0310\n",
      "Epoch 6836/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.5214 - val_loss: 574.8502\n",
      "Epoch 6837/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.4705 - val_loss: 573.4321\n",
      "Epoch 6838/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.2468 - val_loss: 572.2323\n",
      "Epoch 6839/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.3853 - val_loss: 573.7851\n",
      "Epoch 6840/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.6351 - val_loss: 571.5273\n",
      "Epoch 6841/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.8963 - val_loss: 573.4142\n",
      "Epoch 6842/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.7805 - val_loss: 572.1541\n",
      "Epoch 6843/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.2286 - val_loss: 572.4709\n",
      "Epoch 6844/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.5458 - val_loss: 572.5582\n",
      "Epoch 6845/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.5630 - val_loss: 571.9109\n",
      "Epoch 6846/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.1332 - val_loss: 572.4763\n",
      "Epoch 6847/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.4460 - val_loss: 571.7970\n",
      "Epoch 6848/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.0760 - val_loss: 572.7005\n",
      "Epoch 6849/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.6047 - val_loss: 572.4665\n",
      "Epoch 6850/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.3991 - val_loss: 572.9331\n",
      "Epoch 6851/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.2568 - val_loss: 572.1679\n",
      "Epoch 6852/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.7206 - val_loss: 572.0482\n",
      "Epoch 6853/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.3770 - val_loss: 572.3643\n",
      "Epoch 6854/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.9283 - val_loss: 571.2640\n",
      "Epoch 6855/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.2379 - val_loss: 571.6396\n",
      "Epoch 6856/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.6976 - val_loss: 572.3578\n",
      "Epoch 6857/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.0589 - val_loss: 572.7512\n",
      "Epoch 6858/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.3481 - val_loss: 573.5527\n",
      "Epoch 6859/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.0758 - val_loss: 573.7065\n",
      "Epoch 6860/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.3317 - val_loss: 572.6119\n",
      "Epoch 6861/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.9380 - val_loss: 572.7883\n",
      "Epoch 6862/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.9735 - val_loss: 572.6168\n",
      "Epoch 6863/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.1807 - val_loss: 572.7713\n",
      "Epoch 6864/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.0921 - val_loss: 573.3923\n",
      "Epoch 6865/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.2388 - val_loss: 571.6684\n",
      "Epoch 6866/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.3694 - val_loss: 572.4257\n",
      "Epoch 6867/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.1136 - val_loss: 572.3120\n",
      "Epoch 6868/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.9425 - val_loss: 573.3470\n",
      "Epoch 6869/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.5361 - val_loss: 572.5586\n",
      "Epoch 6870/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.2694 - val_loss: 571.9528\n",
      "Epoch 6871/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.3667 - val_loss: 572.7978\n",
      "Epoch 6872/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.9973 - val_loss: 572.1001\n",
      "Epoch 6873/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 475.7181 - val_loss: 573.7178\n",
      "Epoch 6874/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.5908 - val_loss: 572.3556\n",
      "Epoch 6875/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.9284 - val_loss: 572.3743\n",
      "Epoch 6876/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.3621 - val_loss: 572.7842\n",
      "Epoch 6877/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.2661 - val_loss: 571.5146\n",
      "Epoch 6878/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.9718 - val_loss: 572.6421\n",
      "Epoch 6879/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.0264 - val_loss: 571.8059\n",
      "Epoch 6880/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.3762 - val_loss: 571.5447\n",
      "Epoch 6881/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.7977 - val_loss: 572.6528\n",
      "Epoch 6882/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.8783 - val_loss: 572.3081\n",
      "Epoch 6883/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.1967 - val_loss: 572.2237\n",
      "Epoch 6884/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.2380 - val_loss: 571.4385\n",
      "Epoch 6885/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.8002 - val_loss: 571.8400\n",
      "Epoch 6886/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.0608 - val_loss: 572.8631\n",
      "Epoch 6887/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.9782 - val_loss: 573.1264\n",
      "Epoch 6888/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.5952 - val_loss: 573.0564\n",
      "Epoch 6889/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.3167 - val_loss: 573.2477\n",
      "Epoch 6890/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.1805 - val_loss: 572.3890\n",
      "Epoch 6891/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.5671 - val_loss: 572.0999\n",
      "Epoch 6892/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.0619 - val_loss: 572.0465\n",
      "Epoch 6893/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.4866 - val_loss: 571.4086\n",
      "Epoch 6894/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.0918 - val_loss: 572.5850\n",
      "Epoch 6895/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.5136 - val_loss: 572.7216\n",
      "Epoch 6896/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.6920 - val_loss: 572.0388\n",
      "Epoch 6897/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.9238 - val_loss: 571.8130\n",
      "Epoch 6898/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.9145 - val_loss: 571.9461\n",
      "Epoch 6899/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.8805 - val_loss: 572.6575\n",
      "Epoch 6900/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.8461 - val_loss: 572.6003\n",
      "Epoch 6901/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.1482 - val_loss: 571.8353\n",
      "Epoch 6902/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.3924 - val_loss: 572.4520\n",
      "Epoch 6903/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.2783 - val_loss: 572.3193\n",
      "Epoch 6904/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.5256 - val_loss: 571.8299\n",
      "Epoch 6905/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.6531 - val_loss: 570.9496\n",
      "Epoch 6906/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.9139 - val_loss: 572.8492\n",
      "Epoch 6907/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.6521 - val_loss: 572.8613\n",
      "Epoch 6908/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.7049 - val_loss: 571.9798\n",
      "Epoch 6909/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.8747 - val_loss: 572.5935\n",
      "Epoch 6910/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.7870 - val_loss: 571.8651\n",
      "Epoch 6911/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.9266 - val_loss: 572.0514\n",
      "Epoch 6912/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.7774 - val_loss: 571.6597\n",
      "Epoch 6913/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 475.1409 - val_loss: 571.8766\n",
      "Epoch 6914/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.1384 - val_loss: 573.2718\n",
      "Epoch 6915/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.9068 - val_loss: 571.9592\n",
      "Epoch 6916/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.1300 - val_loss: 571.7323\n",
      "Epoch 6917/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.8349 - val_loss: 572.1420\n",
      "Epoch 6918/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.1118 - val_loss: 572.3962\n",
      "Epoch 6919/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.8051 - val_loss: 571.5858\n",
      "Epoch 6920/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.8327 - val_loss: 572.2642\n",
      "Epoch 6921/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.9870 - val_loss: 571.1475\n",
      "Epoch 6922/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.9110 - val_loss: 571.9415\n",
      "Epoch 6923/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.7965 - val_loss: 571.9738\n",
      "Epoch 6924/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.3469 - val_loss: 572.6635\n",
      "Epoch 6925/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.7674 - val_loss: 571.8151\n",
      "Epoch 6926/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.0440 - val_loss: 571.4666\n",
      "Epoch 6927/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.9369 - val_loss: 572.2402\n",
      "Epoch 6928/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.9038 - val_loss: 571.8976\n",
      "Epoch 6929/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.0053 - val_loss: 572.1422\n",
      "Epoch 6930/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.9977 - val_loss: 571.8537\n",
      "Epoch 6931/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.0404 - val_loss: 573.5868\n",
      "Epoch 6932/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.8767 - val_loss: 570.8184\n",
      "Epoch 6933/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.1458 - val_loss: 573.3922\n",
      "Epoch 6934/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 474.7240 - val_loss: 573.6292\n",
      "Epoch 6935/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.6910 - val_loss: 572.1942\n",
      "Epoch 6936/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.7786 - val_loss: 572.6262\n",
      "Epoch 6937/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.2164 - val_loss: 572.3995\n",
      "Epoch 6938/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.6305 - val_loss: 572.2546\n",
      "Epoch 6939/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.1130 - val_loss: 572.1699\n",
      "Epoch 6940/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.3162 - val_loss: 572.8071\n",
      "Epoch 6941/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.3853 - val_loss: 572.7536\n",
      "Epoch 6942/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.7918 - val_loss: 572.3821\n",
      "Epoch 6943/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.3223 - val_loss: 572.2110\n",
      "Epoch 6944/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.6248 - val_loss: 572.8800\n",
      "Epoch 6945/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.2555 - val_loss: 572.8373\n",
      "Epoch 6946/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.6440 - val_loss: 571.7995\n",
      "Epoch 6947/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.7304 - val_loss: 571.7907\n",
      "Epoch 6948/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.0193 - val_loss: 572.2702\n",
      "Epoch 6949/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 474.9338 - val_loss: 571.9930\n",
      "Epoch 6950/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.9848 - val_loss: 571.6229\n",
      "Epoch 6951/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.8065 - val_loss: 571.4813\n",
      "Epoch 6952/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.2366 - val_loss: 572.2444\n",
      "Epoch 6953/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.8567 - val_loss: 571.7778\n",
      "Epoch 6954/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.1475 - val_loss: 572.7853\n",
      "Epoch 6955/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.3995 - val_loss: 572.0224\n",
      "Epoch 6956/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.7639 - val_loss: 571.8597\n",
      "Epoch 6957/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.5951 - val_loss: 572.1216\n",
      "Epoch 6958/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.0199 - val_loss: 572.2221\n",
      "Epoch 6959/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.5158 - val_loss: 571.9705\n",
      "Epoch 6960/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.8544 - val_loss: 572.0321\n",
      "Epoch 6961/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.5537 - val_loss: 572.4311\n",
      "Epoch 6962/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.4618 - val_loss: 572.4493\n",
      "Epoch 6963/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.2548 - val_loss: 572.3366\n",
      "Epoch 6964/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.2848 - val_loss: 572.8695\n",
      "Epoch 6965/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.3061 - val_loss: 570.9620\n",
      "Epoch 6966/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.7385 - val_loss: 571.9784\n",
      "Epoch 6967/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.5973 - val_loss: 572.4119\n",
      "Epoch 6968/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.8408 - val_loss: 571.8079\n",
      "Epoch 6969/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.6143 - val_loss: 572.1673\n",
      "Epoch 6970/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.6886 - val_loss: 571.1088\n",
      "Epoch 6971/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.3740 - val_loss: 571.1568\n",
      "Epoch 6972/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.8634 - val_loss: 571.2290\n",
      "Epoch 6973/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.6550 - val_loss: 571.6028\n",
      "Epoch 6974/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.4906 - val_loss: 570.7310\n",
      "Epoch 6975/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.6620 - val_loss: 571.3076\n",
      "Epoch 6976/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.8671 - val_loss: 571.3245\n",
      "Epoch 6977/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.8875 - val_loss: 572.1658\n",
      "Epoch 6978/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.4759 - val_loss: 571.2571\n",
      "Epoch 6979/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.8124 - val_loss: 571.6164\n",
      "Epoch 6980/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.9583 - val_loss: 571.8093\n",
      "Epoch 6981/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.0412 - val_loss: 571.9443\n",
      "Epoch 6982/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.7014 - val_loss: 571.1320\n",
      "Epoch 6983/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.1921 - val_loss: 571.3808\n",
      "Epoch 6984/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.6241 - val_loss: 571.1433\n",
      "Epoch 6985/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.0179 - val_loss: 570.5823\n",
      "Epoch 6986/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.3801 - val_loss: 570.7891\n",
      "Epoch 6987/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.6467 - val_loss: 571.1217\n",
      "Epoch 6988/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.3194 - val_loss: 571.8752\n",
      "Epoch 6989/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.6102 - val_loss: 571.9746\n",
      "Epoch 6990/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.4498 - val_loss: 571.6272\n",
      "Epoch 6991/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.0065 - val_loss: 570.4188\n",
      "Epoch 6992/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.7226 - val_loss: 571.3217\n",
      "Epoch 6993/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.6874 - val_loss: 572.1041\n",
      "Epoch 6994/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.8567 - val_loss: 570.9773\n",
      "Epoch 6995/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.5481 - val_loss: 571.2151\n",
      "Epoch 6996/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.7785 - val_loss: 572.4037\n",
      "Epoch 6997/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.3564 - val_loss: 571.0496\n",
      "Epoch 6998/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.5587 - val_loss: 571.3870\n",
      "Epoch 6999/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.5176 - val_loss: 571.8789\n",
      "Epoch 7000/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 494.5695Epoch: 7000 - loss: 475.695153 - val_loss: 571.335755\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.6952 - val_loss: 571.3358\n",
      "Epoch 7001/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.2300 - val_loss: 571.9540\n",
      "Epoch 7002/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.9404 - val_loss: 571.9218\n",
      "Epoch 7003/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.6681 - val_loss: 572.3543\n",
      "Epoch 7004/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.9815 - val_loss: 571.4547\n",
      "Epoch 7005/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.8427 - val_loss: 570.5857\n",
      "Epoch 7006/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.5411 - val_loss: 571.1661\n",
      "Epoch 7007/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.4571 - val_loss: 571.4485\n",
      "Epoch 7008/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.2445 - val_loss: 571.7490\n",
      "Epoch 7009/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.5603 - val_loss: 572.0778\n",
      "Epoch 7010/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.0069 - val_loss: 572.8301\n",
      "Epoch 7011/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.1521 - val_loss: 571.9686\n",
      "Epoch 7012/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.7699 - val_loss: 571.3669\n",
      "Epoch 7013/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.1248 - val_loss: 571.8963\n",
      "Epoch 7014/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.8678 - val_loss: 571.8957\n",
      "Epoch 7015/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.4033 - val_loss: 571.5945\n",
      "Epoch 7016/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.5108 - val_loss: 571.5560\n",
      "Epoch 7017/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.6212 - val_loss: 571.5481\n",
      "Epoch 7018/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.7001 - val_loss: 572.7597\n",
      "Epoch 7019/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.3011 - val_loss: 572.4162\n",
      "Epoch 7020/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.5461 - val_loss: 571.7698\n",
      "Epoch 7021/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.4848 - val_loss: 571.7841\n",
      "Epoch 7022/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.0442 - val_loss: 571.6845\n",
      "Epoch 7023/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.2559 - val_loss: 572.9767\n",
      "Epoch 7024/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.7339 - val_loss: 571.5186\n",
      "Epoch 7025/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.3112 - val_loss: 571.4491\n",
      "Epoch 7026/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.3343 - val_loss: 572.3258\n",
      "Epoch 7027/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.9946 - val_loss: 572.5306\n",
      "Epoch 7028/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.2622 - val_loss: 571.5241\n",
      "Epoch 7029/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.4094 - val_loss: 571.5177\n",
      "Epoch 7030/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.2242 - val_loss: 571.7939\n",
      "Epoch 7031/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.9370 - val_loss: 571.3835\n",
      "Epoch 7032/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.7109 - val_loss: 571.8382\n",
      "Epoch 7033/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.6886 - val_loss: 571.3135\n",
      "Epoch 7034/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.2003 - val_loss: 572.2296\n",
      "Epoch 7035/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.7877 - val_loss: 571.9510\n",
      "Epoch 7036/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.6947 - val_loss: 571.1351\n",
      "Epoch 7037/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.7254 - val_loss: 572.6574\n",
      "Epoch 7038/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.4822 - val_loss: 572.1260\n",
      "Epoch 7039/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.7222 - val_loss: 571.0954\n",
      "Epoch 7040/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.6052 - val_loss: 572.0101\n",
      "Epoch 7041/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.4929 - val_loss: 571.8883\n",
      "Epoch 7042/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.2992 - val_loss: 571.6984\n",
      "Epoch 7043/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.9844 - val_loss: 572.0260\n",
      "Epoch 7044/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.3344 - val_loss: 571.5354\n",
      "Epoch 7045/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.6059 - val_loss: 572.2595\n",
      "Epoch 7046/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.4494 - val_loss: 571.2928\n",
      "Epoch 7047/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 474.4439 - val_loss: 571.8326\n",
      "Epoch 7048/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.3198 - val_loss: 571.9346\n",
      "Epoch 7049/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.3723 - val_loss: 570.9450\n",
      "Epoch 7050/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.4864 - val_loss: 570.2337\n",
      "Epoch 7051/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.6025 - val_loss: 571.2023\n",
      "Epoch 7052/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.1650 - val_loss: 571.6341\n",
      "Epoch 7053/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.8672 - val_loss: 571.3213\n",
      "Epoch 7054/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.2268 - val_loss: 570.7300\n",
      "Epoch 7055/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.5542 - val_loss: 571.9688\n",
      "Epoch 7056/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.0412 - val_loss: 572.0254\n",
      "Epoch 7057/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.2599 - val_loss: 571.3854\n",
      "Epoch 7058/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.3964 - val_loss: 571.1092\n",
      "Epoch 7059/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.0431 - val_loss: 570.6662\n",
      "Epoch 7060/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.0335 - val_loss: 570.9704\n",
      "Epoch 7061/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.5098 - val_loss: 572.0809\n",
      "Epoch 7062/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.7484 - val_loss: 571.9104\n",
      "Epoch 7063/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.1916 - val_loss: 571.5621\n",
      "Epoch 7064/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.1562 - val_loss: 571.0077\n",
      "Epoch 7065/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.9608 - val_loss: 572.1444\n",
      "Epoch 7066/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.9286 - val_loss: 571.5196\n",
      "Epoch 7067/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.7380 - val_loss: 571.9975\n",
      "Epoch 7068/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.2188 - val_loss: 571.4123\n",
      "Epoch 7069/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.1839 - val_loss: 571.5990\n",
      "Epoch 7070/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.4672 - val_loss: 572.3590\n",
      "Epoch 7071/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.5038 - val_loss: 570.9562\n",
      "Epoch 7072/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.9062 - val_loss: 571.3194\n",
      "Epoch 7073/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.1535 - val_loss: 571.7101\n",
      "Epoch 7074/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.1869 - val_loss: 571.9598\n",
      "Epoch 7075/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.0209 - val_loss: 571.9535\n",
      "Epoch 7076/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.3523 - val_loss: 571.8000\n",
      "Epoch 7077/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.5441 - val_loss: 571.9530\n",
      "Epoch 7078/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.6826 - val_loss: 570.9335\n",
      "Epoch 7079/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.0734 - val_loss: 571.2044\n",
      "Epoch 7080/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.1717 - val_loss: 570.9117\n",
      "Epoch 7081/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.0674 - val_loss: 571.4950\n",
      "Epoch 7082/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.0340 - val_loss: 571.3573\n",
      "Epoch 7083/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.0315 - val_loss: 571.0977\n",
      "Epoch 7084/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.3494 - val_loss: 571.5908\n",
      "Epoch 7085/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.6705 - val_loss: 571.9750\n",
      "Epoch 7086/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.1481 - val_loss: 570.7846\n",
      "Epoch 7087/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.9767 - val_loss: 571.3659\n",
      "Epoch 7088/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.2322 - val_loss: 571.9221\n",
      "Epoch 7089/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.1731 - val_loss: 571.5037\n",
      "Epoch 7090/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.4871 - val_loss: 572.1238\n",
      "Epoch 7091/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.1210 - val_loss: 571.2356\n",
      "Epoch 7092/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.7739 - val_loss: 571.9438\n",
      "Epoch 7093/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.3622 - val_loss: 571.5315\n",
      "Epoch 7094/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 474.1929 - val_loss: 572.6927\n",
      "Epoch 7095/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.3940 - val_loss: 571.9129\n",
      "Epoch 7096/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.2042 - val_loss: 571.9174\n",
      "Epoch 7097/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.8834 - val_loss: 571.8419\n",
      "Epoch 7098/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.9444 - val_loss: 572.1040\n",
      "Epoch 7099/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.0624 - val_loss: 571.4762\n",
      "Epoch 7100/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 474.4157 - val_loss: 571.1251\n",
      "Epoch 7101/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.7084 - val_loss: 571.5414\n",
      "Epoch 7102/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.4222 - val_loss: 570.4434\n",
      "Epoch 7103/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.9872 - val_loss: 571.6853\n",
      "Epoch 7104/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.4117 - val_loss: 571.5949\n",
      "Epoch 7105/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.3728 - val_loss: 572.7630\n",
      "Epoch 7106/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.3552 - val_loss: 570.9331\n",
      "Epoch 7107/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.0177 - val_loss: 571.7521\n",
      "Epoch 7108/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.2917 - val_loss: 570.9722\n",
      "Epoch 7109/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.7789 - val_loss: 571.0831\n",
      "Epoch 7110/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.2127 - val_loss: 572.1756\n",
      "Epoch 7111/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.3790 - val_loss: 572.0001\n",
      "Epoch 7112/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.6500 - val_loss: 571.6564\n",
      "Epoch 7113/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.9634 - val_loss: 571.5415\n",
      "Epoch 7114/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.8775 - val_loss: 571.5576\n",
      "Epoch 7115/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.6534 - val_loss: 570.8892\n",
      "Epoch 7116/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.8978 - val_loss: 571.4424\n",
      "Epoch 7117/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.2462 - val_loss: 571.3264\n",
      "Epoch 7118/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 474.2805 - val_loss: 572.0166\n",
      "Epoch 7119/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.4341 - val_loss: 571.7125\n",
      "Epoch 7120/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.1800 - val_loss: 571.9034\n",
      "Epoch 7121/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.2666 - val_loss: 570.8384\n",
      "Epoch 7122/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.4971 - val_loss: 570.5970\n",
      "Epoch 7123/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.5200 - val_loss: 572.0027\n",
      "Epoch 7124/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.3862 - val_loss: 570.6881\n",
      "Epoch 7125/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.9360 - val_loss: 571.8450\n",
      "Epoch 7126/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.6887 - val_loss: 570.1958\n",
      "Epoch 7127/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.9110 - val_loss: 572.7414\n",
      "Epoch 7128/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.3550 - val_loss: 571.5518\n",
      "Epoch 7129/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.4925 - val_loss: 571.7020\n",
      "Epoch 7130/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.7999 - val_loss: 571.5206\n",
      "Epoch 7131/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.0853 - val_loss: 571.0784\n",
      "Epoch 7132/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.0360 - val_loss: 571.3387\n",
      "Epoch 7133/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.3403 - val_loss: 571.2052\n",
      "Epoch 7134/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.7788 - val_loss: 571.1991\n",
      "Epoch 7135/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.7210 - val_loss: 571.1645\n",
      "Epoch 7136/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.9978 - val_loss: 570.7343\n",
      "Epoch 7137/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.1050 - val_loss: 570.9450\n",
      "Epoch 7138/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.7629 - val_loss: 571.3724\n",
      "Epoch 7139/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.0508 - val_loss: 571.2582\n",
      "Epoch 7140/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.9298 - val_loss: 570.6466\n",
      "Epoch 7141/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.0945 - val_loss: 570.7830\n",
      "Epoch 7142/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.5627 - val_loss: 570.7312\n",
      "Epoch 7143/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.1136 - val_loss: 570.1269\n",
      "Epoch 7144/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.0376 - val_loss: 570.0843\n",
      "Epoch 7145/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.7922 - val_loss: 570.8680\n",
      "Epoch 7146/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.0507 - val_loss: 571.6709\n",
      "Epoch 7147/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 474.1119 - val_loss: 570.5474\n",
      "Epoch 7148/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.8852 - val_loss: 570.8964\n",
      "Epoch 7149/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.0408 - val_loss: 571.6370\n",
      "Epoch 7150/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.8198 - val_loss: 571.0093\n",
      "Epoch 7151/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.7341 - val_loss: 571.8671\n",
      "Epoch 7152/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.8781 - val_loss: 571.2804\n",
      "Epoch 7153/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.9907 - val_loss: 571.7064\n",
      "Epoch 7154/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.6246 - val_loss: 570.5965\n",
      "Epoch 7155/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.8618 - val_loss: 570.8255\n",
      "Epoch 7156/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.9971 - val_loss: 571.6411\n",
      "Epoch 7157/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.5265 - val_loss: 571.4991\n",
      "Epoch 7158/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.1988 - val_loss: 571.1884\n",
      "Epoch 7159/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.8374 - val_loss: 570.6763\n",
      "Epoch 7160/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.7570 - val_loss: 571.4235\n",
      "Epoch 7161/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.0006 - val_loss: 570.9738\n",
      "Epoch 7162/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.6814 - val_loss: 570.3558\n",
      "Epoch 7163/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.2522 - val_loss: 570.9621\n",
      "Epoch 7164/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 476.1262 - val_loss: 571.1074\n",
      "Epoch 7165/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.0752 - val_loss: 571.1664\n",
      "Epoch 7166/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.0596 - val_loss: 571.2180\n",
      "Epoch 7167/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.0217 - val_loss: 570.8200\n",
      "Epoch 7168/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.9118 - val_loss: 572.1352\n",
      "Epoch 7169/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.1859 - val_loss: 571.8093\n",
      "Epoch 7170/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.8146 - val_loss: 571.5052\n",
      "Epoch 7171/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.4879 - val_loss: 570.7910\n",
      "Epoch 7172/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 475.2938 - val_loss: 570.7489\n",
      "Epoch 7173/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.6515 - val_loss: 570.7911\n",
      "Epoch 7174/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.2953 - val_loss: 570.7582\n",
      "Epoch 7175/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.7264 - val_loss: 570.8395\n",
      "Epoch 7176/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.8325 - val_loss: 570.1544\n",
      "Epoch 7177/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.8292 - val_loss: 570.7203\n",
      "Epoch 7178/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.7358 - val_loss: 571.5220\n",
      "Epoch 7179/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.0275 - val_loss: 570.8298\n",
      "Epoch 7180/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.8638 - val_loss: 570.7773\n",
      "Epoch 7181/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.8540 - val_loss: 570.2404\n",
      "Epoch 7182/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 473.9925 - val_loss: 570.4533\n",
      "Epoch 7183/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.5585 - val_loss: 570.5354\n",
      "Epoch 7184/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.7067 - val_loss: 570.8246\n",
      "Epoch 7185/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.7577 - val_loss: 570.3659\n",
      "Epoch 7186/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.1003 - val_loss: 571.0250\n",
      "Epoch 7187/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.5496 - val_loss: 570.5953\n",
      "Epoch 7188/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.1050 - val_loss: 571.2594\n",
      "Epoch 7189/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.8953 - val_loss: 570.8573\n",
      "Epoch 7190/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.8265 - val_loss: 570.2907\n",
      "Epoch 7191/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.2781 - val_loss: 572.0323\n",
      "Epoch 7192/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.2563 - val_loss: 570.2484\n",
      "Epoch 7193/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.7276 - val_loss: 569.9868\n",
      "Epoch 7194/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.0265 - val_loss: 570.2526\n",
      "Epoch 7195/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.7308 - val_loss: 570.4829\n",
      "Epoch 7196/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.7942 - val_loss: 570.6440\n",
      "Epoch 7197/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.8227 - val_loss: 571.1105\n",
      "Epoch 7198/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.3104 - val_loss: 570.2765\n",
      "Epoch 7199/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.5936 - val_loss: 569.7502\n",
      "Epoch 7200/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.5479 - val_loss: 569.9152\n",
      "Epoch 7201/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.6110 - val_loss: 569.9205\n",
      "Epoch 7202/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.5555 - val_loss: 570.1306\n",
      "Epoch 7203/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.7771 - val_loss: 569.7654\n",
      "Epoch 7204/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.5682 - val_loss: 571.2913\n",
      "Epoch 7205/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.0882 - val_loss: 570.8108\n",
      "Epoch 7206/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.8838 - val_loss: 570.2832\n",
      "Epoch 7207/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.8443 - val_loss: 570.8311\n",
      "Epoch 7208/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.4936 - val_loss: 571.0171\n",
      "Epoch 7209/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.6501 - val_loss: 570.1238\n",
      "Epoch 7210/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.8969 - val_loss: 569.6432\n",
      "Epoch 7211/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.1305 - val_loss: 571.0957\n",
      "Epoch 7212/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.8440 - val_loss: 570.6555\n",
      "Epoch 7213/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.3810 - val_loss: 570.9822\n",
      "Epoch 7214/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.8910 - val_loss: 569.0929\n",
      "Epoch 7215/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.1045 - val_loss: 570.4103\n",
      "Epoch 7216/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.7435 - val_loss: 569.5055\n",
      "Epoch 7217/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.7449 - val_loss: 570.4584\n",
      "Epoch 7218/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.5087 - val_loss: 569.8260\n",
      "Epoch 7219/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.5961 - val_loss: 569.5344\n",
      "Epoch 7220/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.9237 - val_loss: 569.6858\n",
      "Epoch 7221/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.0998 - val_loss: 570.2417\n",
      "Epoch 7222/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.9361 - val_loss: 570.2112\n",
      "Epoch 7223/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.0633 - val_loss: 569.6114\n",
      "Epoch 7224/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.2900 - val_loss: 570.5048\n",
      "Epoch 7225/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.4767 - val_loss: 570.0549\n",
      "Epoch 7226/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.4220 - val_loss: 569.7807\n",
      "Epoch 7227/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.5222 - val_loss: 571.0110\n",
      "Epoch 7228/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.5324 - val_loss: 571.0630\n",
      "Epoch 7229/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.0611 - val_loss: 571.4251\n",
      "Epoch 7230/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.9664 - val_loss: 570.7999\n",
      "Epoch 7231/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.8713 - val_loss: 570.5574\n",
      "Epoch 7232/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.5494 - val_loss: 570.2018\n",
      "Epoch 7233/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.4727 - val_loss: 570.0842\n",
      "Epoch 7234/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.8502 - val_loss: 570.1383\n",
      "Epoch 7235/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.6598 - val_loss: 569.7648\n",
      "Epoch 7236/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.4883 - val_loss: 570.9039\n",
      "Epoch 7237/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.6217 - val_loss: 569.6802\n",
      "Epoch 7238/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.7607 - val_loss: 570.3996\n",
      "Epoch 7239/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.6167 - val_loss: 569.8412\n",
      "Epoch 7240/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.4849 - val_loss: 569.9548\n",
      "Epoch 7241/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.8746 - val_loss: 570.5899\n",
      "Epoch 7242/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.1819 - val_loss: 570.3369\n",
      "Epoch 7243/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.1850 - val_loss: 569.7153\n",
      "Epoch 7244/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 474.5699 - val_loss: 569.9692\n",
      "Epoch 7245/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.2192 - val_loss: 571.2374\n",
      "Epoch 7246/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.8330 - val_loss: 571.4556\n",
      "Epoch 7247/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.8316 - val_loss: 570.5986\n",
      "Epoch 7248/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.4449 - val_loss: 571.5836\n",
      "Epoch 7249/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.6098 - val_loss: 570.3167\n",
      "Epoch 7250/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 353.3233Epoch: 7250 - loss: 473.629477 - val_loss: 569.917308\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.6295 - val_loss: 569.9173\n",
      "Epoch 7251/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.7878 - val_loss: 571.1281\n",
      "Epoch 7252/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.9352 - val_loss: 570.2369\n",
      "Epoch 7253/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.1397 - val_loss: 570.9029\n",
      "Epoch 7254/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.4723 - val_loss: 570.1772\n",
      "Epoch 7255/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.4615 - val_loss: 569.8566\n",
      "Epoch 7256/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.7163 - val_loss: 571.9386\n",
      "Epoch 7257/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.8410 - val_loss: 571.5526\n",
      "Epoch 7258/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.5747 - val_loss: 570.6655\n",
      "Epoch 7259/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.5739 - val_loss: 569.2896\n",
      "Epoch 7260/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.3162 - val_loss: 569.8152\n",
      "Epoch 7261/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.7537 - val_loss: 569.8236\n",
      "Epoch 7262/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.1059 - val_loss: 569.3224\n",
      "Epoch 7263/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.2591 - val_loss: 570.5803\n",
      "Epoch 7264/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.6487 - val_loss: 570.0325\n",
      "Epoch 7265/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.5702 - val_loss: 570.5237\n",
      "Epoch 7266/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.7657 - val_loss: 570.8211\n",
      "Epoch 7267/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.5227 - val_loss: 570.6507\n",
      "Epoch 7268/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.5815 - val_loss: 570.6545\n",
      "Epoch 7269/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.9643 - val_loss: 570.9767\n",
      "Epoch 7270/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 473.8556 - val_loss: 569.9499\n",
      "Epoch 7271/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.2625 - val_loss: 571.1014\n",
      "Epoch 7272/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.0752 - val_loss: 570.1721\n",
      "Epoch 7273/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.3845 - val_loss: 569.6879\n",
      "Epoch 7274/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.5946 - val_loss: 570.0141\n",
      "Epoch 7275/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.0233 - val_loss: 571.4107\n",
      "Epoch 7276/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.4114 - val_loss: 569.6221\n",
      "Epoch 7277/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.2986 - val_loss: 570.0965\n",
      "Epoch 7278/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.2571 - val_loss: 570.0446\n",
      "Epoch 7279/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.2994 - val_loss: 570.4598\n",
      "Epoch 7280/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.6489 - val_loss: 570.3206\n",
      "Epoch 7281/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.1903 - val_loss: 570.1350\n",
      "Epoch 7282/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.3511 - val_loss: 569.9888\n",
      "Epoch 7283/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.2707 - val_loss: 570.1299\n",
      "Epoch 7284/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.3148 - val_loss: 570.3086\n",
      "Epoch 7285/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.9498 - val_loss: 570.3074\n",
      "Epoch 7286/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.4804 - val_loss: 570.5720\n",
      "Epoch 7287/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.2971 - val_loss: 571.5810\n",
      "Epoch 7288/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.6425 - val_loss: 570.8959\n",
      "Epoch 7289/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.8254 - val_loss: 570.3424\n",
      "Epoch 7290/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.6467 - val_loss: 570.8136\n",
      "Epoch 7291/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.0814 - val_loss: 570.9940\n",
      "Epoch 7292/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.4954 - val_loss: 571.2501\n",
      "Epoch 7293/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.4939 - val_loss: 570.4776\n",
      "Epoch 7294/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.8841 - val_loss: 570.6780\n",
      "Epoch 7295/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.7257 - val_loss: 570.5596\n",
      "Epoch 7296/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.2442 - val_loss: 570.7101\n",
      "Epoch 7297/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.5254 - val_loss: 570.6127\n",
      "Epoch 7298/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.3881 - val_loss: 570.5552\n",
      "Epoch 7299/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.5229 - val_loss: 570.7367\n",
      "Epoch 7300/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 473.1653 - val_loss: 569.8228\n",
      "Epoch 7301/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.1469 - val_loss: 570.5623\n",
      "Epoch 7302/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.2456 - val_loss: 570.1042\n",
      "Epoch 7303/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.7909 - val_loss: 570.0167\n",
      "Epoch 7304/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.9075 - val_loss: 570.0041\n",
      "Epoch 7305/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 473.3520 - val_loss: 571.6504\n",
      "Epoch 7306/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.4790 - val_loss: 570.8944\n",
      "Epoch 7307/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.1697 - val_loss: 570.8314\n",
      "Epoch 7308/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.6317 - val_loss: 570.7902\n",
      "Epoch 7309/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.1992 - val_loss: 570.5361\n",
      "Epoch 7310/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.2720 - val_loss: 569.9867\n",
      "Epoch 7311/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.4520 - val_loss: 570.5861\n",
      "Epoch 7312/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 473.4480 - val_loss: 571.2511\n",
      "Epoch 7313/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.6745 - val_loss: 570.7447\n",
      "Epoch 7314/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.2122 - val_loss: 570.0873\n",
      "Epoch 7315/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 473.1788 - val_loss: 570.4060\n",
      "Epoch 7316/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 473.2501 - val_loss: 570.5874\n",
      "Epoch 7317/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 474.2430 - val_loss: 569.9938\n",
      "Epoch 7318/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 473.6826 - val_loss: 569.6441\n",
      "Epoch 7319/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 474.1905 - val_loss: 571.1746\n",
      "Epoch 7320/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 475.1846 - val_loss: 569.6568\n",
      "Epoch 7321/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 473.0872 - val_loss: 570.2628\n",
      "Epoch 7322/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.8729 - val_loss: 570.5226\n",
      "Epoch 7323/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.3242 - val_loss: 570.3198\n",
      "Epoch 7324/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 473.2606 - val_loss: 570.1803\n",
      "Epoch 7325/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 473.5109 - val_loss: 570.3057\n",
      "Epoch 7326/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 473.3660 - val_loss: 569.1074\n",
      "Epoch 7327/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 473.7126 - val_loss: 571.1871\n",
      "Epoch 7328/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 473.0740 - val_loss: 570.2855\n",
      "Epoch 7329/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 473.5702 - val_loss: 569.6961\n",
      "Epoch 7330/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 472.9945 - val_loss: 569.5174\n",
      "Epoch 7331/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 473.0297 - val_loss: 570.1707\n",
      "Epoch 7332/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.4098 - val_loss: 570.7445\n",
      "Epoch 7333/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.7003 - val_loss: 569.1022\n",
      "Epoch 7334/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 474.6493 - val_loss: 570.4231\n",
      "Epoch 7335/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 473.5602 - val_loss: 569.4828\n",
      "Epoch 7336/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 473.1525 - val_loss: 569.6342\n",
      "Epoch 7337/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 473.3125 - val_loss: 570.2799\n",
      "Epoch 7338/10000\n",
      "3000/3000 [==============================] - 0s 14us/sample - loss: 473.2662 - val_loss: 570.0384\n",
      "Epoch 7339/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.0262 - val_loss: 570.2730\n",
      "Epoch 7340/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.9776 - val_loss: 570.1206\n",
      "Epoch 7341/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.5345 - val_loss: 570.8570\n",
      "Epoch 7342/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.2070 - val_loss: 570.5808\n",
      "Epoch 7343/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.6493 - val_loss: 570.4249\n",
      "Epoch 7344/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.6614 - val_loss: 570.3865\n",
      "Epoch 7345/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.9400 - val_loss: 569.5376\n",
      "Epoch 7346/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 473.0877 - val_loss: 570.2654\n",
      "Epoch 7347/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.8026 - val_loss: 571.5576\n",
      "Epoch 7348/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.7995 - val_loss: 570.3871\n",
      "Epoch 7349/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.0823 - val_loss: 570.6969\n",
      "Epoch 7350/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.5393 - val_loss: 570.2845\n",
      "Epoch 7351/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 473.4339 - val_loss: 571.4375\n",
      "Epoch 7352/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 473.1554 - val_loss: 571.1770\n",
      "Epoch 7353/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 473.5804 - val_loss: 569.7052\n",
      "Epoch 7354/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.1942 - val_loss: 569.8161\n",
      "Epoch 7355/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.2037 - val_loss: 569.8640\n",
      "Epoch 7356/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.2048 - val_loss: 569.9304\n",
      "Epoch 7357/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.0187 - val_loss: 569.5240\n",
      "Epoch 7358/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.8703 - val_loss: 570.0948\n",
      "Epoch 7359/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 473.1917 - val_loss: 570.6096\n",
      "Epoch 7360/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.4477 - val_loss: 569.8105\n",
      "Epoch 7361/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.4670 - val_loss: 569.8756\n",
      "Epoch 7362/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.4314 - val_loss: 570.5753\n",
      "Epoch 7363/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.2219 - val_loss: 570.3105\n",
      "Epoch 7364/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.7323 - val_loss: 571.4390\n",
      "Epoch 7365/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.9721 - val_loss: 570.1488\n",
      "Epoch 7366/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 473.0460 - val_loss: 571.0469\n",
      "Epoch 7367/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 473.5321 - val_loss: 571.1535\n",
      "Epoch 7368/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 473.1980 - val_loss: 570.2524\n",
      "Epoch 7369/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.9474 - val_loss: 570.3974\n",
      "Epoch 7370/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.0160 - val_loss: 569.6438\n",
      "Epoch 7371/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 473.1811 - val_loss: 569.4709\n",
      "Epoch 7372/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.0474 - val_loss: 571.3936\n",
      "Epoch 7373/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.8853 - val_loss: 570.7783\n",
      "Epoch 7374/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.9807 - val_loss: 570.3577\n",
      "Epoch 7375/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 473.3167 - val_loss: 570.9895\n",
      "Epoch 7376/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.2560 - val_loss: 570.2251\n",
      "Epoch 7377/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.6426 - val_loss: 570.3537\n",
      "Epoch 7378/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.9208 - val_loss: 570.2337\n",
      "Epoch 7379/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.1291 - val_loss: 570.7341\n",
      "Epoch 7380/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.0052 - val_loss: 570.7758\n",
      "Epoch 7381/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.2604 - val_loss: 571.0532\n",
      "Epoch 7382/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.9436 - val_loss: 570.4538\n",
      "Epoch 7383/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.7888 - val_loss: 570.0912\n",
      "Epoch 7384/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.3344 - val_loss: 570.1484\n",
      "Epoch 7385/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.9392 - val_loss: 570.3692\n",
      "Epoch 7386/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.8915 - val_loss: 570.8678\n",
      "Epoch 7387/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.9129 - val_loss: 570.1753\n",
      "Epoch 7388/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.2893 - val_loss: 570.1776\n",
      "Epoch 7389/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.0095 - val_loss: 570.0208\n",
      "Epoch 7390/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.1082 - val_loss: 570.5298\n",
      "Epoch 7391/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.9324 - val_loss: 570.9528\n",
      "Epoch 7392/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.9877 - val_loss: 571.1812\n",
      "Epoch 7393/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.1988 - val_loss: 571.2959\n",
      "Epoch 7394/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.4027 - val_loss: 570.3448\n",
      "Epoch 7395/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.1085 - val_loss: 569.7045\n",
      "Epoch 7396/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.3721 - val_loss: 569.3704\n",
      "Epoch 7397/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.8140 - val_loss: 571.5045\n",
      "Epoch 7398/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.0831 - val_loss: 570.9490\n",
      "Epoch 7399/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.0366 - val_loss: 569.8181\n",
      "Epoch 7400/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.5839 - val_loss: 570.7471\n",
      "Epoch 7401/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.2075 - val_loss: 569.7025\n",
      "Epoch 7402/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 473.1694 - val_loss: 569.8638\n",
      "Epoch 7403/10000\n",
      "3000/3000 [==============================] - 0s 18us/sample - loss: 473.0500 - val_loss: 569.4272\n",
      "Epoch 7404/10000\n",
      "3000/3000 [==============================] - 0s 15us/sample - loss: 473.1343 - val_loss: 568.8719\n",
      "Epoch 7405/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 472.6583 - val_loss: 570.0503\n",
      "Epoch 7406/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 473.0638 - val_loss: 569.6276\n",
      "Epoch 7407/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.6770 - val_loss: 570.4190\n",
      "Epoch 7408/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.0111 - val_loss: 570.4923\n",
      "Epoch 7409/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.9939 - val_loss: 570.1396\n",
      "Epoch 7410/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.9368 - val_loss: 570.3068\n",
      "Epoch 7411/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.0338 - val_loss: 569.3535\n",
      "Epoch 7412/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.0542 - val_loss: 570.2286\n",
      "Epoch 7413/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.3630 - val_loss: 569.8394\n",
      "Epoch 7414/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.0368 - val_loss: 570.3878\n",
      "Epoch 7415/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.1535 - val_loss: 569.7300\n",
      "Epoch 7416/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.0131 - val_loss: 570.2287\n",
      "Epoch 7417/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.7987 - val_loss: 570.4771\n",
      "Epoch 7418/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.5007 - val_loss: 569.6728\n",
      "Epoch 7419/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.8518 - val_loss: 569.0753\n",
      "Epoch 7420/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 472.7441 - val_loss: 569.7416\n",
      "Epoch 7421/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.5837 - val_loss: 570.6560\n",
      "Epoch 7422/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.8471 - val_loss: 569.6145\n",
      "Epoch 7423/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.8050 - val_loss: 570.3747\n",
      "Epoch 7424/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.3959 - val_loss: 569.7320\n",
      "Epoch 7425/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.7313 - val_loss: 570.0644\n",
      "Epoch 7426/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.7780 - val_loss: 569.6314\n",
      "Epoch 7427/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 473.0698 - val_loss: 569.5141\n",
      "Epoch 7428/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.9248 - val_loss: 569.6235\n",
      "Epoch 7429/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.9959 - val_loss: 570.8286\n",
      "Epoch 7430/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.8107 - val_loss: 570.1357\n",
      "Epoch 7431/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.5421 - val_loss: 569.4752\n",
      "Epoch 7432/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.8004 - val_loss: 569.4676\n",
      "Epoch 7433/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.2305 - val_loss: 569.3483\n",
      "Epoch 7434/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.5214 - val_loss: 570.1688\n",
      "Epoch 7435/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.4287 - val_loss: 569.4130\n",
      "Epoch 7436/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.9844 - val_loss: 568.6535\n",
      "Epoch 7437/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.9983 - val_loss: 570.5755\n",
      "Epoch 7438/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.9919 - val_loss: 569.9130\n",
      "Epoch 7439/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.9178 - val_loss: 568.7274\n",
      "Epoch 7440/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.1303 - val_loss: 569.7898\n",
      "Epoch 7441/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.9622 - val_loss: 569.3451\n",
      "Epoch 7442/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.6562 - val_loss: 569.6126\n",
      "Epoch 7443/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.4756 - val_loss: 569.4221\n",
      "Epoch 7444/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.8170 - val_loss: 569.5079\n",
      "Epoch 7445/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.7379 - val_loss: 569.3293\n",
      "Epoch 7446/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.6454 - val_loss: 569.7738\n",
      "Epoch 7447/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.1921 - val_loss: 570.3556\n",
      "Epoch 7448/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 472.7969 - val_loss: 569.2384\n",
      "Epoch 7449/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.6843 - val_loss: 569.3573\n",
      "Epoch 7450/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.3027 - val_loss: 569.5583\n",
      "Epoch 7451/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.5450 - val_loss: 569.2866\n",
      "Epoch 7452/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.7409 - val_loss: 570.0042\n",
      "Epoch 7453/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.7201 - val_loss: 569.4872\n",
      "Epoch 7454/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.6038 - val_loss: 569.8056\n",
      "Epoch 7455/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.8015 - val_loss: 569.2844\n",
      "Epoch 7456/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.4435 - val_loss: 568.7876\n",
      "Epoch 7457/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.0907 - val_loss: 569.3125\n",
      "Epoch 7458/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.6012 - val_loss: 568.9423\n",
      "Epoch 7459/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.1583 - val_loss: 569.8435\n",
      "Epoch 7460/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.7986 - val_loss: 569.3493\n",
      "Epoch 7461/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.8429 - val_loss: 569.3615\n",
      "Epoch 7462/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.2769 - val_loss: 568.9899\n",
      "Epoch 7463/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.7218 - val_loss: 568.9895\n",
      "Epoch 7464/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.7173 - val_loss: 569.6566\n",
      "Epoch 7465/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.2210 - val_loss: 569.9571\n",
      "Epoch 7466/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.9968 - val_loss: 569.6801\n",
      "Epoch 7467/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.5602 - val_loss: 570.6034\n",
      "Epoch 7468/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.5986 - val_loss: 570.2387\n",
      "Epoch 7469/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.0383 - val_loss: 569.9944\n",
      "Epoch 7470/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.6069 - val_loss: 569.6419\n",
      "Epoch 7471/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.5711 - val_loss: 569.9241\n",
      "Epoch 7472/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.4900 - val_loss: 570.1811\n",
      "Epoch 7473/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.5782 - val_loss: 570.2254\n",
      "Epoch 7474/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.2064 - val_loss: 570.5065\n",
      "Epoch 7475/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.5092 - val_loss: 569.4780\n",
      "Epoch 7476/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.0979 - val_loss: 570.5358\n",
      "Epoch 7477/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.5023 - val_loss: 570.7095\n",
      "Epoch 7478/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.7861 - val_loss: 570.2800\n",
      "Epoch 7479/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.1232 - val_loss: 569.0414\n",
      "Epoch 7480/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.9355 - val_loss: 570.8314\n",
      "Epoch 7481/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.0787 - val_loss: 571.0292\n",
      "Epoch 7482/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.9357 - val_loss: 569.9475\n",
      "Epoch 7483/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.1278 - val_loss: 569.9993\n",
      "Epoch 7484/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.7530 - val_loss: 570.2586\n",
      "Epoch 7485/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.2012 - val_loss: 570.7258\n",
      "Epoch 7486/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.6543 - val_loss: 571.1226\n",
      "Epoch 7487/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.7087 - val_loss: 569.3859\n",
      "Epoch 7488/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.7677 - val_loss: 570.0951\n",
      "Epoch 7489/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.7572 - val_loss: 570.6738\n",
      "Epoch 7490/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 472.6835 - val_loss: 570.5635\n",
      "Epoch 7491/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.6754 - val_loss: 569.7840\n",
      "Epoch 7492/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.9733 - val_loss: 569.1616\n",
      "Epoch 7493/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.6656 - val_loss: 569.6272\n",
      "Epoch 7494/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.6673 - val_loss: 570.3518\n",
      "Epoch 7495/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.9758 - val_loss: 569.2196\n",
      "Epoch 7496/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.0742 - val_loss: 570.1447\n",
      "Epoch 7497/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.7467 - val_loss: 569.4111\n",
      "Epoch 7498/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.4088 - val_loss: 569.3870\n",
      "Epoch 7499/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.6416 - val_loss: 570.2188\n",
      "Epoch 7500/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 358.8754Epoch: 7500 - loss: 472.988698 - val_loss: 570.142617\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.9887 - val_loss: 570.1426\n",
      "Epoch 7501/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.7994 - val_loss: 570.9035\n",
      "Epoch 7502/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.6139 - val_loss: 570.0646\n",
      "Epoch 7503/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.7202 - val_loss: 570.0852\n",
      "Epoch 7504/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.6087 - val_loss: 570.1947\n",
      "Epoch 7505/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.4425 - val_loss: 569.5075\n",
      "Epoch 7506/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.5976 - val_loss: 569.2353\n",
      "Epoch 7507/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.8814 - val_loss: 569.0022\n",
      "Epoch 7508/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.7759 - val_loss: 570.3320\n",
      "Epoch 7509/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.7608 - val_loss: 570.4178\n",
      "Epoch 7510/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.6508 - val_loss: 569.6434\n",
      "Epoch 7511/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.5366 - val_loss: 569.6546\n",
      "Epoch 7512/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.5268 - val_loss: 569.9765\n",
      "Epoch 7513/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.5734 - val_loss: 569.7615\n",
      "Epoch 7514/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.0508 - val_loss: 569.7837\n",
      "Epoch 7515/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.9481 - val_loss: 569.2409\n",
      "Epoch 7516/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.6618 - val_loss: 569.1831\n",
      "Epoch 7517/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.9680 - val_loss: 570.0613\n",
      "Epoch 7518/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.3508 - val_loss: 569.2017\n",
      "Epoch 7519/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.7062 - val_loss: 570.1367\n",
      "Epoch 7520/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.8530 - val_loss: 569.1942\n",
      "Epoch 7521/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.6290 - val_loss: 569.0950\n",
      "Epoch 7522/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.6594 - val_loss: 569.8346\n",
      "Epoch 7523/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.4977 - val_loss: 568.7446\n",
      "Epoch 7524/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.8069 - val_loss: 569.3572\n",
      "Epoch 7525/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.2953 - val_loss: 571.0760\n",
      "Epoch 7526/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.6608 - val_loss: 569.6094\n",
      "Epoch 7527/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.7381 - val_loss: 570.7310\n",
      "Epoch 7528/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.0285 - val_loss: 569.6369\n",
      "Epoch 7529/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.2508 - val_loss: 569.4766\n",
      "Epoch 7530/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.4093 - val_loss: 569.3929\n",
      "Epoch 7531/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.1610 - val_loss: 569.5485\n",
      "Epoch 7532/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.8816 - val_loss: 569.1233\n",
      "Epoch 7533/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.3301 - val_loss: 569.9818\n",
      "Epoch 7534/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.5473 - val_loss: 569.2760\n",
      "Epoch 7535/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.1944 - val_loss: 569.9838\n",
      "Epoch 7536/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.3239 - val_loss: 569.6637\n",
      "Epoch 7537/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.2232 - val_loss: 569.7472\n",
      "Epoch 7538/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.8429 - val_loss: 570.7508\n",
      "Epoch 7539/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.4806 - val_loss: 569.2278\n",
      "Epoch 7540/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.6556 - val_loss: 568.4437\n",
      "Epoch 7541/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.4841 - val_loss: 569.1693\n",
      "Epoch 7542/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.3884 - val_loss: 569.7692\n",
      "Epoch 7543/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.1470 - val_loss: 569.4849\n",
      "Epoch 7544/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.8761 - val_loss: 568.8036\n",
      "Epoch 7545/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.3293 - val_loss: 569.8025\n",
      "Epoch 7546/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.7902 - val_loss: 569.6071\n",
      "Epoch 7547/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.5353 - val_loss: 571.4264\n",
      "Epoch 7548/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.7823 - val_loss: 568.8365\n",
      "Epoch 7549/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.0765 - val_loss: 568.6352\n",
      "Epoch 7550/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.4717 - val_loss: 569.3228\n",
      "Epoch 7551/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.0309 - val_loss: 569.0743\n",
      "Epoch 7552/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.8889 - val_loss: 569.7384\n",
      "Epoch 7553/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 472.5069 - val_loss: 568.5745\n",
      "Epoch 7554/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.4537 - val_loss: 569.1285\n",
      "Epoch 7555/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.4656 - val_loss: 569.2890\n",
      "Epoch 7556/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.2925 - val_loss: 569.4875\n",
      "Epoch 7557/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.2120 - val_loss: 569.3733\n",
      "Epoch 7558/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.1882 - val_loss: 569.3891\n",
      "Epoch 7559/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.7316 - val_loss: 569.4929\n",
      "Epoch 7560/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.2392 - val_loss: 568.6587\n",
      "Epoch 7561/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.7439 - val_loss: 569.4292\n",
      "Epoch 7562/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.3371 - val_loss: 568.7754\n",
      "Epoch 7563/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 472.2794 - val_loss: 569.3168\n",
      "Epoch 7564/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.9349 - val_loss: 569.0671\n",
      "Epoch 7565/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.8723 - val_loss: 569.6827\n",
      "Epoch 7566/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.3346 - val_loss: 568.6881\n",
      "Epoch 7567/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.3978 - val_loss: 569.2293\n",
      "Epoch 7568/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.0657 - val_loss: 569.0364\n",
      "Epoch 7569/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.2456 - val_loss: 569.1384\n",
      "Epoch 7570/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.4481 - val_loss: 569.0985\n",
      "Epoch 7571/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.3431 - val_loss: 569.0188\n",
      "Epoch 7572/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 472.4726 - val_loss: 569.8495\n",
      "Epoch 7573/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.5266 - val_loss: 569.6600\n",
      "Epoch 7574/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.4677 - val_loss: 569.3941\n",
      "Epoch 7575/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.5576 - val_loss: 570.4047\n",
      "Epoch 7576/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 11us/sample - loss: 472.3951 - val_loss: 569.1599\n",
      "Epoch 7577/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.1280 - val_loss: 569.4541\n",
      "Epoch 7578/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.7966 - val_loss: 569.9830\n",
      "Epoch 7579/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.4572 - val_loss: 569.0983\n",
      "Epoch 7580/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.6600 - val_loss: 569.8784\n",
      "Epoch 7581/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.6807 - val_loss: 568.1768\n",
      "Epoch 7582/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.8696 - val_loss: 568.3695\n",
      "Epoch 7583/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.4181 - val_loss: 569.2514\n",
      "Epoch 7584/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.2608 - val_loss: 568.7433\n",
      "Epoch 7585/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.0125 - val_loss: 568.5850\n",
      "Epoch 7586/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.6091 - val_loss: 568.5261\n",
      "Epoch 7587/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.2045 - val_loss: 568.8929\n",
      "Epoch 7588/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.5473 - val_loss: 568.8056\n",
      "Epoch 7589/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.0488 - val_loss: 569.0456\n",
      "Epoch 7590/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.3513 - val_loss: 569.1035\n",
      "Epoch 7591/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.7125 - val_loss: 569.1853\n",
      "Epoch 7592/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.6169 - val_loss: 569.3901\n",
      "Epoch 7593/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.3874 - val_loss: 568.8147\n",
      "Epoch 7594/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.6850 - val_loss: 568.4786\n",
      "Epoch 7595/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.2340 - val_loss: 568.8586\n",
      "Epoch 7596/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.1274 - val_loss: 568.4203\n",
      "Epoch 7597/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.7631 - val_loss: 567.5877\n",
      "Epoch 7598/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.9946 - val_loss: 568.5411\n",
      "Epoch 7599/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.3004 - val_loss: 568.9155\n",
      "Epoch 7600/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.9767 - val_loss: 568.6943\n",
      "Epoch 7601/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.6212 - val_loss: 567.9732\n",
      "Epoch 7602/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.5802 - val_loss: 569.2430\n",
      "Epoch 7603/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.2231 - val_loss: 569.6322\n",
      "Epoch 7604/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.5566 - val_loss: 569.9520\n",
      "Epoch 7605/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.0954 - val_loss: 568.4631\n",
      "Epoch 7606/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.2401 - val_loss: 568.7260\n",
      "Epoch 7607/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.1048 - val_loss: 568.5154\n",
      "Epoch 7608/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.3178 - val_loss: 569.6362\n",
      "Epoch 7609/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.6481 - val_loss: 568.1122\n",
      "Epoch 7610/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.1111 - val_loss: 568.5597\n",
      "Epoch 7611/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.3850 - val_loss: 568.6055\n",
      "Epoch 7612/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.5996 - val_loss: 567.7678\n",
      "Epoch 7613/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.6674 - val_loss: 568.9442\n",
      "Epoch 7614/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.8107 - val_loss: 569.1708\n",
      "Epoch 7615/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.5102 - val_loss: 568.3983\n",
      "Epoch 7616/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.3823 - val_loss: 568.0993\n",
      "Epoch 7617/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.2647 - val_loss: 569.8027\n",
      "Epoch 7618/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.0138 - val_loss: 568.8530\n",
      "Epoch 7619/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.9637 - val_loss: 568.9545\n",
      "Epoch 7620/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.8556 - val_loss: 569.9093\n",
      "Epoch 7621/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.5512 - val_loss: 567.8041\n",
      "Epoch 7622/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.9768 - val_loss: 568.6663\n",
      "Epoch 7623/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.9975 - val_loss: 568.9604\n",
      "Epoch 7624/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.9209 - val_loss: 568.9994\n",
      "Epoch 7625/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.2182 - val_loss: 568.9397\n",
      "Epoch 7626/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.4942 - val_loss: 569.5286\n",
      "Epoch 7627/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.3418 - val_loss: 568.5127\n",
      "Epoch 7628/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 471.8641 - val_loss: 568.9779\n",
      "Epoch 7629/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.4141 - val_loss: 569.7601\n",
      "Epoch 7630/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.3243 - val_loss: 569.3861\n",
      "Epoch 7631/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.9131 - val_loss: 569.4025\n",
      "Epoch 7632/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.1102 - val_loss: 568.8509\n",
      "Epoch 7633/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.0450 - val_loss: 568.8435\n",
      "Epoch 7634/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 472.5408 - val_loss: 569.8352\n",
      "Epoch 7635/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.0886 - val_loss: 569.6331\n",
      "Epoch 7636/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.0395 - val_loss: 569.5420\n",
      "Epoch 7637/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.5059 - val_loss: 569.5090\n",
      "Epoch 7638/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.8980 - val_loss: 569.5179\n",
      "Epoch 7639/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.3311 - val_loss: 569.2406\n",
      "Epoch 7640/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.4409 - val_loss: 569.6245\n",
      "Epoch 7641/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.4176 - val_loss: 569.1358\n",
      "Epoch 7642/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.3758 - val_loss: 569.2017\n",
      "Epoch 7643/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.0749 - val_loss: 569.7550\n",
      "Epoch 7644/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.0456 - val_loss: 568.6464\n",
      "Epoch 7645/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.8794 - val_loss: 568.5422\n",
      "Epoch 7646/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.9250 - val_loss: 569.0446\n",
      "Epoch 7647/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.5050 - val_loss: 568.5255\n",
      "Epoch 7648/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.0025 - val_loss: 569.2662\n",
      "Epoch 7649/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.0907 - val_loss: 569.1818\n",
      "Epoch 7650/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.9928 - val_loss: 568.4811\n",
      "Epoch 7651/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.8929 - val_loss: 568.7884\n",
      "Epoch 7652/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 474.8811 - val_loss: 568.4503\n",
      "Epoch 7653/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.7758 - val_loss: 567.9037\n",
      "Epoch 7654/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.2334 - val_loss: 568.8352\n",
      "Epoch 7655/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.7597 - val_loss: 568.9703\n",
      "Epoch 7656/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.9711 - val_loss: 568.7074\n",
      "Epoch 7657/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.5924 - val_loss: 569.2128\n",
      "Epoch 7658/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.8688 - val_loss: 568.7628\n",
      "Epoch 7659/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.2738 - val_loss: 569.3603\n",
      "Epoch 7660/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.7029 - val_loss: 568.1741\n",
      "Epoch 7661/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.0383 - val_loss: 567.8291\n",
      "Epoch 7662/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.7500 - val_loss: 568.5333\n",
      "Epoch 7663/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.8042 - val_loss: 568.4245\n",
      "Epoch 7664/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.8746 - val_loss: 568.5499\n",
      "Epoch 7665/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.8909 - val_loss: 569.0182\n",
      "Epoch 7666/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.0476 - val_loss: 569.6778\n",
      "Epoch 7667/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.4913 - val_loss: 569.3556\n",
      "Epoch 7668/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.3242 - val_loss: 569.4574\n",
      "Epoch 7669/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.9390 - val_loss: 569.7184\n",
      "Epoch 7670/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.0382 - val_loss: 568.3771\n",
      "Epoch 7671/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.8197 - val_loss: 569.5323\n",
      "Epoch 7672/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.2379 - val_loss: 569.6359\n",
      "Epoch 7673/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.2405 - val_loss: 568.4274\n",
      "Epoch 7674/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.6979 - val_loss: 568.4917\n",
      "Epoch 7675/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.8094 - val_loss: 569.0408\n",
      "Epoch 7676/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.1977 - val_loss: 568.2040\n",
      "Epoch 7677/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.7822 - val_loss: 568.9866\n",
      "Epoch 7678/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.0775 - val_loss: 569.5648\n",
      "Epoch 7679/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.3711 - val_loss: 568.0325\n",
      "Epoch 7680/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.2786 - val_loss: 568.3685\n",
      "Epoch 7681/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.9054 - val_loss: 568.9097\n",
      "Epoch 7682/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.5818 - val_loss: 568.5111\n",
      "Epoch 7683/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.5269 - val_loss: 569.0130\n",
      "Epoch 7684/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.6633 - val_loss: 568.2484\n",
      "Epoch 7685/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.7841 - val_loss: 568.0684\n",
      "Epoch 7686/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.9043 - val_loss: 568.9056\n",
      "Epoch 7687/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.0334 - val_loss: 569.0424\n",
      "Epoch 7688/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.2680 - val_loss: 568.1147\n",
      "Epoch 7689/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.7902 - val_loss: 569.1174\n",
      "Epoch 7690/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.6541 - val_loss: 568.6084\n",
      "Epoch 7691/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.9030 - val_loss: 567.7753\n",
      "Epoch 7692/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.9730 - val_loss: 568.5790\n",
      "Epoch 7693/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.9008 - val_loss: 568.8561\n",
      "Epoch 7694/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.7289 - val_loss: 568.3079\n",
      "Epoch 7695/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.2142 - val_loss: 567.7934\n",
      "Epoch 7696/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.3722 - val_loss: 567.1381\n",
      "Epoch 7697/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.6106 - val_loss: 568.1663\n",
      "Epoch 7698/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.8841 - val_loss: 569.0757\n",
      "Epoch 7699/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.6532 - val_loss: 568.5221\n",
      "Epoch 7700/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.1976 - val_loss: 568.5174\n",
      "Epoch 7701/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.8981 - val_loss: 568.1629\n",
      "Epoch 7702/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.2578 - val_loss: 568.6010\n",
      "Epoch 7703/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.7821 - val_loss: 568.1550\n",
      "Epoch 7704/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.9731 - val_loss: 568.1315\n",
      "Epoch 7705/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.4461 - val_loss: 568.4593\n",
      "Epoch 7706/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.3847 - val_loss: 567.4028\n",
      "Epoch 7707/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.0120 - val_loss: 567.4767\n",
      "Epoch 7708/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.3700 - val_loss: 568.3548\n",
      "Epoch 7709/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.5241 - val_loss: 567.7215\n",
      "Epoch 7710/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.2732 - val_loss: 567.2813\n",
      "Epoch 7711/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.8727 - val_loss: 568.5932\n",
      "Epoch 7712/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.8293 - val_loss: 567.9248\n",
      "Epoch 7713/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.1527 - val_loss: 567.5336\n",
      "Epoch 7714/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.7153 - val_loss: 567.8674\n",
      "Epoch 7715/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.2583 - val_loss: 568.2754\n",
      "Epoch 7716/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.5960 - val_loss: 567.9912\n",
      "Epoch 7717/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.9969 - val_loss: 567.7390\n",
      "Epoch 7718/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.1847 - val_loss: 568.1512\n",
      "Epoch 7719/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.0998 - val_loss: 568.3572\n",
      "Epoch 7720/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.5830 - val_loss: 567.9623\n",
      "Epoch 7721/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 472.2684 - val_loss: 567.9965\n",
      "Epoch 7722/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 472.0807 - val_loss: 567.6812\n",
      "Epoch 7723/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.1665 - val_loss: 567.9660\n",
      "Epoch 7724/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.5213 - val_loss: 567.5407\n",
      "Epoch 7725/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.8419 - val_loss: 568.6451\n",
      "Epoch 7726/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.2503 - val_loss: 567.8748\n",
      "Epoch 7727/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.0286 - val_loss: 567.4872\n",
      "Epoch 7728/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.6716 - val_loss: 568.9420\n",
      "Epoch 7729/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.9665 - val_loss: 568.9433\n",
      "Epoch 7730/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.5023 - val_loss: 568.5109\n",
      "Epoch 7731/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.5615 - val_loss: 568.1422\n",
      "Epoch 7732/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.7476 - val_loss: 568.0405\n",
      "Epoch 7733/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.9521 - val_loss: 567.9939\n",
      "Epoch 7734/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 472.1561 - val_loss: 569.6855\n",
      "Epoch 7735/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.3809 - val_loss: 568.8444\n",
      "Epoch 7736/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.0816 - val_loss: 567.7459\n",
      "Epoch 7737/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.9295 - val_loss: 567.2439\n",
      "Epoch 7738/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.9458 - val_loss: 569.9660\n",
      "Epoch 7739/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.6446 - val_loss: 568.2164\n",
      "Epoch 7740/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.2137 - val_loss: 568.1100\n",
      "Epoch 7741/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.8408 - val_loss: 567.8714\n",
      "Epoch 7742/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.0976 - val_loss: 568.6336\n",
      "Epoch 7743/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.8135 - val_loss: 568.2245\n",
      "Epoch 7744/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.8443 - val_loss: 566.6434\n",
      "Epoch 7745/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.6529 - val_loss: 567.9911\n",
      "Epoch 7746/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 472.4128 - val_loss: 567.2650\n",
      "Epoch 7747/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.9953 - val_loss: 567.9076\n",
      "Epoch 7748/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.4280 - val_loss: 567.8630\n",
      "Epoch 7749/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.0531 - val_loss: 568.3362\n",
      "Epoch 7750/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 658.7186Epoch: 7750 - loss: 472.006451 - val_loss: 568.965548\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.0065 - val_loss: 568.9655\n",
      "Epoch 7751/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.4355 - val_loss: 568.3041\n",
      "Epoch 7752/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.7017 - val_loss: 568.0281\n",
      "Epoch 7753/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.8782 - val_loss: 568.3937\n",
      "Epoch 7754/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.6816 - val_loss: 567.6737\n",
      "Epoch 7755/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.8862 - val_loss: 568.0903\n",
      "Epoch 7756/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.0011 - val_loss: 568.4423\n",
      "Epoch 7757/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.0440 - val_loss: 567.6842\n",
      "Epoch 7758/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.5421 - val_loss: 568.2574\n",
      "Epoch 7759/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.5184 - val_loss: 568.6638\n",
      "Epoch 7760/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.9451 - val_loss: 568.8091\n",
      "Epoch 7761/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.5402 - val_loss: 567.7759\n",
      "Epoch 7762/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.6130 - val_loss: 567.8962\n",
      "Epoch 7763/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.8049 - val_loss: 568.1314\n",
      "Epoch 7764/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.0371 - val_loss: 568.1668\n",
      "Epoch 7765/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.4378 - val_loss: 568.6365\n",
      "Epoch 7766/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.1582 - val_loss: 567.8417\n",
      "Epoch 7767/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.8597 - val_loss: 569.7044\n",
      "Epoch 7768/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.1344 - val_loss: 568.3675\n",
      "Epoch 7769/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.7858 - val_loss: 568.1068\n",
      "Epoch 7770/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.1648 - val_loss: 568.3972\n",
      "Epoch 7771/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.8159 - val_loss: 568.3211\n",
      "Epoch 7772/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.6850 - val_loss: 567.8638\n",
      "Epoch 7773/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.8317 - val_loss: 567.7469\n",
      "Epoch 7774/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.9646 - val_loss: 567.8848\n",
      "Epoch 7775/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.6902 - val_loss: 567.2593\n",
      "Epoch 7776/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.5673 - val_loss: 567.3180\n",
      "Epoch 7777/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.2159 - val_loss: 567.4850\n",
      "Epoch 7778/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.6790 - val_loss: 567.2472\n",
      "Epoch 7779/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.5964 - val_loss: 568.2880\n",
      "Epoch 7780/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.4538 - val_loss: 568.6324\n",
      "Epoch 7781/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.0642 - val_loss: 569.4531\n",
      "Epoch 7782/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.0123 - val_loss: 567.8552\n",
      "Epoch 7783/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.6829 - val_loss: 567.9666\n",
      "Epoch 7784/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.6266 - val_loss: 568.1191\n",
      "Epoch 7785/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.2547 - val_loss: 567.8390\n",
      "Epoch 7786/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.4360 - val_loss: 568.1858\n",
      "Epoch 7787/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.7095 - val_loss: 568.3583\n",
      "Epoch 7788/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.4894 - val_loss: 567.3419\n",
      "Epoch 7789/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.9530 - val_loss: 567.9873\n",
      "Epoch 7790/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.3685 - val_loss: 567.4368\n",
      "Epoch 7791/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.4473 - val_loss: 567.1658\n",
      "Epoch 7792/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.8846 - val_loss: 568.0188\n",
      "Epoch 7793/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.5266 - val_loss: 567.6014\n",
      "Epoch 7794/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.4396 - val_loss: 568.0951\n",
      "Epoch 7795/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.4362 - val_loss: 567.8535\n",
      "Epoch 7796/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.7621 - val_loss: 567.2931\n",
      "Epoch 7797/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.7845 - val_loss: 566.7254\n",
      "Epoch 7798/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.7181 - val_loss: 567.6500\n",
      "Epoch 7799/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.6479 - val_loss: 567.8346\n",
      "Epoch 7800/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.5463 - val_loss: 568.4289\n",
      "Epoch 7801/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.7035 - val_loss: 568.1111\n",
      "Epoch 7802/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.7059 - val_loss: 567.6343\n",
      "Epoch 7803/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.8307 - val_loss: 568.9754\n",
      "Epoch 7804/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.1983 - val_loss: 567.4392\n",
      "Epoch 7805/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.4801 - val_loss: 567.4335\n",
      "Epoch 7806/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 473.0410 - val_loss: 568.0807\n",
      "Epoch 7807/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.7532 - val_loss: 568.3431\n",
      "Epoch 7808/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.4454 - val_loss: 568.8197\n",
      "Epoch 7809/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.6918 - val_loss: 567.9810\n",
      "Epoch 7810/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.8630 - val_loss: 567.2551\n",
      "Epoch 7811/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.5627 - val_loss: 568.6359\n",
      "Epoch 7812/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2331 - val_loss: 567.6987\n",
      "Epoch 7813/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.5056 - val_loss: 567.9763\n",
      "Epoch 7814/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.6922 - val_loss: 568.1710\n",
      "Epoch 7815/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.4878 - val_loss: 568.3158\n",
      "Epoch 7816/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.4641 - val_loss: 568.0063\n",
      "Epoch 7817/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.5006 - val_loss: 568.0969\n",
      "Epoch 7818/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.4230 - val_loss: 567.8028\n",
      "Epoch 7819/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.5139 - val_loss: 568.0363\n",
      "Epoch 7820/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.6160 - val_loss: 568.9232\n",
      "Epoch 7821/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.6859 - val_loss: 567.2283\n",
      "Epoch 7822/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2900 - val_loss: 568.3310\n",
      "Epoch 7823/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.7865 - val_loss: 569.0141\n",
      "Epoch 7824/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.8008 - val_loss: 568.3925\n",
      "Epoch 7825/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.4021 - val_loss: 567.9121\n",
      "Epoch 7826/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2139 - val_loss: 568.7333\n",
      "Epoch 7827/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.3544 - val_loss: 568.6015\n",
      "Epoch 7828/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.6266 - val_loss: 568.8034\n",
      "Epoch 7829/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.5770 - val_loss: 568.7520\n",
      "Epoch 7830/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.5030 - val_loss: 568.1915\n",
      "Epoch 7831/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.6450 - val_loss: 567.8023\n",
      "Epoch 7832/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.9181 - val_loss: 569.3904\n",
      "Epoch 7833/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.3834 - val_loss: 567.9782\n",
      "Epoch 7834/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.7096 - val_loss: 567.3349\n",
      "Epoch 7835/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.7748 - val_loss: 567.2177\n",
      "Epoch 7836/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.7569 - val_loss: 567.9912\n",
      "Epoch 7837/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 471.4452 - val_loss: 568.2805\n",
      "Epoch 7838/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.5942 - val_loss: 567.6808\n",
      "Epoch 7839/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2356 - val_loss: 568.4504\n",
      "Epoch 7840/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.2809 - val_loss: 568.1890\n",
      "Epoch 7841/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2098 - val_loss: 568.1457\n",
      "Epoch 7842/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 471.1946 - val_loss: 567.8850\n",
      "Epoch 7843/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2649 - val_loss: 567.5612\n",
      "Epoch 7844/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.4336 - val_loss: 567.1398\n",
      "Epoch 7845/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.6511 - val_loss: 568.7187\n",
      "Epoch 7846/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.4136 - val_loss: 567.9962\n",
      "Epoch 7847/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.3055 - val_loss: 567.4573\n",
      "Epoch 7848/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.6863 - val_loss: 567.3233\n",
      "Epoch 7849/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 471.7694 - val_loss: 567.9739\n",
      "Epoch 7850/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.3264 - val_loss: 567.4414\n",
      "Epoch 7851/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.6929 - val_loss: 568.0541\n",
      "Epoch 7852/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.4320 - val_loss: 569.2103\n",
      "Epoch 7853/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.6527 - val_loss: 568.2529\n",
      "Epoch 7854/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 471.4338 - val_loss: 568.1638\n",
      "Epoch 7855/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.3620 - val_loss: 568.2781\n",
      "Epoch 7856/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.7961 - val_loss: 568.7561\n",
      "Epoch 7857/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.1550 - val_loss: 567.2541\n",
      "Epoch 7858/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.9314 - val_loss: 566.6630\n",
      "Epoch 7859/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.7790 - val_loss: 566.7573\n",
      "Epoch 7860/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.3992 - val_loss: 567.6767\n",
      "Epoch 7861/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.3760 - val_loss: 567.3117\n",
      "Epoch 7862/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.8042 - val_loss: 567.8130\n",
      "Epoch 7863/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.7764 - val_loss: 568.6786\n",
      "Epoch 7864/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.9696 - val_loss: 566.7679\n",
      "Epoch 7865/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.5875 - val_loss: 567.8220\n",
      "Epoch 7866/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.6832 - val_loss: 567.3049\n",
      "Epoch 7867/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2950 - val_loss: 568.1997\n",
      "Epoch 7868/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2155 - val_loss: 567.5838\n",
      "Epoch 7869/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.4570 - val_loss: 566.4272\n",
      "Epoch 7870/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 471.5434 - val_loss: 565.8391\n",
      "Epoch 7871/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2793 - val_loss: 566.5848\n",
      "Epoch 7872/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.5974 - val_loss: 566.7165\n",
      "Epoch 7873/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.1456 - val_loss: 567.3152\n",
      "Epoch 7874/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.3764 - val_loss: 567.7928\n",
      "Epoch 7875/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.5850 - val_loss: 568.0133\n",
      "Epoch 7876/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.7423 - val_loss: 567.7084\n",
      "Epoch 7877/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.6094 - val_loss: 568.2167\n",
      "Epoch 7878/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.0820 - val_loss: 566.8616\n",
      "Epoch 7879/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2880 - val_loss: 566.6114\n",
      "Epoch 7880/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.4819 - val_loss: 567.1022\n",
      "Epoch 7881/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.5801 - val_loss: 567.3271\n",
      "Epoch 7882/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.0350 - val_loss: 566.1841\n",
      "Epoch 7883/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.1474 - val_loss: 567.1281\n",
      "Epoch 7884/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.1554 - val_loss: 567.3270\n",
      "Epoch 7885/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.1529 - val_loss: 567.9672\n",
      "Epoch 7886/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2118 - val_loss: 568.1648\n",
      "Epoch 7887/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.7981 - val_loss: 567.3605\n",
      "Epoch 7888/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.6016 - val_loss: 566.3206\n",
      "Epoch 7889/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.9566 - val_loss: 567.0653\n",
      "Epoch 7890/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.4741 - val_loss: 566.9764\n",
      "Epoch 7891/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.5385 - val_loss: 567.7913\n",
      "Epoch 7892/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.0019 - val_loss: 567.5051\n",
      "Epoch 7893/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2801 - val_loss: 567.2331\n",
      "Epoch 7894/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.9341 - val_loss: 567.1076\n",
      "Epoch 7895/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.6079 - val_loss: 567.4456\n",
      "Epoch 7896/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.3576 - val_loss: 567.0438\n",
      "Epoch 7897/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.9139 - val_loss: 568.2383\n",
      "Epoch 7898/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.1588 - val_loss: 567.5496\n",
      "Epoch 7899/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.1634 - val_loss: 567.5263\n",
      "Epoch 7900/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.6180 - val_loss: 567.1508\n",
      "Epoch 7901/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.8303 - val_loss: 568.2658\n",
      "Epoch 7902/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.6322 - val_loss: 568.5141\n",
      "Epoch 7903/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.5243 - val_loss: 567.8418\n",
      "Epoch 7904/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.3680 - val_loss: 566.9597\n",
      "Epoch 7905/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.3080 - val_loss: 567.6732\n",
      "Epoch 7906/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.5509 - val_loss: 566.5254\n",
      "Epoch 7907/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.0117 - val_loss: 568.3799\n",
      "Epoch 7908/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.9414 - val_loss: 568.6918\n",
      "Epoch 7909/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.1436 - val_loss: 567.6867\n",
      "Epoch 7910/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.4005 - val_loss: 567.7731\n",
      "Epoch 7911/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.9038 - val_loss: 567.6530\n",
      "Epoch 7912/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.1589 - val_loss: 567.8676\n",
      "Epoch 7913/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2287 - val_loss: 568.1632\n",
      "Epoch 7914/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.0680 - val_loss: 567.8610\n",
      "Epoch 7915/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.0807 - val_loss: 568.2254\n",
      "Epoch 7916/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.0947 - val_loss: 568.1280\n",
      "Epoch 7917/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.6278 - val_loss: 566.9423\n",
      "Epoch 7918/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.5182 - val_loss: 568.2081\n",
      "Epoch 7919/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.1048 - val_loss: 567.7129\n",
      "Epoch 7920/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.8172 - val_loss: 567.4121\n",
      "Epoch 7921/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.0874 - val_loss: 567.6768\n",
      "Epoch 7922/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.1488 - val_loss: 567.1926\n",
      "Epoch 7923/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.1299 - val_loss: 568.0507\n",
      "Epoch 7924/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.0344 - val_loss: 567.2722\n",
      "Epoch 7925/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.3489 - val_loss: 567.6158\n",
      "Epoch 7926/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2628 - val_loss: 568.7609\n",
      "Epoch 7927/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2150 - val_loss: 567.2904\n",
      "Epoch 7928/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.3785 - val_loss: 567.1549\n",
      "Epoch 7929/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.3443 - val_loss: 566.9522\n",
      "Epoch 7930/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.1634 - val_loss: 567.5423\n",
      "Epoch 7931/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.2824 - val_loss: 566.1820\n",
      "Epoch 7932/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.1292 - val_loss: 567.5934\n",
      "Epoch 7933/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.4850 - val_loss: 567.5458\n",
      "Epoch 7934/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.0649 - val_loss: 567.8622\n",
      "Epoch 7935/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.4321 - val_loss: 568.1115\n",
      "Epoch 7936/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.1239 - val_loss: 567.2067\n",
      "Epoch 7937/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.9127 - val_loss: 566.8476\n",
      "Epoch 7938/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.1737 - val_loss: 567.2294\n",
      "Epoch 7939/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.3617 - val_loss: 567.5690\n",
      "Epoch 7940/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.4595 - val_loss: 566.5923\n",
      "Epoch 7941/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.3656 - val_loss: 567.1474\n",
      "Epoch 7942/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.3452 - val_loss: 566.7132\n",
      "Epoch 7943/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.9491 - val_loss: 566.8809\n",
      "Epoch 7944/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.1262 - val_loss: 566.4223\n",
      "Epoch 7945/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.9791 - val_loss: 566.6649\n",
      "Epoch 7946/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2388 - val_loss: 566.4377\n",
      "Epoch 7947/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2110 - val_loss: 567.5016\n",
      "Epoch 7948/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.6312 - val_loss: 567.3332\n",
      "Epoch 7949/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.8918 - val_loss: 567.5719\n",
      "Epoch 7950/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.3671 - val_loss: 567.0875\n",
      "Epoch 7951/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2686 - val_loss: 566.4284\n",
      "Epoch 7952/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 471.5194 - val_loss: 566.3279\n",
      "Epoch 7953/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.4102 - val_loss: 566.8748\n",
      "Epoch 7954/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.1223 - val_loss: 567.2562\n",
      "Epoch 7955/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.9246 - val_loss: 567.2784\n",
      "Epoch 7956/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.4716 - val_loss: 567.8851\n",
      "Epoch 7957/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.1393 - val_loss: 567.0120\n",
      "Epoch 7958/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 471.0512 - val_loss: 567.2478\n",
      "Epoch 7959/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2964 - val_loss: 567.4393\n",
      "Epoch 7960/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.0703 - val_loss: 566.3604\n",
      "Epoch 7961/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.3146 - val_loss: 567.8854\n",
      "Epoch 7962/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 470.8756 - val_loss: 567.2519\n",
      "Epoch 7963/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.6446 - val_loss: 566.6534\n",
      "Epoch 7964/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.0442 - val_loss: 567.3391\n",
      "Epoch 7965/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.7673 - val_loss: 566.4576\n",
      "Epoch 7966/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.5653 - val_loss: 567.0871\n",
      "Epoch 7967/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 472.2430 - val_loss: 567.8656\n",
      "Epoch 7968/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.8316 - val_loss: 566.6686\n",
      "Epoch 7969/10000\n",
      "3000/3000 [==============================] - 0s 16us/sample - loss: 471.2835 - val_loss: 566.5473\n",
      "Epoch 7970/10000\n",
      "3000/3000 [==============================] - 0s 18us/sample - loss: 471.1593 - val_loss: 566.5207\n",
      "Epoch 7971/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 470.9430 - val_loss: 566.9982\n",
      "Epoch 7972/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.8214 - val_loss: 566.6422\n",
      "Epoch 7973/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.6920 - val_loss: 567.1501\n",
      "Epoch 7974/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.0111 - val_loss: 567.9532\n",
      "Epoch 7975/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.0085 - val_loss: 567.5110\n",
      "Epoch 7976/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.3527 - val_loss: 566.0489\n",
      "Epoch 7977/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.7584 - val_loss: 566.3237\n",
      "Epoch 7978/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.3712 - val_loss: 566.4838\n",
      "Epoch 7979/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.1620 - val_loss: 567.1876\n",
      "Epoch 7980/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.7627 - val_loss: 566.0908\n",
      "Epoch 7981/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.7921 - val_loss: 566.6303\n",
      "Epoch 7982/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.7549 - val_loss: 566.2999\n",
      "Epoch 7983/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.0127 - val_loss: 565.8715\n",
      "Epoch 7984/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.1121 - val_loss: 567.3374\n",
      "Epoch 7985/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.8255 - val_loss: 566.2928\n",
      "Epoch 7986/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.8913 - val_loss: 566.8202\n",
      "Epoch 7987/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.8369 - val_loss: 567.2120\n",
      "Epoch 7988/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.8236 - val_loss: 567.6708\n",
      "Epoch 7989/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.0962 - val_loss: 566.8580\n",
      "Epoch 7990/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.1331 - val_loss: 567.2105\n",
      "Epoch 7991/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.9390 - val_loss: 567.4499\n",
      "Epoch 7992/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.0394 - val_loss: 566.9696\n",
      "Epoch 7993/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.8177 - val_loss: 567.4042\n",
      "Epoch 7994/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.1312 - val_loss: 567.3940\n",
      "Epoch 7995/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.9411 - val_loss: 567.0777\n",
      "Epoch 7996/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.7959 - val_loss: 567.0027\n",
      "Epoch 7997/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2823 - val_loss: 565.7624\n",
      "Epoch 7998/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.4734 - val_loss: 566.7828\n",
      "Epoch 7999/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.0245 - val_loss: 566.4649\n",
      "Epoch 8000/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 733.1317Epoch: 8000 - loss: 471.225149 - val_loss: 566.935432\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2251 - val_loss: 566.9354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8001/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.0834 - val_loss: 566.4842\n",
      "Epoch 8002/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.9154 - val_loss: 567.0527\n",
      "Epoch 8003/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.8973 - val_loss: 566.7647\n",
      "Epoch 8004/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.8210 - val_loss: 567.3377\n",
      "Epoch 8005/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2768 - val_loss: 566.7220\n",
      "Epoch 8006/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.9171 - val_loss: 567.2467\n",
      "Epoch 8007/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2349 - val_loss: 566.5352\n",
      "Epoch 8008/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.8314 - val_loss: 567.3583\n",
      "Epoch 8009/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.9674 - val_loss: 565.8727\n",
      "Epoch 8010/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.5174 - val_loss: 566.8176\n",
      "Epoch 8011/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.5219 - val_loss: 567.6133\n",
      "Epoch 8012/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.0214 - val_loss: 567.2083\n",
      "Epoch 8013/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.7439 - val_loss: 569.0264\n",
      "Epoch 8014/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.5597 - val_loss: 567.2715\n",
      "Epoch 8015/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.3902 - val_loss: 567.5056\n",
      "Epoch 8016/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.5278 - val_loss: 568.0282\n",
      "Epoch 8017/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.0264 - val_loss: 567.5629\n",
      "Epoch 8018/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.9814 - val_loss: 566.3114\n",
      "Epoch 8019/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.7126 - val_loss: 566.6910\n",
      "Epoch 8020/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.8450 - val_loss: 567.0061\n",
      "Epoch 8021/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.4380 - val_loss: 567.0723\n",
      "Epoch 8022/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.9339 - val_loss: 567.2145\n",
      "Epoch 8023/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.9676 - val_loss: 567.4218\n",
      "Epoch 8024/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.1485 - val_loss: 566.6423\n",
      "Epoch 8025/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.7289 - val_loss: 567.0100\n",
      "Epoch 8026/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.0770 - val_loss: 568.4309\n",
      "Epoch 8027/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 470.9199 - val_loss: 567.1078\n",
      "Epoch 8028/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.8335 - val_loss: 566.3582\n",
      "Epoch 8029/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.8045 - val_loss: 566.2793\n",
      "Epoch 8030/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.8943 - val_loss: 567.1559\n",
      "Epoch 8031/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2841 - val_loss: 568.0202\n",
      "Epoch 8032/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.8845 - val_loss: 566.7823\n",
      "Epoch 8033/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.6774 - val_loss: 566.9380\n",
      "Epoch 8034/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.5506 - val_loss: 566.4662\n",
      "Epoch 8035/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.9228 - val_loss: 566.6524\n",
      "Epoch 8036/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.7773 - val_loss: 566.9083\n",
      "Epoch 8037/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.8871 - val_loss: 566.1630\n",
      "Epoch 8038/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.4612 - val_loss: 567.0934\n",
      "Epoch 8039/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.6180 - val_loss: 567.3639\n",
      "Epoch 8040/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.8792 - val_loss: 566.6756\n",
      "Epoch 8041/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2324 - val_loss: 566.6875\n",
      "Epoch 8042/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.5827 - val_loss: 567.4517\n",
      "Epoch 8043/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.8530 - val_loss: 567.5660\n",
      "Epoch 8044/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.4717 - val_loss: 567.0229\n",
      "Epoch 8045/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.3887 - val_loss: 566.6710\n",
      "Epoch 8046/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.9776 - val_loss: 567.4822\n",
      "Epoch 8047/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.6759 - val_loss: 566.8245\n",
      "Epoch 8048/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.1847 - val_loss: 567.1617\n",
      "Epoch 8049/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.5672 - val_loss: 566.1401\n",
      "Epoch 8050/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.3785 - val_loss: 567.1784\n",
      "Epoch 8051/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.0909 - val_loss: 567.8193\n",
      "Epoch 8052/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2781 - val_loss: 567.1289\n",
      "Epoch 8053/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2469 - val_loss: 565.9123\n",
      "Epoch 8054/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.6022 - val_loss: 567.9443\n",
      "Epoch 8055/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.5566 - val_loss: 567.1800\n",
      "Epoch 8056/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2575 - val_loss: 567.8062\n",
      "Epoch 8057/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.7110 - val_loss: 566.9112\n",
      "Epoch 8058/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.6876 - val_loss: 567.0070\n",
      "Epoch 8059/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.1166 - val_loss: 567.6698\n",
      "Epoch 8060/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.3588 - val_loss: 567.0018\n",
      "Epoch 8061/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.8132 - val_loss: 567.0653\n",
      "Epoch 8062/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.6492 - val_loss: 567.4911\n",
      "Epoch 8063/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.6939 - val_loss: 567.4765\n",
      "Epoch 8064/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.5995 - val_loss: 567.6527\n",
      "Epoch 8065/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.4462 - val_loss: 567.1348\n",
      "Epoch 8066/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.7150 - val_loss: 567.9447\n",
      "Epoch 8067/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.4249 - val_loss: 566.8815\n",
      "Epoch 8068/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.6037 - val_loss: 567.0407\n",
      "Epoch 8069/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.6897 - val_loss: 568.0656\n",
      "Epoch 8070/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.6278 - val_loss: 566.7544\n",
      "Epoch 8071/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.5830 - val_loss: 566.8761\n",
      "Epoch 8072/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.7711 - val_loss: 566.4897\n",
      "Epoch 8073/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.8306 - val_loss: 567.4795\n",
      "Epoch 8074/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.8604 - val_loss: 566.5884\n",
      "Epoch 8075/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.5204 - val_loss: 566.3082\n",
      "Epoch 8076/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.4429 - val_loss: 566.6104\n",
      "Epoch 8077/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.5144 - val_loss: 566.8161\n",
      "Epoch 8078/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.6156 - val_loss: 567.2788\n",
      "Epoch 8079/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2053 - val_loss: 566.1501\n",
      "Epoch 8080/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.0312 - val_loss: 566.7837\n",
      "Epoch 8081/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.6564 - val_loss: 567.0211\n",
      "Epoch 8082/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.6515 - val_loss: 567.1270\n",
      "Epoch 8083/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 471.2228 - val_loss: 566.2316\n",
      "Epoch 8084/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.5912 - val_loss: 566.9862\n",
      "Epoch 8085/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.5324 - val_loss: 566.5411\n",
      "Epoch 8086/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.5652 - val_loss: 566.8768\n",
      "Epoch 8087/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.9178 - val_loss: 567.1293\n",
      "Epoch 8088/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.4013 - val_loss: 566.9813\n",
      "Epoch 8089/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.5603 - val_loss: 566.0209\n",
      "Epoch 8090/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.4519 - val_loss: 567.0960\n",
      "Epoch 8091/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.8201 - val_loss: 565.8776\n",
      "Epoch 8092/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.4129 - val_loss: 567.1818\n",
      "Epoch 8093/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.6372 - val_loss: 567.7905\n",
      "Epoch 8094/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.2942 - val_loss: 567.2543\n",
      "Epoch 8095/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.6294 - val_loss: 567.2524\n",
      "Epoch 8096/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.6833 - val_loss: 567.6084\n",
      "Epoch 8097/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 470.8096 - val_loss: 566.8146\n",
      "Epoch 8098/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 470.4105 - val_loss: 567.4765\n",
      "Epoch 8099/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 470.6855 - val_loss: 567.3018\n",
      "Epoch 8100/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 470.6715 - val_loss: 567.3954\n",
      "Epoch 8101/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.4907 - val_loss: 567.4352\n",
      "Epoch 8102/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.3698 - val_loss: 567.1832\n",
      "Epoch 8103/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.3372 - val_loss: 567.3824\n",
      "Epoch 8104/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.6934 - val_loss: 567.0224\n",
      "Epoch 8105/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.3828 - val_loss: 566.3585\n",
      "Epoch 8106/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.1908 - val_loss: 566.7985\n",
      "Epoch 8107/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.4078 - val_loss: 566.5448\n",
      "Epoch 8108/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.8641 - val_loss: 567.1521\n",
      "Epoch 8109/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.8489 - val_loss: 565.9621\n",
      "Epoch 8110/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.3321 - val_loss: 567.2856\n",
      "Epoch 8111/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.3100 - val_loss: 566.8021\n",
      "Epoch 8112/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.3693 - val_loss: 566.8565\n",
      "Epoch 8113/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.8433 - val_loss: 566.1318\n",
      "Epoch 8114/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.6122 - val_loss: 567.5901\n",
      "Epoch 8115/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.6617 - val_loss: 567.6437\n",
      "Epoch 8116/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.7982 - val_loss: 566.5113\n",
      "Epoch 8117/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.3505 - val_loss: 566.7603\n",
      "Epoch 8118/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.4569 - val_loss: 566.5461\n",
      "Epoch 8119/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.6649 - val_loss: 566.5425\n",
      "Epoch 8120/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.9012 - val_loss: 566.0654\n",
      "Epoch 8121/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.8018 - val_loss: 567.4921\n",
      "Epoch 8122/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.4857 - val_loss: 566.3246\n",
      "Epoch 8123/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.7777 - val_loss: 566.2483\n",
      "Epoch 8124/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.8655 - val_loss: 566.6882\n",
      "Epoch 8125/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.6277 - val_loss: 565.9813\n",
      "Epoch 8126/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.5191 - val_loss: 566.4574\n",
      "Epoch 8127/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.7735 - val_loss: 566.0045\n",
      "Epoch 8128/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.5870 - val_loss: 566.5557\n",
      "Epoch 8129/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.2928 - val_loss: 566.8242\n",
      "Epoch 8130/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.6605 - val_loss: 565.9291\n",
      "Epoch 8131/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.4306 - val_loss: 566.3634\n",
      "Epoch 8132/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.5020 - val_loss: 566.7363\n",
      "Epoch 8133/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.2929 - val_loss: 566.8170\n",
      "Epoch 8134/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.4315 - val_loss: 566.6689\n",
      "Epoch 8135/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.9606 - val_loss: 566.1765\n",
      "Epoch 8136/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.5189 - val_loss: 566.3351\n",
      "Epoch 8137/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.5072 - val_loss: 566.7886\n",
      "Epoch 8138/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.8482 - val_loss: 566.3318\n",
      "Epoch 8139/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.7723 - val_loss: 567.7820\n",
      "Epoch 8140/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.4446 - val_loss: 567.1809\n",
      "Epoch 8141/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.4537 - val_loss: 566.4349\n",
      "Epoch 8142/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2437 - val_loss: 567.1034\n",
      "Epoch 8143/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.5241 - val_loss: 566.9567\n",
      "Epoch 8144/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.4936 - val_loss: 566.6247\n",
      "Epoch 8145/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.6199 - val_loss: 566.5131\n",
      "Epoch 8146/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.4552 - val_loss: 566.2551\n",
      "Epoch 8147/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.5111 - val_loss: 566.0430\n",
      "Epoch 8148/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.3454 - val_loss: 566.5591\n",
      "Epoch 8149/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2213 - val_loss: 566.4079\n",
      "Epoch 8150/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.7335 - val_loss: 565.8368\n",
      "Epoch 8151/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.7982 - val_loss: 566.8394\n",
      "Epoch 8152/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.0689 - val_loss: 565.9651\n",
      "Epoch 8153/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.6103 - val_loss: 566.2114\n",
      "Epoch 8154/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.2260 - val_loss: 566.7626\n",
      "Epoch 8155/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.7397 - val_loss: 565.5031\n",
      "Epoch 8156/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.5702 - val_loss: 566.0364\n",
      "Epoch 8157/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.2680 - val_loss: 565.7915\n",
      "Epoch 8158/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.4707 - val_loss: 565.5860\n",
      "Epoch 8159/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.6148 - val_loss: 566.4528\n",
      "Epoch 8160/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.3570 - val_loss: 566.7849\n",
      "Epoch 8161/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.3962 - val_loss: 566.8260\n",
      "Epoch 8162/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2478 - val_loss: 566.5375\n",
      "Epoch 8163/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.5045 - val_loss: 566.3222\n",
      "Epoch 8164/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.8144 - val_loss: 566.0344\n",
      "Epoch 8165/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.3655 - val_loss: 567.3784\n",
      "Epoch 8166/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.2601 - val_loss: 566.0599\n",
      "Epoch 8167/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.5667 - val_loss: 565.9112\n",
      "Epoch 8168/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.1766 - val_loss: 565.8748\n",
      "Epoch 8169/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.5195 - val_loss: 567.0705\n",
      "Epoch 8170/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.3114 - val_loss: 566.2114\n",
      "Epoch 8171/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.3257 - val_loss: 566.1117\n",
      "Epoch 8172/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.4017 - val_loss: 566.8019\n",
      "Epoch 8173/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.8842 - val_loss: 567.5154\n",
      "Epoch 8174/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.6272 - val_loss: 567.0235\n",
      "Epoch 8175/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.1281 - val_loss: 566.2170\n",
      "Epoch 8176/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.5679 - val_loss: 567.0532\n",
      "Epoch 8177/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.3067 - val_loss: 566.6463\n",
      "Epoch 8178/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.3723 - val_loss: 567.2510\n",
      "Epoch 8179/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.6809 - val_loss: 566.3633\n",
      "Epoch 8180/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.2508 - val_loss: 566.0673\n",
      "Epoch 8181/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.0288 - val_loss: 566.6802\n",
      "Epoch 8182/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.3326 - val_loss: 566.4013\n",
      "Epoch 8183/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.4845 - val_loss: 567.2796\n",
      "Epoch 8184/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.3801 - val_loss: 566.4068\n",
      "Epoch 8185/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2923 - val_loss: 565.9063\n",
      "Epoch 8186/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.4764 - val_loss: 566.1404\n",
      "Epoch 8187/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.1860 - val_loss: 566.5903\n",
      "Epoch 8188/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.4281 - val_loss: 565.9094\n",
      "Epoch 8189/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.7439 - val_loss: 565.9023\n",
      "Epoch 8190/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.1918 - val_loss: 566.6612\n",
      "Epoch 8191/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 469.9014 - val_loss: 566.1916\n",
      "Epoch 8192/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.3017 - val_loss: 565.9530\n",
      "Epoch 8193/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.2221 - val_loss: 567.0723\n",
      "Epoch 8194/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.4459 - val_loss: 566.8102\n",
      "Epoch 8195/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.5499 - val_loss: 565.8373\n",
      "Epoch 8196/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.9223 - val_loss: 566.3351\n",
      "Epoch 8197/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.1675 - val_loss: 566.3861\n",
      "Epoch 8198/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.1660 - val_loss: 565.8529\n",
      "Epoch 8199/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.5894 - val_loss: 566.3306\n",
      "Epoch 8200/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.5254 - val_loss: 566.1036\n",
      "Epoch 8201/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.1863 - val_loss: 566.4407\n",
      "Epoch 8202/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.1931 - val_loss: 565.6900\n",
      "Epoch 8203/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.3268 - val_loss: 566.6388\n",
      "Epoch 8204/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.9745 - val_loss: 566.3072\n",
      "Epoch 8205/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.3000 - val_loss: 565.8187\n",
      "Epoch 8206/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.9426 - val_loss: 566.8589\n",
      "Epoch 8207/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.2605 - val_loss: 565.9205\n",
      "Epoch 8208/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.4563 - val_loss: 566.8395\n",
      "Epoch 8209/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.9319 - val_loss: 566.1306\n",
      "Epoch 8210/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.0588 - val_loss: 566.0286\n",
      "Epoch 8211/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.3093 - val_loss: 565.5355\n",
      "Epoch 8212/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.5089 - val_loss: 566.8276\n",
      "Epoch 8213/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.5243 - val_loss: 565.4810\n",
      "Epoch 8214/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.4859 - val_loss: 566.9018\n",
      "Epoch 8215/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.2738 - val_loss: 566.6059\n",
      "Epoch 8216/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.2381 - val_loss: 567.3326\n",
      "Epoch 8217/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.8454 - val_loss: 566.0096\n",
      "Epoch 8218/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 470.2991 - val_loss: 566.8358\n",
      "Epoch 8219/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.2018 - val_loss: 567.8875\n",
      "Epoch 8220/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.2888 - val_loss: 566.2147\n",
      "Epoch 8221/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.4313 - val_loss: 567.1549\n",
      "Epoch 8222/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.1987 - val_loss: 566.0949\n",
      "Epoch 8223/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.6356 - val_loss: 567.1198\n",
      "Epoch 8224/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 469.9577 - val_loss: 566.8722\n",
      "Epoch 8225/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.2068 - val_loss: 566.4838\n",
      "Epoch 8226/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.1551 - val_loss: 566.6393\n",
      "Epoch 8227/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.2699 - val_loss: 566.1955\n",
      "Epoch 8228/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 471.3232 - val_loss: 566.4343\n",
      "Epoch 8229/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.2879 - val_loss: 566.0563\n",
      "Epoch 8230/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.3177 - val_loss: 566.4244\n",
      "Epoch 8231/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 470.7382 - val_loss: 566.0180\n",
      "Epoch 8232/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.2940 - val_loss: 566.0254\n",
      "Epoch 8233/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.2389 - val_loss: 567.0405\n",
      "Epoch 8234/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.0316 - val_loss: 566.4513\n",
      "Epoch 8235/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.9761 - val_loss: 565.9419\n",
      "Epoch 8236/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.3464 - val_loss: 565.4051\n",
      "Epoch 8237/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.1465 - val_loss: 566.3027\n",
      "Epoch 8238/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.1371 - val_loss: 565.9876\n",
      "Epoch 8239/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.3858 - val_loss: 566.1132\n",
      "Epoch 8240/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 469.9870 - val_loss: 566.4352\n",
      "Epoch 8241/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 471.1247 - val_loss: 566.5864\n",
      "Epoch 8242/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.9779 - val_loss: 566.2463\n",
      "Epoch 8243/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8782 - val_loss: 566.6296\n",
      "Epoch 8244/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.1701 - val_loss: 567.1506\n",
      "Epoch 8245/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.2536 - val_loss: 567.0682\n",
      "Epoch 8246/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.2201 - val_loss: 567.2788\n",
      "Epoch 8247/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.0604 - val_loss: 566.4350\n",
      "Epoch 8248/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.2841 - val_loss: 565.8513\n",
      "Epoch 8249/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.4289 - val_loss: 566.4378\n",
      "Epoch 8250/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 423.1152Epoch: 8250 - loss: 470.196340 - val_loss: 566.577787\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.1963 - val_loss: 566.5778\n",
      "Epoch 8251/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.3466 - val_loss: 565.3858\n",
      "Epoch 8252/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 469.9997 - val_loss: 567.1173\n",
      "Epoch 8253/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.3065 - val_loss: 566.9356\n",
      "Epoch 8254/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 470.2080 - val_loss: 566.0372\n",
      "Epoch 8255/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 470.4458 - val_loss: 566.5156\n",
      "Epoch 8256/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 470.3784 - val_loss: 566.3271\n",
      "Epoch 8257/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 469.8882 - val_loss: 565.8999\n",
      "Epoch 8258/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.0472 - val_loss: 566.0261\n",
      "Epoch 8259/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 469.9464 - val_loss: 565.9024\n",
      "Epoch 8260/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.2985 - val_loss: 565.9964\n",
      "Epoch 8261/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8027 - val_loss: 565.4087\n",
      "Epoch 8262/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.1785 - val_loss: 565.1792\n",
      "Epoch 8263/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.0633 - val_loss: 566.1184\n",
      "Epoch 8264/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.6293 - val_loss: 566.6976\n",
      "Epoch 8265/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.1397 - val_loss: 565.9949\n",
      "Epoch 8266/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8352 - val_loss: 566.0552\n",
      "Epoch 8267/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8911 - val_loss: 565.9860\n",
      "Epoch 8268/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8179 - val_loss: 565.6565\n",
      "Epoch 8269/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8815 - val_loss: 565.3677\n",
      "Epoch 8270/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.2850 - val_loss: 566.2582\n",
      "Epoch 8271/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.4727 - val_loss: 565.7136\n",
      "Epoch 8272/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.1575 - val_loss: 565.7713\n",
      "Epoch 8273/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.9924 - val_loss: 565.8728\n",
      "Epoch 8274/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.0590 - val_loss: 566.1143\n",
      "Epoch 8275/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.0494 - val_loss: 565.8471\n",
      "Epoch 8276/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 469.9527 - val_loss: 566.5632\n",
      "Epoch 8277/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.2276 - val_loss: 565.9195\n",
      "Epoch 8278/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.3120 - val_loss: 567.2342\n",
      "Epoch 8279/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 469.9480 - val_loss: 567.1783\n",
      "Epoch 8280/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 469.8558 - val_loss: 566.6525\n",
      "Epoch 8281/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.0057 - val_loss: 566.6558\n",
      "Epoch 8282/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 469.8580 - val_loss: 566.7076\n",
      "Epoch 8283/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 469.8589 - val_loss: 566.0901\n",
      "Epoch 8284/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 11us/sample - loss: 469.8489 - val_loss: 565.8362\n",
      "Epoch 8285/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 469.6957 - val_loss: 566.3846\n",
      "Epoch 8286/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.1933 - val_loss: 565.8504\n",
      "Epoch 8287/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8358 - val_loss: 566.0051\n",
      "Epoch 8288/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8442 - val_loss: 565.7432\n",
      "Epoch 8289/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.2034 - val_loss: 565.6919\n",
      "Epoch 8290/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.1537 - val_loss: 565.6571\n",
      "Epoch 8291/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8193 - val_loss: 565.8235\n",
      "Epoch 8292/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8359 - val_loss: 565.9401\n",
      "Epoch 8293/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.6535 - val_loss: 566.0008\n",
      "Epoch 8294/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 470.0653 - val_loss: 567.0331\n",
      "Epoch 8295/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 469.7793 - val_loss: 565.9970\n",
      "Epoch 8296/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.1989 - val_loss: 565.3405\n",
      "Epoch 8297/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.0679 - val_loss: 566.4823\n",
      "Epoch 8298/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.9741 - val_loss: 564.8505\n",
      "Epoch 8299/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.9285 - val_loss: 564.8287\n",
      "Epoch 8300/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.9921 - val_loss: 564.7322\n",
      "Epoch 8301/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.9481 - val_loss: 566.0682\n",
      "Epoch 8302/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8627 - val_loss: 565.6599\n",
      "Epoch 8303/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8172 - val_loss: 566.2031\n",
      "Epoch 8304/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.7913 - val_loss: 565.7569\n",
      "Epoch 8305/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.1860 - val_loss: 565.1936\n",
      "Epoch 8306/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8964 - val_loss: 565.5155\n",
      "Epoch 8307/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.1183 - val_loss: 565.7525\n",
      "Epoch 8308/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8348 - val_loss: 565.6577\n",
      "Epoch 8309/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.1729 - val_loss: 565.9902\n",
      "Epoch 8310/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6128 - val_loss: 565.5442\n",
      "Epoch 8311/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8759 - val_loss: 565.2733\n",
      "Epoch 8312/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 469.6844 - val_loss: 565.1545\n",
      "Epoch 8313/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.7623 - val_loss: 565.2434\n",
      "Epoch 8314/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.9986 - val_loss: 566.0871\n",
      "Epoch 8315/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6096 - val_loss: 566.2987\n",
      "Epoch 8316/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.7115 - val_loss: 566.1899\n",
      "Epoch 8317/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.7091 - val_loss: 566.3683\n",
      "Epoch 8318/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.2533 - val_loss: 566.2026\n",
      "Epoch 8319/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.3813 - val_loss: 565.3226\n",
      "Epoch 8320/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.7155 - val_loss: 566.6665\n",
      "Epoch 8321/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5650 - val_loss: 566.0424\n",
      "Epoch 8322/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.5195 - val_loss: 564.7709\n",
      "Epoch 8323/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.3273 - val_loss: 565.9493\n",
      "Epoch 8324/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.2872 - val_loss: 567.2656\n",
      "Epoch 8325/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 470.4488 - val_loss: 566.1880\n",
      "Epoch 8326/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.9843 - val_loss: 565.8103\n",
      "Epoch 8327/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.8411 - val_loss: 565.5046\n",
      "Epoch 8328/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.3436 - val_loss: 566.1007\n",
      "Epoch 8329/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 469.9565 - val_loss: 566.7237\n",
      "Epoch 8330/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 469.9679 - val_loss: 565.7395\n",
      "Epoch 8331/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 469.6319 - val_loss: 565.8970\n",
      "Epoch 8332/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 469.6186 - val_loss: 566.4331\n",
      "Epoch 8333/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8089 - val_loss: 566.4818\n",
      "Epoch 8334/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.3796 - val_loss: 566.0218\n",
      "Epoch 8335/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 470.0692 - val_loss: 566.1105\n",
      "Epoch 8336/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.7055 - val_loss: 565.7602\n",
      "Epoch 8337/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8596 - val_loss: 566.0688\n",
      "Epoch 8338/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5826 - val_loss: 565.8688\n",
      "Epoch 8339/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 471.1798 - val_loss: 567.0737\n",
      "Epoch 8340/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.9099 - val_loss: 565.6045\n",
      "Epoch 8341/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.6629 - val_loss: 566.6942\n",
      "Epoch 8342/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8353 - val_loss: 565.5536\n",
      "Epoch 8343/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8367 - val_loss: 565.3448\n",
      "Epoch 8344/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8149 - val_loss: 566.2375\n",
      "Epoch 8345/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.9154 - val_loss: 566.7730\n",
      "Epoch 8346/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 469.6229 - val_loss: 566.0906\n",
      "Epoch 8347/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.7880 - val_loss: 565.4470\n",
      "Epoch 8348/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8922 - val_loss: 565.4826\n",
      "Epoch 8349/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 469.5773 - val_loss: 565.3846\n",
      "Epoch 8350/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.1798 - val_loss: 565.3536\n",
      "Epoch 8351/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5700 - val_loss: 565.8826\n",
      "Epoch 8352/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.0786 - val_loss: 565.4533\n",
      "Epoch 8353/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4543 - val_loss: 564.4650\n",
      "Epoch 8354/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.2330 - val_loss: 564.4564\n",
      "Epoch 8355/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4462 - val_loss: 565.3348\n",
      "Epoch 8356/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.3859 - val_loss: 565.7981\n",
      "Epoch 8357/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6339 - val_loss: 565.8505\n",
      "Epoch 8358/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.7072 - val_loss: 565.9909\n",
      "Epoch 8359/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6452 - val_loss: 565.7281\n",
      "Epoch 8360/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.9246 - val_loss: 566.0609\n",
      "Epoch 8361/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8232 - val_loss: 565.8683\n",
      "Epoch 8362/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5623 - val_loss: 566.4441\n",
      "Epoch 8363/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.9480 - val_loss: 566.0542\n",
      "Epoch 8364/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.7991 - val_loss: 566.3930\n",
      "Epoch 8365/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.7925 - val_loss: 565.6371\n",
      "Epoch 8366/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.4716 - val_loss: 565.7904\n",
      "Epoch 8367/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.9805 - val_loss: 565.9023\n",
      "Epoch 8368/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5794 - val_loss: 565.6262\n",
      "Epoch 8369/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.9781 - val_loss: 566.0704\n",
      "Epoch 8370/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.7905 - val_loss: 565.8970\n",
      "Epoch 8371/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6718 - val_loss: 565.0871\n",
      "Epoch 8372/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.7332 - val_loss: 565.6217\n",
      "Epoch 8373/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.4372 - val_loss: 564.7284\n",
      "Epoch 8374/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.1137 - val_loss: 566.0245\n",
      "Epoch 8375/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.9508 - val_loss: 565.3861\n",
      "Epoch 8376/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.7916 - val_loss: 565.2879\n",
      "Epoch 8377/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5870 - val_loss: 565.0689\n",
      "Epoch 8378/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5922 - val_loss: 565.3601\n",
      "Epoch 8379/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5849 - val_loss: 565.4483\n",
      "Epoch 8380/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.7350 - val_loss: 565.3186\n",
      "Epoch 8381/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6411 - val_loss: 565.5449\n",
      "Epoch 8382/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8441 - val_loss: 565.8932\n",
      "Epoch 8383/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5534 - val_loss: 564.9713\n",
      "Epoch 8384/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8068 - val_loss: 565.7986\n",
      "Epoch 8385/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5951 - val_loss: 565.2655\n",
      "Epoch 8386/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6341 - val_loss: 565.1610\n",
      "Epoch 8387/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5089 - val_loss: 565.3095\n",
      "Epoch 8388/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5752 - val_loss: 565.0250\n",
      "Epoch 8389/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6905 - val_loss: 565.7130\n",
      "Epoch 8390/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5317 - val_loss: 565.8919\n",
      "Epoch 8391/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.7284 - val_loss: 565.4013\n",
      "Epoch 8392/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.7442 - val_loss: 566.1560\n",
      "Epoch 8393/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.3765 - val_loss: 564.8602\n",
      "Epoch 8394/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6316 - val_loss: 565.0471\n",
      "Epoch 8395/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5185 - val_loss: 565.2340\n",
      "Epoch 8396/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.3913 - val_loss: 565.0256\n",
      "Epoch 8397/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8968 - val_loss: 565.8005\n",
      "Epoch 8398/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6084 - val_loss: 565.0622\n",
      "Epoch 8399/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6145 - val_loss: 565.0212\n",
      "Epoch 8400/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.4052 - val_loss: 564.9777\n",
      "Epoch 8401/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.3883 - val_loss: 565.5809\n",
      "Epoch 8402/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6293 - val_loss: 566.0502\n",
      "Epoch 8403/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5562 - val_loss: 565.2614\n",
      "Epoch 8404/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.9933 - val_loss: 565.4005\n",
      "Epoch 8405/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4862 - val_loss: 565.2159\n",
      "Epoch 8406/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.7088 - val_loss: 564.6456\n",
      "Epoch 8407/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.3639 - val_loss: 566.3204\n",
      "Epoch 8408/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.7252 - val_loss: 566.2115\n",
      "Epoch 8409/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8313 - val_loss: 565.4646\n",
      "Epoch 8410/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6809 - val_loss: 565.7664\n",
      "Epoch 8411/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6868 - val_loss: 565.7405\n",
      "Epoch 8412/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6405 - val_loss: 565.1355\n",
      "Epoch 8413/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4639 - val_loss: 564.8633\n",
      "Epoch 8414/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4839 - val_loss: 565.4537\n",
      "Epoch 8415/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8508 - val_loss: 565.5560\n",
      "Epoch 8416/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6021 - val_loss: 565.9193\n",
      "Epoch 8417/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.0633 - val_loss: 565.0906\n",
      "Epoch 8418/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8074 - val_loss: 565.2618\n",
      "Epoch 8419/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4066 - val_loss: 564.9848\n",
      "Epoch 8420/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4206 - val_loss: 565.0702\n",
      "Epoch 8421/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.1966 - val_loss: 565.3565\n",
      "Epoch 8422/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8705 - val_loss: 565.4082\n",
      "Epoch 8423/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.9852 - val_loss: 565.9347\n",
      "Epoch 8424/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.7337 - val_loss: 566.6523\n",
      "Epoch 8425/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8267 - val_loss: 566.2169\n",
      "Epoch 8426/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6881 - val_loss: 565.8356\n",
      "Epoch 8427/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.7919 - val_loss: 565.7436\n",
      "Epoch 8428/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4685 - val_loss: 566.2716\n",
      "Epoch 8429/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.9159 - val_loss: 566.1110\n",
      "Epoch 8430/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8535 - val_loss: 566.2370\n",
      "Epoch 8431/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5763 - val_loss: 565.8115\n",
      "Epoch 8432/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6408 - val_loss: 564.8041\n",
      "Epoch 8433/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6177 - val_loss: 566.0386\n",
      "Epoch 8434/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8776 - val_loss: 565.7215\n",
      "Epoch 8435/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.3436 - val_loss: 565.2549\n",
      "Epoch 8436/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4777 - val_loss: 564.9916\n",
      "Epoch 8437/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5967 - val_loss: 565.8523\n",
      "Epoch 8438/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4505 - val_loss: 565.5898\n",
      "Epoch 8439/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5659 - val_loss: 565.1686\n",
      "Epoch 8440/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5916 - val_loss: 564.8841\n",
      "Epoch 8441/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5616 - val_loss: 565.6682\n",
      "Epoch 8442/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.7044 - val_loss: 565.4523\n",
      "Epoch 8443/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5365 - val_loss: 565.7213\n",
      "Epoch 8444/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.9668 - val_loss: 565.4391\n",
      "Epoch 8445/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4126 - val_loss: 566.1415\n",
      "Epoch 8446/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4482 - val_loss: 565.1793\n",
      "Epoch 8447/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6093 - val_loss: 565.1521\n",
      "Epoch 8448/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4322 - val_loss: 565.4111\n",
      "Epoch 8449/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4986 - val_loss: 565.3099\n",
      "Epoch 8450/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4358 - val_loss: 566.1743\n",
      "Epoch 8451/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.7443 - val_loss: 565.4249\n",
      "Epoch 8452/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5224 - val_loss: 565.3750\n",
      "Epoch 8453/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 469.3410 - val_loss: 565.5242\n",
      "Epoch 8454/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4476 - val_loss: 565.7173\n",
      "Epoch 8455/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.4027 - val_loss: 566.4824\n",
      "Epoch 8456/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4615 - val_loss: 564.8929\n",
      "Epoch 8457/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8311 - val_loss: 566.3535\n",
      "Epoch 8458/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5819 - val_loss: 565.4378\n",
      "Epoch 8459/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.3891 - val_loss: 565.3827\n",
      "Epoch 8460/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.0404 - val_loss: 565.7855\n",
      "Epoch 8461/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2441 - val_loss: 565.2359\n",
      "Epoch 8462/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5330 - val_loss: 565.1812\n",
      "Epoch 8463/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4278 - val_loss: 565.0346\n",
      "Epoch 8464/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.0362 - val_loss: 564.7416\n",
      "Epoch 8465/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 469.4453 - val_loss: 564.8447\n",
      "Epoch 8466/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.1216 - val_loss: 565.3648\n",
      "Epoch 8467/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.3780 - val_loss: 566.0381\n",
      "Epoch 8468/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.3068 - val_loss: 565.7206\n",
      "Epoch 8469/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5475 - val_loss: 565.5852\n",
      "Epoch 8470/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4429 - val_loss: 564.8308\n",
      "Epoch 8471/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 469.4328 - val_loss: 565.2877\n",
      "Epoch 8472/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2705 - val_loss: 565.3030\n",
      "Epoch 8473/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.7131 - val_loss: 565.0136\n",
      "Epoch 8474/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2573 - val_loss: 564.5606\n",
      "Epoch 8475/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5263 - val_loss: 564.8770\n",
      "Epoch 8476/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4369 - val_loss: 564.6165\n",
      "Epoch 8477/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.3978 - val_loss: 565.2960\n",
      "Epoch 8478/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4629 - val_loss: 564.9824\n",
      "Epoch 8479/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.9913 - val_loss: 565.2335\n",
      "Epoch 8480/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.3085 - val_loss: 565.4915\n",
      "Epoch 8481/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.3865 - val_loss: 564.3435\n",
      "Epoch 8482/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4825 - val_loss: 565.8263\n",
      "Epoch 8483/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4296 - val_loss: 564.4690\n",
      "Epoch 8484/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 469.5133 - val_loss: 564.5243\n",
      "Epoch 8485/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6504 - val_loss: 565.4326\n",
      "Epoch 8486/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4215 - val_loss: 565.9399\n",
      "Epoch 8487/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5081 - val_loss: 565.3856\n",
      "Epoch 8488/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6089 - val_loss: 564.6852\n",
      "Epoch 8489/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4219 - val_loss: 565.2334\n",
      "Epoch 8490/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2970 - val_loss: 565.1175\n",
      "Epoch 8491/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2684 - val_loss: 565.0669\n",
      "Epoch 8492/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.9662 - val_loss: 565.3215\n",
      "Epoch 8493/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2069 - val_loss: 565.6279\n",
      "Epoch 8494/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.0919 - val_loss: 565.1361\n",
      "Epoch 8495/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6354 - val_loss: 565.4127\n",
      "Epoch 8496/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.7122 - val_loss: 565.3685\n",
      "Epoch 8497/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2118 - val_loss: 565.5360\n",
      "Epoch 8498/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5464 - val_loss: 565.0977\n",
      "Epoch 8499/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5176 - val_loss: 565.2751\n",
      "Epoch 8500/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 584.9371Epoch: 8500 - loss: 470.250547 - val_loss: 565.963511\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.2505 - val_loss: 565.9635\n",
      "Epoch 8501/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8526 - val_loss: 565.5030\n",
      "Epoch 8502/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.3862 - val_loss: 565.5613\n",
      "Epoch 8503/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 469.5586 - val_loss: 565.0406\n",
      "Epoch 8504/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2883 - val_loss: 565.1134\n",
      "Epoch 8505/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.7708 - val_loss: 564.2278\n",
      "Epoch 8506/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8623 - val_loss: 565.7905\n",
      "Epoch 8507/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5459 - val_loss: 563.9623\n",
      "Epoch 8508/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 469.3928 - val_loss: 564.9179\n",
      "Epoch 8509/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.0122 - val_loss: 564.8541\n",
      "Epoch 8510/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.3690 - val_loss: 565.0688\n",
      "Epoch 8511/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4549 - val_loss: 565.1206\n",
      "Epoch 8512/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5865 - val_loss: 565.2721\n",
      "Epoch 8513/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.3921 - val_loss: 564.3096\n",
      "Epoch 8514/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.3961 - val_loss: 564.7669\n",
      "Epoch 8515/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1824 - val_loss: 564.5639\n",
      "Epoch 8516/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4770 - val_loss: 564.4091\n",
      "Epoch 8517/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1784 - val_loss: 564.7004\n",
      "Epoch 8518/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5091 - val_loss: 564.8442\n",
      "Epoch 8519/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1942 - val_loss: 564.3436\n",
      "Epoch 8520/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2348 - val_loss: 564.7245\n",
      "Epoch 8521/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4321 - val_loss: 565.3990\n",
      "Epoch 8522/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1648 - val_loss: 565.0498\n",
      "Epoch 8523/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2269 - val_loss: 565.7817\n",
      "Epoch 8524/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2374 - val_loss: 565.3100\n",
      "Epoch 8525/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4598 - val_loss: 564.4916\n",
      "Epoch 8526/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4186 - val_loss: 564.7177\n",
      "Epoch 8527/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5412 - val_loss: 564.5891\n",
      "Epoch 8528/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2534 - val_loss: 565.1426\n",
      "Epoch 8529/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5767 - val_loss: 565.1307\n",
      "Epoch 8530/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.0899 - val_loss: 564.7462\n",
      "Epoch 8531/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6203 - val_loss: 565.3700\n",
      "Epoch 8532/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.3073 - val_loss: 564.2283\n",
      "Epoch 8533/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.0662 - val_loss: 565.0271\n",
      "Epoch 8534/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6474 - val_loss: 563.8493\n",
      "Epoch 8535/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1703 - val_loss: 565.3115\n",
      "Epoch 8536/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.3267 - val_loss: 564.6087\n",
      "Epoch 8537/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2332 - val_loss: 564.4539\n",
      "Epoch 8538/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5020 - val_loss: 564.5762\n",
      "Epoch 8539/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.7801 - val_loss: 565.0757\n",
      "Epoch 8540/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8730 - val_loss: 563.7514\n",
      "Epoch 8541/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.3490 - val_loss: 564.1980\n",
      "Epoch 8542/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6566 - val_loss: 564.0452\n",
      "Epoch 8543/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1182 - val_loss: 564.2994\n",
      "Epoch 8544/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.7137 - val_loss: 563.8595\n",
      "Epoch 8545/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2629 - val_loss: 564.8956\n",
      "Epoch 8546/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.0410 - val_loss: 564.6324\n",
      "Epoch 8547/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2006 - val_loss: 564.8496\n",
      "Epoch 8548/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2869 - val_loss: 564.8025\n",
      "Epoch 8549/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.3206 - val_loss: 564.5521\n",
      "Epoch 8550/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5536 - val_loss: 564.7683\n",
      "Epoch 8551/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2042 - val_loss: 564.5569\n",
      "Epoch 8552/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.0214 - val_loss: 564.8007\n",
      "Epoch 8553/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4585 - val_loss: 563.9876\n",
      "Epoch 8554/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9123 - val_loss: 565.0762\n",
      "Epoch 8555/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.3650 - val_loss: 564.2815\n",
      "Epoch 8556/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9387 - val_loss: 564.3209\n",
      "Epoch 8557/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1113 - val_loss: 564.4154\n",
      "Epoch 8558/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 469.4140 - val_loss: 564.3979\n",
      "Epoch 8559/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 469.4084 - val_loss: 564.6016\n",
      "Epoch 8560/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.3440 - val_loss: 565.1686\n",
      "Epoch 8561/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6492 - val_loss: 565.5276\n",
      "Epoch 8562/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9910 - val_loss: 564.5587\n",
      "Epoch 8563/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6383 - val_loss: 564.9745\n",
      "Epoch 8564/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1299 - val_loss: 563.8373\n",
      "Epoch 8565/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2318 - val_loss: 564.0081\n",
      "Epoch 8566/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.8292 - val_loss: 564.7241\n",
      "Epoch 8567/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1584 - val_loss: 565.2875\n",
      "Epoch 8568/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 468.9211 - val_loss: 564.8329\n",
      "Epoch 8569/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6460 - val_loss: 564.9660\n",
      "Epoch 8570/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2079 - val_loss: 564.5926\n",
      "Epoch 8571/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.8498 - val_loss: 564.9752\n",
      "Epoch 8572/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.7030 - val_loss: 565.0180\n",
      "Epoch 8573/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2827 - val_loss: 565.3293\n",
      "Epoch 8574/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2185 - val_loss: 564.6110\n",
      "Epoch 8575/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9403 - val_loss: 565.1963\n",
      "Epoch 8576/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2538 - val_loss: 565.4153\n",
      "Epoch 8577/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1349 - val_loss: 564.8611\n",
      "Epoch 8578/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9893 - val_loss: 564.9763\n",
      "Epoch 8579/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4862 - val_loss: 565.3931\n",
      "Epoch 8580/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9549 - val_loss: 565.2826\n",
      "Epoch 8581/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1940 - val_loss: 565.1773\n",
      "Epoch 8582/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.3397 - val_loss: 565.7305\n",
      "Epoch 8583/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1451 - val_loss: 564.9533\n",
      "Epoch 8584/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2904 - val_loss: 565.2545\n",
      "Epoch 8585/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6045 - val_loss: 565.5758\n",
      "Epoch 8586/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.0904 - val_loss: 564.9053\n",
      "Epoch 8587/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.0905 - val_loss: 564.9934\n",
      "Epoch 8588/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.8023 - val_loss: 564.5839\n",
      "Epoch 8589/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2418 - val_loss: 565.1813\n",
      "Epoch 8590/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1542 - val_loss: 565.1798\n",
      "Epoch 8591/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2165 - val_loss: 564.9975\n",
      "Epoch 8592/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6452 - val_loss: 564.8010\n",
      "Epoch 8593/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.6373 - val_loss: 566.6026\n",
      "Epoch 8594/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.3004 - val_loss: 564.6124\n",
      "Epoch 8595/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.0646 - val_loss: 565.1335\n",
      "Epoch 8596/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9354 - val_loss: 564.3263\n",
      "Epoch 8597/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1740 - val_loss: 564.3125\n",
      "Epoch 8598/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2916 - val_loss: 564.8473\n",
      "Epoch 8599/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1369 - val_loss: 564.3388\n",
      "Epoch 8600/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1763 - val_loss: 564.1782\n",
      "Epoch 8601/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2006 - val_loss: 564.6348\n",
      "Epoch 8602/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9513 - val_loss: 564.5204\n",
      "Epoch 8603/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2854 - val_loss: 564.7505\n",
      "Epoch 8604/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1355 - val_loss: 564.2581\n",
      "Epoch 8605/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4223 - val_loss: 564.8041\n",
      "Epoch 8606/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9943 - val_loss: 563.7105\n",
      "Epoch 8607/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9869 - val_loss: 564.0472\n",
      "Epoch 8608/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.0824 - val_loss: 564.3648\n",
      "Epoch 8609/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2970 - val_loss: 563.9752\n",
      "Epoch 8610/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.0752 - val_loss: 563.6169\n",
      "Epoch 8611/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5037 - val_loss: 564.0302\n",
      "Epoch 8612/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2395 - val_loss: 563.7220\n",
      "Epoch 8613/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5301 - val_loss: 564.1063\n",
      "Epoch 8614/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7113 - val_loss: 564.1993\n",
      "Epoch 8615/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7997 - val_loss: 564.7425\n",
      "Epoch 8616/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.8990 - val_loss: 563.7963\n",
      "Epoch 8617/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1292 - val_loss: 563.9479\n",
      "Epoch 8618/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.8823 - val_loss: 565.0675\n",
      "Epoch 8619/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.8253 - val_loss: 564.6020\n",
      "Epoch 8620/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9187 - val_loss: 563.8553\n",
      "Epoch 8621/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2758 - val_loss: 565.1177\n",
      "Epoch 8622/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.0843 - val_loss: 565.0728\n",
      "Epoch 8623/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.3531 - val_loss: 563.9369\n",
      "Epoch 8624/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4396 - val_loss: 565.0228\n",
      "Epoch 8625/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.8499 - val_loss: 564.0968\n",
      "Epoch 8626/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.0025 - val_loss: 564.5301\n",
      "Epoch 8627/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9227 - val_loss: 564.9317\n",
      "Epoch 8628/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6369 - val_loss: 563.9598\n",
      "Epoch 8629/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.8153 - val_loss: 565.1814\n",
      "Epoch 8630/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 470.9783 - val_loss: 565.2399\n",
      "Epoch 8631/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.3499 - val_loss: 564.8878\n",
      "Epoch 8632/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6831 - val_loss: 564.0751\n",
      "Epoch 8633/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7608 - val_loss: 563.9989\n",
      "Epoch 8634/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.3234 - val_loss: 564.2865\n",
      "Epoch 8635/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.0385 - val_loss: 564.3580\n",
      "Epoch 8636/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.0059 - val_loss: 564.3109\n",
      "Epoch 8637/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2982 - val_loss: 563.6836\n",
      "Epoch 8638/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9282 - val_loss: 564.3773\n",
      "Epoch 8639/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.0115 - val_loss: 564.3140\n",
      "Epoch 8640/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2415 - val_loss: 563.5460\n",
      "Epoch 8641/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9276 - val_loss: 564.3532\n",
      "Epoch 8642/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.0550 - val_loss: 564.5255\n",
      "Epoch 8643/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.0545 - val_loss: 564.5594\n",
      "Epoch 8644/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9220 - val_loss: 564.3770\n",
      "Epoch 8645/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.0835 - val_loss: 565.0076\n",
      "Epoch 8646/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4407 - val_loss: 564.3572\n",
      "Epoch 8647/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2396 - val_loss: 564.5945\n",
      "Epoch 8648/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.3694 - val_loss: 565.2866\n",
      "Epoch 8649/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5692 - val_loss: 564.4041\n",
      "Epoch 8650/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.0445 - val_loss: 564.3513\n",
      "Epoch 8651/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9729 - val_loss: 564.0405\n",
      "Epoch 8652/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9528 - val_loss: 564.3604\n",
      "Epoch 8653/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9635 - val_loss: 564.1367\n",
      "Epoch 8654/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9026 - val_loss: 564.6588\n",
      "Epoch 8655/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2789 - val_loss: 564.4194\n",
      "Epoch 8656/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4422 - val_loss: 564.8434\n",
      "Epoch 8657/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5611 - val_loss: 565.2604\n",
      "Epoch 8658/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9421 - val_loss: 564.9386\n",
      "Epoch 8659/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9857 - val_loss: 564.9749\n",
      "Epoch 8660/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5107 - val_loss: 564.6563\n",
      "Epoch 8661/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9364 - val_loss: 564.8111\n",
      "Epoch 8662/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.0411 - val_loss: 564.6026\n",
      "Epoch 8663/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.0485 - val_loss: 564.4993\n",
      "Epoch 8664/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.8797 - val_loss: 565.5078\n",
      "Epoch 8665/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1638 - val_loss: 565.2928\n",
      "Epoch 8666/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.8357 - val_loss: 564.0888\n",
      "Epoch 8667/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1215 - val_loss: 564.6357\n",
      "Epoch 8668/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5733 - val_loss: 564.7050\n",
      "Epoch 8669/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1763 - val_loss: 564.1444\n",
      "Epoch 8670/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5079 - val_loss: 563.4304\n",
      "Epoch 8671/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.0273 - val_loss: 564.6737\n",
      "Epoch 8672/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.3237 - val_loss: 564.1414\n",
      "Epoch 8673/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.0126 - val_loss: 564.2167\n",
      "Epoch 8674/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1324 - val_loss: 564.3704\n",
      "Epoch 8675/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2285 - val_loss: 563.5479\n",
      "Epoch 8676/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5992 - val_loss: 564.0228\n",
      "Epoch 8677/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7133 - val_loss: 563.8396\n",
      "Epoch 8678/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2978 - val_loss: 562.5771\n",
      "Epoch 8679/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7209 - val_loss: 563.8691\n",
      "Epoch 8680/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9159 - val_loss: 564.9105\n",
      "Epoch 8681/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9681 - val_loss: 564.7907\n",
      "Epoch 8682/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9440 - val_loss: 563.7391\n",
      "Epoch 8683/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1463 - val_loss: 564.0597\n",
      "Epoch 8684/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9489 - val_loss: 563.4271\n",
      "Epoch 8685/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.3884 - val_loss: 564.4284\n",
      "Epoch 8686/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4361 - val_loss: 564.2464\n",
      "Epoch 8687/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.0103 - val_loss: 564.8645\n",
      "Epoch 8688/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7733 - val_loss: 563.9938\n",
      "Epoch 8689/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6350 - val_loss: 564.0892\n",
      "Epoch 8690/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6041 - val_loss: 564.0417\n",
      "Epoch 8691/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.0726 - val_loss: 564.9741\n",
      "Epoch 8692/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7971 - val_loss: 564.0590\n",
      "Epoch 8693/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.8333 - val_loss: 564.9740\n",
      "Epoch 8694/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.8981 - val_loss: 564.9645\n",
      "Epoch 8695/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6367 - val_loss: 564.7292\n",
      "Epoch 8696/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.8413 - val_loss: 564.5279\n",
      "Epoch 8697/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1119 - val_loss: 564.2404\n",
      "Epoch 8698/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9725 - val_loss: 563.9995\n",
      "Epoch 8699/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.8291 - val_loss: 565.0039\n",
      "Epoch 8700/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4849 - val_loss: 564.5147\n",
      "Epoch 8701/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.8504 - val_loss: 564.8938\n",
      "Epoch 8702/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6451 - val_loss: 564.4780\n",
      "Epoch 8703/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9250 - val_loss: 564.7405\n",
      "Epoch 8704/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1058 - val_loss: 563.9894\n",
      "Epoch 8705/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7048 - val_loss: 564.3871\n",
      "Epoch 8706/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.4020 - val_loss: 565.4439\n",
      "Epoch 8707/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.8188 - val_loss: 563.9756\n",
      "Epoch 8708/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.8036 - val_loss: 564.0786\n",
      "Epoch 8709/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1834 - val_loss: 564.7208\n",
      "Epoch 8710/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 468.9239 - val_loss: 564.5850\n",
      "Epoch 8711/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.0815 - val_loss: 563.9883\n",
      "Epoch 8712/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2927 - val_loss: 565.0785\n",
      "Epoch 8713/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7274 - val_loss: 564.3298\n",
      "Epoch 8714/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 468.7623 - val_loss: 564.0387\n",
      "Epoch 8715/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2016 - val_loss: 564.3970\n",
      "Epoch 8716/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9180 - val_loss: 565.0364\n",
      "Epoch 8717/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1455 - val_loss: 564.1025\n",
      "Epoch 8718/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9550 - val_loss: 564.1572\n",
      "Epoch 8719/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.5887 - val_loss: 563.6622\n",
      "Epoch 8720/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4470 - val_loss: 564.7508\n",
      "Epoch 8721/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5289 - val_loss: 564.9039\n",
      "Epoch 8722/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5343 - val_loss: 564.1870\n",
      "Epoch 8723/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1157 - val_loss: 563.6559\n",
      "Epoch 8724/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7965 - val_loss: 563.8718\n",
      "Epoch 8725/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.8832 - val_loss: 564.5465\n",
      "Epoch 8726/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4244 - val_loss: 564.4215\n",
      "Epoch 8727/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6994 - val_loss: 564.2256\n",
      "Epoch 8728/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.8675 - val_loss: 564.3260\n",
      "Epoch 8729/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6724 - val_loss: 563.9573\n",
      "Epoch 8730/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6633 - val_loss: 564.3950\n",
      "Epoch 8731/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6408 - val_loss: 563.2161\n",
      "Epoch 8732/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7523 - val_loss: 564.0447\n",
      "Epoch 8733/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5759 - val_loss: 563.9852\n",
      "Epoch 8734/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.8349 - val_loss: 564.0212\n",
      "Epoch 8735/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7906 - val_loss: 563.2646\n",
      "Epoch 8736/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9569 - val_loss: 563.5581\n",
      "Epoch 8737/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 468.6195 - val_loss: 564.0780\n",
      "Epoch 8738/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7542 - val_loss: 564.1157\n",
      "Epoch 8739/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6601 - val_loss: 563.8342\n",
      "Epoch 8740/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9320 - val_loss: 564.5226\n",
      "Epoch 8741/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.0708 - val_loss: 563.3725\n",
      "Epoch 8742/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7970 - val_loss: 563.8408\n",
      "Epoch 8743/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5295 - val_loss: 563.4372\n",
      "Epoch 8744/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1062 - val_loss: 564.8932\n",
      "Epoch 8745/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4709 - val_loss: 564.3794\n",
      "Epoch 8746/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6433 - val_loss: 564.1295\n",
      "Epoch 8747/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7901 - val_loss: 564.0542\n",
      "Epoch 8748/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6280 - val_loss: 564.8103\n",
      "Epoch 8749/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7495 - val_loss: 564.7105\n",
      "Epoch 8750/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 413.0751Epoch: 8750 - loss: 468.654580 - val_loss: 565.019813\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6546 - val_loss: 565.0198\n",
      "Epoch 8751/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.8223 - val_loss: 564.4498\n",
      "Epoch 8752/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7208 - val_loss: 564.5874\n",
      "Epoch 8753/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4636 - val_loss: 564.4073\n",
      "Epoch 8754/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4702 - val_loss: 565.1338\n",
      "Epoch 8755/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7355 - val_loss: 564.9177\n",
      "Epoch 8756/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6150 - val_loss: 564.7550\n",
      "Epoch 8757/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6746 - val_loss: 564.5842\n",
      "Epoch 8758/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5331 - val_loss: 564.6564\n",
      "Epoch 8759/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 468.8309 - val_loss: 564.3491\n",
      "Epoch 8760/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5515 - val_loss: 564.1004\n",
      "Epoch 8761/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6220 - val_loss: 564.2243\n",
      "Epoch 8762/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5860 - val_loss: 564.6176\n",
      "Epoch 8763/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1483 - val_loss: 565.3085\n",
      "Epoch 8764/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6108 - val_loss: 564.3484\n",
      "Epoch 8765/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6372 - val_loss: 564.7059\n",
      "Epoch 8766/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6082 - val_loss: 564.6870\n",
      "Epoch 8767/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.3711 - val_loss: 564.2465\n",
      "Epoch 8768/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4416 - val_loss: 564.6315\n",
      "Epoch 8769/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1638 - val_loss: 564.3556\n",
      "Epoch 8770/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4597 - val_loss: 564.7181\n",
      "Epoch 8771/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7315 - val_loss: 564.8437\n",
      "Epoch 8772/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4096 - val_loss: 563.9345\n",
      "Epoch 8773/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4298 - val_loss: 564.1166\n",
      "Epoch 8774/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9687 - val_loss: 564.2046\n",
      "Epoch 8775/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6134 - val_loss: 564.1632\n",
      "Epoch 8776/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7338 - val_loss: 563.2105\n",
      "Epoch 8777/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7405 - val_loss: 564.7610\n",
      "Epoch 8778/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5256 - val_loss: 564.3572\n",
      "Epoch 8779/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4895 - val_loss: 563.7742\n",
      "Epoch 8780/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7618 - val_loss: 563.5765\n",
      "Epoch 8781/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5425 - val_loss: 564.0387\n",
      "Epoch 8782/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5081 - val_loss: 563.8692\n",
      "Epoch 8783/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6142 - val_loss: 563.9118\n",
      "Epoch 8784/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6754 - val_loss: 564.1554\n",
      "Epoch 8785/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7979 - val_loss: 564.3084\n",
      "Epoch 8786/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5863 - val_loss: 563.6734\n",
      "Epoch 8787/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6434 - val_loss: 563.1618\n",
      "Epoch 8788/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.2760 - val_loss: 562.8568\n",
      "Epoch 8789/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5831 - val_loss: 563.1898\n",
      "Epoch 8790/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.8905 - val_loss: 563.7597\n",
      "Epoch 8791/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7961 - val_loss: 564.0848\n",
      "Epoch 8792/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.3265 - val_loss: 563.4841\n",
      "Epoch 8793/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.3971 - val_loss: 563.5574\n",
      "Epoch 8794/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5129 - val_loss: 563.0798\n",
      "Epoch 8795/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6860 - val_loss: 563.3376\n",
      "Epoch 8796/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6592 - val_loss: 564.0810\n",
      "Epoch 8797/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7199 - val_loss: 563.5584\n",
      "Epoch 8798/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5952 - val_loss: 563.0209\n",
      "Epoch 8799/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.0323 - val_loss: 562.5883\n",
      "Epoch 8800/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.0725 - val_loss: 564.8940\n",
      "Epoch 8801/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9588 - val_loss: 563.6759\n",
      "Epoch 8802/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9063 - val_loss: 564.0334\n",
      "Epoch 8803/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.8154 - val_loss: 563.8448\n",
      "Epoch 8804/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.8892 - val_loss: 563.9849\n",
      "Epoch 8805/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.3357 - val_loss: 563.7893\n",
      "Epoch 8806/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.3879 - val_loss: 564.2453\n",
      "Epoch 8807/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7084 - val_loss: 563.5248\n",
      "Epoch 8808/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6006 - val_loss: 563.1273\n",
      "Epoch 8809/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1741 - val_loss: 563.5146\n",
      "Epoch 8810/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1125 - val_loss: 564.1410\n",
      "Epoch 8811/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.3794 - val_loss: 563.7492\n",
      "Epoch 8812/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4716 - val_loss: 563.2023\n",
      "Epoch 8813/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4758 - val_loss: 564.4096\n",
      "Epoch 8814/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4310 - val_loss: 563.8239\n",
      "Epoch 8815/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5887 - val_loss: 563.6239\n",
      "Epoch 8816/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.3140 - val_loss: 563.7203\n",
      "Epoch 8817/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5039 - val_loss: 563.5196\n",
      "Epoch 8818/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5253 - val_loss: 563.6377\n",
      "Epoch 8819/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7828 - val_loss: 563.0015\n",
      "Epoch 8820/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9129 - val_loss: 564.5757\n",
      "Epoch 8821/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.0801 - val_loss: 564.1553\n",
      "Epoch 8822/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5498 - val_loss: 563.9580\n",
      "Epoch 8823/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2159 - val_loss: 563.6912\n",
      "Epoch 8824/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2839 - val_loss: 563.2912\n",
      "Epoch 8825/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.3798 - val_loss: 563.2881\n",
      "Epoch 8826/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.3856 - val_loss: 563.2723\n",
      "Epoch 8827/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4359 - val_loss: 563.6977\n",
      "Epoch 8828/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.3586 - val_loss: 563.9353\n",
      "Epoch 8829/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2991 - val_loss: 563.8218\n",
      "Epoch 8830/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6453 - val_loss: 563.6000\n",
      "Epoch 8831/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5383 - val_loss: 563.9106\n",
      "Epoch 8832/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6478 - val_loss: 563.6250\n",
      "Epoch 8833/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.8114 - val_loss: 563.4849\n",
      "Epoch 8834/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6285 - val_loss: 564.1665\n",
      "Epoch 8835/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.3994 - val_loss: 563.3150\n",
      "Epoch 8836/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4107 - val_loss: 563.0568\n",
      "Epoch 8837/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.0625 - val_loss: 562.8953\n",
      "Epoch 8838/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6684 - val_loss: 564.3782\n",
      "Epoch 8839/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 469.3720 - val_loss: 565.0817\n",
      "Epoch 8840/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5805 - val_loss: 563.0839\n",
      "Epoch 8841/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4699 - val_loss: 562.7853\n",
      "Epoch 8842/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4955 - val_loss: 563.1858\n",
      "Epoch 8843/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.3834 - val_loss: 562.9182\n",
      "Epoch 8844/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2792 - val_loss: 563.6723\n",
      "Epoch 8845/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.1180 - val_loss: 563.7666\n",
      "Epoch 8846/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.0368 - val_loss: 563.5719\n",
      "Epoch 8847/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.3238 - val_loss: 564.5627\n",
      "Epoch 8848/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.3377 - val_loss: 563.4271\n",
      "Epoch 8849/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7162 - val_loss: 563.4170\n",
      "Epoch 8850/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4865 - val_loss: 563.4705\n",
      "Epoch 8851/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6033 - val_loss: 562.9163\n",
      "Epoch 8852/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.3749 - val_loss: 563.3305\n",
      "Epoch 8853/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.3205 - val_loss: 563.7546\n",
      "Epoch 8854/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4009 - val_loss: 562.6990\n",
      "Epoch 8855/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6849 - val_loss: 563.8602\n",
      "Epoch 8856/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6608 - val_loss: 563.9966\n",
      "Epoch 8857/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2531 - val_loss: 563.8533\n",
      "Epoch 8858/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 468.3441 - val_loss: 563.1195\n",
      "Epoch 8859/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4356 - val_loss: 563.3208\n",
      "Epoch 8860/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2343 - val_loss: 563.7931\n",
      "Epoch 8861/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.1055 - val_loss: 563.4607\n",
      "Epoch 8862/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.3801 - val_loss: 563.6752\n",
      "Epoch 8863/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7101 - val_loss: 563.5433\n",
      "Epoch 8864/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5132 - val_loss: 563.3412\n",
      "Epoch 8865/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4814 - val_loss: 563.4523\n",
      "Epoch 8866/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4708 - val_loss: 564.1839\n",
      "Epoch 8867/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.3780 - val_loss: 563.5935\n",
      "Epoch 8868/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.3443 - val_loss: 563.6265\n",
      "Epoch 8869/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2710 - val_loss: 563.1029\n",
      "Epoch 8870/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6190 - val_loss: 562.5920\n",
      "Epoch 8871/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4990 - val_loss: 563.3086\n",
      "Epoch 8872/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.1818 - val_loss: 563.4318\n",
      "Epoch 8873/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4929 - val_loss: 563.7204\n",
      "Epoch 8874/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.3297 - val_loss: 563.6979\n",
      "Epoch 8875/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.3485 - val_loss: 563.0725\n",
      "Epoch 8876/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4532 - val_loss: 563.2780\n",
      "Epoch 8877/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5666 - val_loss: 563.7717\n",
      "Epoch 8878/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2427 - val_loss: 562.9534\n",
      "Epoch 8879/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0725 - val_loss: 563.1217\n",
      "Epoch 8880/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.1873 - val_loss: 563.2148\n",
      "Epoch 8881/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2494 - val_loss: 563.2979\n",
      "Epoch 8882/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2592 - val_loss: 563.6459\n",
      "Epoch 8883/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.1771 - val_loss: 563.7698\n",
      "Epoch 8884/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2641 - val_loss: 563.2818\n",
      "Epoch 8885/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.1594 - val_loss: 563.0394\n",
      "Epoch 8886/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.1377 - val_loss: 563.1878\n",
      "Epoch 8887/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.1528 - val_loss: 563.2611\n",
      "Epoch 8888/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2976 - val_loss: 562.9717\n",
      "Epoch 8889/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9713 - val_loss: 562.8720\n",
      "Epoch 8890/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5329 - val_loss: 563.1143\n",
      "Epoch 8891/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2034 - val_loss: 562.9994\n",
      "Epoch 8892/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7017 - val_loss: 563.1475\n",
      "Epoch 8893/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.3668 - val_loss: 562.6861\n",
      "Epoch 8894/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2172 - val_loss: 562.9936\n",
      "Epoch 8895/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4084 - val_loss: 563.4814\n",
      "Epoch 8896/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0318 - val_loss: 563.3297\n",
      "Epoch 8897/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.8670 - val_loss: 563.8649\n",
      "Epoch 8898/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.1783 - val_loss: 563.7201\n",
      "Epoch 8899/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.1677 - val_loss: 563.2932\n",
      "Epoch 8900/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9084 - val_loss: 562.7026\n",
      "Epoch 8901/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5068 - val_loss: 562.3379\n",
      "Epoch 8902/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.3071 - val_loss: 563.1859\n",
      "Epoch 8903/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4502 - val_loss: 563.5094\n",
      "Epoch 8904/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4465 - val_loss: 563.0092\n",
      "Epoch 8905/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0661 - val_loss: 563.1157\n",
      "Epoch 8906/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0812 - val_loss: 563.6751\n",
      "Epoch 8907/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2974 - val_loss: 563.1911\n",
      "Epoch 8908/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2758 - val_loss: 563.6907\n",
      "Epoch 8909/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0837 - val_loss: 563.1910\n",
      "Epoch 8910/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.3611 - val_loss: 563.1236\n",
      "Epoch 8911/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.1901 - val_loss: 563.0216\n",
      "Epoch 8912/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4264 - val_loss: 563.6948\n",
      "Epoch 8913/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2044 - val_loss: 563.6871\n",
      "Epoch 8914/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.3258 - val_loss: 563.4262\n",
      "Epoch 8915/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4584 - val_loss: 562.6734\n",
      "Epoch 8916/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5451 - val_loss: 562.2926\n",
      "Epoch 8917/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.1617 - val_loss: 562.1795\n",
      "Epoch 8918/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6509 - val_loss: 562.9835\n",
      "Epoch 8919/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0199 - val_loss: 563.6992\n",
      "Epoch 8920/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2893 - val_loss: 562.9096\n",
      "Epoch 8921/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.1534 - val_loss: 563.3762\n",
      "Epoch 8922/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0999 - val_loss: 563.2223\n",
      "Epoch 8923/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6529 - val_loss: 563.8448\n",
      "Epoch 8924/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4587 - val_loss: 563.6612\n",
      "Epoch 8925/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0313 - val_loss: 563.3394\n",
      "Epoch 8926/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2176 - val_loss: 563.5494\n",
      "Epoch 8927/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4960 - val_loss: 562.6882\n",
      "Epoch 8928/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5405 - val_loss: 563.8706\n",
      "Epoch 8929/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0891 - val_loss: 563.1825\n",
      "Epoch 8930/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.3603 - val_loss: 563.3121\n",
      "Epoch 8931/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0756 - val_loss: 563.2404\n",
      "Epoch 8932/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2308 - val_loss: 562.7535\n",
      "Epoch 8933/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5334 - val_loss: 563.3332\n",
      "Epoch 8934/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9993 - val_loss: 562.9425\n",
      "Epoch 8935/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.3823 - val_loss: 563.1475\n",
      "Epoch 8936/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.1662 - val_loss: 563.7764\n",
      "Epoch 8937/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 468.0508 - val_loss: 563.3072\n",
      "Epoch 8938/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2426 - val_loss: 562.9103\n",
      "Epoch 8939/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5368 - val_loss: 564.0357\n",
      "Epoch 8940/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7133 - val_loss: 563.2072\n",
      "Epoch 8941/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.1444 - val_loss: 563.5135\n",
      "Epoch 8942/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0459 - val_loss: 563.4584\n",
      "Epoch 8943/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 468.0388 - val_loss: 563.2855\n",
      "Epoch 8944/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5134 - val_loss: 562.8060\n",
      "Epoch 8945/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2680 - val_loss: 562.5116\n",
      "Epoch 8946/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6730 - val_loss: 564.1977\n",
      "Epoch 8947/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9799 - val_loss: 563.2125\n",
      "Epoch 8948/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9049 - val_loss: 563.1802\n",
      "Epoch 8949/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.1523 - val_loss: 564.2610\n",
      "Epoch 8950/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.1338 - val_loss: 563.6454\n",
      "Epoch 8951/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6109 - val_loss: 562.5499\n",
      "Epoch 8952/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8563 - val_loss: 563.4135\n",
      "Epoch 8953/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2801 - val_loss: 563.3917\n",
      "Epoch 8954/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9725 - val_loss: 563.6606\n",
      "Epoch 8955/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0396 - val_loss: 563.4188\n",
      "Epoch 8956/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2840 - val_loss: 563.5646\n",
      "Epoch 8957/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7048 - val_loss: 562.9837\n",
      "Epoch 8958/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.1617 - val_loss: 563.7673\n",
      "Epoch 8959/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2599 - val_loss: 563.5037\n",
      "Epoch 8960/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.1727 - val_loss: 563.0830\n",
      "Epoch 8961/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9638 - val_loss: 563.2800\n",
      "Epoch 8962/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2261 - val_loss: 563.1437\n",
      "Epoch 8963/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8299 - val_loss: 563.0598\n",
      "Epoch 8964/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0548 - val_loss: 563.5300\n",
      "Epoch 8965/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0735 - val_loss: 562.9396\n",
      "Epoch 8966/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9459 - val_loss: 563.3415\n",
      "Epoch 8967/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0969 - val_loss: 563.5606\n",
      "Epoch 8968/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0124 - val_loss: 562.6766\n",
      "Epoch 8969/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0308 - val_loss: 562.9067\n",
      "Epoch 8970/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2443 - val_loss: 562.4317\n",
      "Epoch 8971/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.1472 - val_loss: 563.6601\n",
      "Epoch 8972/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5351 - val_loss: 562.6829\n",
      "Epoch 8973/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4620 - val_loss: 562.8633\n",
      "Epoch 8974/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5523 - val_loss: 563.2505\n",
      "Epoch 8975/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8801 - val_loss: 563.2873\n",
      "Epoch 8976/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2306 - val_loss: 563.6847\n",
      "Epoch 8977/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0115 - val_loss: 563.8421\n",
      "Epoch 8978/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5313 - val_loss: 563.6796\n",
      "Epoch 8979/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7771 - val_loss: 563.6904\n",
      "Epoch 8980/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.8532 - val_loss: 564.5825\n",
      "Epoch 8981/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0594 - val_loss: 563.6853\n",
      "Epoch 8982/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.3808 - val_loss: 563.0443\n",
      "Epoch 8983/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0555 - val_loss: 563.0095\n",
      "Epoch 8984/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0484 - val_loss: 562.8282\n",
      "Epoch 8985/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2008 - val_loss: 562.7675\n",
      "Epoch 8986/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2426 - val_loss: 562.9583\n",
      "Epoch 8987/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2045 - val_loss: 563.4328\n",
      "Epoch 8988/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.9482 - val_loss: 562.7094\n",
      "Epoch 8989/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8050 - val_loss: 563.3593\n",
      "Epoch 8990/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0532 - val_loss: 562.8069\n",
      "Epoch 8991/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2094 - val_loss: 562.7567\n",
      "Epoch 8992/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5462 - val_loss: 563.7000\n",
      "Epoch 8993/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7932 - val_loss: 562.9361\n",
      "Epoch 8994/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2685 - val_loss: 563.6332\n",
      "Epoch 8995/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4564 - val_loss: 562.6735\n",
      "Epoch 8996/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9646 - val_loss: 562.7983\n",
      "Epoch 8997/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.6388 - val_loss: 562.6033\n",
      "Epoch 8998/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9968 - val_loss: 562.6866\n",
      "Epoch 8999/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7369 - val_loss: 562.3309\n",
      "Epoch 9000/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 485.8677Epoch: 9000 - loss: 467.919812 - val_loss: 562.667745\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9198 - val_loss: 562.6677\n",
      "Epoch 9001/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2938 - val_loss: 562.1019\n",
      "Epoch 9002/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9255 - val_loss: 562.5895\n",
      "Epoch 9003/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0330 - val_loss: 562.9806\n",
      "Epoch 9004/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6565 - val_loss: 563.3228\n",
      "Epoch 9005/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0283 - val_loss: 563.2268\n",
      "Epoch 9006/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.1427 - val_loss: 563.4166\n",
      "Epoch 9007/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9617 - val_loss: 562.8046\n",
      "Epoch 9008/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0065 - val_loss: 563.0485\n",
      "Epoch 9009/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4214 - val_loss: 563.0289\n",
      "Epoch 9010/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6872 - val_loss: 562.5111\n",
      "Epoch 9011/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7780 - val_loss: 562.7505\n",
      "Epoch 9012/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8752 - val_loss: 562.3761\n",
      "Epoch 9013/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7839 - val_loss: 562.9488\n",
      "Epoch 9014/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0517 - val_loss: 563.1787\n",
      "Epoch 9015/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9254 - val_loss: 562.9473\n",
      "Epoch 9016/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.3386 - val_loss: 563.1578\n",
      "Epoch 9017/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9085 - val_loss: 562.5201\n",
      "Epoch 9018/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8569 - val_loss: 562.8591\n",
      "Epoch 9019/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8227 - val_loss: 562.8811\n",
      "Epoch 9020/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.1744 - val_loss: 563.3726\n",
      "Epoch 9021/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6176 - val_loss: 563.1619\n",
      "Epoch 9022/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8189 - val_loss: 563.4163\n",
      "Epoch 9023/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2522 - val_loss: 564.1093\n",
      "Epoch 9024/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0321 - val_loss: 562.9484\n",
      "Epoch 9025/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0575 - val_loss: 563.2039\n",
      "Epoch 9026/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8697 - val_loss: 563.1128\n",
      "Epoch 9027/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7778 - val_loss: 563.6632\n",
      "Epoch 9028/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7881 - val_loss: 562.6442\n",
      "Epoch 9029/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.1159 - val_loss: 562.4827\n",
      "Epoch 9030/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6703 - val_loss: 562.7508\n",
      "Epoch 9031/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8953 - val_loss: 562.6694\n",
      "Epoch 9032/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5109 - val_loss: 562.9418\n",
      "Epoch 9033/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6419 - val_loss: 562.6241\n",
      "Epoch 9034/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8147 - val_loss: 563.2041\n",
      "Epoch 9035/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.3342 - val_loss: 562.4128\n",
      "Epoch 9036/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6636 - val_loss: 563.0287\n",
      "Epoch 9037/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2135 - val_loss: 563.1879\n",
      "Epoch 9038/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7374 - val_loss: 562.4660\n",
      "Epoch 9039/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9422 - val_loss: 562.8768\n",
      "Epoch 9040/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9473 - val_loss: 563.2107\n",
      "Epoch 9041/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8657 - val_loss: 563.8095\n",
      "Epoch 9042/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7791 - val_loss: 563.9581\n",
      "Epoch 9043/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2381 - val_loss: 563.0005\n",
      "Epoch 9044/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9039 - val_loss: 562.9132\n",
      "Epoch 9045/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6972 - val_loss: 562.5820\n",
      "Epoch 9046/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9764 - val_loss: 562.4603\n",
      "Epoch 9047/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.3423 - val_loss: 563.3663\n",
      "Epoch 9048/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8389 - val_loss: 563.1644\n",
      "Epoch 9049/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6324 - val_loss: 562.8451\n",
      "Epoch 9050/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9540 - val_loss: 562.3106\n",
      "Epoch 9051/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8390 - val_loss: 563.2962\n",
      "Epoch 9052/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8018 - val_loss: 562.4642\n",
      "Epoch 9053/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5760 - val_loss: 562.6537\n",
      "Epoch 9054/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0352 - val_loss: 562.4916\n",
      "Epoch 9055/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2228 - val_loss: 562.7889\n",
      "Epoch 9056/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7221 - val_loss: 562.6205\n",
      "Epoch 9057/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8701 - val_loss: 562.7555\n",
      "Epoch 9058/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9329 - val_loss: 562.3315\n",
      "Epoch 9059/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6025 - val_loss: 562.4161\n",
      "Epoch 9060/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.8336 - val_loss: 563.1546\n",
      "Epoch 9061/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6546 - val_loss: 562.3999\n",
      "Epoch 9062/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7086 - val_loss: 562.8746\n",
      "Epoch 9063/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7476 - val_loss: 562.7144\n",
      "Epoch 9064/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6556 - val_loss: 562.5600\n",
      "Epoch 9065/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7066 - val_loss: 562.4261\n",
      "Epoch 9066/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7687 - val_loss: 563.5168\n",
      "Epoch 9067/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0283 - val_loss: 562.9907\n",
      "Epoch 9068/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.7233 - val_loss: 563.1954\n",
      "Epoch 9069/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.1751 - val_loss: 562.6969\n",
      "Epoch 9070/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5475 - val_loss: 562.8184\n",
      "Epoch 9071/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5646 - val_loss: 562.9676\n",
      "Epoch 9072/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9212 - val_loss: 563.3303\n",
      "Epoch 9073/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9110 - val_loss: 562.6930\n",
      "Epoch 9074/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9717 - val_loss: 561.8103\n",
      "Epoch 9075/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 468.2486 - val_loss: 562.9436\n",
      "Epoch 9076/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8395 - val_loss: 562.4808\n",
      "Epoch 9077/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9441 - val_loss: 562.6573\n",
      "Epoch 9078/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.1579 - val_loss: 562.6741\n",
      "Epoch 9079/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6850 - val_loss: 561.8639\n",
      "Epoch 9080/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9526 - val_loss: 562.0361\n",
      "Epoch 9081/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6022 - val_loss: 562.3708\n",
      "Epoch 9082/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5314 - val_loss: 562.8608\n",
      "Epoch 9083/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2686 - val_loss: 563.5006\n",
      "Epoch 9084/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8817 - val_loss: 564.1596\n",
      "Epoch 9085/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6684 - val_loss: 562.8915\n",
      "Epoch 9086/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 467.9955 - val_loss: 562.3710\n",
      "Epoch 9087/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5691 - val_loss: 562.4796\n",
      "Epoch 9088/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7384 - val_loss: 563.0441\n",
      "Epoch 9089/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2168 - val_loss: 562.2204\n",
      "Epoch 9090/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8676 - val_loss: 562.6394\n",
      "Epoch 9091/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6619 - val_loss: 562.7749\n",
      "Epoch 9092/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7051 - val_loss: 563.1911\n",
      "Epoch 9093/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9091 - val_loss: 562.0002\n",
      "Epoch 9094/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.1843 - val_loss: 563.2045\n",
      "Epoch 9095/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4044 - val_loss: 562.4791\n",
      "Epoch 9096/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7176 - val_loss: 562.5709\n",
      "Epoch 9097/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8446 - val_loss: 562.5335\n",
      "Epoch 9098/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8279 - val_loss: 561.9055\n",
      "Epoch 9099/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9995 - val_loss: 563.2993\n",
      "Epoch 9100/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2280 - val_loss: 561.4949\n",
      "Epoch 9101/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9172 - val_loss: 562.1951\n",
      "Epoch 9102/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2393 - val_loss: 562.6246\n",
      "Epoch 9103/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.1795 - val_loss: 561.8955\n",
      "Epoch 9104/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7487 - val_loss: 561.5563\n",
      "Epoch 9105/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9623 - val_loss: 562.0151\n",
      "Epoch 9106/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4871 - val_loss: 562.1657\n",
      "Epoch 9107/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8982 - val_loss: 561.9656\n",
      "Epoch 9108/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4653 - val_loss: 562.5378\n",
      "Epoch 9109/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8407 - val_loss: 562.4538\n",
      "Epoch 9110/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2349 - val_loss: 563.0539\n",
      "Epoch 9111/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6933 - val_loss: 562.6692\n",
      "Epoch 9112/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5963 - val_loss: 562.6454\n",
      "Epoch 9113/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8991 - val_loss: 562.6868\n",
      "Epoch 9114/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7348 - val_loss: 563.0625\n",
      "Epoch 9115/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7876 - val_loss: 562.4079\n",
      "Epoch 9116/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2382 - val_loss: 563.3036\n",
      "Epoch 9117/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0228 - val_loss: 562.0322\n",
      "Epoch 9118/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3935 - val_loss: 563.0239\n",
      "Epoch 9119/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.1361 - val_loss: 562.6232\n",
      "Epoch 9120/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.1772 - val_loss: 561.8908\n",
      "Epoch 9121/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5935 - val_loss: 562.9632\n",
      "Epoch 9122/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6564 - val_loss: 562.5202\n",
      "Epoch 9123/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7127 - val_loss: 562.7349\n",
      "Epoch 9124/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7553 - val_loss: 562.0257\n",
      "Epoch 9125/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9866 - val_loss: 561.9017\n",
      "Epoch 9126/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6957 - val_loss: 562.9874\n",
      "Epoch 9127/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7447 - val_loss: 562.8811\n",
      "Epoch 9128/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7664 - val_loss: 562.1708\n",
      "Epoch 9129/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9153 - val_loss: 562.7743\n",
      "Epoch 9130/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5136 - val_loss: 562.2858\n",
      "Epoch 9131/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3630 - val_loss: 562.7243\n",
      "Epoch 9132/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4630 - val_loss: 562.9898\n",
      "Epoch 9133/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6119 - val_loss: 562.4295\n",
      "Epoch 9134/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3696 - val_loss: 563.1130\n",
      "Epoch 9135/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7613 - val_loss: 563.2092\n",
      "Epoch 9136/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7515 - val_loss: 562.4964\n",
      "Epoch 9137/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6356 - val_loss: 562.2093\n",
      "Epoch 9138/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8008 - val_loss: 561.3563\n",
      "Epoch 9139/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5084 - val_loss: 562.0446\n",
      "Epoch 9140/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6436 - val_loss: 562.5630\n",
      "Epoch 9141/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8415 - val_loss: 562.4889\n",
      "Epoch 9142/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6613 - val_loss: 562.2159\n",
      "Epoch 9143/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4825 - val_loss: 561.9474\n",
      "Epoch 9144/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8181 - val_loss: 561.9651\n",
      "Epoch 9145/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7140 - val_loss: 562.5312\n",
      "Epoch 9146/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 467.7936 - val_loss: 562.1211\n",
      "Epoch 9147/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6630 - val_loss: 562.5278\n",
      "Epoch 9148/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8393 - val_loss: 562.4324\n",
      "Epoch 9149/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6219 - val_loss: 563.4283\n",
      "Epoch 9150/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.3075 - val_loss: 562.0403\n",
      "Epoch 9151/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7255 - val_loss: 562.1489\n",
      "Epoch 9152/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4144 - val_loss: 562.0820\n",
      "Epoch 9153/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8904 - val_loss: 562.7767\n",
      "Epoch 9154/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5501 - val_loss: 561.9587\n",
      "Epoch 9155/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8661 - val_loss: 562.2708\n",
      "Epoch 9156/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5743 - val_loss: 562.5973\n",
      "Epoch 9157/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6180 - val_loss: 562.7936\n",
      "Epoch 9158/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5322 - val_loss: 562.3127\n",
      "Epoch 9159/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6648 - val_loss: 562.2817\n",
      "Epoch 9160/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5921 - val_loss: 562.5399\n",
      "Epoch 9161/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4536 - val_loss: 562.4593\n",
      "Epoch 9162/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.3325 - val_loss: 562.4876\n",
      "Epoch 9163/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6085 - val_loss: 562.2910\n",
      "Epoch 9164/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7419 - val_loss: 562.4323\n",
      "Epoch 9165/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4441 - val_loss: 562.4006\n",
      "Epoch 9166/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 467.9892 - val_loss: 562.8609\n",
      "Epoch 9167/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2585 - val_loss: 562.8350\n",
      "Epoch 9168/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9009 - val_loss: 563.4727\n",
      "Epoch 9169/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4231 - val_loss: 562.7517\n",
      "Epoch 9170/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6362 - val_loss: 563.2679\n",
      "Epoch 9171/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4816 - val_loss: 562.0012\n",
      "Epoch 9172/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.1333 - val_loss: 561.8540\n",
      "Epoch 9173/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9241 - val_loss: 563.3970\n",
      "Epoch 9174/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4332 - val_loss: 562.6378\n",
      "Epoch 9175/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.1025 - val_loss: 562.6844\n",
      "Epoch 9176/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4745 - val_loss: 562.4915\n",
      "Epoch 9177/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4839 - val_loss: 562.4397\n",
      "Epoch 9178/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9185 - val_loss: 561.9568\n",
      "Epoch 9179/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5024 - val_loss: 562.1983\n",
      "Epoch 9180/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5114 - val_loss: 561.9854\n",
      "Epoch 9181/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4492 - val_loss: 562.0887\n",
      "Epoch 9182/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4577 - val_loss: 561.8334\n",
      "Epoch 9183/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4452 - val_loss: 562.0004\n",
      "Epoch 9184/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6373 - val_loss: 562.8085\n",
      "Epoch 9185/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4196 - val_loss: 562.7092\n",
      "Epoch 9186/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6529 - val_loss: 561.6523\n",
      "Epoch 9187/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3793 - val_loss: 562.0083\n",
      "Epoch 9188/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8645 - val_loss: 562.3197\n",
      "Epoch 9189/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8577 - val_loss: 563.0073\n",
      "Epoch 9190/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3788 - val_loss: 562.9462\n",
      "Epoch 9191/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5127 - val_loss: 561.5581\n",
      "Epoch 9192/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3737 - val_loss: 561.9441\n",
      "Epoch 9193/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5282 - val_loss: 562.6356\n",
      "Epoch 9194/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9103 - val_loss: 561.6986\n",
      "Epoch 9195/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9143 - val_loss: 561.9886\n",
      "Epoch 9196/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8144 - val_loss: 563.2059\n",
      "Epoch 9197/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8680 - val_loss: 562.5132\n",
      "Epoch 9198/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2582 - val_loss: 562.5436\n",
      "Epoch 9199/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0182 - val_loss: 562.6956\n",
      "Epoch 9200/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7922 - val_loss: 561.8989\n",
      "Epoch 9201/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2870 - val_loss: 561.9271\n",
      "Epoch 9202/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3208 - val_loss: 562.3724\n",
      "Epoch 9203/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7362 - val_loss: 562.2098\n",
      "Epoch 9204/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6158 - val_loss: 562.2109\n",
      "Epoch 9205/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4467 - val_loss: 561.8378\n",
      "Epoch 9206/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5888 - val_loss: 561.1480\n",
      "Epoch 9207/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0524 - val_loss: 561.6725\n",
      "Epoch 9208/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7591 - val_loss: 563.2008\n",
      "Epoch 9209/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7768 - val_loss: 562.0249\n",
      "Epoch 9210/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 469.6040 - val_loss: 562.1948\n",
      "Epoch 9211/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5611 - val_loss: 562.4459\n",
      "Epoch 9212/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7417 - val_loss: 561.2944\n",
      "Epoch 9213/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5284 - val_loss: 562.0970\n",
      "Epoch 9214/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8012 - val_loss: 563.7632\n",
      "Epoch 9215/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5533 - val_loss: 562.9520\n",
      "Epoch 9216/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4407 - val_loss: 562.7865\n",
      "Epoch 9217/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3473 - val_loss: 562.4439\n",
      "Epoch 9218/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3542 - val_loss: 562.6820\n",
      "Epoch 9219/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4290 - val_loss: 562.1700\n",
      "Epoch 9220/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2408 - val_loss: 562.7657\n",
      "Epoch 9221/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5118 - val_loss: 562.3954\n",
      "Epoch 9222/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3809 - val_loss: 562.1286\n",
      "Epoch 9223/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8522 - val_loss: 562.3046\n",
      "Epoch 9224/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7803 - val_loss: 562.7613\n",
      "Epoch 9225/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9752 - val_loss: 562.4850\n",
      "Epoch 9226/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5516 - val_loss: 561.7002\n",
      "Epoch 9227/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5526 - val_loss: 562.2026\n",
      "Epoch 9228/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3841 - val_loss: 562.3175\n",
      "Epoch 9229/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0141 - val_loss: 562.0930\n",
      "Epoch 9230/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3975 - val_loss: 562.1825\n",
      "Epoch 9231/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6390 - val_loss: 563.0560\n",
      "Epoch 9232/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5319 - val_loss: 561.8091\n",
      "Epoch 9233/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.1836 - val_loss: 563.0640\n",
      "Epoch 9234/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.2656 - val_loss: 562.1064\n",
      "Epoch 9235/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.4796 - val_loss: 562.5111\n",
      "Epoch 9236/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8405 - val_loss: 562.4473\n",
      "Epoch 9237/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4391 - val_loss: 562.5570\n",
      "Epoch 9238/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3434 - val_loss: 562.0627\n",
      "Epoch 9239/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7685 - val_loss: 561.9190\n",
      "Epoch 9240/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.1539 - val_loss: 563.0133\n",
      "Epoch 9241/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3108 - val_loss: 562.9993\n",
      "Epoch 9242/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7073 - val_loss: 562.2053\n",
      "Epoch 9243/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5486 - val_loss: 562.6464\n",
      "Epoch 9244/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0298 - val_loss: 561.9246\n",
      "Epoch 9245/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7731 - val_loss: 562.6633\n",
      "Epoch 9246/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4398 - val_loss: 562.6506\n",
      "Epoch 9247/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3664 - val_loss: 561.8118\n",
      "Epoch 9248/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3525 - val_loss: 561.8578\n",
      "Epoch 9249/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3831 - val_loss: 562.0558\n",
      "Epoch 9250/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 645.5177Epoch: 9250 - loss: 467.198566 - val_loss: 561.633634\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.1986 - val_loss: 561.6336\n",
      "Epoch 9251/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6336 - val_loss: 561.7333\n",
      "Epoch 9252/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2196 - val_loss: 562.5468\n",
      "Epoch 9253/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2628 - val_loss: 562.3998\n",
      "Epoch 9254/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.1144 - val_loss: 561.9608\n",
      "Epoch 9255/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3703 - val_loss: 562.0450\n",
      "Epoch 9256/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5535 - val_loss: 562.2165\n",
      "Epoch 9257/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2279 - val_loss: 562.0980\n",
      "Epoch 9258/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0368 - val_loss: 562.4181\n",
      "Epoch 9259/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7014 - val_loss: 561.8532\n",
      "Epoch 9260/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5405 - val_loss: 563.2080\n",
      "Epoch 9261/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8485 - val_loss: 562.4531\n",
      "Epoch 9262/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.1591 - val_loss: 562.7203\n",
      "Epoch 9263/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2780 - val_loss: 562.6708\n",
      "Epoch 9264/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9138 - val_loss: 562.0710\n",
      "Epoch 9265/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6821 - val_loss: 562.8306\n",
      "Epoch 9266/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3738 - val_loss: 562.0300\n",
      "Epoch 9267/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0730 - val_loss: 561.4641\n",
      "Epoch 9268/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4293 - val_loss: 561.8293\n",
      "Epoch 9269/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2070 - val_loss: 561.9238\n",
      "Epoch 9270/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9070 - val_loss: 561.0903\n",
      "Epoch 9271/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2939 - val_loss: 562.3248\n",
      "Epoch 9272/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2347 - val_loss: 562.0461\n",
      "Epoch 9273/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3141 - val_loss: 562.0254\n",
      "Epoch 9274/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2361 - val_loss: 561.6371\n",
      "Epoch 9275/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3065 - val_loss: 561.1977\n",
      "Epoch 9276/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3435 - val_loss: 562.0465\n",
      "Epoch 9277/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.1292 - val_loss: 562.2804\n",
      "Epoch 9278/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.1735 - val_loss: 562.6875\n",
      "Epoch 9279/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7317 - val_loss: 562.4259\n",
      "Epoch 9280/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.0542 - val_loss: 561.6942\n",
      "Epoch 9281/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9859 - val_loss: 561.4441\n",
      "Epoch 9282/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3142 - val_loss: 561.4931\n",
      "Epoch 9283/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 467.5373 - val_loss: 562.3979\n",
      "Epoch 9284/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6495 - val_loss: 562.2619\n",
      "Epoch 9285/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5289 - val_loss: 561.9921\n",
      "Epoch 9286/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4203 - val_loss: 561.6012\n",
      "Epoch 9287/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0213 - val_loss: 562.4166\n",
      "Epoch 9288/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4685 - val_loss: 562.0236\n",
      "Epoch 9289/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3271 - val_loss: 562.6252\n",
      "Epoch 9290/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.1328 - val_loss: 562.5615\n",
      "Epoch 9291/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3709 - val_loss: 562.3257\n",
      "Epoch 9292/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9393 - val_loss: 562.3317\n",
      "Epoch 9293/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9403 - val_loss: 562.4355\n",
      "Epoch 9294/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.5303 - val_loss: 563.1272\n",
      "Epoch 9295/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4278 - val_loss: 562.6877\n",
      "Epoch 9296/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5685 - val_loss: 562.1405\n",
      "Epoch 9297/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.8083 - val_loss: 563.4475\n",
      "Epoch 9298/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3834 - val_loss: 562.4740\n",
      "Epoch 9299/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7204 - val_loss: 561.7441\n",
      "Epoch 9300/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7008 - val_loss: 563.0909\n",
      "Epoch 9301/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4844 - val_loss: 562.2424\n",
      "Epoch 9302/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2685 - val_loss: 562.8910\n",
      "Epoch 9303/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 467.2657 - val_loss: 562.4555\n",
      "Epoch 9304/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 467.1796 - val_loss: 562.2337\n",
      "Epoch 9305/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 467.7330 - val_loss: 562.3624\n",
      "Epoch 9306/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 467.2123 - val_loss: 563.1063\n",
      "Epoch 9307/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9666 - val_loss: 561.2957\n",
      "Epoch 9308/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3258 - val_loss: 562.6334\n",
      "Epoch 9309/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.1321 - val_loss: 562.5842\n",
      "Epoch 9310/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4645 - val_loss: 562.0020\n",
      "Epoch 9311/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0708 - val_loss: 562.6465\n",
      "Epoch 9312/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2385 - val_loss: 562.7211\n",
      "Epoch 9313/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.6992 - val_loss: 561.6794\n",
      "Epoch 9314/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3892 - val_loss: 562.2534\n",
      "Epoch 9315/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.1365 - val_loss: 562.1210\n",
      "Epoch 9316/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0737 - val_loss: 561.9869\n",
      "Epoch 9317/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9467 - val_loss: 562.7489\n",
      "Epoch 9318/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0204 - val_loss: 562.1274\n",
      "Epoch 9319/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3095 - val_loss: 561.8484\n",
      "Epoch 9320/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5862 - val_loss: 562.8385\n",
      "Epoch 9321/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3363 - val_loss: 562.6770\n",
      "Epoch 9322/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5350 - val_loss: 561.7598\n",
      "Epoch 9323/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2515 - val_loss: 561.3624\n",
      "Epoch 9324/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0846 - val_loss: 562.2212\n",
      "Epoch 9325/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5158 - val_loss: 561.8618\n",
      "Epoch 9326/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5795 - val_loss: 562.1702\n",
      "Epoch 9327/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9007 - val_loss: 562.0975\n",
      "Epoch 9328/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5389 - val_loss: 561.7550\n",
      "Epoch 9329/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2798 - val_loss: 561.8039\n",
      "Epoch 9330/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0178 - val_loss: 562.1103\n",
      "Epoch 9331/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3631 - val_loss: 562.1147\n",
      "Epoch 9332/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8622 - val_loss: 561.5066\n",
      "Epoch 9333/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5037 - val_loss: 562.3330\n",
      "Epoch 9334/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.1078 - val_loss: 562.2365\n",
      "Epoch 9335/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5864 - val_loss: 561.6811\n",
      "Epoch 9336/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4241 - val_loss: 562.1805\n",
      "Epoch 9337/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9912 - val_loss: 562.5589\n",
      "Epoch 9338/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4038 - val_loss: 562.0646\n",
      "Epoch 9339/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9525 - val_loss: 562.4630\n",
      "Epoch 9340/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0733 - val_loss: 562.8132\n",
      "Epoch 9341/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7395 - val_loss: 562.0271\n",
      "Epoch 9342/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0620 - val_loss: 562.1064\n",
      "Epoch 9343/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9318 - val_loss: 562.5752\n",
      "Epoch 9344/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9898 - val_loss: 562.2677\n",
      "Epoch 9345/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2162 - val_loss: 561.7793\n",
      "Epoch 9346/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9243 - val_loss: 562.5740\n",
      "Epoch 9347/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9521 - val_loss: 562.3201\n",
      "Epoch 9348/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.1684 - val_loss: 562.3217\n",
      "Epoch 9349/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0026 - val_loss: 562.4669\n",
      "Epoch 9350/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9778 - val_loss: 562.4960\n",
      "Epoch 9351/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9442 - val_loss: 562.5890\n",
      "Epoch 9352/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2748 - val_loss: 562.2398\n",
      "Epoch 9353/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2534 - val_loss: 560.9122\n",
      "Epoch 9354/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.1803 - val_loss: 561.1066\n",
      "Epoch 9355/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3472 - val_loss: 562.0783\n",
      "Epoch 9356/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.1248 - val_loss: 561.4573\n",
      "Epoch 9357/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3294 - val_loss: 562.2127\n",
      "Epoch 9358/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0083 - val_loss: 561.4193\n",
      "Epoch 9359/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2347 - val_loss: 561.1877\n",
      "Epoch 9360/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3303 - val_loss: 561.1309\n",
      "Epoch 9361/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9354 - val_loss: 561.0845\n",
      "Epoch 9362/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3684 - val_loss: 561.1049\n",
      "Epoch 9363/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 468.1150 - val_loss: 561.1274\n",
      "Epoch 9364/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0064 - val_loss: 562.4049\n",
      "Epoch 9365/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8555 - val_loss: 561.7769\n",
      "Epoch 9366/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.1381 - val_loss: 561.7064\n",
      "Epoch 9367/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4712 - val_loss: 562.2420\n",
      "Epoch 9368/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0094 - val_loss: 561.4888\n",
      "Epoch 9369/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8476 - val_loss: 561.2175\n",
      "Epoch 9370/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0949 - val_loss: 561.8468\n",
      "Epoch 9371/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.1059 - val_loss: 561.6251\n",
      "Epoch 9372/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0110 - val_loss: 562.0333\n",
      "Epoch 9373/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 467.0580 - val_loss: 562.1819\n",
      "Epoch 9374/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0681 - val_loss: 561.8842\n",
      "Epoch 9375/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2974 - val_loss: 561.6902\n",
      "Epoch 9376/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.1616 - val_loss: 562.3653\n",
      "Epoch 9377/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0762 - val_loss: 562.0734\n",
      "Epoch 9378/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8823 - val_loss: 562.3043\n",
      "Epoch 9379/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0162 - val_loss: 562.2987\n",
      "Epoch 9380/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9621 - val_loss: 561.4756\n",
      "Epoch 9381/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9128 - val_loss: 561.7401\n",
      "Epoch 9382/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3151 - val_loss: 562.3165\n",
      "Epoch 9383/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2557 - val_loss: 561.7140\n",
      "Epoch 9384/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9806 - val_loss: 561.3914\n",
      "Epoch 9385/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9581 - val_loss: 561.5612\n",
      "Epoch 9386/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9362 - val_loss: 561.1346\n",
      "Epoch 9387/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0146 - val_loss: 561.7233\n",
      "Epoch 9388/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6996 - val_loss: 561.5173\n",
      "Epoch 9389/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2649 - val_loss: 561.2176\n",
      "Epoch 9390/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3582 - val_loss: 560.9608\n",
      "Epoch 9391/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9129 - val_loss: 561.5410\n",
      "Epoch 9392/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.1945 - val_loss: 562.2855\n",
      "Epoch 9393/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3680 - val_loss: 561.3509\n",
      "Epoch 9394/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0401 - val_loss: 561.7272\n",
      "Epoch 9395/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4136 - val_loss: 561.0696\n",
      "Epoch 9396/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.7493 - val_loss: 562.1083\n",
      "Epoch 9397/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8459 - val_loss: 561.9976\n",
      "Epoch 9398/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8558 - val_loss: 561.6241\n",
      "Epoch 9399/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4888 - val_loss: 561.0716\n",
      "Epoch 9400/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 467.5924 - val_loss: 561.8456\n",
      "Epoch 9401/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7541 - val_loss: 561.1457\n",
      "Epoch 9402/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8682 - val_loss: 561.7503\n",
      "Epoch 9403/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0134 - val_loss: 561.5136\n",
      "Epoch 9404/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0447 - val_loss: 560.6729\n",
      "Epoch 9405/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.1152 - val_loss: 560.9951\n",
      "Epoch 9406/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0384 - val_loss: 561.3557\n",
      "Epoch 9407/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9608 - val_loss: 561.3869\n",
      "Epoch 9408/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3057 - val_loss: 561.6101\n",
      "Epoch 9409/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.9295 - val_loss: 560.6704\n",
      "Epoch 9410/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0910 - val_loss: 561.5579\n",
      "Epoch 9411/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8104 - val_loss: 561.8701\n",
      "Epoch 9412/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9450 - val_loss: 561.3689\n",
      "Epoch 9413/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8607 - val_loss: 561.8333\n",
      "Epoch 9414/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8086 - val_loss: 561.7727\n",
      "Epoch 9415/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9483 - val_loss: 561.8493\n",
      "Epoch 9416/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8564 - val_loss: 561.9292\n",
      "Epoch 9417/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6739 - val_loss: 561.4989\n",
      "Epoch 9418/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 467.0770 - val_loss: 561.4190\n",
      "Epoch 9419/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0205 - val_loss: 562.0229\n",
      "Epoch 9420/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0492 - val_loss: 561.0183\n",
      "Epoch 9421/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9006 - val_loss: 561.9061\n",
      "Epoch 9422/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7531 - val_loss: 562.0300\n",
      "Epoch 9423/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2340 - val_loss: 562.4924\n",
      "Epoch 9424/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 466.6230 - val_loss: 561.3824\n",
      "Epoch 9425/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9814 - val_loss: 561.2843\n",
      "Epoch 9426/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6243 - val_loss: 561.4088\n",
      "Epoch 9427/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7060 - val_loss: 561.3240\n",
      "Epoch 9428/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9076 - val_loss: 561.4584\n",
      "Epoch 9429/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8987 - val_loss: 561.7740\n",
      "Epoch 9430/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2861 - val_loss: 561.7716\n",
      "Epoch 9431/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3802 - val_loss: 562.3919\n",
      "Epoch 9432/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9896 - val_loss: 561.0329\n",
      "Epoch 9433/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0197 - val_loss: 561.1831\n",
      "Epoch 9434/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5781 - val_loss: 561.6876\n",
      "Epoch 9435/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9772 - val_loss: 561.7657\n",
      "Epoch 9436/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2582 - val_loss: 561.1624\n",
      "Epoch 9437/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6292 - val_loss: 562.0368\n",
      "Epoch 9438/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6887 - val_loss: 561.9572\n",
      "Epoch 9439/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7257 - val_loss: 561.9110\n",
      "Epoch 9440/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7453 - val_loss: 561.9594\n",
      "Epoch 9441/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8494 - val_loss: 562.5517\n",
      "Epoch 9442/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9320 - val_loss: 561.7273\n",
      "Epoch 9443/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0602 - val_loss: 562.6031\n",
      "Epoch 9444/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0552 - val_loss: 561.6985\n",
      "Epoch 9445/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.5496 - val_loss: 562.5336\n",
      "Epoch 9446/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9121 - val_loss: 561.7440\n",
      "Epoch 9447/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.1231 - val_loss: 562.3664\n",
      "Epoch 9448/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7062 - val_loss: 561.9737\n",
      "Epoch 9449/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8067 - val_loss: 562.5622\n",
      "Epoch 9450/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9471 - val_loss: 562.8019\n",
      "Epoch 9451/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6846 - val_loss: 561.9756\n",
      "Epoch 9452/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6988 - val_loss: 561.8660\n",
      "Epoch 9453/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0574 - val_loss: 561.6086\n",
      "Epoch 9454/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8631 - val_loss: 561.7049\n",
      "Epoch 9455/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9534 - val_loss: 561.9281\n",
      "Epoch 9456/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5826 - val_loss: 561.9820\n",
      "Epoch 9457/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5748 - val_loss: 562.0590\n",
      "Epoch 9458/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.1047 - val_loss: 561.5346\n",
      "Epoch 9459/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0111 - val_loss: 562.8206\n",
      "Epoch 9460/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2431 - val_loss: 561.4297\n",
      "Epoch 9461/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8768 - val_loss: 562.1056\n",
      "Epoch 9462/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6775 - val_loss: 562.2123\n",
      "Epoch 9463/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.1919 - val_loss: 562.0668\n",
      "Epoch 9464/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6638 - val_loss: 562.1861\n",
      "Epoch 9465/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6424 - val_loss: 561.7706\n",
      "Epoch 9466/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.4054 - val_loss: 561.2952\n",
      "Epoch 9467/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9545 - val_loss: 561.6734\n",
      "Epoch 9468/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4678 - val_loss: 562.2560\n",
      "Epoch 9469/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.1941 - val_loss: 562.9990\n",
      "Epoch 9470/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6190 - val_loss: 562.2596\n",
      "Epoch 9471/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2667 - val_loss: 562.6874\n",
      "Epoch 9472/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6818 - val_loss: 561.3909\n",
      "Epoch 9473/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9250 - val_loss: 561.3147\n",
      "Epoch 9474/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7438 - val_loss: 561.5426\n",
      "Epoch 9475/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0923 - val_loss: 560.7476\n",
      "Epoch 9476/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9046 - val_loss: 561.4350\n",
      "Epoch 9477/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9076 - val_loss: 561.5565\n",
      "Epoch 9478/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8324 - val_loss: 561.3230\n",
      "Epoch 9479/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6632 - val_loss: 561.7440\n",
      "Epoch 9480/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7411 - val_loss: 562.0554\n",
      "Epoch 9481/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6516 - val_loss: 561.7331\n",
      "Epoch 9482/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9873 - val_loss: 561.9749\n",
      "Epoch 9483/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7227 - val_loss: 561.3570\n",
      "Epoch 9484/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7472 - val_loss: 561.0665\n",
      "Epoch 9485/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7986 - val_loss: 561.1890\n",
      "Epoch 9486/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8709 - val_loss: 561.3154\n",
      "Epoch 9487/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9821 - val_loss: 561.9150\n",
      "Epoch 9488/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7811 - val_loss: 561.7537\n",
      "Epoch 9489/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2058 - val_loss: 561.7829\n",
      "Epoch 9490/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.1557 - val_loss: 561.8155\n",
      "Epoch 9491/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5872 - val_loss: 561.3806\n",
      "Epoch 9492/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2091 - val_loss: 560.5946\n",
      "Epoch 9493/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.1306 - val_loss: 561.6488\n",
      "Epoch 9494/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6084 - val_loss: 560.9644\n",
      "Epoch 9495/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5966 - val_loss: 561.2660\n",
      "Epoch 9496/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7244 - val_loss: 561.1432\n",
      "Epoch 9497/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8623 - val_loss: 561.0370\n",
      "Epoch 9498/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.1331 - val_loss: 561.1814\n",
      "Epoch 9499/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0908 - val_loss: 560.8776\n",
      "Epoch 9500/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 887.0335Epoch: 9500 - loss: 466.690998 - val_loss: 560.797456\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6910 - val_loss: 560.7975\n",
      "Epoch 9501/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5307 - val_loss: 561.2600\n",
      "Epoch 9502/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 466.6268 - val_loss: 561.2855\n",
      "Epoch 9503/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4208 - val_loss: 561.2532\n",
      "Epoch 9504/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2653 - val_loss: 560.5399\n",
      "Epoch 9505/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9748 - val_loss: 561.4564\n",
      "Epoch 9506/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8189 - val_loss: 561.2124\n",
      "Epoch 9507/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5658 - val_loss: 561.2804\n",
      "Epoch 9508/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3132 - val_loss: 561.3746\n",
      "Epoch 9509/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0703 - val_loss: 561.6876\n",
      "Epoch 9510/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8938 - val_loss: 561.3962\n",
      "Epoch 9511/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2823 - val_loss: 561.2743\n",
      "Epoch 9512/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6862 - val_loss: 561.0921\n",
      "Epoch 9513/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8911 - val_loss: 561.7395\n",
      "Epoch 9514/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9035 - val_loss: 561.3960\n",
      "Epoch 9515/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0815 - val_loss: 562.0955\n",
      "Epoch 9516/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8373 - val_loss: 561.1252\n",
      "Epoch 9517/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7748 - val_loss: 561.6788\n",
      "Epoch 9518/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7697 - val_loss: 561.3717\n",
      "Epoch 9519/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7143 - val_loss: 561.2402\n",
      "Epoch 9520/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8576 - val_loss: 561.0365\n",
      "Epoch 9521/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0607 - val_loss: 560.9135\n",
      "Epoch 9522/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7056 - val_loss: 560.7472\n",
      "Epoch 9523/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8525 - val_loss: 560.8164\n",
      "Epoch 9524/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4284 - val_loss: 561.2193\n",
      "Epoch 9525/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4994 - val_loss: 561.4360\n",
      "Epoch 9526/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4798 - val_loss: 561.0924\n",
      "Epoch 9527/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6784 - val_loss: 560.3293\n",
      "Epoch 9528/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5900 - val_loss: 560.3515\n",
      "Epoch 9529/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.0566 - val_loss: 560.7568\n",
      "Epoch 9530/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7531 - val_loss: 560.3625\n",
      "Epoch 9531/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6080 - val_loss: 560.5510\n",
      "Epoch 9532/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6943 - val_loss: 560.8019\n",
      "Epoch 9533/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5905 - val_loss: 560.7636\n",
      "Epoch 9534/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3370 - val_loss: 560.0970\n",
      "Epoch 9535/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8481 - val_loss: 560.0266\n",
      "Epoch 9536/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4867 - val_loss: 559.8491\n",
      "Epoch 9537/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7522 - val_loss: 559.5815\n",
      "Epoch 9538/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9786 - val_loss: 561.1195\n",
      "Epoch 9539/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6477 - val_loss: 560.9267\n",
      "Epoch 9540/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4396 - val_loss: 560.4433\n",
      "Epoch 9541/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8007 - val_loss: 560.8725\n",
      "Epoch 9542/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4657 - val_loss: 561.1748\n",
      "Epoch 9543/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6270 - val_loss: 560.8545\n",
      "Epoch 9544/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6125 - val_loss: 561.3437\n",
      "Epoch 9545/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5017 - val_loss: 561.5298\n",
      "Epoch 9546/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5266 - val_loss: 560.8030\n",
      "Epoch 9547/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2389 - val_loss: 560.5963\n",
      "Epoch 9548/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4873 - val_loss: 561.0128\n",
      "Epoch 9549/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8144 - val_loss: 560.9483\n",
      "Epoch 9550/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8057 - val_loss: 560.9376\n",
      "Epoch 9551/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3397 - val_loss: 561.5492\n",
      "Epoch 9552/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5210 - val_loss: 561.6378\n",
      "Epoch 9553/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2752 - val_loss: 560.6585\n",
      "Epoch 9554/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6974 - val_loss: 561.4621\n",
      "Epoch 9555/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9032 - val_loss: 561.4493\n",
      "Epoch 9556/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7401 - val_loss: 561.7216\n",
      "Epoch 9557/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4563 - val_loss: 561.5184\n",
      "Epoch 9558/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7935 - val_loss: 560.9481\n",
      "Epoch 9559/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5040 - val_loss: 560.9871\n",
      "Epoch 9560/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7390 - val_loss: 561.7697\n",
      "Epoch 9561/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5842 - val_loss: 561.0263\n",
      "Epoch 9562/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6182 - val_loss: 561.1486\n",
      "Epoch 9563/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3971 - val_loss: 561.4083\n",
      "Epoch 9564/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9770 - val_loss: 560.9658\n",
      "Epoch 9565/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9430 - val_loss: 561.7096\n",
      "Epoch 9566/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7902 - val_loss: 561.4200\n",
      "Epoch 9567/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.1761 - val_loss: 560.1848\n",
      "Epoch 9568/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7108 - val_loss: 561.7266\n",
      "Epoch 9569/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7020 - val_loss: 561.2556\n",
      "Epoch 9570/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8940 - val_loss: 562.6023\n",
      "Epoch 9571/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8695 - val_loss: 561.6900\n",
      "Epoch 9572/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4074 - val_loss: 562.6890\n",
      "Epoch 9573/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7200 - val_loss: 561.7637\n",
      "Epoch 9574/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5678 - val_loss: 562.2437\n",
      "Epoch 9575/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6791 - val_loss: 561.0088\n",
      "Epoch 9576/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.2752 - val_loss: 561.6180\n",
      "Epoch 9577/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3895 - val_loss: 561.5806\n",
      "Epoch 9578/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5482 - val_loss: 561.0680\n",
      "Epoch 9579/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5826 - val_loss: 561.4607\n",
      "Epoch 9580/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7670 - val_loss: 561.1805\n",
      "Epoch 9581/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9693 - val_loss: 561.8135\n",
      "Epoch 9582/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5897 - val_loss: 561.9528\n",
      "Epoch 9583/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4542 - val_loss: 561.9827\n",
      "Epoch 9584/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3750 - val_loss: 561.1776\n",
      "Epoch 9585/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5516 - val_loss: 561.2933\n",
      "Epoch 9586/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.1634 - val_loss: 560.7273\n",
      "Epoch 9587/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8829 - val_loss: 561.9636\n",
      "Epoch 9588/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5910 - val_loss: 560.7518\n",
      "Epoch 9589/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3443 - val_loss: 560.7503\n",
      "Epoch 9590/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5292 - val_loss: 561.0321\n",
      "Epoch 9591/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 467.2034 - val_loss: 561.9572\n",
      "Epoch 9592/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8503 - val_loss: 561.3224\n",
      "Epoch 9593/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9732 - val_loss: 561.0486\n",
      "Epoch 9594/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7364 - val_loss: 561.1450\n",
      "Epoch 9595/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4226 - val_loss: 560.8672\n",
      "Epoch 9596/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 466.4209 - val_loss: 561.1036\n",
      "Epoch 9597/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5221 - val_loss: 561.7574\n",
      "Epoch 9598/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6136 - val_loss: 560.9608\n",
      "Epoch 9599/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7948 - val_loss: 560.9654\n",
      "Epoch 9600/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3393 - val_loss: 560.7796\n",
      "Epoch 9601/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 466.3727 - val_loss: 560.9745\n",
      "Epoch 9602/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6522 - val_loss: 560.6443\n",
      "Epoch 9603/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6665 - val_loss: 560.7179\n",
      "Epoch 9604/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4815 - val_loss: 561.4474\n",
      "Epoch 9605/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5208 - val_loss: 560.9997\n",
      "Epoch 9606/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.1275 - val_loss: 561.3636\n",
      "Epoch 9607/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7722 - val_loss: 560.6544\n",
      "Epoch 9608/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6899 - val_loss: 560.5801\n",
      "Epoch 9609/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.1485 - val_loss: 561.6727\n",
      "Epoch 9610/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4143 - val_loss: 560.3744\n",
      "Epoch 9611/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4502 - val_loss: 560.0478\n",
      "Epoch 9612/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8067 - val_loss: 560.8352\n",
      "Epoch 9613/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6188 - val_loss: 561.0105\n",
      "Epoch 9614/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3802 - val_loss: 560.9504\n",
      "Epoch 9615/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.9241 - val_loss: 561.1630\n",
      "Epoch 9616/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4679 - val_loss: 561.1027\n",
      "Epoch 9617/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3607 - val_loss: 560.5089\n",
      "Epoch 9618/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 466.2802 - val_loss: 560.7724\n",
      "Epoch 9619/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4595 - val_loss: 560.7126\n",
      "Epoch 9620/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6482 - val_loss: 560.2447\n",
      "Epoch 9621/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6892 - val_loss: 561.0739\n",
      "Epoch 9622/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0786 - val_loss: 560.5730\n",
      "Epoch 9623/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3668 - val_loss: 560.9405\n",
      "Epoch 9624/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5620 - val_loss: 560.6689\n",
      "Epoch 9625/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5784 - val_loss: 561.1938\n",
      "Epoch 9626/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5340 - val_loss: 560.1138\n",
      "Epoch 9627/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5095 - val_loss: 560.7069\n",
      "Epoch 9628/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7053 - val_loss: 561.4706\n",
      "Epoch 9629/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5828 - val_loss: 561.4554\n",
      "Epoch 9630/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3205 - val_loss: 560.7966\n",
      "Epoch 9631/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6345 - val_loss: 560.9911\n",
      "Epoch 9632/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.2297 - val_loss: 560.9573\n",
      "Epoch 9633/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6166 - val_loss: 561.0468\n",
      "Epoch 9634/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.2514 - val_loss: 560.8786\n",
      "Epoch 9635/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4818 - val_loss: 560.3953\n",
      "Epoch 9636/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3633 - val_loss: 561.0889\n",
      "Epoch 9637/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3797 - val_loss: 561.0701\n",
      "Epoch 9638/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4197 - val_loss: 560.6436\n",
      "Epoch 9639/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7939 - val_loss: 560.6381\n",
      "Epoch 9640/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6321 - val_loss: 559.9574\n",
      "Epoch 9641/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6001 - val_loss: 560.6150\n",
      "Epoch 9642/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4765 - val_loss: 561.6721\n",
      "Epoch 9643/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4022 - val_loss: 561.5538\n",
      "Epoch 9644/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5973 - val_loss: 561.1353\n",
      "Epoch 9645/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5412 - val_loss: 561.3307\n",
      "Epoch 9646/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1001 - val_loss: 561.0343\n",
      "Epoch 9647/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3667 - val_loss: 560.8726\n",
      "Epoch 9648/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3196 - val_loss: 561.3556\n",
      "Epoch 9649/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3842 - val_loss: 561.8919\n",
      "Epoch 9650/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5753 - val_loss: 561.5019\n",
      "Epoch 9651/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3061 - val_loss: 560.6330\n",
      "Epoch 9652/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3074 - val_loss: 560.3838\n",
      "Epoch 9653/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1587 - val_loss: 560.9085\n",
      "Epoch 9654/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5210 - val_loss: 561.8227\n",
      "Epoch 9655/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3424 - val_loss: 561.2287\n",
      "Epoch 9656/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3437 - val_loss: 560.2267\n",
      "Epoch 9657/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.2629 - val_loss: 560.8764\n",
      "Epoch 9658/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 466.1571 - val_loss: 561.2525\n",
      "Epoch 9659/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 466.7896 - val_loss: 561.1100\n",
      "Epoch 9660/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.2415 - val_loss: 560.8093\n",
      "Epoch 9661/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5541 - val_loss: 561.3138\n",
      "Epoch 9662/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4240 - val_loss: 561.5693\n",
      "Epoch 9663/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5252 - val_loss: 562.2123\n",
      "Epoch 9664/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 466.1469 - val_loss: 561.5197\n",
      "Epoch 9665/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.2721 - val_loss: 560.7557\n",
      "Epoch 9666/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6285 - val_loss: 560.8364\n",
      "Epoch 9667/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5579 - val_loss: 560.9714\n",
      "Epoch 9668/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4426 - val_loss: 560.9274\n",
      "Epoch 9669/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.3682 - val_loss: 560.8330\n",
      "Epoch 9670/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7505 - val_loss: 561.2608\n",
      "Epoch 9671/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4866 - val_loss: 561.2679\n",
      "Epoch 9672/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4086 - val_loss: 561.5825\n",
      "Epoch 9673/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5413 - val_loss: 561.3324\n",
      "Epoch 9674/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.2252 - val_loss: 561.2715\n",
      "Epoch 9675/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6208 - val_loss: 561.0435\n",
      "Epoch 9676/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3293 - val_loss: 561.7234\n",
      "Epoch 9677/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5761 - val_loss: 560.7912\n",
      "Epoch 9678/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1687 - val_loss: 561.4064\n",
      "Epoch 9679/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4309 - val_loss: 561.5821\n",
      "Epoch 9680/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.2756 - val_loss: 561.6897\n",
      "Epoch 9681/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3673 - val_loss: 561.4629\n",
      "Epoch 9682/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5613 - val_loss: 561.0757\n",
      "Epoch 9683/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5460 - val_loss: 561.5077\n",
      "Epoch 9684/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4986 - val_loss: 560.8333\n",
      "Epoch 9685/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1956 - val_loss: 561.1630\n",
      "Epoch 9686/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3114 - val_loss: 560.6214\n",
      "Epoch 9687/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1898 - val_loss: 560.9571\n",
      "Epoch 9688/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4608 - val_loss: 560.3446\n",
      "Epoch 9689/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1965 - val_loss: 560.8452\n",
      "Epoch 9690/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3876 - val_loss: 560.6491\n",
      "Epoch 9691/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7668 - val_loss: 561.0994\n",
      "Epoch 9692/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5474 - val_loss: 560.1463\n",
      "Epoch 9693/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0668 - val_loss: 560.6079\n",
      "Epoch 9694/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0538 - val_loss: 561.2525\n",
      "Epoch 9695/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4402 - val_loss: 561.5902\n",
      "Epoch 9696/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6180 - val_loss: 561.9757\n",
      "Epoch 9697/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3402 - val_loss: 560.9982\n",
      "Epoch 9698/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4500 - val_loss: 561.2050\n",
      "Epoch 9699/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0850 - val_loss: 560.9294\n",
      "Epoch 9700/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.2400 - val_loss: 560.7382\n",
      "Epoch 9701/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6592 - val_loss: 560.6546\n",
      "Epoch 9702/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.2532 - val_loss: 560.4552\n",
      "Epoch 9703/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1202 - val_loss: 560.7667\n",
      "Epoch 9704/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.2120 - val_loss: 561.0411\n",
      "Epoch 9705/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3858 - val_loss: 561.6579\n",
      "Epoch 9706/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3727 - val_loss: 561.7923\n",
      "Epoch 9707/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 466.0433 - val_loss: 560.7860\n",
      "Epoch 9708/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4769 - val_loss: 560.9798\n",
      "Epoch 9709/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1654 - val_loss: 560.8382\n",
      "Epoch 9710/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3158 - val_loss: 560.5032\n",
      "Epoch 9711/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.2878 - val_loss: 561.0944\n",
      "Epoch 9712/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3059 - val_loss: 561.2795\n",
      "Epoch 9713/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1458 - val_loss: 560.9192\n",
      "Epoch 9714/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 466.2338 - val_loss: 561.4278\n",
      "Epoch 9715/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 465.9923 - val_loss: 560.9498\n",
      "Epoch 9716/10000\n",
      "3000/3000 [==============================] - 0s 14us/sample - loss: 466.2138 - val_loss: 560.6033\n",
      "Epoch 9717/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 466.3905 - val_loss: 560.8390\n",
      "Epoch 9718/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 466.6616 - val_loss: 560.5128\n",
      "Epoch 9719/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6787 - val_loss: 560.9413\n",
      "Epoch 9720/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1444 - val_loss: 560.7160\n",
      "Epoch 9721/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 466.2657 - val_loss: 561.2133\n",
      "Epoch 9722/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 466.0725 - val_loss: 561.1549\n",
      "Epoch 9723/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 466.3094 - val_loss: 560.9819\n",
      "Epoch 9724/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 466.1834 - val_loss: 560.9201\n",
      "Epoch 9725/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 466.3523 - val_loss: 561.0656\n",
      "Epoch 9726/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 466.1978 - val_loss: 561.1548\n",
      "Epoch 9727/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 466.1817 - val_loss: 560.7126\n",
      "Epoch 9728/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0281 - val_loss: 560.1946\n",
      "Epoch 9729/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1649 - val_loss: 561.5239\n",
      "Epoch 9730/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 467.3610 - val_loss: 561.1846\n",
      "Epoch 9731/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 465.8790 - val_loss: 560.8975\n",
      "Epoch 9732/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 466.1559 - val_loss: 560.1804\n",
      "Epoch 9733/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 466.6580 - val_loss: 560.8190\n",
      "Epoch 9734/10000\n",
      "3000/3000 [==============================] - 0s 13us/sample - loss: 466.3101 - val_loss: 560.2175\n",
      "Epoch 9735/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 466.0803 - val_loss: 560.5742\n",
      "Epoch 9736/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 466.0978 - val_loss: 561.1403\n",
      "Epoch 9737/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9477 - val_loss: 560.6675\n",
      "Epoch 9738/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3752 - val_loss: 560.6957\n",
      "Epoch 9739/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.2567 - val_loss: 560.4654\n",
      "Epoch 9740/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.2210 - val_loss: 561.6880\n",
      "Epoch 9741/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1515 - val_loss: 561.1609\n",
      "Epoch 9742/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1144 - val_loss: 561.2578\n",
      "Epoch 9743/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 467.1625 - val_loss: 560.2640\n",
      "Epoch 9744/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9149 - val_loss: 561.0434\n",
      "Epoch 9745/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9618 - val_loss: 561.2323\n",
      "Epoch 9746/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3360 - val_loss: 561.1392\n",
      "Epoch 9747/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 466.2212 - val_loss: 561.1813\n",
      "Epoch 9748/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9312 - val_loss: 560.4954\n",
      "Epoch 9749/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6139 - val_loss: 561.0156\n",
      "Epoch 9750/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 382.2390Epoch: 9750 - loss: 466.519313 - val_loss: 560.456895\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5193 - val_loss: 560.4569\n",
      "Epoch 9751/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9848 - val_loss: 560.6643\n",
      "Epoch 9752/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.2875 - val_loss: 560.6209\n",
      "Epoch 9753/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.2160 - val_loss: 560.2474\n",
      "Epoch 9754/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1109 - val_loss: 560.0312\n",
      "Epoch 9755/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0547 - val_loss: 561.1161\n",
      "Epoch 9756/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3162 - val_loss: 560.6726\n",
      "Epoch 9757/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9445 - val_loss: 560.6888\n",
      "Epoch 9758/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9890 - val_loss: 560.1884\n",
      "Epoch 9759/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1764 - val_loss: 560.4116\n",
      "Epoch 9760/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.2488 - val_loss: 560.2610\n",
      "Epoch 9761/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6518 - val_loss: 561.1159\n",
      "Epoch 9762/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1425 - val_loss: 560.6516\n",
      "Epoch 9763/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1748 - val_loss: 559.9653\n",
      "Epoch 9764/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 466.0687 - val_loss: 561.3208\n",
      "Epoch 9765/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 466.0226 - val_loss: 561.3677\n",
      "Epoch 9766/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9001 - val_loss: 561.0565\n",
      "Epoch 9767/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1626 - val_loss: 560.4349\n",
      "Epoch 9768/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1168 - val_loss: 560.4599\n",
      "Epoch 9769/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9894 - val_loss: 559.7439\n",
      "Epoch 9770/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0540 - val_loss: 560.2099\n",
      "Epoch 9771/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.8045 - val_loss: 561.3961\n",
      "Epoch 9772/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.8184 - val_loss: 560.4098\n",
      "Epoch 9773/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3603 - val_loss: 560.0199\n",
      "Epoch 9774/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0139 - val_loss: 560.0481\n",
      "Epoch 9775/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0767 - val_loss: 560.0088\n",
      "Epoch 9776/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.6306 - val_loss: 560.3239\n",
      "Epoch 9777/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0763 - val_loss: 560.2747\n",
      "Epoch 9778/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1887 - val_loss: 559.1682\n",
      "Epoch 9779/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1566 - val_loss: 560.1413\n",
      "Epoch 9780/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5565 - val_loss: 560.7610\n",
      "Epoch 9781/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1150 - val_loss: 559.5279\n",
      "Epoch 9782/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4030 - val_loss: 559.8880\n",
      "Epoch 9783/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3310 - val_loss: 559.8413\n",
      "Epoch 9784/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0123 - val_loss: 559.7013\n",
      "Epoch 9785/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7294 - val_loss: 560.2335\n",
      "Epoch 9786/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3406 - val_loss: 559.8031\n",
      "Epoch 9787/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.2282 - val_loss: 559.7138\n",
      "Epoch 9788/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.2074 - val_loss: 560.2266\n",
      "Epoch 9789/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.2640 - val_loss: 560.0831\n",
      "Epoch 9790/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9122 - val_loss: 560.1495\n",
      "Epoch 9791/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9603 - val_loss: 559.6045\n",
      "Epoch 9792/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1472 - val_loss: 560.6614\n",
      "Epoch 9793/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0808 - val_loss: 560.4942\n",
      "Epoch 9794/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0394 - val_loss: 560.5048\n",
      "Epoch 9795/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0756 - val_loss: 560.4386\n",
      "Epoch 9796/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.8729 - val_loss: 560.7238\n",
      "Epoch 9797/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1206 - val_loss: 560.4520\n",
      "Epoch 9798/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4677 - val_loss: 560.4419\n",
      "Epoch 9799/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9353 - val_loss: 560.1006\n",
      "Epoch 9800/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9997 - val_loss: 561.4203\n",
      "Epoch 9801/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0452 - val_loss: 560.4525\n",
      "Epoch 9802/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9530 - val_loss: 560.3159\n",
      "Epoch 9803/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.8138 - val_loss: 560.4677\n",
      "Epoch 9804/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9305 - val_loss: 560.6645\n",
      "Epoch 9805/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1383 - val_loss: 560.7642\n",
      "Epoch 9806/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1432 - val_loss: 561.0883\n",
      "Epoch 9807/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1368 - val_loss: 561.1546\n",
      "Epoch 9808/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.8401 - val_loss: 560.4328\n",
      "Epoch 9809/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0029 - val_loss: 560.2661\n",
      "Epoch 9810/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.6138 - val_loss: 560.4048\n",
      "Epoch 9811/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 465.9191 - val_loss: 560.7176\n",
      "Epoch 9812/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9663 - val_loss: 560.4811\n",
      "Epoch 9813/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3691 - val_loss: 560.9990\n",
      "Epoch 9814/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4194 - val_loss: 560.3150\n",
      "Epoch 9815/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.2100 - val_loss: 560.9024\n",
      "Epoch 9816/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0281 - val_loss: 559.9742\n",
      "Epoch 9817/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9666 - val_loss: 560.8690\n",
      "Epoch 9818/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9575 - val_loss: 560.5845\n",
      "Epoch 9819/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.2668 - val_loss: 561.2137\n",
      "Epoch 9820/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9411 - val_loss: 560.3534\n",
      "Epoch 9821/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3586 - val_loss: 561.3394\n",
      "Epoch 9822/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7723 - val_loss: 561.3712\n",
      "Epoch 9823/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.7426 - val_loss: 560.3668\n",
      "Epoch 9824/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0764 - val_loss: 560.4756\n",
      "Epoch 9825/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0585 - val_loss: 560.2941\n",
      "Epoch 9826/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.2006 - val_loss: 560.8391\n",
      "Epoch 9827/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9644 - val_loss: 559.9349\n",
      "Epoch 9828/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.7234 - val_loss: 560.5970\n",
      "Epoch 9829/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0895 - val_loss: 560.4143\n",
      "Epoch 9830/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.8932 - val_loss: 560.2269\n",
      "Epoch 9831/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9424 - val_loss: 560.6360\n",
      "Epoch 9832/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9182 - val_loss: 560.7815\n",
      "Epoch 9833/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.8078 - val_loss: 560.2096\n",
      "Epoch 9834/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.6763 - val_loss: 559.3645\n",
      "Epoch 9835/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1220 - val_loss: 558.8735\n",
      "Epoch 9836/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3458 - val_loss: 560.1523\n",
      "Epoch 9837/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1165 - val_loss: 559.3244\n",
      "Epoch 9838/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3810 - val_loss: 560.0100\n",
      "Epoch 9839/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3257 - val_loss: 559.5316\n",
      "Epoch 9840/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9254 - val_loss: 559.9091\n",
      "Epoch 9841/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9022 - val_loss: 560.8271\n",
      "Epoch 9842/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.5052 - val_loss: 560.1304\n",
      "Epoch 9843/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 465.7792 - val_loss: 560.1846\n",
      "Epoch 9844/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1034 - val_loss: 560.0991\n",
      "Epoch 9845/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3606 - val_loss: 559.9955\n",
      "Epoch 9846/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.8463 - val_loss: 560.2218\n",
      "Epoch 9847/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.8578 - val_loss: 560.3594\n",
      "Epoch 9848/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.8370 - val_loss: 560.2530\n",
      "Epoch 9849/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 466.2069 - val_loss: 560.1517\n",
      "Epoch 9850/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4816 - val_loss: 560.5456\n",
      "Epoch 9851/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9420 - val_loss: 560.7192\n",
      "Epoch 9852/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9180 - val_loss: 560.7641\n",
      "Epoch 9853/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9068 - val_loss: 560.0294\n",
      "Epoch 9854/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4047 - val_loss: 560.8757\n",
      "Epoch 9855/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.8765 - val_loss: 559.8364\n",
      "Epoch 9856/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0278 - val_loss: 560.6296\n",
      "Epoch 9857/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3458 - val_loss: 559.8931\n",
      "Epoch 9858/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.4356 - val_loss: 559.9963\n",
      "Epoch 9859/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9496 - val_loss: 560.1039\n",
      "Epoch 9860/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0368 - val_loss: 560.8982\n",
      "Epoch 9861/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1588 - val_loss: 560.7084\n",
      "Epoch 9862/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0824 - val_loss: 560.3399\n",
      "Epoch 9863/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0523 - val_loss: 560.7510\n",
      "Epoch 9864/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1775 - val_loss: 560.1576\n",
      "Epoch 9865/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0733 - val_loss: 560.2987\n",
      "Epoch 9866/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9767 - val_loss: 560.6155\n",
      "Epoch 9867/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3968 - val_loss: 560.7432\n",
      "Epoch 9868/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.8476 - val_loss: 560.4878\n",
      "Epoch 9869/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.8162 - val_loss: 560.4037\n",
      "Epoch 9870/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.8944 - val_loss: 560.7740\n",
      "Epoch 9871/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0665 - val_loss: 560.2388\n",
      "Epoch 9872/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.8213 - val_loss: 560.7922\n",
      "Epoch 9873/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0417 - val_loss: 561.3342\n",
      "Epoch 9874/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0794 - val_loss: 561.0591\n",
      "Epoch 9875/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.8822 - val_loss: 560.8818\n",
      "Epoch 9876/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.7592 - val_loss: 560.2088\n",
      "Epoch 9877/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.7485 - val_loss: 560.4209\n",
      "Epoch 9878/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3138 - val_loss: 559.5146\n",
      "Epoch 9879/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.8439 - val_loss: 560.0092\n",
      "Epoch 9880/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.7092 - val_loss: 560.0985\n",
      "Epoch 9881/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.8591 - val_loss: 560.2585\n",
      "Epoch 9882/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.6992 - val_loss: 559.9608\n",
      "Epoch 9883/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0980 - val_loss: 559.6716\n",
      "Epoch 9884/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.8939 - val_loss: 560.0028\n",
      "Epoch 9885/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.2387 - val_loss: 560.5944\n",
      "Epoch 9886/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0829 - val_loss: 559.3793\n",
      "Epoch 9887/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.8279 - val_loss: 560.2193\n",
      "Epoch 9888/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 465.8724 - val_loss: 560.8396\n",
      "Epoch 9889/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9157 - val_loss: 560.2701\n",
      "Epoch 9890/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0935 - val_loss: 559.7188\n",
      "Epoch 9891/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0332 - val_loss: 560.4299\n",
      "Epoch 9892/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0294 - val_loss: 559.6387\n",
      "Epoch 9893/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1774 - val_loss: 559.6535\n",
      "Epoch 9894/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.7928 - val_loss: 560.4981\n",
      "Epoch 9895/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.7778 - val_loss: 560.2832\n",
      "Epoch 9896/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9124 - val_loss: 560.4761\n",
      "Epoch 9897/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.7008 - val_loss: 560.2300\n",
      "Epoch 9898/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0633 - val_loss: 559.9647\n",
      "Epoch 9899/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.8901 - val_loss: 559.9186\n",
      "Epoch 9900/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.8428 - val_loss: 559.7805\n",
      "Epoch 9901/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1162 - val_loss: 559.5072\n",
      "Epoch 9902/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.4752 - val_loss: 560.0400\n",
      "Epoch 9903/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.8967 - val_loss: 559.3470\n",
      "Epoch 9904/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.2536 - val_loss: 559.9788\n",
      "Epoch 9905/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9528 - val_loss: 559.6747\n",
      "Epoch 9906/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.6993 - val_loss: 560.7670\n",
      "Epoch 9907/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 466.0218 - val_loss: 560.1981\n",
      "Epoch 9908/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3951 - val_loss: 560.1717\n",
      "Epoch 9909/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0300 - val_loss: 560.9744\n",
      "Epoch 9910/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9249 - val_loss: 560.3047\n",
      "Epoch 9911/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 11us/sample - loss: 465.6251 - val_loss: 560.0888\n",
      "Epoch 9912/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9474 - val_loss: 560.7925\n",
      "Epoch 9913/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1683 - val_loss: 560.1357\n",
      "Epoch 9914/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0265 - val_loss: 559.4152\n",
      "Epoch 9915/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.5720 - val_loss: 560.2083\n",
      "Epoch 9916/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0767 - val_loss: 560.6390\n",
      "Epoch 9917/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9021 - val_loss: 559.9393\n",
      "Epoch 9918/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.6653 - val_loss: 559.9830\n",
      "Epoch 9919/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9269 - val_loss: 560.0926\n",
      "Epoch 9920/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.8241 - val_loss: 560.8219\n",
      "Epoch 9921/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.8723 - val_loss: 560.1618\n",
      "Epoch 9922/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.8099 - val_loss: 559.7596\n",
      "Epoch 9923/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.6106 - val_loss: 560.2610\n",
      "Epoch 9924/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.5693 - val_loss: 559.8076\n",
      "Epoch 9925/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.8917 - val_loss: 560.5369\n",
      "Epoch 9926/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9327 - val_loss: 560.0035\n",
      "Epoch 9927/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.6682 - val_loss: 560.5232\n",
      "Epoch 9928/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9473 - val_loss: 560.7252\n",
      "Epoch 9929/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.6793 - val_loss: 560.2585\n",
      "Epoch 9930/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.8241 - val_loss: 560.7142\n",
      "Epoch 9931/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0309 - val_loss: 560.2412\n",
      "Epoch 9932/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.5290 - val_loss: 560.7379\n",
      "Epoch 9933/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.6536 - val_loss: 560.1926\n",
      "Epoch 9934/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9902 - val_loss: 560.6947\n",
      "Epoch 9935/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0048 - val_loss: 559.8633\n",
      "Epoch 9936/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.5860 - val_loss: 559.8513\n",
      "Epoch 9937/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.7197 - val_loss: 560.6007\n",
      "Epoch 9938/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.5988 - val_loss: 560.0737\n",
      "Epoch 9939/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.5669 - val_loss: 559.5598\n",
      "Epoch 9940/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.7791 - val_loss: 559.7587\n",
      "Epoch 9941/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.2137 - val_loss: 559.9482\n",
      "Epoch 9942/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1120 - val_loss: 560.8532\n",
      "Epoch 9943/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.6097 - val_loss: 560.6459\n",
      "Epoch 9944/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.8075 - val_loss: 559.9250\n",
      "Epoch 9945/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.6466 - val_loss: 559.9924\n",
      "Epoch 9946/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1846 - val_loss: 560.0548\n",
      "Epoch 9947/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1064 - val_loss: 559.7415\n",
      "Epoch 9948/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.6831 - val_loss: 560.1198\n",
      "Epoch 9949/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1272 - val_loss: 559.8543\n",
      "Epoch 9950/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.6242 - val_loss: 559.9403\n",
      "Epoch 9951/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.2700 - val_loss: 559.7831\n",
      "Epoch 9952/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.4657 - val_loss: 560.0798\n",
      "Epoch 9953/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0160 - val_loss: 560.0239\n",
      "Epoch 9954/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.5198 - val_loss: 560.2419\n",
      "Epoch 9955/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0366 - val_loss: 559.4859\n",
      "Epoch 9956/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0281 - val_loss: 560.0675\n",
      "Epoch 9957/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.6459 - val_loss: 559.6836\n",
      "Epoch 9958/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.6613 - val_loss: 560.4336\n",
      "Epoch 9959/10000\n",
      "3000/3000 [==============================] - 0s 9us/sample - loss: 466.1388 - val_loss: 559.8560\n",
      "Epoch 9960/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9163 - val_loss: 560.3468\n",
      "Epoch 9961/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.8319 - val_loss: 559.9859\n",
      "Epoch 9962/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9498 - val_loss: 559.4922\n",
      "Epoch 9963/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9977 - val_loss: 560.4711\n",
      "Epoch 9964/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.8217 - val_loss: 560.0556\n",
      "Epoch 9965/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.6329 - val_loss: 560.4987\n",
      "Epoch 9966/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.8570 - val_loss: 560.4633\n",
      "Epoch 9967/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.6234 - val_loss: 560.3438\n",
      "Epoch 9968/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9579 - val_loss: 559.8329\n",
      "Epoch 9969/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 465.5336 - val_loss: 560.4845\n",
      "Epoch 9970/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 465.4996 - val_loss: 559.9676\n",
      "Epoch 9971/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 465.6889 - val_loss: 560.0523\n",
      "Epoch 9972/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 466.0318 - val_loss: 560.0456\n",
      "Epoch 9973/10000\n",
      "3000/3000 [==============================] - 0s 14us/sample - loss: 466.5248 - val_loss: 559.6509\n",
      "Epoch 9974/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.6653 - val_loss: 559.0451\n",
      "Epoch 9975/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.7163 - val_loss: 559.6248\n",
      "Epoch 9976/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 465.5882 - val_loss: 559.7811\n",
      "Epoch 9977/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.6469 - val_loss: 559.9045\n",
      "Epoch 9978/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.4903 - val_loss: 559.4506\n",
      "Epoch 9979/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.6589 - val_loss: 559.2725\n",
      "Epoch 9980/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 465.4487 - val_loss: 559.7079\n",
      "Epoch 9981/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 465.8304 - val_loss: 559.1091\n",
      "Epoch 9982/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 11us/sample - loss: 466.2938 - val_loss: 560.1682\n",
      "Epoch 9983/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 465.5398 - val_loss: 560.0436\n",
      "Epoch 9984/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 465.6163 - val_loss: 560.4833\n",
      "Epoch 9985/10000\n",
      "3000/3000 [==============================] - 0s 11us/sample - loss: 465.6786 - val_loss: 559.9481\n",
      "Epoch 9986/10000\n",
      "3000/3000 [==============================] - 0s 12us/sample - loss: 466.0895 - val_loss: 559.1964\n",
      "Epoch 9987/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.7885 - val_loss: 559.6363\n",
      "Epoch 9988/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.0110 - val_loss: 560.0271\n",
      "Epoch 9989/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.3271 - val_loss: 560.2384\n",
      "Epoch 9990/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.8145 - val_loss: 559.5313\n",
      "Epoch 9991/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.7410 - val_loss: 560.5089\n",
      "Epoch 9992/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.7115 - val_loss: 560.3741\n",
      "Epoch 9993/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9785 - val_loss: 559.2041\n",
      "Epoch 9994/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.7686 - val_loss: 559.8858\n",
      "Epoch 9995/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.9153 - val_loss: 559.3595\n",
      "Epoch 9996/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.7029 - val_loss: 560.0104\n",
      "Epoch 9997/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 466.1615 - val_loss: 560.0904\n",
      "Epoch 9998/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.7839 - val_loss: 560.4315\n",
      "Epoch 9999/10000\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.4327 - val_loss: 559.9514\n",
      "Epoch 10000/10000\n",
      " 128/3000 [>.............................] - ETA: 0s - loss: 504.7535Epoch: 10000 - loss: 465.633302 - val_loss: 559.995841\n",
      "3000/3000 [==============================] - 0s 10us/sample - loss: 465.6333 - val_loss: 559.9958\n"
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "model.compile(loss=\n",
    "'mse', optimizer=keras.optimizers.Adam(lr=.8, beta_1=0.9, beta_2=0.999, decay=1e-03, amsgrad=True))\n",
    "\n",
    "# Note continuous and categorical columns are inserted in the same order as defined in all_inputs\n",
    "history = model.fit([X_train_continuous, X_train_categorical['area_mapping']], y_train, \n",
    "          epochs=epochs, batch_size=128, \n",
    "          callbacks=[periodic_logger_250], verbose=1,\n",
    "          validation_data=([X_val_continuous, X_val_categorical[\n",
    "'area_mapping']], y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the train/validation loss values\n",
    "plt.figure(figsize=(20,10))\n",
    "_loss = history.history['loss'][250:]\n",
    "_val_loss = history.history['val_loss'][250:]\n",
    "train_loss_plot, = plt.plot(range(1, len(_loss)+1), _loss, label='Train Loss')\n",
    "val_loss_plot, = plt.plot(range(1, len(_val_loss)+1), _val_loss, label='Validation Loss')\n",
    "_ = plt.legend(handles=[train_loss_plot, val_loss_plot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How good are the model’s predictions\n",
    "\n",
    "df = y_val.copy()\n",
    "# Add a column for the model's predicted values\n",
    "df['pred'] = model.predict([X_val_continuous, X_val_categorical['area_mapping']])\n",
    "# Calculate the difference between the predicted and the actual price\n",
    "df['diff'] = df['pred'] - df['price']\n",
    "# Calculate the absolute difference between the predicted and the actual price\n",
    "df['abs_diff'] = np.abs(df['diff'])\n",
    "# Calculate the percentage of the difference from the actual price\n",
    "df['%diff'] = 100 * (df['diff'] / df['price'])\n",
    "# Calculate the absolute percentage difference from the actual price\n",
    "df['abs_%diff'] = np.abs(df['%diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>pred</th>\n",
       "      <th>diff</th>\n",
       "      <th>abs_diff</th>\n",
       "      <th>%diff</th>\n",
       "      <th>abs_%diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>412600.0</td>\n",
       "      <td>412720.781250</td>\n",
       "      <td>120.781250</td>\n",
       "      <td>120.781250</td>\n",
       "      <td>0.029273</td>\n",
       "      <td>0.029273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>412600.0</td>\n",
       "      <td>412720.781250</td>\n",
       "      <td>120.781250</td>\n",
       "      <td>120.781250</td>\n",
       "      <td>0.029273</td>\n",
       "      <td>0.029273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>203680.0</td>\n",
       "      <td>203792.875000</td>\n",
       "      <td>112.875000</td>\n",
       "      <td>112.875000</td>\n",
       "      <td>0.055418</td>\n",
       "      <td>0.055418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>207590.0</td>\n",
       "      <td>207489.453125</td>\n",
       "      <td>-100.546875</td>\n",
       "      <td>100.546875</td>\n",
       "      <td>-0.048435</td>\n",
       "      <td>0.048435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>207590.0</td>\n",
       "      <td>207489.453125</td>\n",
       "      <td>-100.546875</td>\n",
       "      <td>100.546875</td>\n",
       "      <td>-0.048435</td>\n",
       "      <td>0.048435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        price           pred        diff    abs_diff     %diff  abs_%diff\n",
       "223  412600.0  412720.781250  120.781250  120.781250  0.029273   0.029273\n",
       "133  412600.0  412720.781250  120.781250  120.781250  0.029273   0.029273\n",
       "137  203680.0  203792.875000  112.875000  112.875000  0.055418   0.055418\n",
       "35   207590.0  207489.453125 -100.546875  100.546875 -0.048435   0.048435\n",
       "65   207590.0  207489.453125 -100.546875  100.546875 -0.048435   0.048435"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the biggest difference in absolute values?\n",
    "# Sort by the 'abs_diff' field and show the 5 largest mistakes in absolute values\n",
    "df.sort_values(\"abs_diff\", ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean is very close to 0 (-0.51) with std. 23.7.\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean and std. of the diff field\n",
    "diff_mean, diff_std = df['diff'].mean(), df['diff'].std()\n",
    "print(\"The mean is very close to 0 ({mean}) with std. {std}.\".format(mean=round(diff_mean, 2),\n",
    "                                                                     std=round(diff_std, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram of the differences\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.hist(df['diff'], bins=100)\n",
    "plt.xlabel(\"$\")\n",
    "plt.ylabel(\"# samples\")\n",
    "_ = plt.title(\"Difference between predicted and actual price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
