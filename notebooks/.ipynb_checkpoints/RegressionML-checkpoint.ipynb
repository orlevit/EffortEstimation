{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "np.random.seed(7)\n",
    "\n",
    "# Constants\n",
    "TRAIN_AND_VALIDATION_TEST_SPLIT = 0.3\n",
    "VALID_AND_TEST_SPLIT            = 0.5\n",
    "BATCH_SIZE                      = 100\n",
    "\n",
    "# All posible relevent attributes\n",
    "relevent_attributes=[\"Priority\",\"RaisedByID\",\"AssignedToID\",\"StatusCode\",\\\n",
    "                     \"ProjectCode\",\"Category\",\"SubCategory\",\"HoursEstimate\",\"HoursActual\",\"AuthorisedByID\"]\n",
    "X_attributes=[\"Priority\",\"RaisedByID\",\"AssignedToID\",\"StatusCode\",\\\n",
    "                     \"ProjectCode\",\"Category\",\"SubCategory\",\"HoursEstimate\",\"AuthorisedByID\"]\n",
    "\n",
    "\n",
    "# The attributes that make the best accuarcy for the models\n",
    "relevent_attributes=[\"Priority\",\"AssignedToID\",\"StatusCode\",\\\n",
    "                     \"SubCategory\",\"HoursEstimate\",\"HoursActual\"]\n",
    "X_attributes=[\"Priority\",\"AssignedToID\",\"StatusCode\",\\\n",
    "                     \"SubCategory\",\"HoursEstimate\"]\n",
    "Y_attributes=[\"HoursActual\"]\n",
    "\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_curr_time():\n",
    "    dt = datetime.datetime.now()\n",
    "    curr_dt = '{0}{1}{2}_{3}_{4}'.format(datetime.datetime.now().year, datetime.datetime.now().month,\n",
    "                                       datetime.datetime.now().day, datetime.datetime.now().hour,\n",
    "                                      datetime.datetime.now().minute)\n",
    "    return curr_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Priority</th>\n",
       "      <th>RaisedByID</th>\n",
       "      <th>AssignedToID</th>\n",
       "      <th>AuthorisedByID</th>\n",
       "      <th>StatusCode</th>\n",
       "      <th>ProjectCode</th>\n",
       "      <th>Category</th>\n",
       "      <th>SubCategory</th>\n",
       "      <th>HoursEstimate</th>\n",
       "      <th>HoursActual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12299.000000</td>\n",
       "      <td>1.229900e+04</td>\n",
       "      <td>1.229900e+04</td>\n",
       "      <td>1.229900e+04</td>\n",
       "      <td>1.229900e+04</td>\n",
       "      <td>1.229900e+04</td>\n",
       "      <td>1.229900e+04</td>\n",
       "      <td>1.229900e+04</td>\n",
       "      <td>1.229900e+04</td>\n",
       "      <td>1.229900e+04</td>\n",
       "      <td>1.229900e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6149.000000</td>\n",
       "      <td>1.848717e-17</td>\n",
       "      <td>8.319225e-17</td>\n",
       "      <td>1.178557e-16</td>\n",
       "      <td>2.773075e-17</td>\n",
       "      <td>-3.697434e-17</td>\n",
       "      <td>-2.033588e-16</td>\n",
       "      <td>5.546150e-17</td>\n",
       "      <td>-1.201666e-16</td>\n",
       "      <td>4.621792e-17</td>\n",
       "      <td>-9.243584e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3550.559815</td>\n",
       "      <td>1.000041e+00</td>\n",
       "      <td>1.000041e+00</td>\n",
       "      <td>1.000041e+00</td>\n",
       "      <td>5.889010e-01</td>\n",
       "      <td>1.000041e+00</td>\n",
       "      <td>1.000041e+00</td>\n",
       "      <td>1.000041e+00</td>\n",
       "      <td>1.000041e+00</td>\n",
       "      <td>1.000041e+00</td>\n",
       "      <td>1.000041e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.839360e-01</td>\n",
       "      <td>-1.817993e+00</td>\n",
       "      <td>-1.928330e+00</td>\n",
       "      <td>-2.113198e+00</td>\n",
       "      <td>-2.854560e+00</td>\n",
       "      <td>-2.807881e+00</td>\n",
       "      <td>-6.513367e-01</td>\n",
       "      <td>-1.412901e+00</td>\n",
       "      <td>-3.516581e-01</td>\n",
       "      <td>-1.915761e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3074.500000</td>\n",
       "      <td>-6.839360e-01</td>\n",
       "      <td>-1.062657e+00</td>\n",
       "      <td>-8.126678e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-5.174389e-01</td>\n",
       "      <td>-6.273901e-01</td>\n",
       "      <td>-6.513367e-01</td>\n",
       "      <td>-9.425033e-01</td>\n",
       "      <td>-3.173315e-01</td>\n",
       "      <td>-1.771702e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6149.000000</td>\n",
       "      <td>-6.839360e-01</td>\n",
       "      <td>2.465911e-01</td>\n",
       "      <td>2.498672e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-5.174389e-01</td>\n",
       "      <td>-1.428367e-01</td>\n",
       "      <td>-6.513367e-01</td>\n",
       "      <td>-3.153067e-01</td>\n",
       "      <td>-2.479848e-01</td>\n",
       "      <td>-1.480674e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9223.500000</td>\n",
       "      <td>4.788687e-01</td>\n",
       "      <td>1.052282e+00</td>\n",
       "      <td>1.099895e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.040642e+00</td>\n",
       "      <td>5.839935e-01</td>\n",
       "      <td>6.721046e-01</td>\n",
       "      <td>6.254883e-01</td>\n",
       "      <td>-1.092915e-01</td>\n",
       "      <td>-6.803464e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12298.000000</td>\n",
       "      <td>4.548685e+00</td>\n",
       "      <td>1.505484e+00</td>\n",
       "      <td>1.471783e+00</td>\n",
       "      <td>6.569847e-01</td>\n",
       "      <td>2.598723e+00</td>\n",
       "      <td>1.795377e+00</td>\n",
       "      <td>1.995546e+00</td>\n",
       "      <td>2.193480e+00</td>\n",
       "      <td>3.120073e+01</td>\n",
       "      <td>3.604361e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0      Priority    RaisedByID  AssignedToID  AuthorisedByID  \\\n",
       "count  12299.000000  1.229900e+04  1.229900e+04  1.229900e+04    1.229900e+04   \n",
       "mean    6149.000000  1.848717e-17  8.319225e-17  1.178557e-16    2.773075e-17   \n",
       "std     3550.559815  1.000041e+00  1.000041e+00  1.000041e+00    5.889010e-01   \n",
       "min        0.000000 -6.839360e-01 -1.817993e+00 -1.928330e+00   -2.113198e+00   \n",
       "25%     3074.500000 -6.839360e-01 -1.062657e+00 -8.126678e-01    0.000000e+00   \n",
       "50%     6149.000000 -6.839360e-01  2.465911e-01  2.498672e-01    0.000000e+00   \n",
       "75%     9223.500000  4.788687e-01  1.052282e+00  1.099895e+00    0.000000e+00   \n",
       "max    12298.000000  4.548685e+00  1.505484e+00  1.471783e+00    6.569847e-01   \n",
       "\n",
       "         StatusCode   ProjectCode      Category   SubCategory  HoursEstimate  \\\n",
       "count  1.229900e+04  1.229900e+04  1.229900e+04  1.229900e+04   1.229900e+04   \n",
       "mean  -3.697434e-17 -2.033588e-16  5.546150e-17 -1.201666e-16   4.621792e-17   \n",
       "std    1.000041e+00  1.000041e+00  1.000041e+00  1.000041e+00   1.000041e+00   \n",
       "min   -2.854560e+00 -2.807881e+00 -6.513367e-01 -1.412901e+00  -3.516581e-01   \n",
       "25%   -5.174389e-01 -6.273901e-01 -6.513367e-01 -9.425033e-01  -3.173315e-01   \n",
       "50%   -5.174389e-01 -1.428367e-01 -6.513367e-01 -3.153067e-01  -2.479848e-01   \n",
       "75%    1.040642e+00  5.839935e-01  6.721046e-01  6.254883e-01  -1.092915e-01   \n",
       "max    2.598723e+00  1.795377e+00  1.995546e+00  2.193480e+00   3.120073e+01   \n",
       "\n",
       "        HoursActual  \n",
       "count  1.229900e+04  \n",
       "mean  -9.243584e-18  \n",
       "std    1.000041e+00  \n",
       "min   -1.915761e-01  \n",
       "25%   -1.771702e-01  \n",
       "50%   -1.480674e-01  \n",
       "75%   -6.803464e-02  \n",
       "max    3.604361e+01  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../SiP_dataset-master/SIP_CAT_GAUS.csv', encoding='cp1252') \n",
    "data.fillna(0, inplace = True)\n",
    "\n",
    "data.head()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Priority</th>\n",
       "      <th>AssignedToID</th>\n",
       "      <th>StatusCode</th>\n",
       "      <th>SubCategory</th>\n",
       "      <th>HoursEstimate</th>\n",
       "      <th>HoursActual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.683936</td>\n",
       "      <td>1.099895</td>\n",
       "      <td>1.040642</td>\n",
       "      <td>-0.315307</td>\n",
       "      <td>0.133422</td>\n",
       "      <td>-0.166257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.683936</td>\n",
       "      <td>0.249867</td>\n",
       "      <td>1.040642</td>\n",
       "      <td>-0.315307</td>\n",
       "      <td>-0.109292</td>\n",
       "      <td>-0.089862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.102534</td>\n",
       "      <td>1.099895</td>\n",
       "      <td>1.040642</td>\n",
       "      <td>-0.001708</td>\n",
       "      <td>-0.327734</td>\n",
       "      <td>-0.181536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.641673</td>\n",
       "      <td>0.249867</td>\n",
       "      <td>1.040642</td>\n",
       "      <td>-1.256102</td>\n",
       "      <td>-0.327734</td>\n",
       "      <td>-0.181536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.548685</td>\n",
       "      <td>-1.290809</td>\n",
       "      <td>1.040642</td>\n",
       "      <td>-1.256102</td>\n",
       "      <td>-0.230648</td>\n",
       "      <td>-0.140792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Priority  AssignedToID  StatusCode  SubCategory  HoursEstimate  HoursActual\n",
       "0 -0.683936      1.099895    1.040642    -0.315307       0.133422    -0.166257\n",
       "1 -0.683936      0.249867    1.040642    -0.315307      -0.109292    -0.089862\n",
       "2 -0.102534      1.099895    1.040642    -0.001708      -0.327734    -0.181536\n",
       "3  1.641673      0.249867    1.040642    -1.256102      -0.327734    -0.181536\n",
       "4  4.548685     -1.290809    1.040642    -1.256102      -0.230648    -0.140792"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[relevent_attributes]\n",
    "ROW_COUNT = max(data.count())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples: (8609, 5)\n",
      "Valid examples: (1845, 5)\n",
      "Test examples: (1845, 5)\n"
     ]
    }
   ],
   "source": [
    "# HoursEstimate_filter=HoursEstimate[HoursEstimate[\"HoursEstimate\"]<200]\n",
    "# HoursEstimate_filter=HoursEstimate_filter[HoursEstimate_filter[\"HoursActual\"]<800]\n",
    "\n",
    "x_train_label, xx_test_label, y_train_label, yy_test_label \\\n",
    "              = train_test_split(data[X_attributes].values[:], data[Y_attributes].values[:], test_size=TRAIN_AND_VALIDATION_TEST_SPLIT)\n",
    "x_valid_label, x_test_label, y_valid_label, y_test_label \\\n",
    "              = train_test_split(xx_test_label, yy_test_label, test_size=VALID_AND_TEST_SPLIT)  \n",
    "\n",
    "print(\"Train examples: {}\".format(x_train_label.shape))\n",
    "print(\"Valid examples: {}\".format(x_valid_label.shape))\n",
    "print(\"Test examples: {}\".format(x_test_label.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1845, 5)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Dense(2048, kernel_initializer='normal'), \n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.8),\n",
    "#     tf.keras.layers.Dense(1024,  kernel_initializer='normal'), \n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.8),\n",
    "#     tf.keras.layers.add(tf.keras.layers.Flatten(input_shape = (BATCH_SIZE,x_train_label.shape[1],1))),\n",
    "    tf.keras.layers.Dense(2048, kernel_initializer='normal',input_shape = (x_train_label.shape[1],)), \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.8),\n",
    "    tf.keras.layers.Dense(1024, kernel_initializer='normal'), \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.8),\n",
    "#     tf.keras.layers.Dense(128, kernel_initializer='normal'), \n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.8),\n",
    "#     tf.keras.layers.Dense(64, kernel_initializer='normal'), \n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.8),\n",
    "    tf.keras.layers.Dense(1)\n",
    "    \n",
    "    \n",
    "#     tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8609 samples, validate on 1845 samples\n",
      "Epoch 1/350\n",
      "8609/8609 [==============================] - 1s 80us/step - loss: 6.8290 - mean_squared_error: 6.8290 - val_loss: 1.4158 - val_mean_squared_error: 1.4158\n",
      "Epoch 2/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 6.0032 - mean_squared_error: 6.0032 - val_loss: 1.4013 - val_mean_squared_error: 1.4013\n",
      "Epoch 3/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 6.2411 - mean_squared_error: 6.2411 - val_loss: 1.4353 - val_mean_squared_error: 1.4353\n",
      "Epoch 4/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 5.6582 - mean_squared_error: 5.6582 - val_loss: 1.4516 - val_mean_squared_error: 1.4516\n",
      "Epoch 5/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 5.2950 - mean_squared_error: 5.2950 - val_loss: 1.4619 - val_mean_squared_error: 1.4619\n",
      "Epoch 6/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 5.5234 - mean_squared_error: 5.5234 - val_loss: 1.4809 - val_mean_squared_error: 1.4809\n",
      "Epoch 7/350\n",
      "8609/8609 [==============================] - 0s 4us/step - loss: 5.3660 - mean_squared_error: 5.3660 - val_loss: 1.4935 - val_mean_squared_error: 1.4935\n",
      "Epoch 8/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 5.3672 - mean_squared_error: 5.3672 - val_loss: 1.4928 - val_mean_squared_error: 1.4928\n",
      "Epoch 9/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 5.1310 - mean_squared_error: 5.1310 - val_loss: 1.4788 - val_mean_squared_error: 1.4788\n",
      "Epoch 10/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 4.7434 - mean_squared_error: 4.7434 - val_loss: 1.4668 - val_mean_squared_error: 1.4668\n",
      "Epoch 11/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 4.7007 - mean_squared_error: 4.7007 - val_loss: 1.4520 - val_mean_squared_error: 1.4520\n",
      "Epoch 12/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 4.8423 - mean_squared_error: 4.8423 - val_loss: 1.4370 - val_mean_squared_error: 1.4370\n",
      "Epoch 13/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 4.2714 - mean_squared_error: 4.2714 - val_loss: 1.4221 - val_mean_squared_error: 1.4221\n",
      "Epoch 14/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 4.4136 - mean_squared_error: 4.4136 - val_loss: 1.4094 - val_mean_squared_error: 1.4094\n",
      "Epoch 15/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 4.0974 - mean_squared_error: 4.0974 - val_loss: 1.4028 - val_mean_squared_error: 1.4028\n",
      "Epoch 16/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 4.5596 - mean_squared_error: 4.5596 - val_loss: 1.4045 - val_mean_squared_error: 1.4045\n",
      "Epoch 17/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 4.0208 - mean_squared_error: 4.0208 - val_loss: 1.4094 - val_mean_squared_error: 1.4094\n",
      "Epoch 18/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 4.4256 - mean_squared_error: 4.4256 - val_loss: 1.4171 - val_mean_squared_error: 1.4171\n",
      "Epoch 19/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 3.7790 - mean_squared_error: 3.7790 - val_loss: 1.4256 - val_mean_squared_error: 1.4256\n",
      "Epoch 20/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 3.9281 - mean_squared_error: 3.9281 - val_loss: 1.4335 - val_mean_squared_error: 1.4335\n",
      "Epoch 21/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 3.6317 - mean_squared_error: 3.6317 - val_loss: 1.4404 - val_mean_squared_error: 1.4404\n",
      "Epoch 22/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 3.4316 - mean_squared_error: 3.4316 - val_loss: 1.4467 - val_mean_squared_error: 1.4467\n",
      "Epoch 23/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 3.4515 - mean_squared_error: 3.4515 - val_loss: 1.4496 - val_mean_squared_error: 1.4496\n",
      "Epoch 24/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 3.3603 - mean_squared_error: 3.3603 - val_loss: 1.4498 - val_mean_squared_error: 1.4498\n",
      "Epoch 25/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 3.3892 - mean_squared_error: 3.3892 - val_loss: 1.4472 - val_mean_squared_error: 1.4472\n",
      "Epoch 26/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 3.3144 - mean_squared_error: 3.3144 - val_loss: 1.4451 - val_mean_squared_error: 1.4451\n",
      "Epoch 27/350\n",
      "8609/8609 [==============================] - 0s 4us/step - loss: 3.2559 - mean_squared_error: 3.2559 - val_loss: 1.4411 - val_mean_squared_error: 1.4411\n",
      "Epoch 28/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 3.2535 - mean_squared_error: 3.2535 - val_loss: 1.4381 - val_mean_squared_error: 1.4381\n",
      "Epoch 29/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 3.1288 - mean_squared_error: 3.1288 - val_loss: 1.4362 - val_mean_squared_error: 1.4362\n",
      "Epoch 30/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 3.0103 - mean_squared_error: 3.0103 - val_loss: 1.4335 - val_mean_squared_error: 1.4335\n",
      "Epoch 31/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 2.9908 - mean_squared_error: 2.9908 - val_loss: 1.4294 - val_mean_squared_error: 1.4294\n",
      "Epoch 32/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 3.0411 - mean_squared_error: 3.0411 - val_loss: 1.4256 - val_mean_squared_error: 1.4256\n",
      "Epoch 33/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 2.7801 - mean_squared_error: 2.7801 - val_loss: 1.4220 - val_mean_squared_error: 1.4220\n",
      "Epoch 34/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 2.8151 - mean_squared_error: 2.8151 - val_loss: 1.4183 - val_mean_squared_error: 1.4183\n",
      "Epoch 35/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 2.6094 - mean_squared_error: 2.6094 - val_loss: 1.4149 - val_mean_squared_error: 1.4149\n",
      "Epoch 36/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 2.5933 - mean_squared_error: 2.5933 - val_loss: 1.4119 - val_mean_squared_error: 1.4119\n",
      "Epoch 37/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 2.6311 - mean_squared_error: 2.6311 - val_loss: 1.4092 - val_mean_squared_error: 1.4092\n",
      "Epoch 38/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 2.5965 - mean_squared_error: 2.5965 - val_loss: 1.4068 - val_mean_squared_error: 1.4068\n",
      "Epoch 39/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 2.8292 - mean_squared_error: 2.8292 - val_loss: 1.4057 - val_mean_squared_error: 1.4057\n",
      "Epoch 40/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 2.4711 - mean_squared_error: 2.4711 - val_loss: 1.4056 - val_mean_squared_error: 1.4056\n",
      "Epoch 41/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 2.4189 - mean_squared_error: 2.4189 - val_loss: 1.4061 - val_mean_squared_error: 1.4061\n",
      "Epoch 42/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 2.4856 - mean_squared_error: 2.4856 - val_loss: 1.4077 - val_mean_squared_error: 1.4077\n",
      "Epoch 43/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 2.2242 - mean_squared_error: 2.2242 - val_loss: 1.4098 - val_mean_squared_error: 1.4098\n",
      "Epoch 44/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 2.2523 - mean_squared_error: 2.2523 - val_loss: 1.4118 - val_mean_squared_error: 1.4118\n",
      "Epoch 45/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 2.1731 - mean_squared_error: 2.1731 - val_loss: 1.4136 - val_mean_squared_error: 1.4136\n",
      "Epoch 46/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 2.2601 - mean_squared_error: 2.2601 - val_loss: 1.4153 - val_mean_squared_error: 1.4153\n",
      "Epoch 47/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 2.1957 - mean_squared_error: 2.1957 - val_loss: 1.4163 - val_mean_squared_error: 1.4163\n",
      "Epoch 48/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 2.1801 - mean_squared_error: 2.1801 - val_loss: 1.4174 - val_mean_squared_error: 1.4174\n",
      "Epoch 49/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 2.0772 - mean_squared_error: 2.0772 - val_loss: 1.4178 - val_mean_squared_error: 1.4178\n",
      "Epoch 50/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 2.0106 - mean_squared_error: 2.0106 - val_loss: 1.4177 - val_mean_squared_error: 1.4177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.9500 - mean_squared_error: 1.9500 - val_loss: 1.4171 - val_mean_squared_error: 1.4171\n",
      "Epoch 52/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.9729 - mean_squared_error: 1.9729 - val_loss: 1.4159 - val_mean_squared_error: 1.4159\n",
      "Epoch 53/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.8421 - mean_squared_error: 1.8421 - val_loss: 1.4145 - val_mean_squared_error: 1.4145\n",
      "Epoch 54/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.9468 - mean_squared_error: 1.9468 - val_loss: 1.4133 - val_mean_squared_error: 1.4133\n",
      "Epoch 55/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.8953 - mean_squared_error: 1.8953 - val_loss: 1.4120 - val_mean_squared_error: 1.4120\n",
      "Epoch 56/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.8536 - mean_squared_error: 1.8536 - val_loss: 1.4105 - val_mean_squared_error: 1.4105\n",
      "Epoch 57/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.8299 - mean_squared_error: 1.8299 - val_loss: 1.4090 - val_mean_squared_error: 1.4090\n",
      "Epoch 58/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.8131 - mean_squared_error: 1.8131 - val_loss: 1.4075 - val_mean_squared_error: 1.4075\n",
      "Epoch 59/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.7788 - mean_squared_error: 1.7788 - val_loss: 1.4060 - val_mean_squared_error: 1.4060\n",
      "Epoch 60/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.7542 - mean_squared_error: 1.7542 - val_loss: 1.4048 - val_mean_squared_error: 1.4048\n",
      "Epoch 61/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.7229 - mean_squared_error: 1.7229 - val_loss: 1.4038 - val_mean_squared_error: 1.4038\n",
      "Epoch 62/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.7031 - mean_squared_error: 1.7031 - val_loss: 1.4031 - val_mean_squared_error: 1.4031\n",
      "Epoch 63/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.6703 - mean_squared_error: 1.6703 - val_loss: 1.4026 - val_mean_squared_error: 1.4026\n",
      "Epoch 64/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.6375 - mean_squared_error: 1.6375 - val_loss: 1.4021 - val_mean_squared_error: 1.4021\n",
      "Epoch 65/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.6120 - mean_squared_error: 1.6120 - val_loss: 1.4016 - val_mean_squared_error: 1.4016\n",
      "Epoch 66/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.6238 - mean_squared_error: 1.6238 - val_loss: 1.4012 - val_mean_squared_error: 1.4012\n",
      "Epoch 67/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.6623 - mean_squared_error: 1.6623 - val_loss: 1.4011 - val_mean_squared_error: 1.4011\n",
      "Epoch 68/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.5767 - mean_squared_error: 1.5767 - val_loss: 1.4011 - val_mean_squared_error: 1.4011\n",
      "Epoch 69/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.5776 - mean_squared_error: 1.5776 - val_loss: 1.4015 - val_mean_squared_error: 1.4015\n",
      "Epoch 70/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.4773 - mean_squared_error: 1.4773 - val_loss: 1.4019 - val_mean_squared_error: 1.4019\n",
      "Epoch 71/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.5471 - mean_squared_error: 1.5471 - val_loss: 1.4024 - val_mean_squared_error: 1.4024\n",
      "Epoch 72/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.5916 - mean_squared_error: 1.5916 - val_loss: 1.4030 - val_mean_squared_error: 1.4030\n",
      "Epoch 73/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.5131 - mean_squared_error: 1.5131 - val_loss: 1.4034 - val_mean_squared_error: 1.4034\n",
      "Epoch 74/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.4515 - mean_squared_error: 1.4515 - val_loss: 1.4040 - val_mean_squared_error: 1.4040\n",
      "Epoch 75/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.4528 - mean_squared_error: 1.4528 - val_loss: 1.4045 - val_mean_squared_error: 1.4045\n",
      "Epoch 76/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.4295 - mean_squared_error: 1.4295 - val_loss: 1.4048 - val_mean_squared_error: 1.4048\n",
      "Epoch 77/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.4492 - mean_squared_error: 1.4492 - val_loss: 1.4052 - val_mean_squared_error: 1.4052\n",
      "Epoch 78/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.3735 - mean_squared_error: 1.3735 - val_loss: 1.4054 - val_mean_squared_error: 1.4054\n",
      "Epoch 79/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.3873 - mean_squared_error: 1.3873 - val_loss: 1.4056 - val_mean_squared_error: 1.4056\n",
      "Epoch 80/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.3948 - mean_squared_error: 1.3948 - val_loss: 1.4056 - val_mean_squared_error: 1.4056\n",
      "Epoch 81/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.3481 - mean_squared_error: 1.3481 - val_loss: 1.4055 - val_mean_squared_error: 1.4055\n",
      "Epoch 82/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.3572 - mean_squared_error: 1.3572 - val_loss: 1.4054 - val_mean_squared_error: 1.4054\n",
      "Epoch 83/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.3825 - mean_squared_error: 1.3825 - val_loss: 1.4052 - val_mean_squared_error: 1.4052\n",
      "Epoch 84/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.3331 - mean_squared_error: 1.3331 - val_loss: 1.4050 - val_mean_squared_error: 1.4050\n",
      "Epoch 85/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.3157 - mean_squared_error: 1.3157 - val_loss: 1.4048 - val_mean_squared_error: 1.4048\n",
      "Epoch 86/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.3258 - mean_squared_error: 1.3258 - val_loss: 1.4045 - val_mean_squared_error: 1.4045\n",
      "Epoch 87/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.3233 - mean_squared_error: 1.3233 - val_loss: 1.4041 - val_mean_squared_error: 1.4041\n",
      "Epoch 88/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.2808 - mean_squared_error: 1.2808 - val_loss: 1.4038 - val_mean_squared_error: 1.4038\n",
      "Epoch 89/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.2884 - mean_squared_error: 1.2884 - val_loss: 1.4034 - val_mean_squared_error: 1.4034\n",
      "Epoch 90/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.3006 - mean_squared_error: 1.3006 - val_loss: 1.4030 - val_mean_squared_error: 1.4030\n",
      "Epoch 91/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.3140 - mean_squared_error: 1.3140 - val_loss: 1.4026 - val_mean_squared_error: 1.4026\n",
      "Epoch 92/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.2403 - mean_squared_error: 1.2403 - val_loss: 1.4023 - val_mean_squared_error: 1.4023\n",
      "Epoch 93/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.2590 - mean_squared_error: 1.2590 - val_loss: 1.4020 - val_mean_squared_error: 1.4020\n",
      "Epoch 94/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.2695 - mean_squared_error: 1.2695 - val_loss: 1.4019 - val_mean_squared_error: 1.4019\n",
      "Epoch 95/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.2619 - mean_squared_error: 1.2619 - val_loss: 1.4020 - val_mean_squared_error: 1.4020\n",
      "Epoch 96/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.2437 - mean_squared_error: 1.2437 - val_loss: 1.4021 - val_mean_squared_error: 1.4021\n",
      "Epoch 97/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.1884 - mean_squared_error: 1.1884 - val_loss: 1.4023 - val_mean_squared_error: 1.4023\n",
      "Epoch 98/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.2417 - mean_squared_error: 1.2417 - val_loss: 1.4024 - val_mean_squared_error: 1.4024\n",
      "Epoch 99/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.1933 - mean_squared_error: 1.1933 - val_loss: 1.4025 - val_mean_squared_error: 1.4025\n",
      "Epoch 100/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.2144 - mean_squared_error: 1.2144 - val_loss: 1.4026 - val_mean_squared_error: 1.4026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.2088 - mean_squared_error: 1.2088 - val_loss: 1.4028 - val_mean_squared_error: 1.4028\n",
      "Epoch 102/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.2128 - mean_squared_error: 1.2128 - val_loss: 1.4030 - val_mean_squared_error: 1.4030\n",
      "Epoch 103/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.1917 - mean_squared_error: 1.1917 - val_loss: 1.4032 - val_mean_squared_error: 1.4032\n",
      "Epoch 104/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.1492 - mean_squared_error: 1.1492 - val_loss: 1.4032 - val_mean_squared_error: 1.4032\n",
      "Epoch 105/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.1970 - mean_squared_error: 1.1970 - val_loss: 1.4032 - val_mean_squared_error: 1.4032\n",
      "Epoch 106/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.1718 - mean_squared_error: 1.1718 - val_loss: 1.4031 - val_mean_squared_error: 1.4031\n",
      "Epoch 107/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.1869 - mean_squared_error: 1.1869 - val_loss: 1.4029 - val_mean_squared_error: 1.4029\n",
      "Epoch 108/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.1526 - mean_squared_error: 1.1526 - val_loss: 1.4027 - val_mean_squared_error: 1.4027\n",
      "Epoch 109/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.1558 - mean_squared_error: 1.1558 - val_loss: 1.4025 - val_mean_squared_error: 1.4025\n",
      "Epoch 110/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.1431 - mean_squared_error: 1.1431 - val_loss: 1.4023 - val_mean_squared_error: 1.4023\n",
      "Epoch 111/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.1502 - mean_squared_error: 1.1502 - val_loss: 1.4022 - val_mean_squared_error: 1.4022\n",
      "Epoch 112/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.1499 - mean_squared_error: 1.1499 - val_loss: 1.4021 - val_mean_squared_error: 1.4021\n",
      "Epoch 113/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.1435 - mean_squared_error: 1.1435 - val_loss: 1.4020 - val_mean_squared_error: 1.4020\n",
      "Epoch 114/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.1375 - mean_squared_error: 1.1375 - val_loss: 1.4019 - val_mean_squared_error: 1.4019\n",
      "Epoch 115/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.1453 - mean_squared_error: 1.1453 - val_loss: 1.4019 - val_mean_squared_error: 1.4019\n",
      "Epoch 116/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.1326 - mean_squared_error: 1.1326 - val_loss: 1.4019 - val_mean_squared_error: 1.4019\n",
      "Epoch 117/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.1387 - mean_squared_error: 1.1387 - val_loss: 1.4019 - val_mean_squared_error: 1.4019\n",
      "Epoch 118/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.1256 - mean_squared_error: 1.1256 - val_loss: 1.4018 - val_mean_squared_error: 1.4018\n",
      "Epoch 119/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.1182 - mean_squared_error: 1.1182 - val_loss: 1.4017 - val_mean_squared_error: 1.4017\n",
      "Epoch 120/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.1148 - mean_squared_error: 1.1148 - val_loss: 1.4014 - val_mean_squared_error: 1.4014\n",
      "Epoch 121/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.1231 - mean_squared_error: 1.1231 - val_loss: 1.4011 - val_mean_squared_error: 1.4011\n",
      "Epoch 122/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.1232 - mean_squared_error: 1.1232 - val_loss: 1.4008 - val_mean_squared_error: 1.4008\n",
      "Epoch 123/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.1172 - mean_squared_error: 1.1172 - val_loss: 1.4008 - val_mean_squared_error: 1.4008\n",
      "Epoch 124/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.1037 - mean_squared_error: 1.1037 - val_loss: 1.4007 - val_mean_squared_error: 1.4007\n",
      "Epoch 125/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0821 - mean_squared_error: 1.0821 - val_loss: 1.4006 - val_mean_squared_error: 1.4006\n",
      "Epoch 126/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0801 - mean_squared_error: 1.0801 - val_loss: 1.4005 - val_mean_squared_error: 1.4005\n",
      "Epoch 127/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.1103 - mean_squared_error: 1.1103 - val_loss: 1.4005 - val_mean_squared_error: 1.4005\n",
      "Epoch 128/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.1026 - mean_squared_error: 1.1026 - val_loss: 1.4006 - val_mean_squared_error: 1.4006\n",
      "Epoch 129/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0813 - mean_squared_error: 1.0813 - val_loss: 1.4006 - val_mean_squared_error: 1.4006\n",
      "Epoch 130/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0660 - mean_squared_error: 1.0660 - val_loss: 1.4006 - val_mean_squared_error: 1.4006\n",
      "Epoch 131/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0755 - mean_squared_error: 1.0755 - val_loss: 1.4006 - val_mean_squared_error: 1.4006\n",
      "Epoch 132/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0795 - mean_squared_error: 1.0795 - val_loss: 1.4004 - val_mean_squared_error: 1.4004\n",
      "Epoch 133/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0786 - mean_squared_error: 1.0786 - val_loss: 1.4003 - val_mean_squared_error: 1.4003\n",
      "Epoch 134/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0763 - mean_squared_error: 1.0763 - val_loss: 1.4001 - val_mean_squared_error: 1.4001\n",
      "Epoch 135/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0894 - mean_squared_error: 1.0894 - val_loss: 1.3999 - val_mean_squared_error: 1.3999\n",
      "Epoch 136/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0575 - mean_squared_error: 1.0575 - val_loss: 1.3998 - val_mean_squared_error: 1.3998\n",
      "Epoch 137/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0641 - mean_squared_error: 1.0641 - val_loss: 1.3997 - val_mean_squared_error: 1.3997\n",
      "Epoch 138/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0603 - mean_squared_error: 1.0603 - val_loss: 1.3997 - val_mean_squared_error: 1.3997\n",
      "Epoch 139/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0588 - mean_squared_error: 1.0588 - val_loss: 1.3997 - val_mean_squared_error: 1.3997\n",
      "Epoch 140/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0626 - mean_squared_error: 1.0626 - val_loss: 1.3997 - val_mean_squared_error: 1.3997\n",
      "Epoch 141/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0626 - mean_squared_error: 1.0626 - val_loss: 1.3998 - val_mean_squared_error: 1.3998\n",
      "Epoch 142/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0562 - mean_squared_error: 1.0562 - val_loss: 1.3998 - val_mean_squared_error: 1.3998\n",
      "Epoch 143/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0500 - mean_squared_error: 1.0500 - val_loss: 1.3999 - val_mean_squared_error: 1.3999\n",
      "Epoch 144/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0384 - mean_squared_error: 1.0384 - val_loss: 1.3999 - val_mean_squared_error: 1.3999\n",
      "Epoch 145/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0428 - mean_squared_error: 1.0428 - val_loss: 1.3998 - val_mean_squared_error: 1.3998\n",
      "Epoch 146/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0395 - mean_squared_error: 1.0395 - val_loss: 1.3996 - val_mean_squared_error: 1.3996\n",
      "Epoch 147/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0620 - mean_squared_error: 1.0620 - val_loss: 1.3995 - val_mean_squared_error: 1.3995\n",
      "Epoch 148/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0438 - mean_squared_error: 1.0438 - val_loss: 1.3995 - val_mean_squared_error: 1.3995\n",
      "Epoch 149/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0332 - mean_squared_error: 1.0332 - val_loss: 1.3993 - val_mean_squared_error: 1.3993\n",
      "Epoch 150/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0423 - mean_squared_error: 1.0423 - val_loss: 1.3991 - val_mean_squared_error: 1.3991\n",
      "Epoch 151/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0454 - mean_squared_error: 1.0454 - val_loss: 1.3989 - val_mean_squared_error: 1.3989\n",
      "Epoch 152/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0628 - mean_squared_error: 1.0628 - val_loss: 1.3989 - val_mean_squared_error: 1.3989\n",
      "Epoch 153/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0332 - mean_squared_error: 1.0332 - val_loss: 1.3989 - val_mean_squared_error: 1.3989\n",
      "Epoch 154/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0255 - mean_squared_error: 1.0255 - val_loss: 1.3988 - val_mean_squared_error: 1.3988\n",
      "Epoch 155/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0245 - mean_squared_error: 1.0245 - val_loss: 1.3986 - val_mean_squared_error: 1.3986\n",
      "Epoch 156/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0291 - mean_squared_error: 1.0291 - val_loss: 1.3984 - val_mean_squared_error: 1.3984\n",
      "Epoch 157/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0288 - mean_squared_error: 1.0288 - val_loss: 1.3981 - val_mean_squared_error: 1.3981\n",
      "Epoch 158/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0356 - mean_squared_error: 1.0356 - val_loss: 1.3979 - val_mean_squared_error: 1.3979\n",
      "Epoch 159/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0415 - mean_squared_error: 1.0415 - val_loss: 1.3977 - val_mean_squared_error: 1.3977\n",
      "Epoch 160/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0257 - mean_squared_error: 1.0257 - val_loss: 1.3975 - val_mean_squared_error: 1.3975\n",
      "Epoch 161/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0282 - mean_squared_error: 1.0282 - val_loss: 1.3974 - val_mean_squared_error: 1.3974\n",
      "Epoch 162/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0235 - mean_squared_error: 1.0235 - val_loss: 1.3972 - val_mean_squared_error: 1.3972\n",
      "Epoch 163/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0138 - mean_squared_error: 1.0138 - val_loss: 1.3969 - val_mean_squared_error: 1.3969\n",
      "Epoch 164/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0207 - mean_squared_error: 1.0207 - val_loss: 1.3967 - val_mean_squared_error: 1.3967\n",
      "Epoch 165/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0177 - mean_squared_error: 1.0177 - val_loss: 1.3963 - val_mean_squared_error: 1.3963\n",
      "Epoch 166/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0285 - mean_squared_error: 1.0285 - val_loss: 1.3961 - val_mean_squared_error: 1.3961\n",
      "Epoch 167/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0129 - mean_squared_error: 1.0129 - val_loss: 1.3958 - val_mean_squared_error: 1.3958\n",
      "Epoch 168/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0099 - mean_squared_error: 1.0099 - val_loss: 1.3955 - val_mean_squared_error: 1.3955\n",
      "Epoch 169/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0174 - mean_squared_error: 1.0174 - val_loss: 1.3951 - val_mean_squared_error: 1.3951\n",
      "Epoch 170/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0026 - mean_squared_error: 1.0026 - val_loss: 1.3948 - val_mean_squared_error: 1.3948\n",
      "Epoch 171/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0125 - mean_squared_error: 1.0125 - val_loss: 1.3944 - val_mean_squared_error: 1.3944\n",
      "Epoch 172/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0071 - mean_squared_error: 1.0071 - val_loss: 1.3941 - val_mean_squared_error: 1.3941\n",
      "Epoch 173/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0159 - mean_squared_error: 1.0159 - val_loss: 1.3937 - val_mean_squared_error: 1.3937\n",
      "Epoch 174/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0168 - mean_squared_error: 1.0168 - val_loss: 1.3933 - val_mean_squared_error: 1.3933\n",
      "Epoch 175/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0109 - mean_squared_error: 1.0109 - val_loss: 1.3930 - val_mean_squared_error: 1.3930\n",
      "Epoch 176/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0031 - mean_squared_error: 1.0031 - val_loss: 1.3927 - val_mean_squared_error: 1.3927\n",
      "Epoch 177/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0165 - mean_squared_error: 1.0165 - val_loss: 1.3925 - val_mean_squared_error: 1.3925\n",
      "Epoch 178/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0191 - mean_squared_error: 1.0191 - val_loss: 1.3925 - val_mean_squared_error: 1.3925\n",
      "Epoch 179/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0141 - mean_squared_error: 1.0141 - val_loss: 1.3925 - val_mean_squared_error: 1.3925\n",
      "Epoch 180/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0114 - mean_squared_error: 1.0114 - val_loss: 1.3926 - val_mean_squared_error: 1.3926\n",
      "Epoch 181/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0030 - mean_squared_error: 1.0030 - val_loss: 1.3927 - val_mean_squared_error: 1.3927\n",
      "Epoch 182/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0050 - mean_squared_error: 1.0050 - val_loss: 1.3927 - val_mean_squared_error: 1.3927\n",
      "Epoch 183/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0085 - mean_squared_error: 1.0085 - val_loss: 1.3927 - val_mean_squared_error: 1.3927\n",
      "Epoch 184/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0030 - mean_squared_error: 1.0030 - val_loss: 1.3926 - val_mean_squared_error: 1.3926\n",
      "Epoch 185/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0056 - mean_squared_error: 1.0056 - val_loss: 1.3924 - val_mean_squared_error: 1.3924\n",
      "Epoch 186/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0069 - mean_squared_error: 1.0069 - val_loss: 1.3923 - val_mean_squared_error: 1.3923\n",
      "Epoch 187/350\n",
      "8609/8609 [==============================] - 0s 4us/step - loss: 1.0031 - mean_squared_error: 1.0031 - val_loss: 1.3923 - val_mean_squared_error: 1.3923\n",
      "Epoch 188/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0095 - mean_squared_error: 1.0095 - val_loss: 1.3923 - val_mean_squared_error: 1.3923\n",
      "Epoch 189/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0003 - mean_squared_error: 1.0003 - val_loss: 1.3923 - val_mean_squared_error: 1.3923\n",
      "Epoch 190/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9984 - mean_squared_error: 0.9984 - val_loss: 1.3922 - val_mean_squared_error: 1.3922\n",
      "Epoch 191/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9973 - mean_squared_error: 0.9973 - val_loss: 1.3921 - val_mean_squared_error: 1.3921\n",
      "Epoch 192/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9984 - mean_squared_error: 0.9984 - val_loss: 1.3919 - val_mean_squared_error: 1.3919\n",
      "Epoch 193/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0143 - mean_squared_error: 1.0143 - val_loss: 1.3916 - val_mean_squared_error: 1.3916\n",
      "Epoch 194/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0008 - mean_squared_error: 1.0008 - val_loss: 1.3913 - val_mean_squared_error: 1.3913\n",
      "Epoch 195/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9951 - mean_squared_error: 0.9951 - val_loss: 1.3909 - val_mean_squared_error: 1.3909\n",
      "Epoch 196/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9957 - mean_squared_error: 0.9957 - val_loss: 1.3905 - val_mean_squared_error: 1.3905\n",
      "Epoch 197/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9933 - mean_squared_error: 0.9933 - val_loss: 1.3901 - val_mean_squared_error: 1.3901\n",
      "Epoch 198/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0005 - mean_squared_error: 1.0005 - val_loss: 1.3898 - val_mean_squared_error: 1.3898\n",
      "Epoch 199/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0043 - mean_squared_error: 1.0043 - val_loss: 1.3897 - val_mean_squared_error: 1.3897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9916 - mean_squared_error: 0.9916 - val_loss: 1.3896 - val_mean_squared_error: 1.3896\n",
      "Epoch 201/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0011 - mean_squared_error: 1.0011 - val_loss: 1.3894 - val_mean_squared_error: 1.3894\n",
      "Epoch 202/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9981 - mean_squared_error: 0.9981 - val_loss: 1.3891 - val_mean_squared_error: 1.3891\n",
      "Epoch 203/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9972 - mean_squared_error: 0.9972 - val_loss: 1.3889 - val_mean_squared_error: 1.3889\n",
      "Epoch 204/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9968 - mean_squared_error: 0.9968 - val_loss: 1.3886 - val_mean_squared_error: 1.3886\n",
      "Epoch 205/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9987 - mean_squared_error: 0.9987 - val_loss: 1.3882 - val_mean_squared_error: 1.3882\n",
      "Epoch 206/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9921 - mean_squared_error: 0.9921 - val_loss: 1.3878 - val_mean_squared_error: 1.3878\n",
      "Epoch 207/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9985 - mean_squared_error: 0.9985 - val_loss: 1.3875 - val_mean_squared_error: 1.3875\n",
      "Epoch 208/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9947 - mean_squared_error: 0.9947 - val_loss: 1.3872 - val_mean_squared_error: 1.3872\n",
      "Epoch 209/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 1.0030 - mean_squared_error: 1.0030 - val_loss: 1.3870 - val_mean_squared_error: 1.3870\n",
      "Epoch 210/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9940 - mean_squared_error: 0.9940 - val_loss: 1.3868 - val_mean_squared_error: 1.3868\n",
      "Epoch 211/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9915 - mean_squared_error: 0.9915 - val_loss: 1.3866 - val_mean_squared_error: 1.3866\n",
      "Epoch 212/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9870 - mean_squared_error: 0.9870 - val_loss: 1.3863 - val_mean_squared_error: 1.3863\n",
      "Epoch 213/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9984 - mean_squared_error: 0.9984 - val_loss: 1.3861 - val_mean_squared_error: 1.3861\n",
      "Epoch 214/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9920 - mean_squared_error: 0.9920 - val_loss: 1.3860 - val_mean_squared_error: 1.3860\n",
      "Epoch 215/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9958 - mean_squared_error: 0.9958 - val_loss: 1.3858 - val_mean_squared_error: 1.3858\n",
      "Epoch 216/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9803 - mean_squared_error: 0.9803 - val_loss: 1.3856 - val_mean_squared_error: 1.3856\n",
      "Epoch 217/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9998 - mean_squared_error: 0.9998 - val_loss: 1.3855 - val_mean_squared_error: 1.3855\n",
      "Epoch 218/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9853 - mean_squared_error: 0.9853 - val_loss: 1.3854 - val_mean_squared_error: 1.3854\n",
      "Epoch 219/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9868 - mean_squared_error: 0.9868 - val_loss: 1.3852 - val_mean_squared_error: 1.3852\n",
      "Epoch 220/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9829 - mean_squared_error: 0.9829 - val_loss: 1.3851 - val_mean_squared_error: 1.3851\n",
      "Epoch 221/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9884 - mean_squared_error: 0.9884 - val_loss: 1.3848 - val_mean_squared_error: 1.3848\n",
      "Epoch 222/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9861 - mean_squared_error: 0.9861 - val_loss: 1.3846 - val_mean_squared_error: 1.3846\n",
      "Epoch 223/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9938 - mean_squared_error: 0.9938 - val_loss: 1.3845 - val_mean_squared_error: 1.3845\n",
      "Epoch 224/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9862 - mean_squared_error: 0.9862 - val_loss: 1.3843 - val_mean_squared_error: 1.3843\n",
      "Epoch 225/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9886 - mean_squared_error: 0.9886 - val_loss: 1.3841 - val_mean_squared_error: 1.3841\n",
      "Epoch 226/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9870 - mean_squared_error: 0.9870 - val_loss: 1.3838 - val_mean_squared_error: 1.3838\n",
      "Epoch 227/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9807 - mean_squared_error: 0.9807 - val_loss: 1.3837 - val_mean_squared_error: 1.3837\n",
      "Epoch 228/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9885 - mean_squared_error: 0.9885 - val_loss: 1.3834 - val_mean_squared_error: 1.3834\n",
      "Epoch 229/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9863 - mean_squared_error: 0.9863 - val_loss: 1.3832 - val_mean_squared_error: 1.3832\n",
      "Epoch 230/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9932 - mean_squared_error: 0.9932 - val_loss: 1.3830 - val_mean_squared_error: 1.3830\n",
      "Epoch 231/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9784 - mean_squared_error: 0.9784 - val_loss: 1.3825 - val_mean_squared_error: 1.3825\n",
      "Epoch 232/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9900 - mean_squared_error: 0.9900 - val_loss: 1.3821 - val_mean_squared_error: 1.3821\n",
      "Epoch 233/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9824 - mean_squared_error: 0.9824 - val_loss: 1.3817 - val_mean_squared_error: 1.3817\n",
      "Epoch 234/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9861 - mean_squared_error: 0.9861 - val_loss: 1.3815 - val_mean_squared_error: 1.3815\n",
      "Epoch 235/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9844 - mean_squared_error: 0.9844 - val_loss: 1.3814 - val_mean_squared_error: 1.3814\n",
      "Epoch 236/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9845 - mean_squared_error: 0.9845 - val_loss: 1.3813 - val_mean_squared_error: 1.3813\n",
      "Epoch 237/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9729 - mean_squared_error: 0.9729 - val_loss: 1.3811 - val_mean_squared_error: 1.3811\n",
      "Epoch 238/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9819 - mean_squared_error: 0.9819 - val_loss: 1.3810 - val_mean_squared_error: 1.3810\n",
      "Epoch 239/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9792 - mean_squared_error: 0.9792 - val_loss: 1.3808 - val_mean_squared_error: 1.3808\n",
      "Epoch 240/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9847 - mean_squared_error: 0.9847 - val_loss: 1.3806 - val_mean_squared_error: 1.3806\n",
      "Epoch 241/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9820 - mean_squared_error: 0.9820 - val_loss: 1.3805 - val_mean_squared_error: 1.3805\n",
      "Epoch 242/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9919 - mean_squared_error: 0.9919 - val_loss: 1.3806 - val_mean_squared_error: 1.3806\n",
      "Epoch 243/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9808 - mean_squared_error: 0.9808 - val_loss: 1.3806 - val_mean_squared_error: 1.3806\n",
      "Epoch 244/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9895 - mean_squared_error: 0.9895 - val_loss: 1.3805 - val_mean_squared_error: 1.3805\n",
      "Epoch 245/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9865 - mean_squared_error: 0.9865 - val_loss: 1.3804 - val_mean_squared_error: 1.3804\n",
      "Epoch 246/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9774 - mean_squared_error: 0.9774 - val_loss: 1.3801 - val_mean_squared_error: 1.3801\n",
      "Epoch 247/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9758 - mean_squared_error: 0.9758 - val_loss: 1.3796 - val_mean_squared_error: 1.3796\n",
      "Epoch 248/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9734 - mean_squared_error: 0.9734 - val_loss: 1.3790 - val_mean_squared_error: 1.3790\n",
      "Epoch 249/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9711 - mean_squared_error: 0.9711 - val_loss: 1.3784 - val_mean_squared_error: 1.3784\n",
      "Epoch 250/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9861 - mean_squared_error: 0.9861 - val_loss: 1.3780 - val_mean_squared_error: 1.3780\n",
      "Epoch 251/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9690 - mean_squared_error: 0.9690 - val_loss: 1.3775 - val_mean_squared_error: 1.3775\n",
      "Epoch 252/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9761 - mean_squared_error: 0.9761 - val_loss: 1.3770 - val_mean_squared_error: 1.3770\n",
      "Epoch 253/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9821 - mean_squared_error: 0.9821 - val_loss: 1.3766 - val_mean_squared_error: 1.3766\n",
      "Epoch 254/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9831 - mean_squared_error: 0.9831 - val_loss: 1.3764 - val_mean_squared_error: 1.3764\n",
      "Epoch 255/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9810 - mean_squared_error: 0.9810 - val_loss: 1.3762 - val_mean_squared_error: 1.3762\n",
      "Epoch 256/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9774 - mean_squared_error: 0.9774 - val_loss: 1.3759 - val_mean_squared_error: 1.3759\n",
      "Epoch 257/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9817 - mean_squared_error: 0.9817 - val_loss: 1.3758 - val_mean_squared_error: 1.3758\n",
      "Epoch 258/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9781 - mean_squared_error: 0.9781 - val_loss: 1.3756 - val_mean_squared_error: 1.3756\n",
      "Epoch 259/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9814 - mean_squared_error: 0.9814 - val_loss: 1.3755 - val_mean_squared_error: 1.3755\n",
      "Epoch 260/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9792 - mean_squared_error: 0.9792 - val_loss: 1.3754 - val_mean_squared_error: 1.3754\n",
      "Epoch 261/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9837 - mean_squared_error: 0.9837 - val_loss: 1.3753 - val_mean_squared_error: 1.3753\n",
      "Epoch 262/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9814 - mean_squared_error: 0.9814 - val_loss: 1.3750 - val_mean_squared_error: 1.3750\n",
      "Epoch 263/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9719 - mean_squared_error: 0.9719 - val_loss: 1.3745 - val_mean_squared_error: 1.3745\n",
      "Epoch 264/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9765 - mean_squared_error: 0.9765 - val_loss: 1.3741 - val_mean_squared_error: 1.3741\n",
      "Epoch 265/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9861 - mean_squared_error: 0.9861 - val_loss: 1.3738 - val_mean_squared_error: 1.3738\n",
      "Epoch 266/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9707 - mean_squared_error: 0.9707 - val_loss: 1.3734 - val_mean_squared_error: 1.3734\n",
      "Epoch 267/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9852 - mean_squared_error: 0.9852 - val_loss: 1.3733 - val_mean_squared_error: 1.3733\n",
      "Epoch 268/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9787 - mean_squared_error: 0.9787 - val_loss: 1.3731 - val_mean_squared_error: 1.3731\n",
      "Epoch 269/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9760 - mean_squared_error: 0.9760 - val_loss: 1.3731 - val_mean_squared_error: 1.3731\n",
      "Epoch 270/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9793 - mean_squared_error: 0.9793 - val_loss: 1.3731 - val_mean_squared_error: 1.3731\n",
      "Epoch 271/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9843 - mean_squared_error: 0.9843 - val_loss: 1.3732 - val_mean_squared_error: 1.3732\n",
      "Epoch 272/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9703 - mean_squared_error: 0.9703 - val_loss: 1.3731 - val_mean_squared_error: 1.3731\n",
      "Epoch 273/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9718 - mean_squared_error: 0.9718 - val_loss: 1.3731 - val_mean_squared_error: 1.3731\n",
      "Epoch 274/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9828 - mean_squared_error: 0.9828 - val_loss: 1.3729 - val_mean_squared_error: 1.3729\n",
      "Epoch 275/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9711 - mean_squared_error: 0.9711 - val_loss: 1.3727 - val_mean_squared_error: 1.3727\n",
      "Epoch 276/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9870 - mean_squared_error: 0.9870 - val_loss: 1.3726 - val_mean_squared_error: 1.3726\n",
      "Epoch 277/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9780 - mean_squared_error: 0.9780 - val_loss: 1.3725 - val_mean_squared_error: 1.3725\n",
      "Epoch 278/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9762 - mean_squared_error: 0.9762 - val_loss: 1.3722 - val_mean_squared_error: 1.3722\n",
      "Epoch 279/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9886 - mean_squared_error: 0.9886 - val_loss: 1.3721 - val_mean_squared_error: 1.3721\n",
      "Epoch 280/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9641 - mean_squared_error: 0.9641 - val_loss: 1.3719 - val_mean_squared_error: 1.3719\n",
      "Epoch 281/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9759 - mean_squared_error: 0.9759 - val_loss: 1.3718 - val_mean_squared_error: 1.3718\n",
      "Epoch 282/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9700 - mean_squared_error: 0.9700 - val_loss: 1.3716 - val_mean_squared_error: 1.3716\n",
      "Epoch 283/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9734 - mean_squared_error: 0.9734 - val_loss: 1.3715 - val_mean_squared_error: 1.3715\n",
      "Epoch 284/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9677 - mean_squared_error: 0.9677 - val_loss: 1.3713 - val_mean_squared_error: 1.3713\n",
      "Epoch 285/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9831 - mean_squared_error: 0.9831 - val_loss: 1.3713 - val_mean_squared_error: 1.3713\n",
      "Epoch 286/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9780 - mean_squared_error: 0.9780 - val_loss: 1.3712 - val_mean_squared_error: 1.3712\n",
      "Epoch 287/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9703 - mean_squared_error: 0.9703 - val_loss: 1.3711 - val_mean_squared_error: 1.3711\n",
      "Epoch 288/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9809 - mean_squared_error: 0.9809 - val_loss: 1.3709 - val_mean_squared_error: 1.3709\n",
      "Epoch 289/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9772 - mean_squared_error: 0.9772 - val_loss: 1.3706 - val_mean_squared_error: 1.3706\n",
      "Epoch 290/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9829 - mean_squared_error: 0.9829 - val_loss: 1.3703 - val_mean_squared_error: 1.3703\n",
      "Epoch 291/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9743 - mean_squared_error: 0.9743 - val_loss: 1.3699 - val_mean_squared_error: 1.3699\n",
      "Epoch 292/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9690 - mean_squared_error: 0.9690 - val_loss: 1.3695 - val_mean_squared_error: 1.3695\n",
      "Epoch 293/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9704 - mean_squared_error: 0.9704 - val_loss: 1.3691 - val_mean_squared_error: 1.3691\n",
      "Epoch 294/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9718 - mean_squared_error: 0.9718 - val_loss: 1.3686 - val_mean_squared_error: 1.3686\n",
      "Epoch 295/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9784 - mean_squared_error: 0.9784 - val_loss: 1.3682 - val_mean_squared_error: 1.3682\n",
      "Epoch 296/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9677 - mean_squared_error: 0.9677 - val_loss: 1.3678 - val_mean_squared_error: 1.3678\n",
      "Epoch 297/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9817 - mean_squared_error: 0.9817 - val_loss: 1.3676 - val_mean_squared_error: 1.3676\n",
      "Epoch 298/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9788 - mean_squared_error: 0.9788 - val_loss: 1.3675 - val_mean_squared_error: 1.3675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9782 - mean_squared_error: 0.9782 - val_loss: 1.3674 - val_mean_squared_error: 1.3674\n",
      "Epoch 300/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9777 - mean_squared_error: 0.9777 - val_loss: 1.3674 - val_mean_squared_error: 1.3674\n",
      "Epoch 301/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9644 - mean_squared_error: 0.9644 - val_loss: 1.3670 - val_mean_squared_error: 1.3670\n",
      "Epoch 302/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9798 - mean_squared_error: 0.9798 - val_loss: 1.3667 - val_mean_squared_error: 1.3667\n",
      "Epoch 303/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9651 - mean_squared_error: 0.9651 - val_loss: 1.3661 - val_mean_squared_error: 1.3661\n",
      "Epoch 304/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9614 - mean_squared_error: 0.9614 - val_loss: 1.3655 - val_mean_squared_error: 1.3655\n",
      "Epoch 305/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9705 - mean_squared_error: 0.9705 - val_loss: 1.3649 - val_mean_squared_error: 1.3649\n",
      "Epoch 306/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9769 - mean_squared_error: 0.9769 - val_loss: 1.3644 - val_mean_squared_error: 1.3644\n",
      "Epoch 307/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9761 - mean_squared_error: 0.9761 - val_loss: 1.3642 - val_mean_squared_error: 1.3642\n",
      "Epoch 308/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9779 - mean_squared_error: 0.9779 - val_loss: 1.3643 - val_mean_squared_error: 1.3643\n",
      "Epoch 309/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9704 - mean_squared_error: 0.9704 - val_loss: 1.3643 - val_mean_squared_error: 1.3643\n",
      "Epoch 310/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9690 - mean_squared_error: 0.9690 - val_loss: 1.3643 - val_mean_squared_error: 1.3643\n",
      "Epoch 311/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9724 - mean_squared_error: 0.9724 - val_loss: 1.3642 - val_mean_squared_error: 1.3642\n",
      "Epoch 312/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9748 - mean_squared_error: 0.9748 - val_loss: 1.3642 - val_mean_squared_error: 1.3642\n",
      "Epoch 313/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9711 - mean_squared_error: 0.9711 - val_loss: 1.3641 - val_mean_squared_error: 1.3641\n",
      "Epoch 314/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9689 - mean_squared_error: 0.9689 - val_loss: 1.3640 - val_mean_squared_error: 1.3640\n",
      "Epoch 315/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9755 - mean_squared_error: 0.9755 - val_loss: 1.3640 - val_mean_squared_error: 1.3640\n",
      "Epoch 316/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9696 - mean_squared_error: 0.9696 - val_loss: 1.3640 - val_mean_squared_error: 1.3640\n",
      "Epoch 317/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9713 - mean_squared_error: 0.9713 - val_loss: 1.3641 - val_mean_squared_error: 1.3641\n",
      "Epoch 318/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9729 - mean_squared_error: 0.9729 - val_loss: 1.3640 - val_mean_squared_error: 1.3640\n",
      "Epoch 319/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9787 - mean_squared_error: 0.9787 - val_loss: 1.3640 - val_mean_squared_error: 1.3640\n",
      "Epoch 320/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9718 - mean_squared_error: 0.9718 - val_loss: 1.3640 - val_mean_squared_error: 1.3640\n",
      "Epoch 321/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9661 - mean_squared_error: 0.9661 - val_loss: 1.3639 - val_mean_squared_error: 1.3639\n",
      "Epoch 322/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9699 - mean_squared_error: 0.9699 - val_loss: 1.3637 - val_mean_squared_error: 1.3637\n",
      "Epoch 323/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9678 - mean_squared_error: 0.9678 - val_loss: 1.3635 - val_mean_squared_error: 1.3635\n",
      "Epoch 324/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9756 - mean_squared_error: 0.9756 - val_loss: 1.3632 - val_mean_squared_error: 1.3632\n",
      "Epoch 325/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9688 - mean_squared_error: 0.9688 - val_loss: 1.3629 - val_mean_squared_error: 1.3629\n",
      "Epoch 326/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9756 - mean_squared_error: 0.9756 - val_loss: 1.3627 - val_mean_squared_error: 1.3627\n",
      "Epoch 327/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9747 - mean_squared_error: 0.9747 - val_loss: 1.3625 - val_mean_squared_error: 1.3625\n",
      "Epoch 328/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9791 - mean_squared_error: 0.9791 - val_loss: 1.3622 - val_mean_squared_error: 1.3622\n",
      "Epoch 329/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9754 - mean_squared_error: 0.9754 - val_loss: 1.3619 - val_mean_squared_error: 1.3619\n",
      "Epoch 330/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9758 - mean_squared_error: 0.9758 - val_loss: 1.3618 - val_mean_squared_error: 1.3618\n",
      "Epoch 331/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9654 - mean_squared_error: 0.9654 - val_loss: 1.3616 - val_mean_squared_error: 1.3616\n",
      "Epoch 332/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9634 - mean_squared_error: 0.9634 - val_loss: 1.3613 - val_mean_squared_error: 1.3613\n",
      "Epoch 333/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9741 - mean_squared_error: 0.9741 - val_loss: 1.3611 - val_mean_squared_error: 1.3611\n",
      "Epoch 334/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9738 - mean_squared_error: 0.9738 - val_loss: 1.3609 - val_mean_squared_error: 1.3609\n",
      "Epoch 335/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9731 - mean_squared_error: 0.9731 - val_loss: 1.3607 - val_mean_squared_error: 1.3607\n",
      "Epoch 336/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9661 - mean_squared_error: 0.9661 - val_loss: 1.3605 - val_mean_squared_error: 1.3605\n",
      "Epoch 337/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9753 - mean_squared_error: 0.9753 - val_loss: 1.3603 - val_mean_squared_error: 1.3603\n",
      "Epoch 338/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9782 - mean_squared_error: 0.9782 - val_loss: 1.3602 - val_mean_squared_error: 1.3602\n",
      "Epoch 339/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9636 - mean_squared_error: 0.9636 - val_loss: 1.3600 - val_mean_squared_error: 1.3600\n",
      "Epoch 340/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9734 - mean_squared_error: 0.9734 - val_loss: 1.3597 - val_mean_squared_error: 1.3597\n",
      "Epoch 341/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9832 - mean_squared_error: 0.9832 - val_loss: 1.3595 - val_mean_squared_error: 1.3595\n",
      "Epoch 342/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9786 - mean_squared_error: 0.9786 - val_loss: 1.3594 - val_mean_squared_error: 1.3594\n",
      "Epoch 343/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9711 - mean_squared_error: 0.9711 - val_loss: 1.3593 - val_mean_squared_error: 1.3593\n",
      "Epoch 344/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9602 - mean_squared_error: 0.9602 - val_loss: 1.3591 - val_mean_squared_error: 1.3591\n",
      "Epoch 345/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9709 - mean_squared_error: 0.9709 - val_loss: 1.3589 - val_mean_squared_error: 1.3589\n",
      "Epoch 346/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9665 - mean_squared_error: 0.9665 - val_loss: 1.3586 - val_mean_squared_error: 1.3586\n",
      "Epoch 347/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9634 - mean_squared_error: 0.9634 - val_loss: 1.3583 - val_mean_squared_error: 1.3583\n",
      "Epoch 348/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9702 - mean_squared_error: 0.9702 - val_loss: 1.3579 - val_mean_squared_error: 1.3579\n",
      "Epoch 349/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9761 - mean_squared_error: 0.9761 - val_loss: 1.3575 - val_mean_squared_error: 1.3575\n",
      "Epoch 350/350\n",
      "8609/8609 [==============================] - 0s 3us/step - loss: 0.9672 - mean_squared_error: 0.9672 - val_loss: 1.3572 - val_mean_squared_error: 1.3572\n",
      "Training time:13.284416675567627\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mean_squared_error'])\n",
    "\n",
    "curr_dt = set_curr_time()\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir='../logs/{0}'.format(curr_dt), histogram_freq=0, write_graph=True)\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=100)\n",
    "\n",
    "tic = time.time()\n",
    "model.fit(\n",
    "    x_train_label,\n",
    "    y_train_label,\n",
    "    epochs = 350,\n",
    "    batch_size = x_train_label.shape[0],\n",
    "    validation_data = (x_valid_label, y_valid_label),\n",
    "    shuffle = True,\n",
    "#     steps_per_epoch = round(ROW_COUNT/BATCH_SIZE),\n",
    "    callbacks=[es,tb_callback])\n",
    "toc = time.time()\n",
    "\n",
    "print('Training time:{}'.format(toc-tic))\n",
    "\n",
    "# model.save('../models/{0}.h5'.format(curr_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('../model/{0}.h5'.format('4096_1024_512_64__'))\n",
    "model_loaded =tf.keras.models.load_model('../model/4096_1024_512_64.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_y=model_loaded.predict(x_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For error in of 0.5 hours the precision: 11.71\n",
      "For error in of 1 hours the precision: 24.82\n",
      "For error in of 5 hours the precision: 72.85\n",
      "For error in of 10 hours the precision: 82.38\n",
      "For error in of 112 hours the precision: 99.02\n"
     ]
    }
   ],
   "source": [
    "# #accuracy max-min\n",
    "# ERROE_MERGE = 0.5 # in hours\n",
    "# SCALE = (ERROE_MERGE-0.01)/(910 - 0.01)\n",
    "# correct = 0\n",
    "# for i in range(0,len(y_test_label)):    \n",
    "#     if (((pred_y[i] - SCALE) < y_test_label[i][0]) and ((pred_y[i] + SCALE) > y_test_label[i][0])):\n",
    "#         correct += 1\n",
    "# print(correct/len(y_test_label))\n",
    "\n",
    "\n",
    "#accuracy Gussian(mean,std)\n",
    "ERROER_MERGE = [0.5,1,5,10,112] # in hours\n",
    "x_bar = []\n",
    "y_bar = []\n",
    "for error in ERROER_MERGE:\n",
    "    correct = 0\n",
    "    for i in range(0,len(y_test_label)):\n",
    "        scale_pred = (pred_y[i]*68.72187295)+(+13.17546792)\n",
    "        scale_test = (y_test_label[i][0]*68.72187295)+(+13.17546792)\n",
    "\n",
    "        if (((scale_pred - error) < scale_test) and ((scale_pred + error) > scale_test)):\n",
    "            correct += 1\n",
    "    accuracy = np.round(correct*100/len(y_test_label),2)\n",
    "    print(\"For error in of {0} hours the precision: {1}\".format(error,accuracy))\n",
    "    x_bar.append(error)\n",
    "    y_bar.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pos = np.arange(len(x_bar))\n",
    "plt.bar(y_pos, y_bar, align='center')#, width=1.0)\n",
    "\n",
    "plt.xticks(y_pos, x_bar)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Vs Hours')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML - OneHot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Priority</th>\n",
       "      <th>RaisedByID</th>\n",
       "      <th>AssignedToID</th>\n",
       "      <th>AuthorisedByID</th>\n",
       "      <th>HoursEstimate</th>\n",
       "      <th>HoursActual</th>\n",
       "      <th>StatusCode_AUTHORISE</th>\n",
       "      <th>StatusCode_CANCELLED</th>\n",
       "      <th>StatusCode_CHRONICLE</th>\n",
       "      <th>...</th>\n",
       "      <th>SubCategory_Project Management</th>\n",
       "      <th>SubCategory_Release</th>\n",
       "      <th>SubCategory_Research</th>\n",
       "      <th>SubCategory_Staff Management</th>\n",
       "      <th>SubCategory_Staff Recruitment</th>\n",
       "      <th>SubCategory_Support</th>\n",
       "      <th>SubCategory_Technical Specification</th>\n",
       "      <th>SubCategory_Testing</th>\n",
       "      <th>SubCategory_Third Party</th>\n",
       "      <th>SubCategory_Training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>42</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>58</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>42</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>46</td>\n",
       "      <td>13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Priority  RaisedByID  AssignedToID  AuthorisedByID  \\\n",
       "0           0         1          58            58             6.0   \n",
       "1           1         1          58            42             6.0   \n",
       "2           2         2           7            58             6.0   \n",
       "3           3         5          50            42             6.0   \n",
       "4           4        10          46            13             6.0   \n",
       "\n",
       "   HoursEstimate  HoursActual  StatusCode_AUTHORISE  StatusCode_CANCELLED  \\\n",
       "0           14.0         1.75                     0                     0   \n",
       "1            7.0         7.00                     0                     0   \n",
       "2            0.7         0.70                     0                     0   \n",
       "3            0.7         0.70                     0                     0   \n",
       "4            3.5         3.50                     0                     0   \n",
       "\n",
       "   StatusCode_CHRONICLE  ...  SubCategory_Project Management  \\\n",
       "0                     0  ...                               0   \n",
       "1                     0  ...                               0   \n",
       "2                     0  ...                               0   \n",
       "3                     0  ...                               0   \n",
       "4                     0  ...                               0   \n",
       "\n",
       "   SubCategory_Release  SubCategory_Research  SubCategory_Staff Management  \\\n",
       "0                    0                     0                             0   \n",
       "1                    0                     0                             0   \n",
       "2                    0                     0                             0   \n",
       "3                    0                     0                             0   \n",
       "4                    0                     0                             0   \n",
       "\n",
       "   SubCategory_Staff Recruitment  SubCategory_Support  \\\n",
       "0                              0                    0   \n",
       "1                              0                    0   \n",
       "2                              0                    0   \n",
       "3                              0                    0   \n",
       "4                              0                    0   \n",
       "\n",
       "   SubCategory_Technical Specification  SubCategory_Testing  \\\n",
       "0                                    0                    0   \n",
       "1                                    0                    0   \n",
       "2                                    0                    0   \n",
       "3                                    0                    0   \n",
       "4                                    0                    0   \n",
       "\n",
       "   SubCategory_Third Party  SubCategory_Training  \n",
       "0                        0                     0  \n",
       "1                        0                     0  \n",
       "2                        0                     0  \n",
       "3                        0                     0  \n",
       "4                        0                     0  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../SiP_dataset-master/SIP_OneHot.csv', encoding='cp1252') \n",
    "data.fillna(0, inplace = True)\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples: (8609, 61)\n",
      "Valid examples: (1845, 61)\n",
      "Test examples: (1845, 61)\n"
     ]
    }
   ],
   "source": [
    "# HoursEstimate_filter=HoursEstimate[HoursEstimate[\"HoursEstimate\"]<200]\n",
    "# HoursEstimate_filter=HoursEstimate_filter[HoursEstimate_filter[\"HoursActual\"]<800]\n",
    "\n",
    "x_train_label, xx_test_label, y_train_label, yy_test_label \\\n",
    "              = train_test_split(data.loc[:, data.columns != 'HoursActual'].values[:], data[Y_attributes].values[:], test_size=TRAIN_AND_VALIDATION_TEST_SPLIT)\n",
    "x_valid_label, x_test_label, y_valid_label, y_test_label \\\n",
    "              = train_test_split(xx_test_label, yy_test_label, test_size=VALID_AND_TEST_SPLIT)  \n",
    "\n",
    "print(\"Train examples: {}\".format(x_train_label.shape))\n",
    "print(\"Valid examples: {}\".format(x_valid_label.shape))\n",
    "print(\"Test examples: {}\".format(x_test_label.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Dense(2048, kernel_initializer='normal'), \n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.8),\n",
    "#     tf.keras.layers.Dense(1024,  kernel_initializer='normal'), \n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.8),\n",
    "#     tf.keras.layers.add(tf.keras.layers.Flatten(input_shape = (BATCH_SIZE,x_train_label.shape[1],1))),\n",
    "    tf.keras.layers.Dense(8192, kernel_initializer='normal',input_shape = (x_train_label.shape[1],)), \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(2048, kernel_initializer='normal'), \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(128, kernel_initializer='normal'), \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(64, kernel_initializer='normal'), \n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.8),\n",
    "    tf.keras.layers.Dense(1)\n",
    "    \n",
    "    \n",
    "#     tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8609 samples, validate on 1845 samples\n",
      "Epoch 1/300\n",
      "8609/8609 [==============================] - 1s 107us/step - loss: 5259.6235 - mean_squared_error: 5259.6235 - val_loss: 1589.7592 - val_mean_squared_error: 1589.7592\n",
      "Epoch 2/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 5206.8779 - mean_squared_error: 5206.8779 - val_loss: 1585.6847 - val_mean_squared_error: 1585.6847\n",
      "Epoch 3/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 5168.4824 - mean_squared_error: 5168.4824 - val_loss: 1575.9669 - val_mean_squared_error: 1575.9669\n",
      "Epoch 4/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 5125.0601 - mean_squared_error: 5125.0601 - val_loss: 1572.1866 - val_mean_squared_error: 1572.1866\n",
      "Epoch 5/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 5114.5664 - mean_squared_error: 5114.5664 - val_loss: 1582.6741 - val_mean_squared_error: 1582.6741\n",
      "Epoch 6/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 5128.0913 - mean_squared_error: 5128.0913 - val_loss: 1566.7032 - val_mean_squared_error: 1566.7032\n",
      "Epoch 7/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 5107.8940 - mean_squared_error: 5107.8940 - val_loss: 1534.9203 - val_mean_squared_error: 1534.9203\n",
      "Epoch 8/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 5108.0054 - mean_squared_error: 5108.0054 - val_loss: 1516.7351 - val_mean_squared_error: 1516.7351\n",
      "Epoch 9/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 5093.6011 - mean_squared_error: 5093.6011 - val_loss: 1510.6835 - val_mean_squared_error: 1510.6835\n",
      "Epoch 10/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 5091.7271 - mean_squared_error: 5091.7271 - val_loss: 1519.3911 - val_mean_squared_error: 1519.3911\n",
      "Epoch 11/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 5064.1504 - mean_squared_error: 5064.1504 - val_loss: 1521.8961 - val_mean_squared_error: 1521.8961\n",
      "Epoch 12/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 5063.0229 - mean_squared_error: 5063.0229 - val_loss: 1517.5908 - val_mean_squared_error: 1517.5908\n",
      "Epoch 13/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 5039.9189 - mean_squared_error: 5039.9189 - val_loss: 1510.3003 - val_mean_squared_error: 1510.3003\n",
      "Epoch 14/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 5068.9907 - mean_squared_error: 5068.9907 - val_loss: 1502.3070 - val_mean_squared_error: 1502.3070\n",
      "Epoch 15/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 5046.0078 - mean_squared_error: 5046.0078 - val_loss: 1495.1094 - val_mean_squared_error: 1495.1094\n",
      "Epoch 16/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 5068.2935 - mean_squared_error: 5068.2935 - val_loss: 1489.1007 - val_mean_squared_error: 1489.1007\n",
      "Epoch 17/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 5065.9556 - mean_squared_error: 5065.9556 - val_loss: 1487.3768 - val_mean_squared_error: 1487.3768\n",
      "Epoch 18/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 5042.1309 - mean_squared_error: 5042.1309 - val_loss: 1487.7209 - val_mean_squared_error: 1487.7209\n",
      "Epoch 19/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 5039.0312 - mean_squared_error: 5039.0312 - val_loss: 1486.6648 - val_mean_squared_error: 1486.6648\n",
      "Epoch 20/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 5023.5898 - mean_squared_error: 5023.5898 - val_loss: 1480.1987 - val_mean_squared_error: 1480.1987\n",
      "Epoch 21/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 5016.7510 - mean_squared_error: 5016.7510 - val_loss: 1471.0618 - val_mean_squared_error: 1471.0618\n",
      "Epoch 22/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 5037.1191 - mean_squared_error: 5037.1191 - val_loss: 1462.2220 - val_mean_squared_error: 1462.2220\n",
      "Epoch 23/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 5039.0815 - mean_squared_error: 5039.0815 - val_loss: 1457.5657 - val_mean_squared_error: 1457.5657\n",
      "Epoch 24/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 5007.1943 - mean_squared_error: 5007.1943 - val_loss: 1452.5397 - val_mean_squared_error: 1452.5397\n",
      "Epoch 25/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 5017.7637 - mean_squared_error: 5017.7637 - val_loss: 1447.4067 - val_mean_squared_error: 1447.4067\n",
      "Epoch 26/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 5048.8242 - mean_squared_error: 5048.8242 - val_loss: 1438.9279 - val_mean_squared_error: 1438.9279\n",
      "Epoch 27/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4982.4277 - mean_squared_error: 4982.4277 - val_loss: 1424.7067 - val_mean_squared_error: 1424.7067\n",
      "Epoch 28/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4988.1880 - mean_squared_error: 4988.1880 - val_loss: 1410.2535 - val_mean_squared_error: 1410.2535\n",
      "Epoch 29/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4990.0088 - mean_squared_error: 4990.0088 - val_loss: 1401.4507 - val_mean_squared_error: 1401.4507\n",
      "Epoch 30/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4999.5791 - mean_squared_error: 4999.5791 - val_loss: 1397.8387 - val_mean_squared_error: 1397.8387\n",
      "Epoch 31/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4980.8496 - mean_squared_error: 4980.8496 - val_loss: 1396.2620 - val_mean_squared_error: 1396.2620\n",
      "Epoch 32/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4966.3481 - mean_squared_error: 4966.3481 - val_loss: 1396.9359 - val_mean_squared_error: 1396.9359\n",
      "Epoch 33/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4940.3604 - mean_squared_error: 4940.3604 - val_loss: 1395.0079 - val_mean_squared_error: 1395.0079\n",
      "Epoch 34/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4945.1274 - mean_squared_error: 4945.1274 - val_loss: 1392.1636 - val_mean_squared_error: 1392.1636\n",
      "Epoch 35/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4944.2158 - mean_squared_error: 4944.2158 - val_loss: 1388.6606 - val_mean_squared_error: 1388.6606\n",
      "Epoch 36/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4967.6685 - mean_squared_error: 4967.6685 - val_loss: 1384.5336 - val_mean_squared_error: 1384.5336\n",
      "Epoch 37/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4922.3984 - mean_squared_error: 4922.3984 - val_loss: 1381.8594 - val_mean_squared_error: 1381.8594\n",
      "Epoch 38/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4950.6904 - mean_squared_error: 4950.6904 - val_loss: 1380.4910 - val_mean_squared_error: 1380.4910\n",
      "Epoch 39/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4972.1504 - mean_squared_error: 4972.1504 - val_loss: 1378.5450 - val_mean_squared_error: 1378.5450\n",
      "Epoch 40/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4922.5293 - mean_squared_error: 4922.5293 - val_loss: 1376.0596 - val_mean_squared_error: 1376.0596\n",
      "Epoch 41/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4892.0688 - mean_squared_error: 4892.0688 - val_loss: 1377.9238 - val_mean_squared_error: 1377.9238\n",
      "Epoch 42/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4885.9072 - mean_squared_error: 4885.9072 - val_loss: 1380.9951 - val_mean_squared_error: 1380.9951\n",
      "Epoch 43/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4885.8833 - mean_squared_error: 4885.8833 - val_loss: 1383.1659 - val_mean_squared_error: 1383.1659\n",
      "Epoch 44/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4905.2998 - mean_squared_error: 4905.2998 - val_loss: 1383.3151 - val_mean_squared_error: 1383.3151\n",
      "Epoch 45/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4965.4565 - mean_squared_error: 4965.4565 - val_loss: 1382.2733 - val_mean_squared_error: 1382.2733\n",
      "Epoch 46/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4858.0581 - mean_squared_error: 4858.0581 - val_loss: 1383.0225 - val_mean_squared_error: 1383.0225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4856.3428 - mean_squared_error: 4856.3428 - val_loss: 1384.3202 - val_mean_squared_error: 1384.3202\n",
      "Epoch 48/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4886.4229 - mean_squared_error: 4886.4229 - val_loss: 1386.6888 - val_mean_squared_error: 1386.6888\n",
      "Epoch 49/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4828.4810 - mean_squared_error: 4828.4810 - val_loss: 1389.1089 - val_mean_squared_error: 1389.1089\n",
      "Epoch 50/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4881.3374 - mean_squared_error: 4881.3374 - val_loss: 1394.4064 - val_mean_squared_error: 1394.4064\n",
      "Epoch 51/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4866.7070 - mean_squared_error: 4866.7070 - val_loss: 1391.3584 - val_mean_squared_error: 1391.3584\n",
      "Epoch 52/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4883.5054 - mean_squared_error: 4883.5054 - val_loss: 1389.7820 - val_mean_squared_error: 1389.7820\n",
      "Epoch 53/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4854.2764 - mean_squared_error: 4854.2764 - val_loss: 1387.9050 - val_mean_squared_error: 1387.9050\n",
      "Epoch 54/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4832.0967 - mean_squared_error: 4832.0967 - val_loss: 1387.2878 - val_mean_squared_error: 1387.2878\n",
      "Epoch 55/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4867.5635 - mean_squared_error: 4867.5635 - val_loss: 1390.7894 - val_mean_squared_error: 1390.7894\n",
      "Epoch 56/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4856.3931 - mean_squared_error: 4856.3931 - val_loss: 1391.9407 - val_mean_squared_error: 1391.9407\n",
      "Epoch 57/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4876.8691 - mean_squared_error: 4876.8691 - val_loss: 1396.5382 - val_mean_squared_error: 1396.5382\n",
      "Epoch 58/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4888.6348 - mean_squared_error: 4888.6348 - val_loss: 1400.2062 - val_mean_squared_error: 1400.2062\n",
      "Epoch 59/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4840.8501 - mean_squared_error: 4840.8501 - val_loss: 1397.2402 - val_mean_squared_error: 1397.2402\n",
      "Epoch 60/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4860.1768 - mean_squared_error: 4860.1768 - val_loss: 1402.7958 - val_mean_squared_error: 1402.7958\n",
      "Epoch 61/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4831.6250 - mean_squared_error: 4831.6250 - val_loss: 1399.1544 - val_mean_squared_error: 1399.1544\n",
      "Epoch 62/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4849.4951 - mean_squared_error: 4849.4951 - val_loss: 1396.3948 - val_mean_squared_error: 1396.3948\n",
      "Epoch 63/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4909.1030 - mean_squared_error: 4909.1030 - val_loss: 1407.6365 - val_mean_squared_error: 1407.6365\n",
      "Epoch 64/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4802.6099 - mean_squared_error: 4802.6099 - val_loss: 1396.9656 - val_mean_squared_error: 1396.9656\n",
      "Epoch 65/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4811.9248 - mean_squared_error: 4811.9248 - val_loss: 1399.3029 - val_mean_squared_error: 1399.3029\n",
      "Epoch 66/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4826.0327 - mean_squared_error: 4826.0327 - val_loss: 1417.6956 - val_mean_squared_error: 1417.6956\n",
      "Epoch 67/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4816.0298 - mean_squared_error: 4816.0298 - val_loss: 1414.2430 - val_mean_squared_error: 1414.2430\n",
      "Epoch 68/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4854.3984 - mean_squared_error: 4854.3984 - val_loss: 1419.8514 - val_mean_squared_error: 1419.8514\n",
      "Epoch 69/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4819.1138 - mean_squared_error: 4819.1138 - val_loss: 1424.1908 - val_mean_squared_error: 1424.1908\n",
      "Epoch 70/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4781.1846 - mean_squared_error: 4781.1846 - val_loss: 1427.1260 - val_mean_squared_error: 1427.1260\n",
      "Epoch 71/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4765.2671 - mean_squared_error: 4765.2671 - val_loss: 1440.7819 - val_mean_squared_error: 1440.7819\n",
      "Epoch 72/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4769.2471 - mean_squared_error: 4769.2471 - val_loss: 1433.4861 - val_mean_squared_error: 1433.4861\n",
      "Epoch 73/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4785.5376 - mean_squared_error: 4785.5376 - val_loss: 1450.4944 - val_mean_squared_error: 1450.4944\n",
      "Epoch 74/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4769.0835 - mean_squared_error: 4769.0835 - val_loss: 1441.1703 - val_mean_squared_error: 1441.1703\n",
      "Epoch 75/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4748.3208 - mean_squared_error: 4748.3208 - val_loss: 1459.2561 - val_mean_squared_error: 1459.2561\n",
      "Epoch 76/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4777.4980 - mean_squared_error: 4777.4980 - val_loss: 1443.4124 - val_mean_squared_error: 1443.4124\n",
      "Epoch 77/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4722.1484 - mean_squared_error: 4722.1484 - val_loss: 1450.6404 - val_mean_squared_error: 1450.6404\n",
      "Epoch 78/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4820.9541 - mean_squared_error: 4820.9541 - val_loss: 1443.6427 - val_mean_squared_error: 1443.6427\n",
      "Epoch 79/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4718.3452 - mean_squared_error: 4718.3452 - val_loss: 1446.5616 - val_mean_squared_error: 1446.5616\n",
      "Epoch 80/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4745.5498 - mean_squared_error: 4745.5498 - val_loss: 1472.1959 - val_mean_squared_error: 1472.1959\n",
      "Epoch 81/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4755.9829 - mean_squared_error: 4755.9829 - val_loss: 1450.9479 - val_mean_squared_error: 1450.9479\n",
      "Epoch 82/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4745.6455 - mean_squared_error: 4745.6455 - val_loss: 1466.1027 - val_mean_squared_error: 1466.1027\n",
      "Epoch 83/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4742.7188 - mean_squared_error: 4742.7188 - val_loss: 1451.4889 - val_mean_squared_error: 1451.4889\n",
      "Epoch 84/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4697.7905 - mean_squared_error: 4697.7905 - val_loss: 1454.5367 - val_mean_squared_error: 1454.5367\n",
      "Epoch 85/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4767.5845 - mean_squared_error: 4767.5845 - val_loss: 1452.4288 - val_mean_squared_error: 1452.4288\n",
      "Epoch 86/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4740.9702 - mean_squared_error: 4740.9702 - val_loss: 1450.0435 - val_mean_squared_error: 1450.0435\n",
      "Epoch 87/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4773.1670 - mean_squared_error: 4773.1670 - val_loss: 1453.5139 - val_mean_squared_error: 1453.5139\n",
      "Epoch 88/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4684.8755 - mean_squared_error: 4684.8755 - val_loss: 1449.3781 - val_mean_squared_error: 1449.3781\n",
      "Epoch 89/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4646.9141 - mean_squared_error: 4646.9141 - val_loss: 1457.8601 - val_mean_squared_error: 1457.8601\n",
      "Epoch 90/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4735.5234 - mean_squared_error: 4735.5234 - val_loss: 1449.7542 - val_mean_squared_error: 1449.7542\n",
      "Epoch 91/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4731.6772 - mean_squared_error: 4731.6772 - val_loss: 1477.5948 - val_mean_squared_error: 1477.5948\n",
      "Epoch 92/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4697.3945 - mean_squared_error: 4697.3945 - val_loss: 1445.2841 - val_mean_squared_error: 1445.2841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4720.4590 - mean_squared_error: 4720.4590 - val_loss: 1442.6033 - val_mean_squared_error: 1442.6033\n",
      "Epoch 94/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4773.4937 - mean_squared_error: 4773.4937 - val_loss: 1452.0680 - val_mean_squared_error: 1452.0680\n",
      "Epoch 95/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4741.0439 - mean_squared_error: 4741.0439 - val_loss: 1454.3629 - val_mean_squared_error: 1454.3629\n",
      "Epoch 96/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4637.5562 - mean_squared_error: 4637.5562 - val_loss: 1456.8203 - val_mean_squared_error: 1456.8203\n",
      "Epoch 97/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4639.9385 - mean_squared_error: 4639.9385 - val_loss: 1464.0544 - val_mean_squared_error: 1464.0544\n",
      "Epoch 98/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4737.6367 - mean_squared_error: 4737.6367 - val_loss: 1458.7401 - val_mean_squared_error: 1458.7401\n",
      "Epoch 99/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4688.8735 - mean_squared_error: 4688.8735 - val_loss: 1459.6713 - val_mean_squared_error: 1459.6713\n",
      "Epoch 100/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4655.1245 - mean_squared_error: 4655.1245 - val_loss: 1449.1951 - val_mean_squared_error: 1449.1951\n",
      "Epoch 101/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4705.8921 - mean_squared_error: 4705.8921 - val_loss: 1451.1316 - val_mean_squared_error: 1451.1316\n",
      "Epoch 102/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4629.4224 - mean_squared_error: 4629.4224 - val_loss: 1456.4993 - val_mean_squared_error: 1456.4993\n",
      "Epoch 103/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4640.9575 - mean_squared_error: 4640.9575 - val_loss: 1462.1619 - val_mean_squared_error: 1462.1619\n",
      "Epoch 104/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4578.0674 - mean_squared_error: 4578.0674 - val_loss: 1470.0551 - val_mean_squared_error: 1470.0551\n",
      "Epoch 105/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4715.6333 - mean_squared_error: 4715.6333 - val_loss: 1473.2764 - val_mean_squared_error: 1473.2764\n",
      "Epoch 106/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4700.8652 - mean_squared_error: 4700.8652 - val_loss: 1478.0237 - val_mean_squared_error: 1478.0237\n",
      "Epoch 107/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4617.0981 - mean_squared_error: 4617.0981 - val_loss: 1474.7250 - val_mean_squared_error: 1474.7250\n",
      "Epoch 108/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4592.5425 - mean_squared_error: 4592.5425 - val_loss: 1477.2866 - val_mean_squared_error: 1477.2866\n",
      "Epoch 109/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4642.6602 - mean_squared_error: 4642.6602 - val_loss: 1468.0681 - val_mean_squared_error: 1468.0681\n",
      "Epoch 110/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4720.1978 - mean_squared_error: 4720.1978 - val_loss: 1477.3683 - val_mean_squared_error: 1477.3683\n",
      "Epoch 111/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4698.7803 - mean_squared_error: 4698.7803 - val_loss: 1457.9607 - val_mean_squared_error: 1457.9607\n",
      "Epoch 112/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4706.4751 - mean_squared_error: 4706.4751 - val_loss: 1450.9263 - val_mean_squared_error: 1450.9263\n",
      "Epoch 113/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4737.4888 - mean_squared_error: 4737.4888 - val_loss: 1454.2535 - val_mean_squared_error: 1454.2535\n",
      "Epoch 114/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4587.9858 - mean_squared_error: 4587.9858 - val_loss: 1464.8378 - val_mean_squared_error: 1464.8378\n",
      "Epoch 115/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4608.0840 - mean_squared_error: 4608.0840 - val_loss: 1458.1674 - val_mean_squared_error: 1458.1674\n",
      "Epoch 116/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4618.0894 - mean_squared_error: 4618.0894 - val_loss: 1464.1064 - val_mean_squared_error: 1464.1064\n",
      "Epoch 117/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4597.8105 - mean_squared_error: 4597.8105 - val_loss: 1478.9891 - val_mean_squared_error: 1478.9891\n",
      "Epoch 118/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4638.4482 - mean_squared_error: 4638.4482 - val_loss: 1456.9331 - val_mean_squared_error: 1456.9331\n",
      "Epoch 119/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4651.5181 - mean_squared_error: 4651.5181 - val_loss: 1478.5238 - val_mean_squared_error: 1478.5238\n",
      "Epoch 120/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4661.6724 - mean_squared_error: 4661.6724 - val_loss: 1474.1798 - val_mean_squared_error: 1474.1798\n",
      "Epoch 121/300\n",
      "8609/8609 [==============================] - 0s 16us/step - loss: 4497.8257 - mean_squared_error: 4497.8257 - val_loss: 1477.7238 - val_mean_squared_error: 1477.7238\n",
      "Epoch 122/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4532.8320 - mean_squared_error: 4532.8320 - val_loss: 1476.0112 - val_mean_squared_error: 1476.0112\n",
      "Epoch 123/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4653.9814 - mean_squared_error: 4653.9814 - val_loss: 1479.0251 - val_mean_squared_error: 1479.0251\n",
      "Epoch 124/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4674.7100 - mean_squared_error: 4674.7100 - val_loss: 1476.6339 - val_mean_squared_error: 1476.6339\n",
      "Epoch 125/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4631.2588 - mean_squared_error: 4631.2588 - val_loss: 1481.4426 - val_mean_squared_error: 1481.4426\n",
      "Epoch 126/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4633.9478 - mean_squared_error: 4633.9478 - val_loss: 1501.0507 - val_mean_squared_error: 1501.0507\n",
      "Epoch 127/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4539.1094 - mean_squared_error: 4539.1094 - val_loss: 1464.6323 - val_mean_squared_error: 1464.6323\n",
      "Epoch 128/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4506.9297 - mean_squared_error: 4506.9297 - val_loss: 1558.0271 - val_mean_squared_error: 1558.0271\n",
      "Epoch 129/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4632.1152 - mean_squared_error: 4632.1152 - val_loss: 1459.0681 - val_mean_squared_error: 1459.0681\n",
      "Epoch 130/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4669.8682 - mean_squared_error: 4669.8682 - val_loss: 1511.9634 - val_mean_squared_error: 1511.9634\n",
      "Epoch 131/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4581.0640 - mean_squared_error: 4581.0640 - val_loss: 1542.9088 - val_mean_squared_error: 1542.9088\n",
      "Epoch 132/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4594.4839 - mean_squared_error: 4594.4839 - val_loss: 1464.0593 - val_mean_squared_error: 1464.0593\n",
      "Epoch 133/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4500.8257 - mean_squared_error: 4500.8257 - val_loss: 1470.7930 - val_mean_squared_error: 1470.7930\n",
      "Epoch 134/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4559.3242 - mean_squared_error: 4559.3242 - val_loss: 1486.5319 - val_mean_squared_error: 1486.5319\n",
      "Epoch 135/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4584.5000 - mean_squared_error: 4584.5000 - val_loss: 1465.0948 - val_mean_squared_error: 1465.0948\n",
      "Epoch 136/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4511.1797 - mean_squared_error: 4511.1797 - val_loss: 1514.2936 - val_mean_squared_error: 1514.2936\n",
      "Epoch 137/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4626.8740 - mean_squared_error: 4626.8740 - val_loss: 1463.1023 - val_mean_squared_error: 1463.1023\n",
      "Epoch 138/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4539.8320 - mean_squared_error: 4539.8320 - val_loss: 1455.2512 - val_mean_squared_error: 1455.2512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4568.2183 - mean_squared_error: 4568.2183 - val_loss: 1479.8420 - val_mean_squared_error: 1479.8420\n",
      "Epoch 140/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4632.6523 - mean_squared_error: 4632.6523 - val_loss: 1468.2150 - val_mean_squared_error: 1468.2150\n",
      "Epoch 141/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4581.8857 - mean_squared_error: 4581.8857 - val_loss: 1453.9594 - val_mean_squared_error: 1453.9594\n",
      "Epoch 142/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4606.8066 - mean_squared_error: 4606.8066 - val_loss: 1465.6029 - val_mean_squared_error: 1465.6029\n",
      "Epoch 143/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4537.4087 - mean_squared_error: 4537.4087 - val_loss: 1490.5009 - val_mean_squared_error: 1490.5009\n",
      "Epoch 144/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4498.9478 - mean_squared_error: 4498.9478 - val_loss: 1455.7850 - val_mean_squared_error: 1455.7850\n",
      "Epoch 145/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4530.7422 - mean_squared_error: 4530.7422 - val_loss: 1457.7430 - val_mean_squared_error: 1457.7430\n",
      "Epoch 146/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4538.2515 - mean_squared_error: 4538.2515 - val_loss: 1472.1178 - val_mean_squared_error: 1472.1178\n",
      "Epoch 147/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4560.2256 - mean_squared_error: 4560.2256 - val_loss: 1459.6481 - val_mean_squared_error: 1459.6481\n",
      "Epoch 148/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4447.8550 - mean_squared_error: 4447.8550 - val_loss: 1463.0507 - val_mean_squared_error: 1463.0507\n",
      "Epoch 149/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4540.8970 - mean_squared_error: 4540.8970 - val_loss: 1471.0564 - val_mean_squared_error: 1471.0564\n",
      "Epoch 150/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4560.4692 - mean_squared_error: 4560.4692 - val_loss: 1454.0056 - val_mean_squared_error: 1454.0056\n",
      "Epoch 151/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4540.5215 - mean_squared_error: 4540.5215 - val_loss: 1466.7734 - val_mean_squared_error: 1466.7734\n",
      "Epoch 152/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4579.8574 - mean_squared_error: 4579.8574 - val_loss: 1454.8385 - val_mean_squared_error: 1454.8385\n",
      "Epoch 153/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4460.4458 - mean_squared_error: 4460.4458 - val_loss: 1452.1427 - val_mean_squared_error: 1452.1427\n",
      "Epoch 154/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4420.1724 - mean_squared_error: 4420.1724 - val_loss: 1491.6573 - val_mean_squared_error: 1491.6573\n",
      "Epoch 155/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4610.8818 - mean_squared_error: 4610.8818 - val_loss: 1462.4020 - val_mean_squared_error: 1462.4020\n",
      "Epoch 156/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4472.1436 - mean_squared_error: 4472.1436 - val_loss: 1471.1941 - val_mean_squared_error: 1471.1941\n",
      "Epoch 157/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4496.8154 - mean_squared_error: 4496.8154 - val_loss: 1551.7144 - val_mean_squared_error: 1551.7144\n",
      "Epoch 158/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4383.3813 - mean_squared_error: 4383.3813 - val_loss: 1498.1342 - val_mean_squared_error: 1498.1342\n",
      "Epoch 159/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4420.9639 - mean_squared_error: 4420.9639 - val_loss: 1482.6525 - val_mean_squared_error: 1482.6525\n",
      "Epoch 160/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4342.5879 - mean_squared_error: 4342.5879 - val_loss: 1551.5000 - val_mean_squared_error: 1551.5000\n",
      "Epoch 00160: early stopping\n",
      "Training time:24.169837474822998\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mean_squared_error'])\n",
    "\n",
    "curr_dt = set_curr_time()\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir='../logs/{0}'.format(curr_dt), histogram_freq=0, write_graph=True)\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=120)\n",
    "\n",
    "\n",
    "tic = time.time()\n",
    "model.fit(\n",
    "    x_train_label,\n",
    "    y_train_label,\n",
    "    epochs = 300,\n",
    "    batch_size = x_train_label.shape[0],\n",
    "    validation_data = (x_valid_label, y_valid_label),\n",
    "    shuffle = True,\n",
    "    callbacks=[es,tb_callback])\n",
    "toc = time.time()\n",
    "\n",
    "print('Training time:{}'.format(toc-tic))\n",
    "pred_y=model.predict(x_test_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "ERROE_MERGE = 0.5 # in hours\n",
    "correct = 0\n",
    "for i in range(0,len(y_test_label)):\n",
    "    scale_pred = (pred_y[i]*68.72187295)+(+13.17546792)\n",
    "    scale_test = (y_test_label[i][0]*68.72187295)+(+13.17546792)\n",
    "\n",
    "    if (((scale_pred - ERROE_MERGE) < scale_test) and ((scale_pred + ERROE_MERGE) > scale_test)):\n",
    "        correct += 1\n",
    "print(correct/len(y_test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
