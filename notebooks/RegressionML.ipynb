{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras import regularizers\n",
    "\n",
    "np.random.seed(7)\n",
    "\n",
    "# Constants\n",
    "TRAIN_AND_VALIDATION_TEST_SPLIT = 0.3\n",
    "VALID_AND_TEST_SPLIT            = 0.5\n",
    "BATCH_SIZE                      = 10\n",
    "\n",
    "relevent_attributes=[\"Priority\",\"RaisedByID\",\"AssignedToID\",\"StatusCode\",\\\n",
    "                     \"ProjectCode\",\"Category\",\"SubCategory\",\"HoursEstimate\",\"HoursActual\"]\n",
    "X_attributes=[\"Priority\",\"RaisedByID\",\"AssignedToID\",\"StatusCode\",\\\n",
    "                     \"ProjectCode\",\"Category\",\"SubCategory\",\"HoursEstimate\"]\n",
    "Y_attributes=[\"HoursActual\"]\n",
    "\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_curr_time():\n",
    "    dt = datetime.datetime.now()\n",
    "    curr_dt = '{0}{1}{2}_{3}_{4}'.format(datetime.datetime.now().year, datetime.datetime.now().month,\n",
    "                                       datetime.datetime.now().day, datetime.datetime.now().hour,\n",
    "                                      datetime.datetime.now().minute)\n",
    "    return curr_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Priority</th>\n",
       "      <th>RaisedByID</th>\n",
       "      <th>AssignedToID</th>\n",
       "      <th>AuthorisedByID</th>\n",
       "      <th>StatusCode</th>\n",
       "      <th>ProjectCode</th>\n",
       "      <th>Category</th>\n",
       "      <th>SubCategory</th>\n",
       "      <th>HoursEstimate</th>\n",
       "      <th>HoursActual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.683936</td>\n",
       "      <td>1.052282</td>\n",
       "      <td>1.099895</td>\n",
       "      <td>-2.113198</td>\n",
       "      <td>1.040642</td>\n",
       "      <td>-0.142837</td>\n",
       "      <td>-0.651337</td>\n",
       "      <td>-0.315307</td>\n",
       "      <td>0.133422</td>\n",
       "      <td>-0.166257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.683936</td>\n",
       "      <td>1.052282</td>\n",
       "      <td>0.249867</td>\n",
       "      <td>-2.113198</td>\n",
       "      <td>1.040642</td>\n",
       "      <td>-0.142837</td>\n",
       "      <td>-0.651337</td>\n",
       "      <td>-0.315307</td>\n",
       "      <td>-0.109292</td>\n",
       "      <td>-0.089862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.102534</td>\n",
       "      <td>-1.515859</td>\n",
       "      <td>1.099895</td>\n",
       "      <td>-2.113198</td>\n",
       "      <td>1.040642</td>\n",
       "      <td>-0.142837</td>\n",
       "      <td>1.995546</td>\n",
       "      <td>-0.001708</td>\n",
       "      <td>-0.327734</td>\n",
       "      <td>-0.181536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.641673</td>\n",
       "      <td>0.649437</td>\n",
       "      <td>0.249867</td>\n",
       "      <td>-2.113198</td>\n",
       "      <td>1.040642</td>\n",
       "      <td>-0.142837</td>\n",
       "      <td>-0.651337</td>\n",
       "      <td>-1.256102</td>\n",
       "      <td>-0.327734</td>\n",
       "      <td>-0.181536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.548685</td>\n",
       "      <td>0.448014</td>\n",
       "      <td>-1.290809</td>\n",
       "      <td>-2.113198</td>\n",
       "      <td>1.040642</td>\n",
       "      <td>-0.142837</td>\n",
       "      <td>-0.651337</td>\n",
       "      <td>-1.256102</td>\n",
       "      <td>-0.230648</td>\n",
       "      <td>-0.140792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Priority  RaisedByID  AssignedToID  AuthorisedByID  StatusCode  \\\n",
       "0           0 -0.683936    1.052282      1.099895       -2.113198    1.040642   \n",
       "1           1 -0.683936    1.052282      0.249867       -2.113198    1.040642   \n",
       "2           2 -0.102534   -1.515859      1.099895       -2.113198    1.040642   \n",
       "3           3  1.641673    0.649437      0.249867       -2.113198    1.040642   \n",
       "4           4  4.548685    0.448014     -1.290809       -2.113198    1.040642   \n",
       "\n",
       "   ProjectCode  Category  SubCategory  HoursEstimate  HoursActual  \n",
       "0    -0.142837 -0.651337    -0.315307       0.133422    -0.166257  \n",
       "1    -0.142837 -0.651337    -0.315307      -0.109292    -0.089862  \n",
       "2    -0.142837  1.995546    -0.001708      -0.327734    -0.181536  \n",
       "3    -0.142837 -0.651337    -1.256102      -0.327734    -0.181536  \n",
       "4    -0.142837 -0.651337    -1.256102      -0.230648    -0.140792  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../SiP_dataset-master/SIP_CAT.csv', encoding='cp1252') \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[relevent_attributes]\n",
    "ROW_COUNT = max(data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples: (8609, 8)\n",
      "Valid examples: (1845, 8)\n",
      "Test examples: (1845, 8)\n"
     ]
    }
   ],
   "source": [
    "# HoursEstimate_filter=HoursEstimate[HoursEstimate[\"HoursEstimate\"]<200]\n",
    "# HoursEstimate_filter=HoursEstimate_filter[HoursEstimate_filter[\"HoursActual\"]<800]\n",
    "\n",
    "x_train_label, xx_test_label, y_train_label, yy_test_label \\\n",
    "              = train_test_split(data[X_attributes].values[:], data[Y_attributes].values[:], test_size=TRAIN_AND_VALIDATION_TEST_SPLIT)\n",
    "x_valid_label, x_test_label, y_valid_label, y_test_label \\\n",
    "              = train_test_split(xx_test_label, yy_test_label, test_size=VALID_AND_TEST_SPLIT)  \n",
    "\n",
    "print(\"Train examples: {}\".format(x_train_label.shape))\n",
    "print(\"Valid examples: {}\".format(x_valid_label.shape))\n",
    "print(\"Test examples: {}\".format(x_test_label.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(2048, kernel_initializer='normal'), \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.8),\n",
    "    tf.keras.layers.Dense(1024,  kernel_initializer='normal'), \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.8),\n",
    "    tf.keras.layers.Dense(512, kernel_initializer='normal'), \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.8),\n",
    "    tf.keras.layers.Dense(256, kernel_initializer='normal'), \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.8),\n",
    "    tf.keras.layers.Dense(128, kernel_initializer='normal'), \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.8),\n",
    "    tf.keras.layers.Dense(64, kernel_initializer='normal'), \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.488),\n",
    "    tf.keras.layers.Dense(1)\n",
    "    \n",
    "    \n",
    "#     tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8609 samples, validate on 1845 samples\n",
      "Epoch 1/300\n",
      "8609/8609 [==============================] - 8s 909us/step - loss: 1.0950 - mean_absolute_error: 0.1959 - val_loss: 0.9758 - val_mean_absolute_error: 0.2062\n",
      "Epoch 2/300\n",
      "8609/8609 [==============================] - 7s 765us/step - loss: 1.0752 - mean_absolute_error: 0.1958 - val_loss: 0.9416 - val_mean_absolute_error: 0.1921\n",
      "Epoch 3/300\n",
      "8609/8609 [==============================] - 6s 754us/step - loss: 1.0482 - mean_absolute_error: 0.1923 - val_loss: 0.9384 - val_mean_absolute_error: 0.1773\n",
      "Epoch 4/300\n",
      "8609/8609 [==============================] - 7s 760us/step - loss: 1.0402 - mean_absolute_error: 0.1869 - val_loss: 1.0495 - val_mean_absolute_error: 0.4150\n",
      "Epoch 5/300\n",
      "8609/8609 [==============================] - 7s 762us/step - loss: 1.0407 - mean_absolute_error: 0.1934 - val_loss: 0.9254 - val_mean_absolute_error: 0.2078\n",
      "Epoch 6/300\n",
      "8609/8609 [==============================] - 7s 759us/step - loss: 1.0389 - mean_absolute_error: 0.1991 - val_loss: 0.9145 - val_mean_absolute_error: 0.1659\n",
      "Epoch 7/300\n",
      "8609/8609 [==============================] - 7s 774us/step - loss: 1.0019 - mean_absolute_error: 0.1793 - val_loss: 0.9305 - val_mean_absolute_error: 0.1737\n",
      "Epoch 8/300\n",
      "8609/8609 [==============================] - 7s 780us/step - loss: 1.0023 - mean_absolute_error: 0.1818 - val_loss: 0.9626 - val_mean_absolute_error: 0.1698\n",
      "Epoch 9/300\n",
      "8609/8609 [==============================] - 7s 780us/step - loss: 1.0298 - mean_absolute_error: 0.1938 - val_loss: 0.8891 - val_mean_absolute_error: 0.1663\n",
      "Epoch 10/300\n",
      "8609/8609 [==============================] - 7s 780us/step - loss: 0.9865 - mean_absolute_error: 0.1861 - val_loss: 0.8709 - val_mean_absolute_error: 0.1737\n",
      "Epoch 11/300\n",
      "8609/8609 [==============================] - 7s 779us/step - loss: 1.0341 - mean_absolute_error: 0.1853 - val_loss: 0.9560 - val_mean_absolute_error: 0.1711\n",
      "Epoch 12/300\n",
      "8609/8609 [==============================] - 7s 781us/step - loss: 0.9043 - mean_absolute_error: 0.1798 - val_loss: 0.8694 - val_mean_absolute_error: 0.1601\n",
      "Epoch 13/300\n",
      "8609/8609 [==============================] - 7s 772us/step - loss: 1.0296 - mean_absolute_error: 0.1902 - val_loss: 0.8587 - val_mean_absolute_error: 0.1895\n",
      "Epoch 14/300\n",
      "8609/8609 [==============================] - 7s 777us/step - loss: 0.9310 - mean_absolute_error: 0.1766 - val_loss: 0.9353 - val_mean_absolute_error: 0.1683\n",
      "Epoch 15/300\n",
      "8609/8609 [==============================] - 7s 776us/step - loss: 0.9660 - mean_absolute_error: 0.1921 - val_loss: 0.8167 - val_mean_absolute_error: 0.1703\n",
      "Epoch 16/300\n",
      "8609/8609 [==============================] - 7s 782us/step - loss: 0.9632 - mean_absolute_error: 0.1918 - val_loss: 0.7986 - val_mean_absolute_error: 0.1737\n",
      "Epoch 17/300\n",
      "8609/8609 [==============================] - 7s 781us/step - loss: 1.0759 - mean_absolute_error: 0.1882 - val_loss: 0.9650 - val_mean_absolute_error: 0.1884\n",
      "Epoch 18/300\n",
      "8609/8609 [==============================] - 7s 780us/step - loss: 0.8944 - mean_absolute_error: 0.1804 - val_loss: 0.9072 - val_mean_absolute_error: 0.1845\n",
      "Epoch 19/300\n",
      "8609/8609 [==============================] - 7s 782us/step - loss: 1.4412 - mean_absolute_error: 0.1914 - val_loss: 0.9532 - val_mean_absolute_error: 0.1834\n",
      "Epoch 20/300\n",
      "8609/8609 [==============================] - 7s 787us/step - loss: 1.0099 - mean_absolute_error: 0.1892 - val_loss: 0.9357 - val_mean_absolute_error: 0.2064\n",
      "Epoch 21/300\n",
      "8609/8609 [==============================] - 7s 773us/step - loss: 0.9288 - mean_absolute_error: 0.1845 - val_loss: 0.7908 - val_mean_absolute_error: 0.1934\n",
      "Epoch 22/300\n",
      "8609/8609 [==============================] - 7s 776us/step - loss: 0.8115 - mean_absolute_error: 0.1826 - val_loss: 0.6568 - val_mean_absolute_error: 0.1623\n",
      "Epoch 23/300\n",
      "8609/8609 [==============================] - 7s 769us/step - loss: 1.4352 - mean_absolute_error: 0.1901 - val_loss: 0.9339 - val_mean_absolute_error: 0.1633\n",
      "Epoch 24/300\n",
      "8609/8609 [==============================] - 7s 763us/step - loss: 0.9409 - mean_absolute_error: 0.1769 - val_loss: 0.7344 - val_mean_absolute_error: 0.1803\n",
      "Epoch 25/300\n",
      "8609/8609 [==============================] - 7s 770us/step - loss: 0.8019 - mean_absolute_error: 0.1780 - val_loss: 0.6432 - val_mean_absolute_error: 0.1825\n",
      "Epoch 26/300\n",
      "8609/8609 [==============================] - 7s 783us/step - loss: 0.9164 - mean_absolute_error: 0.1852 - val_loss: 0.7038 - val_mean_absolute_error: 0.2338\n",
      "Epoch 27/300\n",
      "8609/8609 [==============================] - 7s 780us/step - loss: 0.8106 - mean_absolute_error: 0.1895 - val_loss: 0.7089 - val_mean_absolute_error: 0.1894\n",
      "Epoch 28/300\n",
      "8609/8609 [==============================] - 7s 772us/step - loss: 0.7863 - mean_absolute_error: 0.1827 - val_loss: 0.2547 - val_mean_absolute_error: 0.1555\n",
      "Epoch 29/300\n",
      "8609/8609 [==============================] - 7s 782us/step - loss: 0.7599 - mean_absolute_error: 0.1756 - val_loss: 0.6392 - val_mean_absolute_error: 0.1575\n",
      "Epoch 30/300\n",
      "8609/8609 [==============================] - 7s 783us/step - loss: 0.6817 - mean_absolute_error: 0.1770 - val_loss: 0.6092 - val_mean_absolute_error: 0.1857\n",
      "Epoch 31/300\n",
      "8609/8609 [==============================] - 7s 779us/step - loss: 0.6451 - mean_absolute_error: 0.1764 - val_loss: 0.5563 - val_mean_absolute_error: 0.1838\n",
      "Epoch 32/300\n",
      "8609/8609 [==============================] - 7s 776us/step - loss: 0.8496 - mean_absolute_error: 0.1957 - val_loss: 1.0529 - val_mean_absolute_error: 0.1838\n",
      "Epoch 33/300\n",
      "8609/8609 [==============================] - 7s 768us/step - loss: 1.3158 - mean_absolute_error: 0.2158 - val_loss: 0.9120 - val_mean_absolute_error: 0.1688\n",
      "Epoch 34/300\n",
      "8609/8609 [==============================] - 7s 768us/step - loss: 0.8973 - mean_absolute_error: 0.1946 - val_loss: 0.7410 - val_mean_absolute_error: 0.2482\n",
      "Epoch 35/300\n",
      "8609/8609 [==============================] - 7s 764us/step - loss: 0.8090 - mean_absolute_error: 0.2126 - val_loss: 0.9435 - val_mean_absolute_error: 0.2695\n",
      "Epoch 36/300\n",
      "8609/8609 [==============================] - 7s 764us/step - loss: 0.9639 - mean_absolute_error: 0.1938 - val_loss: 0.9336 - val_mean_absolute_error: 0.1951\n",
      "Epoch 37/300\n",
      "8609/8609 [==============================] - 6s 752us/step - loss: 0.8528 - mean_absolute_error: 0.1832 - val_loss: 0.8581 - val_mean_absolute_error: 0.1709\n",
      "Epoch 38/300\n",
      "8609/8609 [==============================] - 6s 748us/step - loss: 0.8292 - mean_absolute_error: 0.2050 - val_loss: 0.7590 - val_mean_absolute_error: 0.3136\n",
      "Epoch 39/300\n",
      "8609/8609 [==============================] - 6s 753us/step - loss: 1.2123 - mean_absolute_error: 0.1913 - val_loss: 0.9263 - val_mean_absolute_error: 0.1814\n",
      "Epoch 40/300\n",
      "8609/8609 [==============================] - 6s 750us/step - loss: 0.9090 - mean_absolute_error: 0.1895 - val_loss: 0.8673 - val_mean_absolute_error: 0.2159\n",
      "Epoch 41/300\n",
      "8609/8609 [==============================] - 6s 751us/step - loss: 0.7324 - mean_absolute_error: 0.1971 - val_loss: 0.6134 - val_mean_absolute_error: 0.1974\n",
      "Epoch 42/300\n",
      "8609/8609 [==============================] - 7s 772us/step - loss: 0.7429 - mean_absolute_error: 0.1927 - val_loss: 0.5439 - val_mean_absolute_error: 0.1632\n",
      "Epoch 43/300\n",
      "8609/8609 [==============================] - 7s 776us/step - loss: 0.7183 - mean_absolute_error: 0.1731 - val_loss: 0.8999 - val_mean_absolute_error: 0.1622\n",
      "Epoch 44/300\n",
      "8609/8609 [==============================] - 7s 771us/step - loss: 0.7694 - mean_absolute_error: 0.1958 - val_loss: 0.6714 - val_mean_absolute_error: 0.1956\n",
      "Epoch 45/300\n",
      "8609/8609 [==============================] - 7s 760us/step - loss: 0.6385 - mean_absolute_error: 0.1825 - val_loss: 0.5073 - val_mean_absolute_error: 0.1601\n",
      "Epoch 46/300\n",
      "8609/8609 [==============================] - 7s 767us/step - loss: 0.6522 - mean_absolute_error: 0.1747 - val_loss: 0.8446 - val_mean_absolute_error: 0.1665\n",
      "Epoch 47/300\n",
      "8609/8609 [==============================] - 7s 766us/step - loss: 1.4244 - mean_absolute_error: 0.1828 - val_loss: 0.4616 - val_mean_absolute_error: 0.1559\n",
      "Epoch 48/300\n",
      "8609/8609 [==============================] - 7s 778us/step - loss: 0.5079 - mean_absolute_error: 0.1614 - val_loss: 0.4669 - val_mean_absolute_error: 0.1527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/300\n",
      "8609/8609 [==============================] - 7s 777us/step - loss: 0.4199 - mean_absolute_error: 0.1586 - val_loss: 0.7926 - val_mean_absolute_error: 0.1778\n",
      "Epoch 50/300\n",
      "8609/8609 [==============================] - 7s 774us/step - loss: 0.5233 - mean_absolute_error: 0.1622 - val_loss: 0.5827 - val_mean_absolute_error: 0.3922\n",
      "Epoch 51/300\n",
      "8609/8609 [==============================] - 7s 771us/step - loss: 0.3709 - mean_absolute_error: 0.1598 - val_loss: 0.9070 - val_mean_absolute_error: 0.1710\n",
      "Epoch 52/300\n",
      "8609/8609 [==============================] - 7s 776us/step - loss: 0.7083 - mean_absolute_error: 0.1645 - val_loss: 0.8298 - val_mean_absolute_error: 0.1913\n",
      "Epoch 53/300\n",
      "8609/8609 [==============================] - 7s 778us/step - loss: 0.7357 - mean_absolute_error: 0.1861 - val_loss: 0.4411 - val_mean_absolute_error: 0.1596\n",
      "Epoch 54/300\n",
      "8609/8609 [==============================] - 7s 766us/step - loss: 0.3863 - mean_absolute_error: 0.1565 - val_loss: 0.4029 - val_mean_absolute_error: 0.1821\n",
      "Epoch 55/300\n",
      "8609/8609 [==============================] - 7s 765us/step - loss: 0.3418 - mean_absolute_error: 0.1466 - val_loss: 0.2567 - val_mean_absolute_error: 0.1777\n",
      "Epoch 56/300\n",
      "8609/8609 [==============================] - 7s 771us/step - loss: 0.2924 - mean_absolute_error: 0.1436 - val_loss: 0.2649 - val_mean_absolute_error: 0.1385\n",
      "Epoch 57/300\n",
      "8609/8609 [==============================] - 7s 772us/step - loss: 0.2706 - mean_absolute_error: 0.1391 - val_loss: 0.2566 - val_mean_absolute_error: 0.1414\n",
      "Epoch 58/300\n",
      "8609/8609 [==============================] - 7s 764us/step - loss: 0.2713 - mean_absolute_error: 0.1425 - val_loss: 0.3656 - val_mean_absolute_error: 0.1763\n",
      "Epoch 59/300\n",
      "8609/8609 [==============================] - 6s 754us/step - loss: 0.6514 - mean_absolute_error: 0.1705 - val_loss: 0.3743 - val_mean_absolute_error: 0.1697\n",
      "Epoch 60/300\n",
      "8609/8609 [==============================] - 7s 756us/step - loss: 0.6035 - mean_absolute_error: 0.1560 - val_loss: 0.4556 - val_mean_absolute_error: 0.1623\n",
      "Epoch 61/300\n",
      "8609/8609 [==============================] - 7s 766us/step - loss: 0.4741 - mean_absolute_error: 0.1590 - val_loss: 0.2969 - val_mean_absolute_error: 0.1439\n",
      "Epoch 62/300\n",
      "8609/8609 [==============================] - 7s 765us/step - loss: 1.0321 - mean_absolute_error: 0.1833 - val_loss: 0.9089 - val_mean_absolute_error: 0.1894\n",
      "Epoch 63/300\n",
      "8609/8609 [==============================] - 7s 769us/step - loss: 0.6370 - mean_absolute_error: 0.1709 - val_loss: 0.5186 - val_mean_absolute_error: 0.3812\n",
      "Epoch 64/300\n",
      "8609/8609 [==============================] - 7s 771us/step - loss: 0.4541 - mean_absolute_error: 0.1456 - val_loss: 0.8453 - val_mean_absolute_error: 0.1502\n",
      "Epoch 65/300\n",
      "8609/8609 [==============================] - 7s 770us/step - loss: 0.8182 - mean_absolute_error: 0.1785 - val_loss: 0.8621 - val_mean_absolute_error: 0.1842\n",
      "Epoch 66/300\n",
      "8609/8609 [==============================] - 7s 766us/step - loss: 0.6469 - mean_absolute_error: 0.1688 - val_loss: 0.3944 - val_mean_absolute_error: 0.1405\n",
      "Epoch 67/300\n",
      "8609/8609 [==============================] - 7s 767us/step - loss: 0.4628 - mean_absolute_error: 0.1576 - val_loss: 0.3486 - val_mean_absolute_error: 0.1426\n",
      "Epoch 68/300\n",
      "8609/8609 [==============================] - 7s 772us/step - loss: 0.5396 - mean_absolute_error: 0.1661 - val_loss: 0.7031 - val_mean_absolute_error: 0.2080\n",
      "Epoch 69/300\n",
      "8609/8609 [==============================] - 7s 762us/step - loss: 0.6981 - mean_absolute_error: 0.1675 - val_loss: 0.3935 - val_mean_absolute_error: 0.1574\n",
      "Epoch 70/300\n",
      "8609/8609 [==============================] - 7s 761us/step - loss: 0.6148 - mean_absolute_error: 0.1643 - val_loss: 0.6508 - val_mean_absolute_error: 0.1487\n",
      "Epoch 71/300\n",
      "8609/8609 [==============================] - 7s 769us/step - loss: 0.4490 - mean_absolute_error: 0.1467 - val_loss: 0.3805 - val_mean_absolute_error: 0.1511\n",
      "Epoch 72/300\n",
      "8609/8609 [==============================] - 7s 774us/step - loss: 0.3837 - mean_absolute_error: 0.1443 - val_loss: 0.3216 - val_mean_absolute_error: 0.1406\n",
      "Epoch 73/300\n",
      "8609/8609 [==============================] - 7s 775us/step - loss: 0.6636 - mean_absolute_error: 0.1655 - val_loss: 0.3267 - val_mean_absolute_error: 0.1449\n",
      "Epoch 74/300\n",
      "8609/8609 [==============================] - 7s 776us/step - loss: 0.3562 - mean_absolute_error: 0.1458 - val_loss: 0.9036 - val_mean_absolute_error: 0.1926\n",
      "Epoch 75/300\n",
      "8609/8609 [==============================] - 7s 775us/step - loss: 0.6824 - mean_absolute_error: 0.1614 - val_loss: 0.8082 - val_mean_absolute_error: 0.1469\n",
      "Epoch 76/300\n",
      "8609/8609 [==============================] - 7s 774us/step - loss: 0.4424 - mean_absolute_error: 0.1590 - val_loss: 0.3209 - val_mean_absolute_error: 0.1504\n",
      "Epoch 77/300\n",
      "8609/8609 [==============================] - 7s 774us/step - loss: 0.7327 - mean_absolute_error: 0.1652 - val_loss: 0.8656 - val_mean_absolute_error: 0.1561\n",
      "Epoch 78/300\n",
      "8609/8609 [==============================] - 7s 771us/step - loss: 0.8726 - mean_absolute_error: 0.1772 - val_loss: 0.5147 - val_mean_absolute_error: 0.1616\n",
      "Epoch 79/300\n",
      "8609/8609 [==============================] - 7s 776us/step - loss: 0.5114 - mean_absolute_error: 0.1588 - val_loss: 0.2880 - val_mean_absolute_error: 0.1400\n",
      "Epoch 80/300\n",
      "8609/8609 [==============================] - 7s 778us/step - loss: 0.5344 - mean_absolute_error: 0.1602 - val_loss: 0.3688 - val_mean_absolute_error: 0.2976\n",
      "Epoch 81/300\n",
      "8609/8609 [==============================] - 7s 776us/step - loss: 0.3758 - mean_absolute_error: 0.1552 - val_loss: 0.4957 - val_mean_absolute_error: 0.1564\n",
      "Epoch 82/300\n",
      "8609/8609 [==============================] - 7s 777us/step - loss: 0.4677 - mean_absolute_error: 0.1516 - val_loss: 0.3064 - val_mean_absolute_error: 0.1370\n",
      "Epoch 83/300\n",
      "8609/8609 [==============================] - 7s 775us/step - loss: 0.2638 - mean_absolute_error: 0.1314 - val_loss: 0.2903 - val_mean_absolute_error: 0.1556\n",
      "Epoch 84/300\n",
      "8609/8609 [==============================] - 7s 773us/step - loss: 0.5485 - mean_absolute_error: 0.1528 - val_loss: 0.8634 - val_mean_absolute_error: 0.1507\n",
      "Epoch 85/300\n",
      "8609/8609 [==============================] - 7s 771us/step - loss: 0.6888 - mean_absolute_error: 0.1500 - val_loss: 0.7489 - val_mean_absolute_error: 0.1542\n",
      "Epoch 86/300\n",
      "8609/8609 [==============================] - 7s 766us/step - loss: 0.5076 - mean_absolute_error: 0.1537 - val_loss: 0.2923 - val_mean_absolute_error: 0.1358\n",
      "Epoch 87/300\n",
      "8609/8609 [==============================] - 7s 771us/step - loss: 0.1476 - mean_absolute_error: 0.1298 - val_loss: 0.8737 - val_mean_absolute_error: 0.1520\n",
      "Epoch 88/300\n",
      "8609/8609 [==============================] - 7s 768us/step - loss: 0.5459 - mean_absolute_error: 0.1497 - val_loss: 0.2493 - val_mean_absolute_error: 0.1598\n",
      "Epoch 89/300\n",
      "8609/8609 [==============================] - 7s 765us/step - loss: 0.3891 - mean_absolute_error: 0.1503 - val_loss: 0.2033 - val_mean_absolute_error: 0.1468\n",
      "Epoch 90/300\n",
      "8609/8609 [==============================] - 7s 757us/step - loss: 0.2639 - mean_absolute_error: 0.1377 - val_loss: 0.2221 - val_mean_absolute_error: 0.1312\n",
      "Epoch 91/300\n",
      "8609/8609 [==============================] - 7s 769us/step - loss: 0.5148 - mean_absolute_error: 0.1604 - val_loss: 0.3315 - val_mean_absolute_error: 0.2525\n",
      "Epoch 92/300\n",
      "8609/8609 [==============================] - 7s 765us/step - loss: 0.3028 - mean_absolute_error: 0.1421 - val_loss: 0.2207 - val_mean_absolute_error: 0.1590\n",
      "Epoch 93/300\n",
      "8609/8609 [==============================] - 6s 752us/step - loss: 0.2773 - mean_absolute_error: 0.1320 - val_loss: 0.2270 - val_mean_absolute_error: 0.1288\n",
      "Epoch 94/300\n",
      "8609/8609 [==============================] - 6s 746us/step - loss: 0.2369 - mean_absolute_error: 0.1276 - val_loss: 0.3578 - val_mean_absolute_error: 0.2103\n",
      "Epoch 95/300\n",
      "8609/8609 [==============================] - 7s 763us/step - loss: 0.2951 - mean_absolute_error: 0.1400 - val_loss: 0.3063 - val_mean_absolute_error: 0.1842\n",
      "Epoch 96/300\n",
      "8609/8609 [==============================] - 7s 758us/step - loss: 0.4704 - mean_absolute_error: 0.1454 - val_loss: 0.8563 - val_mean_absolute_error: 0.1765\n",
      "Epoch 97/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8609/8609 [==============================] - 7s 767us/step - loss: 0.3723 - mean_absolute_error: 0.1356 - val_loss: 0.2363 - val_mean_absolute_error: 0.1424\n",
      "Epoch 98/300\n",
      "8609/8609 [==============================] - 7s 769us/step - loss: 0.2640 - mean_absolute_error: 0.1325 - val_loss: 0.2715 - val_mean_absolute_error: 0.2055\n",
      "Epoch 99/300\n",
      "8609/8609 [==============================] - 7s 772us/step - loss: 0.3115 - mean_absolute_error: 0.1372 - val_loss: 0.2182 - val_mean_absolute_error: 0.1383\n",
      "Epoch 100/300\n",
      "8609/8609 [==============================] - 7s 758us/step - loss: 0.3284 - mean_absolute_error: 0.1360 - val_loss: 0.2317 - val_mean_absolute_error: 0.1349\n",
      "Epoch 101/300\n",
      "8609/8609 [==============================] - 7s 774us/step - loss: 0.2428 - mean_absolute_error: 0.1308 - val_loss: 0.2351 - val_mean_absolute_error: 0.1317\n",
      "Epoch 102/300\n",
      "8609/8609 [==============================] - 7s 774us/step - loss: 0.2235 - mean_absolute_error: 0.1232 - val_loss: 0.2391 - val_mean_absolute_error: 0.1621\n",
      "Epoch 103/300\n",
      "8609/8609 [==============================] - 7s 767us/step - loss: 0.4063 - mean_absolute_error: 0.1405 - val_loss: 0.8892 - val_mean_absolute_error: 0.1566\n",
      "Epoch 104/300\n",
      "8609/8609 [==============================] - 7s 766us/step - loss: 0.7452 - mean_absolute_error: 0.1612 - val_loss: 0.8211 - val_mean_absolute_error: 0.2330\n",
      "Epoch 105/300\n",
      "8609/8609 [==============================] - 7s 767us/step - loss: 0.5388 - mean_absolute_error: 0.1495 - val_loss: 0.2458 - val_mean_absolute_error: 0.1452\n",
      "Epoch 106/300\n",
      "8609/8609 [==============================] - 7s 768us/step - loss: 0.3364 - mean_absolute_error: 0.1343 - val_loss: 0.2503 - val_mean_absolute_error: 0.1603\n",
      "Epoch 107/300\n",
      "8609/8609 [==============================] - 7s 779us/step - loss: 0.2728 - mean_absolute_error: 0.1284 - val_loss: 0.2241 - val_mean_absolute_error: 0.1314\n",
      "Epoch 108/300\n",
      "8609/8609 [==============================] - 7s 776us/step - loss: 0.5955 - mean_absolute_error: 0.1464 - val_loss: 0.6046 - val_mean_absolute_error: 0.1513\n",
      "Epoch 109/300\n",
      "8609/8609 [==============================] - 7s 776us/step - loss: 0.5957 - mean_absolute_error: 0.1643 - val_loss: 0.3784 - val_mean_absolute_error: 0.1411\n",
      "Epoch 110/300\n",
      "8609/8609 [==============================] - 7s 774us/step - loss: 0.3200 - mean_absolute_error: 0.1430 - val_loss: 0.2422 - val_mean_absolute_error: 0.1346\n",
      "Epoch 111/300\n",
      "8609/8609 [==============================] - 7s 767us/step - loss: 0.2507 - mean_absolute_error: 0.1283 - val_loss: 0.2222 - val_mean_absolute_error: 0.1296\n",
      "Epoch 112/300\n",
      "8609/8609 [==============================] - 7s 766us/step - loss: 0.2259 - mean_absolute_error: 0.1226 - val_loss: 0.2121 - val_mean_absolute_error: 0.1595\n",
      "Epoch 113/300\n",
      "8609/8609 [==============================] - 7s 768us/step - loss: 0.2288 - mean_absolute_error: 0.1272 - val_loss: 0.2011 - val_mean_absolute_error: 0.1258\n",
      "Epoch 114/300\n",
      "8609/8609 [==============================] - 7s 778us/step - loss: 0.3847 - mean_absolute_error: 0.1442 - val_loss: 0.2117 - val_mean_absolute_error: 0.1287\n",
      "Epoch 115/300\n",
      "8609/8609 [==============================] - 7s 772us/step - loss: 0.2604 - mean_absolute_error: 0.1297 - val_loss: 0.2418 - val_mean_absolute_error: 0.1810\n",
      "Epoch 116/300\n",
      "8609/8609 [==============================] - 7s 770us/step - loss: 0.5760 - mean_absolute_error: 0.1602 - val_loss: 0.9011 - val_mean_absolute_error: 0.1498\n",
      "Epoch 117/300\n",
      "8609/8609 [==============================] - 7s 767us/step - loss: 0.8004 - mean_absolute_error: 0.1685 - val_loss: 0.7488 - val_mean_absolute_error: 0.1560\n",
      "Epoch 118/300\n",
      "8609/8609 [==============================] - 7s 765us/step - loss: 0.5729 - mean_absolute_error: 0.1549 - val_loss: 0.3001 - val_mean_absolute_error: 0.1352\n",
      "Epoch 119/300\n",
      "8609/8609 [==============================] - 6s 748us/step - loss: 0.6393 - mean_absolute_error: 0.1524 - val_loss: 0.6069 - val_mean_absolute_error: 0.1686\n",
      "Epoch 120/300\n",
      "8609/8609 [==============================] - 7s 768us/step - loss: 0.4891 - mean_absolute_error: 0.1508 - val_loss: 0.2482 - val_mean_absolute_error: 0.1506\n",
      "Epoch 121/300\n",
      "8609/8609 [==============================] - 6s 749us/step - loss: 0.2245 - mean_absolute_error: 0.1249 - val_loss: 0.2302 - val_mean_absolute_error: 0.1407\n",
      "Epoch 122/300\n",
      "8609/8609 [==============================] - 6s 751us/step - loss: 0.3816 - mean_absolute_error: 0.1318 - val_loss: 0.2534 - val_mean_absolute_error: 0.1524\n",
      "Epoch 123/300\n",
      "8609/8609 [==============================] - 7s 759us/step - loss: 0.2319 - mean_absolute_error: 0.1316 - val_loss: 0.2584 - val_mean_absolute_error: 0.1434\n",
      "Epoch 124/300\n",
      "8609/8609 [==============================] - 7s 765us/step - loss: 0.3370 - mean_absolute_error: 0.1411 - val_loss: 0.2346 - val_mean_absolute_error: 0.1382\n",
      "Epoch 125/300\n",
      "8609/8609 [==============================] - 7s 762us/step - loss: 0.2938 - mean_absolute_error: 0.1497 - val_loss: 0.2745 - val_mean_absolute_error: 0.1370\n",
      "Epoch 126/300\n",
      "8609/8609 [==============================] - 7s 773us/step - loss: 0.2460 - mean_absolute_error: 0.1283 - val_loss: 0.2266 - val_mean_absolute_error: 0.1363\n",
      "Epoch 127/300\n",
      "8609/8609 [==============================] - 7s 767us/step - loss: 0.2280 - mean_absolute_error: 0.1217 - val_loss: 0.2963 - val_mean_absolute_error: 0.1310\n",
      "Epoch 128/300\n",
      "8609/8609 [==============================] - 7s 764us/step - loss: 0.2430 - mean_absolute_error: 0.1230 - val_loss: 0.2608 - val_mean_absolute_error: 0.1309\n",
      "Epoch 129/300\n",
      "8609/8609 [==============================] - 7s 767us/step - loss: 0.2265 - mean_absolute_error: 0.1275 - val_loss: 0.2264 - val_mean_absolute_error: 0.1520\n",
      "Epoch 130/300\n",
      "8609/8609 [==============================] - 7s 771us/step - loss: 0.2195 - mean_absolute_error: 0.1245 - val_loss: 0.2155 - val_mean_absolute_error: 0.1295\n",
      "Epoch 131/300\n",
      "8609/8609 [==============================] - 6s 754us/step - loss: 0.6831 - mean_absolute_error: 0.1617 - val_loss: 0.8628 - val_mean_absolute_error: 0.1811\n",
      "Epoch 132/300\n",
      "8609/8609 [==============================] - 7s 769us/step - loss: 0.6080 - mean_absolute_error: 0.1434 - val_loss: 0.7156 - val_mean_absolute_error: 0.1493\n",
      "Epoch 133/300\n",
      "8609/8609 [==============================] - 7s 769us/step - loss: 0.3257 - mean_absolute_error: 0.1308 - val_loss: 0.1998 - val_mean_absolute_error: 0.1494\n",
      "Epoch 134/300\n",
      "8609/8609 [==============================] - 7s 772us/step - loss: 0.5201 - mean_absolute_error: 0.1408 - val_loss: 0.2273 - val_mean_absolute_error: 0.1381\n",
      "Epoch 135/300\n",
      "8609/8609 [==============================] - 7s 774us/step - loss: 0.2232 - mean_absolute_error: 0.1195 - val_loss: 0.2001 - val_mean_absolute_error: 0.1215\n",
      "Epoch 136/300\n",
      "8609/8609 [==============================] - 7s 772us/step - loss: 0.2320 - mean_absolute_error: 0.1218 - val_loss: 0.2449 - val_mean_absolute_error: 0.1499\n",
      "Epoch 137/300\n",
      "8609/8609 [==============================] - 7s 770us/step - loss: 0.2271 - mean_absolute_error: 0.1257 - val_loss: 0.2382 - val_mean_absolute_error: 0.1350\n",
      "Epoch 138/300\n",
      "8609/8609 [==============================] - 7s 771us/step - loss: 0.2903 - mean_absolute_error: 0.1242 - val_loss: 0.2459 - val_mean_absolute_error: 0.1245\n",
      "Epoch 139/300\n",
      "8609/8609 [==============================] - 7s 774us/step - loss: 0.2188 - mean_absolute_error: 0.1230 - val_loss: 0.2277 - val_mean_absolute_error: 0.1258\n",
      "Epoch 140/300\n",
      "8609/8609 [==============================] - 7s 773us/step - loss: 0.4362 - mean_absolute_error: 0.1316 - val_loss: 0.2463 - val_mean_absolute_error: 0.1315\n",
      "Epoch 141/300\n",
      "8609/8609 [==============================] - 7s 773us/step - loss: 0.2209 - mean_absolute_error: 0.1236 - val_loss: 0.2500 - val_mean_absolute_error: 0.1349\n",
      "Epoch 142/300\n",
      "8609/8609 [==============================] - 7s 778us/step - loss: 0.2200 - mean_absolute_error: 0.1284 - val_loss: 0.2449 - val_mean_absolute_error: 0.1632\n",
      "Epoch 143/300\n",
      "8609/8609 [==============================] - 7s 778us/step - loss: 0.2121 - mean_absolute_error: 0.1270 - val_loss: 0.2446 - val_mean_absolute_error: 0.1518\n",
      "Epoch 144/300\n",
      "8609/8609 [==============================] - 7s 764us/step - loss: 0.2215 - mean_absolute_error: 0.1255 - val_loss: 0.2107 - val_mean_absolute_error: 0.2026\n",
      "Epoch 145/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8609/8609 [==============================] - 7s 774us/step - loss: 0.2520 - mean_absolute_error: 0.1247 - val_loss: 0.2480 - val_mean_absolute_error: 0.2050\n",
      "Epoch 146/300\n",
      "8609/8609 [==============================] - 7s 772us/step - loss: 0.2430 - mean_absolute_error: 0.1222 - val_loss: 0.2344 - val_mean_absolute_error: 0.1383\n",
      "Epoch 147/300\n",
      "8609/8609 [==============================] - 7s 769us/step - loss: 0.2440 - mean_absolute_error: 0.1269 - val_loss: 0.2357 - val_mean_absolute_error: 0.1283\n",
      "Epoch 148/300\n",
      "8609/8609 [==============================] - 7s 768us/step - loss: 0.3263 - mean_absolute_error: 0.1258 - val_loss: 0.2714 - val_mean_absolute_error: 0.1303\n",
      "Epoch 149/300\n",
      "8609/8609 [==============================] - 7s 765us/step - loss: 0.2251 - mean_absolute_error: 0.1267 - val_loss: 0.2497 - val_mean_absolute_error: 0.1320\n",
      "Epoch 150/300\n",
      "8609/8609 [==============================] - 7s 760us/step - loss: 0.3378 - mean_absolute_error: 0.1255 - val_loss: 0.2763 - val_mean_absolute_error: 0.1438\n",
      "Epoch 151/300\n",
      "8609/8609 [==============================] - 7s 762us/step - loss: 0.2983 - mean_absolute_error: 0.1274 - val_loss: 0.3630 - val_mean_absolute_error: 0.1958\n",
      "Epoch 152/300\n",
      "8609/8609 [==============================] - 7s 764us/step - loss: 0.2157 - mean_absolute_error: 0.1223 - val_loss: 0.2124 - val_mean_absolute_error: 0.1508\n",
      "Epoch 153/300\n",
      "8609/8609 [==============================] - 7s 771us/step - loss: 0.2799 - mean_absolute_error: 0.1177 - val_loss: 0.2278 - val_mean_absolute_error: 0.1362\n",
      "Epoch 154/300\n",
      "8609/8609 [==============================] - 7s 770us/step - loss: 0.2991 - mean_absolute_error: 0.1327 - val_loss: 0.2851 - val_mean_absolute_error: 0.1490\n",
      "Epoch 155/300\n",
      "8609/8609 [==============================] - 7s 771us/step - loss: 0.4881 - mean_absolute_error: 0.1358 - val_loss: 0.6931 - val_mean_absolute_error: 0.1705\n",
      "Epoch 156/300\n",
      "8609/8609 [==============================] - 7s 770us/step - loss: 0.5353 - mean_absolute_error: 0.1739 - val_loss: 0.4440 - val_mean_absolute_error: 0.1504\n",
      "Epoch 157/300\n",
      "8609/8609 [==============================] - 7s 766us/step - loss: 0.2932 - mean_absolute_error: 0.1429 - val_loss: 0.2949 - val_mean_absolute_error: 0.1452\n",
      "Epoch 158/300\n",
      "8609/8609 [==============================] - 7s 769us/step - loss: 0.2511 - mean_absolute_error: 0.1344 - val_loss: 0.2372 - val_mean_absolute_error: 0.1438\n",
      "Epoch 159/300\n",
      "8609/8609 [==============================] - 7s 762us/step - loss: 0.2162 - mean_absolute_error: 0.1211 - val_loss: 0.2820 - val_mean_absolute_error: 0.1314\n",
      "Epoch 160/300\n",
      "8609/8609 [==============================] - 7s 765us/step - loss: 0.2310 - mean_absolute_error: 0.1314 - val_loss: 0.2184 - val_mean_absolute_error: 0.1295\n",
      "Epoch 161/300\n",
      "8609/8609 [==============================] - 7s 768us/step - loss: 0.2190 - mean_absolute_error: 0.1225 - val_loss: 0.2243 - val_mean_absolute_error: 0.1284\n",
      "Epoch 162/300\n",
      "8609/8609 [==============================] - 7s 770us/step - loss: 0.2203 - mean_absolute_error: 0.1282 - val_loss: 0.2462 - val_mean_absolute_error: 0.1362\n",
      "Epoch 163/300\n",
      "8609/8609 [==============================] - 7s 772us/step - loss: 0.2243 - mean_absolute_error: 0.1317 - val_loss: 0.2070 - val_mean_absolute_error: 0.1265\n",
      "Epoch 164/300\n",
      "8609/8609 [==============================] - 7s 763us/step - loss: 0.2157 - mean_absolute_error: 0.1201 - val_loss: 0.2083 - val_mean_absolute_error: 0.1368\n",
      "Epoch 165/300\n",
      "8609/8609 [==============================] - 7s 764us/step - loss: 0.4335 - mean_absolute_error: 0.1275 - val_loss: 0.5671 - val_mean_absolute_error: 0.1409\n",
      "Epoch 166/300\n",
      "8609/8609 [==============================] - 7s 765us/step - loss: 0.2977 - mean_absolute_error: 0.1271 - val_loss: 0.2422 - val_mean_absolute_error: 0.1326\n",
      "Epoch 167/300\n",
      "8609/8609 [==============================] - 7s 763us/step - loss: 0.2976 - mean_absolute_error: 0.1394 - val_loss: 0.2312 - val_mean_absolute_error: 0.1278\n",
      "Epoch 168/300\n",
      "8609/8609 [==============================] - 7s 768us/step - loss: 0.2961 - mean_absolute_error: 0.1306 - val_loss: 0.2147 - val_mean_absolute_error: 0.1293\n",
      "Epoch 169/300\n",
      "8609/8609 [==============================] - 7s 762us/step - loss: 0.2103 - mean_absolute_error: 0.1158 - val_loss: 0.2127 - val_mean_absolute_error: 0.1265\n",
      "Epoch 170/300\n",
      "8609/8609 [==============================] - 6s 746us/step - loss: 0.2099 - mean_absolute_error: 0.1188 - val_loss: 0.2087 - val_mean_absolute_error: 0.1194\n",
      "Epoch 171/300\n",
      "8609/8609 [==============================] - 7s 758us/step - loss: 0.2092 - mean_absolute_error: 0.1174 - val_loss: 0.2048 - val_mean_absolute_error: 0.1197\n",
      "Epoch 172/300\n",
      "8609/8609 [==============================] - 7s 770us/step - loss: 0.2148 - mean_absolute_error: 0.1254 - val_loss: 0.4222 - val_mean_absolute_error: 0.1460\n",
      "Epoch 173/300\n",
      "8609/8609 [==============================] - 7s 775us/step - loss: 0.2513 - mean_absolute_error: 0.1171 - val_loss: 0.2507 - val_mean_absolute_error: 0.1666\n",
      "Epoch 174/300\n",
      "8609/8609 [==============================] - 7s 761us/step - loss: 0.2025 - mean_absolute_error: 0.1233 - val_loss: 0.2441 - val_mean_absolute_error: 0.1265\n",
      "Epoch 175/300\n",
      "8609/8609 [==============================] - 7s 763us/step - loss: 0.2153 - mean_absolute_error: 0.1215 - val_loss: 0.2145 - val_mean_absolute_error: 0.1223\n",
      "Epoch 176/300\n",
      "8609/8609 [==============================] - 6s 751us/step - loss: 0.2964 - mean_absolute_error: 0.1207 - val_loss: 0.2377 - val_mean_absolute_error: 0.1453\n",
      "Epoch 177/300\n",
      "8609/8609 [==============================] - 7s 769us/step - loss: 0.5925 - mean_absolute_error: 0.1348 - val_loss: 0.1970 - val_mean_absolute_error: 0.1243\n",
      "Epoch 178/300\n",
      "8609/8609 [==============================] - 7s 766us/step - loss: 0.3881 - mean_absolute_error: 0.1270 - val_loss: 0.2538 - val_mean_absolute_error: 0.1340\n",
      "Epoch 179/300\n",
      "8609/8609 [==============================] - 7s 767us/step - loss: 0.2156 - mean_absolute_error: 0.1214 - val_loss: 0.2289 - val_mean_absolute_error: 0.1303\n",
      "Epoch 180/300\n",
      "8609/8609 [==============================] - 7s 771us/step - loss: 0.2873 - mean_absolute_error: 0.1288 - val_loss: 0.2191 - val_mean_absolute_error: 0.1265\n",
      "Epoch 181/300\n",
      "8609/8609 [==============================] - 7s 767us/step - loss: 0.2124 - mean_absolute_error: 0.1180 - val_loss: 0.2243 - val_mean_absolute_error: 0.1260\n",
      "Epoch 182/300\n",
      "8609/8609 [==============================] - 7s 773us/step - loss: 0.2088 - mean_absolute_error: 0.1117 - val_loss: 0.2111 - val_mean_absolute_error: 0.1242\n",
      "Epoch 183/300\n",
      "8609/8609 [==============================] - 7s 766us/step - loss: 0.2032 - mean_absolute_error: 0.1155 - val_loss: 0.2087 - val_mean_absolute_error: 0.1426\n",
      "Epoch 184/300\n",
      "8609/8609 [==============================] - 7s 783us/step - loss: 0.2098 - mean_absolute_error: 0.1172 - val_loss: 0.2167 - val_mean_absolute_error: 0.1350\n",
      "Epoch 185/300\n",
      "8609/8609 [==============================] - 7s 777us/step - loss: 0.2079 - mean_absolute_error: 0.1156 - val_loss: 0.2207 - val_mean_absolute_error: 0.1231\n",
      "Epoch 186/300\n",
      "8609/8609 [==============================] - 7s 776us/step - loss: 0.2044 - mean_absolute_error: 0.1178 - val_loss: 0.2325 - val_mean_absolute_error: 0.1604\n",
      "Epoch 187/300\n",
      "8609/8609 [==============================] - 7s 768us/step - loss: 0.2084 - mean_absolute_error: 0.1183 - val_loss: 0.2056 - val_mean_absolute_error: 0.1265\n",
      "Epoch 188/300\n",
      "8609/8609 [==============================] - 7s 761us/step - loss: 0.4892 - mean_absolute_error: 0.1388 - val_loss: 0.5913 - val_mean_absolute_error: 0.1609\n",
      "Epoch 189/300\n",
      "8609/8609 [==============================] - 6s 752us/step - loss: 0.6879 - mean_absolute_error: 0.1509 - val_loss: 0.2500 - val_mean_absolute_error: 0.1497\n",
      "Epoch 190/300\n",
      "8609/8609 [==============================] - 7s 765us/step - loss: 0.2091 - mean_absolute_error: 0.1182 - val_loss: 0.2225 - val_mean_absolute_error: 0.1313\n",
      "Epoch 191/300\n",
      "8609/8609 [==============================] - 7s 758us/step - loss: 0.4304 - mean_absolute_error: 0.1124 - val_loss: 0.2332 - val_mean_absolute_error: 0.1237\n",
      "Epoch 192/300\n",
      "8609/8609 [==============================] - 7s 765us/step - loss: 0.2012 - mean_absolute_error: 0.1114 - val_loss: 0.2743 - val_mean_absolute_error: 0.1453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/300\n",
      "8609/8609 [==============================] - 6s 750us/step - loss: 0.2003 - mean_absolute_error: 0.1113 - val_loss: 0.2500 - val_mean_absolute_error: 0.1378\n",
      "Epoch 194/300\n",
      "8609/8609 [==============================] - 7s 767us/step - loss: 0.2004 - mean_absolute_error: 0.1148 - val_loss: 0.2186 - val_mean_absolute_error: 0.1220\n",
      "Epoch 195/300\n",
      "8609/8609 [==============================] - 7s 764us/step - loss: 0.2815 - mean_absolute_error: 0.1243 - val_loss: 0.4166 - val_mean_absolute_error: 0.1341\n",
      "Epoch 196/300\n",
      "8609/8609 [==============================] - 7s 756us/step - loss: 0.2440 - mean_absolute_error: 0.1244 - val_loss: 0.2270 - val_mean_absolute_error: 0.1258\n",
      "Epoch 197/300\n",
      "8609/8609 [==============================] - 6s 754us/step - loss: 0.2102 - mean_absolute_error: 0.1151 - val_loss: 0.2150 - val_mean_absolute_error: 0.1270\n",
      "Epoch 198/300\n",
      "8609/8609 [==============================] - 6s 752us/step - loss: 0.2021 - mean_absolute_error: 0.1114 - val_loss: 0.2144 - val_mean_absolute_error: 0.1411\n",
      "Epoch 199/300\n",
      "8609/8609 [==============================] - 6s 737us/step - loss: 0.1993 - mean_absolute_error: 0.1109 - val_loss: 0.1970 - val_mean_absolute_error: 0.1271\n",
      "Epoch 200/300\n",
      "8609/8609 [==============================] - 6s 754us/step - loss: 0.2022 - mean_absolute_error: 0.1116 - val_loss: 0.2021 - val_mean_absolute_error: 0.1270\n",
      "Epoch 201/300\n",
      "8609/8609 [==============================] - 7s 758us/step - loss: 0.2030 - mean_absolute_error: 0.1108 - val_loss: 0.2057 - val_mean_absolute_error: 0.1331\n",
      "Epoch 202/300\n",
      "8609/8609 [==============================] - 6s 753us/step - loss: 0.2122 - mean_absolute_error: 0.1199 - val_loss: 0.2393 - val_mean_absolute_error: 0.1335\n",
      "Epoch 203/300\n",
      "8609/8609 [==============================] - 6s 746us/step - loss: 0.2024 - mean_absolute_error: 0.1141 - val_loss: 0.2282 - val_mean_absolute_error: 0.1337\n",
      "Epoch 204/300\n",
      "8609/8609 [==============================] - 6s 748us/step - loss: 0.1732 - mean_absolute_error: 0.1187 - val_loss: 0.8826 - val_mean_absolute_error: 0.1478\n",
      "Epoch 205/300\n",
      "8609/8609 [==============================] - 6s 742us/step - loss: 0.6547 - mean_absolute_error: 0.1283 - val_loss: 0.7890 - val_mean_absolute_error: 0.1422\n",
      "Epoch 206/300\n",
      "8609/8609 [==============================] - 6s 748us/step - loss: 0.4931 - mean_absolute_error: 0.1398 - val_loss: 0.2902 - val_mean_absolute_error: 0.1603\n",
      "Epoch 207/300\n",
      "8609/8609 [==============================] - 7s 762us/step - loss: 0.4741 - mean_absolute_error: 0.1571 - val_loss: 0.9088 - val_mean_absolute_error: 0.2099\n",
      "Epoch 208/300\n",
      "8609/8609 [==============================] - 6s 753us/step - loss: 0.5804 - mean_absolute_error: 0.1373 - val_loss: 0.3338 - val_mean_absolute_error: 0.2362\n",
      "Epoch 209/300\n",
      "8609/8609 [==============================] - 6s 739us/step - loss: 0.4468 - mean_absolute_error: 0.1331 - val_loss: 0.7260 - val_mean_absolute_error: 0.1408\n",
      "Epoch 210/300\n",
      "8609/8609 [==============================] - 6s 745us/step - loss: 0.5308 - mean_absolute_error: 0.1421 - val_loss: 0.2456 - val_mean_absolute_error: 0.1428\n",
      "Epoch 211/300\n",
      "8609/8609 [==============================] - 6s 746us/step - loss: 0.3065 - mean_absolute_error: 0.1333 - val_loss: 0.2494 - val_mean_absolute_error: 0.1435\n",
      "Epoch 212/300\n",
      "8609/8609 [==============================] - 6s 740us/step - loss: 0.2037 - mean_absolute_error: 0.1130 - val_loss: 0.2267 - val_mean_absolute_error: 0.1314\n",
      "Epoch 213/300\n",
      "8609/8609 [==============================] - 7s 769us/step - loss: 0.1993 - mean_absolute_error: 0.1116 - val_loss: 0.2221 - val_mean_absolute_error: 0.1303\n",
      "Epoch 214/300\n",
      "8609/8609 [==============================] - 7s 770us/step - loss: 0.2009 - mean_absolute_error: 0.1139 - val_loss: 0.2198 - val_mean_absolute_error: 0.1243\n",
      "Epoch 215/300\n",
      "8609/8609 [==============================] - 7s 769us/step - loss: 0.2118 - mean_absolute_error: 0.1204 - val_loss: 0.7413 - val_mean_absolute_error: 0.1532\n",
      "Epoch 216/300\n",
      "8609/8609 [==============================] - 7s 770us/step - loss: 0.7924 - mean_absolute_error: 0.1444 - val_loss: 0.2199 - val_mean_absolute_error: 0.1386\n",
      "Epoch 217/300\n",
      "8609/8609 [==============================] - 7s 768us/step - loss: 0.1996 - mean_absolute_error: 0.1119 - val_loss: 0.2397 - val_mean_absolute_error: 0.1277\n",
      "Epoch 218/300\n",
      "8609/8609 [==============================] - 7s 775us/step - loss: 0.2234 - mean_absolute_error: 0.1135 - val_loss: 0.2529 - val_mean_absolute_error: 0.1313\n",
      "Epoch 219/300\n",
      "8609/8609 [==============================] - 7s 770us/step - loss: 0.2049 - mean_absolute_error: 0.1164 - val_loss: 0.2310 - val_mean_absolute_error: 0.1344\n",
      "Epoch 220/300\n",
      "8609/8609 [==============================] - 7s 766us/step - loss: 0.2087 - mean_absolute_error: 0.1167 - val_loss: 0.2142 - val_mean_absolute_error: 0.1269\n",
      "Epoch 221/300\n",
      "8609/8609 [==============================] - 7s 759us/step - loss: 0.2069 - mean_absolute_error: 0.1161 - val_loss: 0.2272 - val_mean_absolute_error: 0.1679\n",
      "Epoch 222/300\n",
      "8609/8609 [==============================] - 7s 760us/step - loss: 0.2290 - mean_absolute_error: 0.1166 - val_loss: 0.2195 - val_mean_absolute_error: 0.1208\n",
      "Epoch 223/300\n",
      "8609/8609 [==============================] - 7s 762us/step - loss: 0.2005 - mean_absolute_error: 0.1129 - val_loss: 0.2184 - val_mean_absolute_error: 0.1315\n",
      "Epoch 224/300\n",
      "8609/8609 [==============================] - 7s 767us/step - loss: 0.2479 - mean_absolute_error: 0.1213 - val_loss: 0.1996 - val_mean_absolute_error: 0.1354\n",
      "Epoch 225/300\n",
      "8609/8609 [==============================] - 7s 766us/step - loss: 0.2393 - mean_absolute_error: 0.1171 - val_loss: 0.7258 - val_mean_absolute_error: 0.1415\n",
      "Epoch 226/300\n",
      "8609/8609 [==============================] - 7s 768us/step - loss: 0.3358 - mean_absolute_error: 0.1327 - val_loss: 0.2160 - val_mean_absolute_error: 0.1335\n",
      "Epoch 227/300\n",
      "8609/8609 [==============================] - 7s 767us/step - loss: 0.2331 - mean_absolute_error: 0.1231 - val_loss: 0.2362 - val_mean_absolute_error: 0.1261\n",
      "Epoch 228/300\n",
      "8609/8609 [==============================] - 7s 769us/step - loss: 0.1959 - mean_absolute_error: 0.1030 - val_loss: 0.2222 - val_mean_absolute_error: 0.1991\n",
      "Epoch 229/300\n",
      "8609/8609 [==============================] - 7s 771us/step - loss: 0.2024 - mean_absolute_error: 0.1112 - val_loss: 0.2188 - val_mean_absolute_error: 0.1340\n",
      "Epoch 230/300\n",
      "8609/8609 [==============================] - 7s 773us/step - loss: 0.1998 - mean_absolute_error: 0.1103 - val_loss: 0.2242 - val_mean_absolute_error: 0.1308\n",
      "Epoch 231/300\n",
      "8609/8609 [==============================] - 7s 770us/step - loss: 0.2014 - mean_absolute_error: 0.1142 - val_loss: 0.2184 - val_mean_absolute_error: 0.1315\n",
      "Epoch 232/300\n",
      "8609/8609 [==============================] - 7s 772us/step - loss: 0.2077 - mean_absolute_error: 0.1169 - val_loss: 0.2527 - val_mean_absolute_error: 0.1360\n",
      "Epoch 233/300\n",
      "8609/8609 [==============================] - 7s 771us/step - loss: 0.2010 - mean_absolute_error: 0.1145 - val_loss: 0.2118 - val_mean_absolute_error: 0.1254\n",
      "Epoch 234/300\n",
      "8609/8609 [==============================] - 7s 770us/step - loss: 0.1993 - mean_absolute_error: 0.1147 - val_loss: 0.2086 - val_mean_absolute_error: 0.1344\n",
      "Epoch 235/300\n",
      "8609/8609 [==============================] - 7s 770us/step - loss: 0.2019 - mean_absolute_error: 0.1135 - val_loss: 0.2044 - val_mean_absolute_error: 0.1218\n",
      "Epoch 236/300\n",
      "8609/8609 [==============================] - 7s 768us/step - loss: 0.1951 - mean_absolute_error: 0.1100 - val_loss: 0.6368 - val_mean_absolute_error: 0.1357\n",
      "Epoch 237/300\n",
      "8609/8609 [==============================] - 7s 770us/step - loss: 0.3553 - mean_absolute_error: 0.1291 - val_loss: 0.2407 - val_mean_absolute_error: 0.1254\n",
      "Epoch 238/300\n",
      "8609/8609 [==============================] - 7s 771us/step - loss: 0.2425 - mean_absolute_error: 0.1122 - val_loss: 0.2274 - val_mean_absolute_error: 0.1240\n",
      "Epoch 239/300\n",
      "8609/8609 [==============================] - 7s 769us/step - loss: 0.1971 - mean_absolute_error: 0.1088 - val_loss: 0.2232 - val_mean_absolute_error: 0.1241\n",
      "Epoch 240/300\n",
      "8609/8609 [==============================] - 7s 765us/step - loss: 0.4284 - mean_absolute_error: 0.1154 - val_loss: 0.2308 - val_mean_absolute_error: 0.1209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/300\n",
      "8609/8609 [==============================] - 7s 766us/step - loss: 0.2348 - mean_absolute_error: 0.1115 - val_loss: 0.2260 - val_mean_absolute_error: 0.1240\n",
      "Epoch 242/300\n",
      "8609/8609 [==============================] - 7s 760us/step - loss: 0.2875 - mean_absolute_error: 0.1175 - val_loss: 0.2258 - val_mean_absolute_error: 0.1315\n",
      "Epoch 243/300\n",
      "8609/8609 [==============================] - 7s 764us/step - loss: 0.1771 - mean_absolute_error: 0.1070 - val_loss: 0.2637 - val_mean_absolute_error: 0.1329\n",
      "Epoch 244/300\n",
      "8609/8609 [==============================] - 7s 769us/step - loss: 0.2006 - mean_absolute_error: 0.1124 - val_loss: 0.2503 - val_mean_absolute_error: 0.1270\n",
      "Epoch 245/300\n",
      "8609/8609 [==============================] - 7s 771us/step - loss: 0.2005 - mean_absolute_error: 0.1143 - val_loss: 0.2256 - val_mean_absolute_error: 0.1685\n",
      "Epoch 246/300\n",
      "8609/8609 [==============================] - 7s 770us/step - loss: 0.2047 - mean_absolute_error: 0.1124 - val_loss: 0.2305 - val_mean_absolute_error: 0.1307\n",
      "Epoch 247/300\n",
      "8609/8609 [==============================] - 7s 768us/step - loss: 0.2085 - mean_absolute_error: 0.1087 - val_loss: 0.2205 - val_mean_absolute_error: 0.1224\n",
      "Epoch 248/300\n",
      "8609/8609 [==============================] - 7s 769us/step - loss: 0.2574 - mean_absolute_error: 0.1079 - val_loss: 0.2293 - val_mean_absolute_error: 0.1487\n",
      "Epoch 249/300\n",
      "8609/8609 [==============================] - 7s 769us/step - loss: 0.1994 - mean_absolute_error: 0.1111 - val_loss: 0.2438 - val_mean_absolute_error: 0.1293\n",
      "Epoch 250/300\n",
      "8609/8609 [==============================] - 7s 770us/step - loss: 0.1959 - mean_absolute_error: 0.1107 - val_loss: 0.2150 - val_mean_absolute_error: 0.1192\n",
      "Epoch 251/300\n",
      "8609/8609 [==============================] - 7s 769us/step - loss: 0.1991 - mean_absolute_error: 0.1098 - val_loss: 0.2208 - val_mean_absolute_error: 0.2125\n",
      "Epoch 252/300\n",
      "8609/8609 [==============================] - 6s 742us/step - loss: 0.2105 - mean_absolute_error: 0.1092 - val_loss: 0.2285 - val_mean_absolute_error: 0.1446\n",
      "Epoch 253/300\n",
      "8609/8609 [==============================] - 7s 758us/step - loss: 0.1936 - mean_absolute_error: 0.1059 - val_loss: 0.3738 - val_mean_absolute_error: 0.1500\n",
      "Epoch 254/300\n",
      "8609/8609 [==============================] - 7s 763us/step - loss: 0.3766 - mean_absolute_error: 0.1215 - val_loss: 0.2098 - val_mean_absolute_error: 0.1269\n",
      "Epoch 255/300\n",
      "8609/8609 [==============================] - 7s 763us/step - loss: 0.1971 - mean_absolute_error: 0.1061 - val_loss: 0.1885 - val_mean_absolute_error: 0.1150\n",
      "Epoch 256/300\n",
      "8609/8609 [==============================] - 7s 761us/step - loss: 0.2175 - mean_absolute_error: 0.1054 - val_loss: 0.1980 - val_mean_absolute_error: 0.1254\n",
      "Epoch 257/300\n",
      "8609/8609 [==============================] - 7s 771us/step - loss: 0.2161 - mean_absolute_error: 0.1064 - val_loss: 0.2303 - val_mean_absolute_error: 0.1186\n",
      "Epoch 258/300\n",
      "8609/8609 [==============================] - 7s 772us/step - loss: 0.1899 - mean_absolute_error: 0.1041 - val_loss: 0.2226 - val_mean_absolute_error: 0.1226\n",
      "Epoch 259/300\n",
      "8609/8609 [==============================] - 7s 770us/step - loss: 0.2077 - mean_absolute_error: 0.1103 - val_loss: 0.2329 - val_mean_absolute_error: 0.1282\n",
      "Epoch 260/300\n",
      "8609/8609 [==============================] - 7s 770us/step - loss: 0.1946 - mean_absolute_error: 0.1098 - val_loss: 0.2037 - val_mean_absolute_error: 0.1565\n",
      "Epoch 261/300\n",
      "8609/8609 [==============================] - 7s 771us/step - loss: 0.2170 - mean_absolute_error: 0.1075 - val_loss: 0.2143 - val_mean_absolute_error: 0.1320\n",
      "Epoch 262/300\n",
      "8609/8609 [==============================] - 7s 770us/step - loss: 0.2015 - mean_absolute_error: 0.1137 - val_loss: 0.2296 - val_mean_absolute_error: 0.1253\n",
      "Epoch 263/300\n",
      "8609/8609 [==============================] - 7s 763us/step - loss: 0.1962 - mean_absolute_error: 0.1125 - val_loss: 0.2093 - val_mean_absolute_error: 0.1168\n",
      "Epoch 264/300\n",
      "8609/8609 [==============================] - 7s 764us/step - loss: 0.1968 - mean_absolute_error: 0.1095 - val_loss: 0.2175 - val_mean_absolute_error: 0.1327\n",
      "Epoch 265/300\n",
      "8609/8609 [==============================] - 7s 762us/step - loss: 0.1986 - mean_absolute_error: 0.1071 - val_loss: 0.2099 - val_mean_absolute_error: 0.1191\n",
      "Epoch 266/300\n",
      "8609/8609 [==============================] - 7s 764us/step - loss: 0.1917 - mean_absolute_error: 0.1068 - val_loss: 0.2132 - val_mean_absolute_error: 0.1561\n",
      "Epoch 267/300\n",
      "8609/8609 [==============================] - 7s 764us/step - loss: 0.2003 - mean_absolute_error: 0.1073 - val_loss: 0.2062 - val_mean_absolute_error: 0.1230\n",
      "Epoch 268/300\n",
      "8609/8609 [==============================] - 7s 767us/step - loss: 0.3984 - mean_absolute_error: 0.1236 - val_loss: 0.2413 - val_mean_absolute_error: 0.1265\n",
      "Epoch 269/300\n",
      "8609/8609 [==============================] - 7s 771us/step - loss: 0.2128 - mean_absolute_error: 0.1155 - val_loss: 0.2342 - val_mean_absolute_error: 0.1637\n",
      "Epoch 270/300\n",
      "8609/8609 [==============================] - 7s 771us/step - loss: 0.1894 - mean_absolute_error: 0.1027 - val_loss: 0.2077 - val_mean_absolute_error: 0.1149\n",
      "Epoch 271/300\n",
      "8609/8609 [==============================] - 7s 767us/step - loss: 0.1907 - mean_absolute_error: 0.1016 - val_loss: 0.2004 - val_mean_absolute_error: 0.1275\n",
      "Epoch 272/300\n",
      "8609/8609 [==============================] - 7s 766us/step - loss: 0.1946 - mean_absolute_error: 0.1075 - val_loss: 0.2136 - val_mean_absolute_error: 0.1197\n",
      "Epoch 273/300\n",
      "8609/8609 [==============================] - 7s 762us/step - loss: 0.1911 - mean_absolute_error: 0.1037 - val_loss: 0.2161 - val_mean_absolute_error: 0.1268\n",
      "Epoch 274/300\n",
      "8609/8609 [==============================] - 7s 760us/step - loss: 0.1935 - mean_absolute_error: 0.1081 - val_loss: 0.2108 - val_mean_absolute_error: 0.1216\n",
      "Epoch 275/300\n",
      "8609/8609 [==============================] - 7s 766us/step - loss: 0.1894 - mean_absolute_error: 0.1080 - val_loss: 0.2237 - val_mean_absolute_error: 0.1374\n",
      "Epoch 276/300\n",
      "8609/8609 [==============================] - 7s 767us/step - loss: 0.1898 - mean_absolute_error: 0.1041 - val_loss: 0.2483 - val_mean_absolute_error: 0.2204\n",
      "Epoch 277/300\n",
      "8609/8609 [==============================] - 7s 757us/step - loss: 0.1921 - mean_absolute_error: 0.1095 - val_loss: 0.2075 - val_mean_absolute_error: 0.1428\n",
      "Epoch 278/300\n",
      "8609/8609 [==============================] - 7s 757us/step - loss: 0.1965 - mean_absolute_error: 0.1141 - val_loss: 0.2071 - val_mean_absolute_error: 0.1231\n",
      "Epoch 279/300\n",
      "8609/8609 [==============================] - 7s 760us/step - loss: 0.1925 - mean_absolute_error: 0.1063 - val_loss: 0.2121 - val_mean_absolute_error: 0.1217\n",
      "Epoch 280/300\n",
      "8609/8609 [==============================] - 7s 777us/step - loss: 0.1946 - mean_absolute_error: 0.1108 - val_loss: 0.1999 - val_mean_absolute_error: 0.1278\n",
      "Epoch 281/300\n",
      "8609/8609 [==============================] - 7s 770us/step - loss: 0.1949 - mean_absolute_error: 0.1080 - val_loss: 0.2045 - val_mean_absolute_error: 0.1384\n",
      "Epoch 282/300\n",
      "8609/8609 [==============================] - 7s 765us/step - loss: 0.2368 - mean_absolute_error: 0.1060 - val_loss: 0.2256 - val_mean_absolute_error: 0.1227\n",
      "Epoch 283/300\n",
      "8609/8609 [==============================] - 7s 769us/step - loss: 0.1879 - mean_absolute_error: 0.1029 - val_loss: 0.2065 - val_mean_absolute_error: 0.1738\n",
      "Epoch 284/300\n",
      "8609/8609 [==============================] - 7s 763us/step - loss: 0.1872 - mean_absolute_error: 0.1047 - val_loss: 0.2157 - val_mean_absolute_error: 0.1182\n",
      "Epoch 285/300\n",
      "8609/8609 [==============================] - 7s 779us/step - loss: 0.1898 - mean_absolute_error: 0.1013 - val_loss: 0.2146 - val_mean_absolute_error: 0.1182\n",
      "Epoch 286/300\n",
      "8609/8609 [==============================] - 7s 775us/step - loss: 0.1908 - mean_absolute_error: 0.1047 - val_loss: 0.2094 - val_mean_absolute_error: 0.1280\n",
      "Epoch 287/300\n",
      "8609/8609 [==============================] - 7s 772us/step - loss: 0.1862 - mean_absolute_error: 0.1049 - val_loss: 0.2017 - val_mean_absolute_error: 0.1180\n",
      "Epoch 288/300\n",
      "8609/8609 [==============================] - 7s 770us/step - loss: 0.1943 - mean_absolute_error: 0.1087 - val_loss: 0.2150 - val_mean_absolute_error: 0.1188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 289/300\n",
      "8609/8609 [==============================] - 7s 772us/step - loss: 0.1895 - mean_absolute_error: 0.1077 - val_loss: 0.2036 - val_mean_absolute_error: 0.1360\n",
      "Epoch 290/300\n",
      "8609/8609 [==============================] - 7s 771us/step - loss: 0.2029 - mean_absolute_error: 0.1092 - val_loss: 0.2119 - val_mean_absolute_error: 0.1278\n",
      "Epoch 291/300\n",
      "8609/8609 [==============================] - 7s 770us/step - loss: 0.1912 - mean_absolute_error: 0.1022 - val_loss: 0.2264 - val_mean_absolute_error: 0.1196\n",
      "Epoch 292/300\n",
      "8609/8609 [==============================] - 7s 770us/step - loss: 0.1870 - mean_absolute_error: 0.1011 - val_loss: 0.2134 - val_mean_absolute_error: 0.1304\n",
      "Epoch 293/300\n",
      "8609/8609 [==============================] - 7s 771us/step - loss: 0.1881 - mean_absolute_error: 0.1031 - val_loss: 0.2063 - val_mean_absolute_error: 0.1589\n",
      "Epoch 294/300\n",
      "8609/8609 [==============================] - 7s 771us/step - loss: 0.1916 - mean_absolute_error: 0.1075 - val_loss: 0.2069 - val_mean_absolute_error: 0.1343\n",
      "Epoch 295/300\n",
      "8609/8609 [==============================] - 7s 770us/step - loss: 0.1856 - mean_absolute_error: 0.1020 - val_loss: 0.2132 - val_mean_absolute_error: 0.1280\n",
      "Epoch 296/300\n",
      "8609/8609 [==============================] - 7s 766us/step - loss: 0.1946 - mean_absolute_error: 0.1066 - val_loss: 0.2103 - val_mean_absolute_error: 0.1214\n",
      "Epoch 297/300\n",
      "8609/8609 [==============================] - 7s 766us/step - loss: 0.1942 - mean_absolute_error: 0.1026 - val_loss: 0.2161 - val_mean_absolute_error: 0.1246\n",
      "Epoch 298/300\n",
      "8609/8609 [==============================] - 7s 766us/step - loss: 0.1855 - mean_absolute_error: 0.0989 - val_loss: 0.2121 - val_mean_absolute_error: 0.1286\n",
      "Epoch 299/300\n",
      "8609/8609 [==============================] - 7s 766us/step - loss: 0.1842 - mean_absolute_error: 0.1006 - val_loss: 0.1968 - val_mean_absolute_error: 0.1237\n",
      "Epoch 300/300\n",
      "8609/8609 [==============================] - 7s 760us/step - loss: 0.1893 - mean_absolute_error: 0.1004 - val_loss: 0.2194 - val_mean_absolute_error: 0.1288\n",
      "Training time:1985.7694659233093\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mean_absolute_error'])\n",
    "\n",
    "curr_dt = set_curr_time()\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir='../logs/{0}'.format(curr_dt), histogram_freq=0, write_graph=True)\n",
    "\n",
    "tic = time.time()\n",
    "model.fit(\n",
    "    x_train_label,\n",
    "    y_train_label,\n",
    "    epochs = 300,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    validation_data = (x_valid_label, y_valid_label),\n",
    "    shuffle = True,\n",
    "#     steps_per_epoch = round(ROW_COUNT/BATCH_SIZE),\n",
    "    callbacks=[tb_callback])\n",
    "toc = time.time()\n",
    "\n",
    "print('Training time:{}'.format(toc-tic))\n",
    "\n",
    "# model.save('../models/{0}.h5'.format(curr_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y=model.predict(x_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             multiple                  18432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc multiple                  8192      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             multiple                  2098176   \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc multiple                  4096      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             multiple                  524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc multiple                  2048      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             multiple                  131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc multiple                  1024      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             multiple                  32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc multiple                  512       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             multiple                  8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc multiple                  256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             multiple                  65        \n",
      "=================================================================\n",
      "Total params: 2,830,081\n",
      "Trainable params: 2,822,017\n",
      "Non-trainable params: 8,064\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09051490514905149\n"
     ]
    }
   ],
   "source": [
    "# #accuracy max-min\n",
    "# ERROE_MERGE = 0.5 # in hours\n",
    "# SCALE = (ERROE_MERGE-0.01)/(910 - 0.01)\n",
    "# correct = 0\n",
    "# for i in range(0,len(y_test_label)):    \n",
    "#     if (((pred_y[i] - SCALE) < y_test_label[i][0]) and ((pred_y[i] + SCALE) > y_test_label[i][0])):\n",
    "#         correct += 1\n",
    "# print(correct/len(y_test_label))\n",
    "\n",
    "\n",
    "#accuracy Gussian(mean,std)\n",
    "ERROE_MERGE = 0.5 # in hours\n",
    "correct = 0\n",
    "for i in range(0,len(y_test_label)):\n",
    "    scale_pred = (pred_y[i]*68.72187295)+(+13.17546792)\n",
    "    scale_test = (y_test_label[i][0]*68.72187295)+(+13.17546792)\n",
    "\n",
    "    if (((scale_pred - ERROE_MERGE) < scale_test) and ((scale_pred + ERROE_MERGE) > scale_test)):\n",
    "        correct += 1\n",
    "print(correct/len(y_test_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML - OneHot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Priority</th>\n",
       "      <th>RaisedByID</th>\n",
       "      <th>AssignedToID</th>\n",
       "      <th>AuthorisedByID</th>\n",
       "      <th>HoursEstimate</th>\n",
       "      <th>HoursActual</th>\n",
       "      <th>StatusCode_AUTHORISE</th>\n",
       "      <th>StatusCode_CANCELLED</th>\n",
       "      <th>StatusCode_CHRONICLE</th>\n",
       "      <th>...</th>\n",
       "      <th>SubCategory_Project Management</th>\n",
       "      <th>SubCategory_Release</th>\n",
       "      <th>SubCategory_Research</th>\n",
       "      <th>SubCategory_Staff Management</th>\n",
       "      <th>SubCategory_Staff Recruitment</th>\n",
       "      <th>SubCategory_Support</th>\n",
       "      <th>SubCategory_Technical Specification</th>\n",
       "      <th>SubCategory_Testing</th>\n",
       "      <th>SubCategory_Third Party</th>\n",
       "      <th>SubCategory_Training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>42</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>58</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>42</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>46</td>\n",
       "      <td>13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Priority  RaisedByID  AssignedToID  AuthorisedByID  \\\n",
       "0           0         1          58            58             6.0   \n",
       "1           1         1          58            42             6.0   \n",
       "2           2         2           7            58             6.0   \n",
       "3           3         5          50            42             6.0   \n",
       "4           4        10          46            13             6.0   \n",
       "\n",
       "   HoursEstimate  HoursActual  StatusCode_AUTHORISE  StatusCode_CANCELLED  \\\n",
       "0           14.0         1.75                     0                     0   \n",
       "1            7.0         7.00                     0                     0   \n",
       "2            0.7         0.70                     0                     0   \n",
       "3            0.7         0.70                     0                     0   \n",
       "4            3.5         3.50                     0                     0   \n",
       "\n",
       "   StatusCode_CHRONICLE  ...  SubCategory_Project Management  \\\n",
       "0                     0  ...                               0   \n",
       "1                     0  ...                               0   \n",
       "2                     0  ...                               0   \n",
       "3                     0  ...                               0   \n",
       "4                     0  ...                               0   \n",
       "\n",
       "   SubCategory_Release  SubCategory_Research  SubCategory_Staff Management  \\\n",
       "0                    0                     0                             0   \n",
       "1                    0                     0                             0   \n",
       "2                    0                     0                             0   \n",
       "3                    0                     0                             0   \n",
       "4                    0                     0                             0   \n",
       "\n",
       "   SubCategory_Staff Recruitment  SubCategory_Support  \\\n",
       "0                              0                    0   \n",
       "1                              0                    0   \n",
       "2                              0                    0   \n",
       "3                              0                    0   \n",
       "4                              0                    0   \n",
       "\n",
       "   SubCategory_Technical Specification  SubCategory_Testing  \\\n",
       "0                                    0                    0   \n",
       "1                                    0                    0   \n",
       "2                                    0                    0   \n",
       "3                                    0                    0   \n",
       "4                                    0                    0   \n",
       "\n",
       "   SubCategory_Third Party  SubCategory_Training  \n",
       "0                        0                     0  \n",
       "1                        0                     0  \n",
       "2                        0                     0  \n",
       "3                        0                     0  \n",
       "4                        0                     0  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../SiP_dataset-master/SIP_OneHot.csv', encoding='cp1252') \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples: (8609, 61)\n",
      "Valid examples: (1845, 61)\n",
      "Test examples: (1845, 61)\n"
     ]
    }
   ],
   "source": [
    "# HoursEstimate_filter=HoursEstimate[HoursEstimate[\"HoursEstimate\"]<200]\n",
    "# HoursEstimate_filter=HoursEstimate_filter[HoursEstimate_filter[\"HoursActual\"]<800]\n",
    "\n",
    "x_train_label, xx_test_label, y_train_label, yy_test_label \\\n",
    "              = train_test_split(data.loc[:, data.columns != 'HoursActual'].values[:], data[Y_attributes].values[:], test_size=TRAIN_AND_VALIDATION_TEST_SPLIT)\n",
    "x_valid_label, x_test_label, y_valid_label, y_test_label \\\n",
    "              = train_test_split(xx_test_label, yy_test_label, test_size=VALID_AND_TEST_SPLIT)  \n",
    "\n",
    "print(\"Train examples: {}\".format(x_train_label.shape))\n",
    "print(\"Valid examples: {}\".format(x_valid_label.shape))\n",
    "print(\"Test examples: {}\".format(x_test_label.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               7936      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 172,801\n",
      "Trainable params: 172,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_model = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = x_train_label.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8609 samples, validate on 1845 samples\n",
      "Epoch 1/300\n",
      "8609/8609 [==============================] - 3s 336us/step - loss: 12.4008 - mean_absolute_error: 12.4008 - val_loss: 11.6302 - val_mean_absolute_error: 11.6302\n",
      "Epoch 2/300\n",
      "8609/8609 [==============================] - 2s 261us/step - loss: 12.3496 - mean_absolute_error: 12.3496 - val_loss: 11.6875 - val_mean_absolute_error: 11.6875\n",
      "Epoch 3/300\n",
      "8609/8609 [==============================] - 2s 261us/step - loss: 12.3439 - mean_absolute_error: 12.3439 - val_loss: 11.6336 - val_mean_absolute_error: 11.6336\n",
      "Epoch 4/300\n",
      "8609/8609 [==============================] - 2s 263us/step - loss: 12.3498 - mean_absolute_error: 12.3498 - val_loss: 11.6245 - val_mean_absolute_error: 11.6245\n",
      "Epoch 5/300\n",
      "8609/8609 [==============================] - 2s 261us/step - loss: 12.3487 - mean_absolute_error: 12.3487 - val_loss: 11.6286 - val_mean_absolute_error: 11.6286\n",
      "Epoch 6/300\n",
      "8609/8609 [==============================] - 2s 254us/step - loss: 12.3479 - mean_absolute_error: 12.3479 - val_loss: 11.6278 - val_mean_absolute_error: 11.6278\n",
      "Epoch 7/300\n",
      "8609/8609 [==============================] - 2s 255us/step - loss: 12.3463 - mean_absolute_error: 12.3463 - val_loss: 11.6569 - val_mean_absolute_error: 11.6569\n",
      "Epoch 8/300\n",
      "8609/8609 [==============================] - 2s 256us/step - loss: 12.3414 - mean_absolute_error: 12.3414 - val_loss: 11.6266 - val_mean_absolute_error: 11.6266\n",
      "Epoch 9/300\n",
      "8609/8609 [==============================] - 2s 257us/step - loss: 12.3441 - mean_absolute_error: 12.3441 - val_loss: 11.6241 - val_mean_absolute_error: 11.6241\n",
      "Epoch 10/300\n",
      "8609/8609 [==============================] - 2s 255us/step - loss: 12.3424 - mean_absolute_error: 12.3424 - val_loss: 11.6283 - val_mean_absolute_error: 11.6283\n",
      "Epoch 11/300\n",
      "8609/8609 [==============================] - 2s 252us/step - loss: 12.3431 - mean_absolute_error: 12.3431 - val_loss: 11.6238 - val_mean_absolute_error: 11.6238\n",
      "Epoch 12/300\n",
      "8609/8609 [==============================] - 2s 254us/step - loss: 12.3405 - mean_absolute_error: 12.3405 - val_loss: 11.6704 - val_mean_absolute_error: 11.6704\n",
      "Epoch 13/300\n",
      "8609/8609 [==============================] - 2s 247us/step - loss: 12.3419 - mean_absolute_error: 12.3419 - val_loss: 11.6230 - val_mean_absolute_error: 11.6230\n",
      "Epoch 14/300\n",
      "8609/8609 [==============================] - 2s 250us/step - loss: 12.3410 - mean_absolute_error: 12.3410 - val_loss: 11.6234 - val_mean_absolute_error: 11.6234\n",
      "Epoch 15/300\n",
      "8609/8609 [==============================] - 2s 246us/step - loss: 12.3430 - mean_absolute_error: 12.3430 - val_loss: 11.6258 - val_mean_absolute_error: 11.6258\n",
      "Epoch 16/300\n",
      "8609/8609 [==============================] - 2s 244us/step - loss: 12.3401 - mean_absolute_error: 12.3401 - val_loss: 11.6246 - val_mean_absolute_error: 11.6246\n",
      "Epoch 17/300\n",
      "8609/8609 [==============================] - 2s 244us/step - loss: 12.3421 - mean_absolute_error: 12.3421 - val_loss: 11.6214 - val_mean_absolute_error: 11.6214\n",
      "Epoch 18/300\n",
      "8609/8609 [==============================] - 2s 242us/step - loss: 12.3413 - mean_absolute_error: 12.3413 - val_loss: 11.6250 - val_mean_absolute_error: 11.6250\n",
      "Epoch 19/300\n",
      "8609/8609 [==============================] - 2s 240us/step - loss: 12.3412 - mean_absolute_error: 12.3412 - val_loss: 11.6551 - val_mean_absolute_error: 11.6551\n",
      "Epoch 20/300\n",
      "8609/8609 [==============================] - 2s 242us/step - loss: 12.3442 - mean_absolute_error: 12.3442 - val_loss: 11.6464 - val_mean_absolute_error: 11.6464\n",
      "Epoch 21/300\n",
      "8609/8609 [==============================] - 2s 242us/step - loss: 12.3383 - mean_absolute_error: 12.3383 - val_loss: 11.6916 - val_mean_absolute_error: 11.6916\n",
      "Epoch 22/300\n",
      "8609/8609 [==============================] - 2s 240us/step - loss: 12.3369 - mean_absolute_error: 12.3369 - val_loss: 11.6241 - val_mean_absolute_error: 11.6241\n",
      "Epoch 23/300\n",
      "8609/8609 [==============================] - 2s 240us/step - loss: 12.3409 - mean_absolute_error: 12.3409 - val_loss: 11.6215 - val_mean_absolute_error: 11.6215\n",
      "Epoch 24/300\n",
      "8609/8609 [==============================] - 2s 241us/step - loss: 12.3396 - mean_absolute_error: 12.3396 - val_loss: 11.6341 - val_mean_absolute_error: 11.6341\n",
      "Epoch 25/300\n",
      "8609/8609 [==============================] - 2s 243us/step - loss: 12.3394 - mean_absolute_error: 12.3394 - val_loss: 11.6256 - val_mean_absolute_error: 11.6256\n",
      "Epoch 26/300\n",
      "8609/8609 [==============================] - 2s 241us/step - loss: 12.3404 - mean_absolute_error: 12.3404 - val_loss: 11.6291 - val_mean_absolute_error: 11.6291\n",
      "Epoch 27/300\n",
      "8609/8609 [==============================] - 2s 240us/step - loss: 12.3389 - mean_absolute_error: 12.3389 - val_loss: 11.6347 - val_mean_absolute_error: 11.6347\n",
      "Epoch 28/300\n",
      "8609/8609 [==============================] - 2s 241us/step - loss: 12.3393 - mean_absolute_error: 12.3393 - val_loss: 11.6219 - val_mean_absolute_error: 11.6219\n",
      "Epoch 29/300\n",
      "8609/8609 [==============================] - 2s 242us/step - loss: 12.3402 - mean_absolute_error: 12.3402 - val_loss: 11.6252 - val_mean_absolute_error: 11.6252\n",
      "Epoch 30/300\n",
      "8609/8609 [==============================] - 2s 240us/step - loss: 12.3389 - mean_absolute_error: 12.3389 - val_loss: 11.6277 - val_mean_absolute_error: 11.6277\n",
      "Epoch 31/300\n",
      "8609/8609 [==============================] - 2s 240us/step - loss: 12.3368 - mean_absolute_error: 12.3368 - val_loss: 11.6226 - val_mean_absolute_error: 11.6226\n",
      "Epoch 32/300\n",
      "8609/8609 [==============================] - 2s 240us/step - loss: 12.3410 - mean_absolute_error: 12.3410 - val_loss: 11.6215 - val_mean_absolute_error: 11.6215\n",
      "Epoch 33/300\n",
      "8609/8609 [==============================] - 2s 240us/step - loss: 12.3380 - mean_absolute_error: 12.3380 - val_loss: 11.6364 - val_mean_absolute_error: 11.6364\n",
      "Epoch 34/300\n",
      "8609/8609 [==============================] - 2s 240us/step - loss: 12.3404 - mean_absolute_error: 12.3404 - val_loss: 11.6215 - val_mean_absolute_error: 11.6215\n",
      "Epoch 35/300\n",
      "8609/8609 [==============================] - 2s 239us/step - loss: 12.3394 - mean_absolute_error: 12.3394 - val_loss: 11.6585 - val_mean_absolute_error: 11.6585\n",
      "Epoch 36/300\n",
      "8609/8609 [==============================] - 2s 241us/step - loss: 12.3393 - mean_absolute_error: 12.3393 - val_loss: 11.6495 - val_mean_absolute_error: 11.6495\n",
      "Epoch 37/300\n",
      "8609/8609 [==============================] - 2s 244us/step - loss: 12.3401 - mean_absolute_error: 12.3401 - val_loss: 11.6619 - val_mean_absolute_error: 11.6619\n",
      "Epoch 38/300\n",
      "8609/8609 [==============================] - 2s 247us/step - loss: 12.3391 - mean_absolute_error: 12.3391 - val_loss: 11.6590 - val_mean_absolute_error: 11.6590\n",
      "Epoch 39/300\n",
      "8609/8609 [==============================] - 2s 245us/step - loss: 12.3395 - mean_absolute_error: 12.3395 - val_loss: 11.6214 - val_mean_absolute_error: 11.6214\n",
      "Epoch 40/300\n",
      "8609/8609 [==============================] - 2s 243us/step - loss: 12.3404 - mean_absolute_error: 12.3404 - val_loss: 11.6226 - val_mean_absolute_error: 11.6226\n",
      "Epoch 41/300\n",
      "8609/8609 [==============================] - 2s 242us/step - loss: 12.3366 - mean_absolute_error: 12.3366 - val_loss: 11.6231 - val_mean_absolute_error: 11.6231\n",
      "Epoch 42/300\n",
      "8609/8609 [==============================] - 2s 239us/step - loss: 12.3369 - mean_absolute_error: 12.3369 - val_loss: 11.6216 - val_mean_absolute_error: 11.6216\n",
      "Epoch 43/300\n",
      "8609/8609 [==============================] - 2s 239us/step - loss: 12.3381 - mean_absolute_error: 12.3381 - val_loss: 11.6425 - val_mean_absolute_error: 11.6425\n",
      "Epoch 44/300\n",
      "8609/8609 [==============================] - 2s 239us/step - loss: 12.3379 - mean_absolute_error: 12.3379 - val_loss: 11.6371 - val_mean_absolute_error: 11.6371\n",
      "Epoch 45/300\n",
      "8609/8609 [==============================] - 2s 240us/step - loss: 12.3370 - mean_absolute_error: 12.3370 - val_loss: 11.6217 - val_mean_absolute_error: 11.6217\n",
      "Epoch 46/300\n",
      "8609/8609 [==============================] - 2s 241us/step - loss: 12.3370 - mean_absolute_error: 12.3370 - val_loss: 11.6255 - val_mean_absolute_error: 11.6255\n",
      "Epoch 47/300\n",
      "8609/8609 [==============================] - 2s 241us/step - loss: 12.3379 - mean_absolute_error: 12.3379 - val_loss: 11.6218 - val_mean_absolute_error: 11.6218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/300\n",
      "8609/8609 [==============================] - 2s 241us/step - loss: 12.3361 - mean_absolute_error: 12.3361 - val_loss: 11.6437 - val_mean_absolute_error: 11.6437\n",
      "Epoch 49/300\n",
      "8609/8609 [==============================] - 2s 241us/step - loss: 12.3384 - mean_absolute_error: 12.3384 - val_loss: 11.6323 - val_mean_absolute_error: 11.6323\n",
      "Epoch 50/300\n",
      "8609/8609 [==============================] - 2s 241us/step - loss: 12.3380 - mean_absolute_error: 12.3380 - val_loss: 11.6354 - val_mean_absolute_error: 11.6354\n",
      "Epoch 51/300\n",
      "8609/8609 [==============================] - 2s 243us/step - loss: 12.3388 - mean_absolute_error: 12.3388 - val_loss: 11.6216 - val_mean_absolute_error: 11.6216\n",
      "Epoch 52/300\n",
      "8609/8609 [==============================] - 2s 242us/step - loss: 12.3375 - mean_absolute_error: 12.3375 - val_loss: 11.6227 - val_mean_absolute_error: 11.6227\n",
      "Epoch 53/300\n",
      "8609/8609 [==============================] - 2s 242us/step - loss: 12.3392 - mean_absolute_error: 12.3392 - val_loss: 11.6216 - val_mean_absolute_error: 11.6216\n",
      "Epoch 54/300\n",
      "8609/8609 [==============================] - 2s 246us/step - loss: 12.3387 - mean_absolute_error: 12.3387 - val_loss: 11.6220 - val_mean_absolute_error: 11.6220\n",
      "Epoch 55/300\n",
      "8609/8609 [==============================] - 2s 244us/step - loss: 12.3369 - mean_absolute_error: 12.3369 - val_loss: 11.6223 - val_mean_absolute_error: 11.6223\n",
      "Epoch 56/300\n",
      "8609/8609 [==============================] - 2s 246us/step - loss: 12.3368 - mean_absolute_error: 12.3368 - val_loss: 11.6220 - val_mean_absolute_error: 11.6220\n",
      "Epoch 57/300\n",
      "8609/8609 [==============================] - 2s 244us/step - loss: 12.3362 - mean_absolute_error: 12.3362 - val_loss: 11.6490 - val_mean_absolute_error: 11.6490\n",
      "Epoch 58/300\n",
      "8609/8609 [==============================] - 2s 243us/step - loss: 12.3383 - mean_absolute_error: 12.3383 - val_loss: 11.6368 - val_mean_absolute_error: 11.6368\n",
      "Epoch 59/300\n",
      "8609/8609 [==============================] - 2s 245us/step - loss: 12.3376 - mean_absolute_error: 12.3376 - val_loss: 11.6281 - val_mean_absolute_error: 11.6281\n",
      "Epoch 60/300\n",
      "8609/8609 [==============================] - 2s 246us/step - loss: 12.3348 - mean_absolute_error: 12.3348 - val_loss: 11.6371 - val_mean_absolute_error: 11.6371\n",
      "Epoch 61/300\n",
      "8609/8609 [==============================] - 2s 247us/step - loss: 12.3382 - mean_absolute_error: 12.3382 - val_loss: 11.6216 - val_mean_absolute_error: 11.6216\n",
      "Epoch 62/300\n",
      "8609/8609 [==============================] - 2s 247us/step - loss: 12.3358 - mean_absolute_error: 12.3358 - val_loss: 11.6337 - val_mean_absolute_error: 11.6337\n",
      "Epoch 63/300\n",
      "8609/8609 [==============================] - 2s 247us/step - loss: 12.3371 - mean_absolute_error: 12.3371 - val_loss: 11.6367 - val_mean_absolute_error: 11.6367\n",
      "Epoch 64/300\n",
      "8609/8609 [==============================] - 2s 245us/step - loss: 12.3366 - mean_absolute_error: 12.3366 - val_loss: 11.6536 - val_mean_absolute_error: 11.6536\n",
      "Epoch 65/300\n",
      " 670/8609 [=>............................] - ETA: 1s - loss: 12.1114 - mean_absolute_error: 12.1114"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b458c6706f95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_valid_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     callbacks=[tb_callback])\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mtoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/conda/envs/effort-est/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/work/conda/envs/effort-est/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/conda/envs/effort-est/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/conda/envs/effort-est/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/conda/envs/effort-est/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "curr_dt = set_curr_time()\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir='../logs/{0}'.format(curr_dt), histogram_freq=0, write_graph=True)\n",
    "\n",
    "tic = time.time()\n",
    "NN_model.fit(\n",
    "    x_train_label,\n",
    "    y_train_label,\n",
    "    epochs = 300,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    validation_data = (x_valid_label, y_valid_label),\n",
    "    shuffle = True,\n",
    "    callbacks=[tb_callback])\n",
    "toc = time.time()\n",
    "\n",
    "print('Training time:{}'.format(toc-tic))\n",
    "pred_y=model.predict(x_test_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor()\n",
    "model.fit(train_X,train_y)\n",
    "\n",
    "# Get the mean absolute error on the validation data\n",
    "predicted_prices = model.predict(val_X)\n",
    "MAE = mean_absolute_error(val_y , predicted_prices)\n",
    "print('Random forest validation MAE = ', MAE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
