{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "np.random.seed(7)\n",
    "\n",
    "# Constants\n",
    "TRAIN_AND_VALIDATION_TEST_SPLIT = 0.3\n",
    "VALID_AND_TEST_SPLIT            = 0.5\n",
    "BATCH_SIZE                      = 100\n",
    "\n",
    "# All posible relevent attributes\n",
    "relevent_attributes=[\"Priority\",\"RaisedByID\",\"AssignedToID\",\"StatusCode\",\\\n",
    "                     \"ProjectCode\",\"Category\",\"SubCategory\",\"HoursEstimate\",\"HoursActual\",\"AuthorisedByID\"]\n",
    "X_attributes=[\"Priority\",\"RaisedByID\",\"AssignedToID\",\"StatusCode\",\\\n",
    "                     \"ProjectCode\",\"Category\",\"SubCategory\",\"HoursEstimate\",\"AuthorisedByID\"]\n",
    "\n",
    "\n",
    "# The attributes that make the best accuarcy for the models\n",
    "relevent_attributes=[\"Priority\",\"AssignedToID\",\"StatusCode\",\\\n",
    "                     \"SubCategory\",\"HoursEstimate\",\"HoursActual\"]\n",
    "X_attributes=[\"Priority\",\"AssignedToID\",\"StatusCode\",\\\n",
    "                     \"SubCategory\",\"HoursEstimate\"]\n",
    "Y_attributes=[\"HoursActual\"]\n",
    "\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_curr_time():\n",
    "    dt = datetime.datetime.now()\n",
    "    curr_dt = '{0}{1}{2}_{3}_{4}'.format(datetime.datetime.now().year, datetime.datetime.now().month,\n",
    "                                       datetime.datetime.now().day, datetime.datetime.now().hour,\n",
    "                                      datetime.datetime.now().minute)\n",
    "    return curr_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Priority</th>\n",
       "      <th>RaisedByID</th>\n",
       "      <th>AssignedToID</th>\n",
       "      <th>AuthorisedByID</th>\n",
       "      <th>StatusCode</th>\n",
       "      <th>ProjectCode</th>\n",
       "      <th>Category</th>\n",
       "      <th>SubCategory</th>\n",
       "      <th>HoursEstimate</th>\n",
       "      <th>HoursActual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12299.000000</td>\n",
       "      <td>1.229900e+04</td>\n",
       "      <td>1.229900e+04</td>\n",
       "      <td>1.229900e+04</td>\n",
       "      <td>1.229900e+04</td>\n",
       "      <td>1.229900e+04</td>\n",
       "      <td>1.229900e+04</td>\n",
       "      <td>1.229900e+04</td>\n",
       "      <td>1.229900e+04</td>\n",
       "      <td>1.229900e+04</td>\n",
       "      <td>1.229900e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6149.000000</td>\n",
       "      <td>1.848717e-17</td>\n",
       "      <td>8.319225e-17</td>\n",
       "      <td>1.178557e-16</td>\n",
       "      <td>2.773075e-17</td>\n",
       "      <td>-3.697434e-17</td>\n",
       "      <td>-2.033588e-16</td>\n",
       "      <td>5.546150e-17</td>\n",
       "      <td>-1.201666e-16</td>\n",
       "      <td>4.621792e-17</td>\n",
       "      <td>-9.243584e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3550.559815</td>\n",
       "      <td>1.000041e+00</td>\n",
       "      <td>1.000041e+00</td>\n",
       "      <td>1.000041e+00</td>\n",
       "      <td>5.889010e-01</td>\n",
       "      <td>1.000041e+00</td>\n",
       "      <td>1.000041e+00</td>\n",
       "      <td>1.000041e+00</td>\n",
       "      <td>1.000041e+00</td>\n",
       "      <td>1.000041e+00</td>\n",
       "      <td>1.000041e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.839360e-01</td>\n",
       "      <td>-1.817993e+00</td>\n",
       "      <td>-1.928330e+00</td>\n",
       "      <td>-2.113198e+00</td>\n",
       "      <td>-2.854560e+00</td>\n",
       "      <td>-2.807881e+00</td>\n",
       "      <td>-6.513367e-01</td>\n",
       "      <td>-1.412901e+00</td>\n",
       "      <td>-3.516581e-01</td>\n",
       "      <td>-1.915761e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3074.500000</td>\n",
       "      <td>-6.839360e-01</td>\n",
       "      <td>-1.062657e+00</td>\n",
       "      <td>-8.126678e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-5.174389e-01</td>\n",
       "      <td>-6.273901e-01</td>\n",
       "      <td>-6.513367e-01</td>\n",
       "      <td>-9.425033e-01</td>\n",
       "      <td>-3.173315e-01</td>\n",
       "      <td>-1.771702e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6149.000000</td>\n",
       "      <td>-6.839360e-01</td>\n",
       "      <td>2.465911e-01</td>\n",
       "      <td>2.498672e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-5.174389e-01</td>\n",
       "      <td>-1.428367e-01</td>\n",
       "      <td>-6.513367e-01</td>\n",
       "      <td>-3.153067e-01</td>\n",
       "      <td>-2.479848e-01</td>\n",
       "      <td>-1.480674e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9223.500000</td>\n",
       "      <td>4.788687e-01</td>\n",
       "      <td>1.052282e+00</td>\n",
       "      <td>1.099895e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.040642e+00</td>\n",
       "      <td>5.839935e-01</td>\n",
       "      <td>6.721046e-01</td>\n",
       "      <td>6.254883e-01</td>\n",
       "      <td>-1.092915e-01</td>\n",
       "      <td>-6.803464e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12298.000000</td>\n",
       "      <td>4.548685e+00</td>\n",
       "      <td>1.505484e+00</td>\n",
       "      <td>1.471783e+00</td>\n",
       "      <td>6.569847e-01</td>\n",
       "      <td>2.598723e+00</td>\n",
       "      <td>1.795377e+00</td>\n",
       "      <td>1.995546e+00</td>\n",
       "      <td>2.193480e+00</td>\n",
       "      <td>3.120073e+01</td>\n",
       "      <td>3.604361e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0      Priority    RaisedByID  AssignedToID  AuthorisedByID  \\\n",
       "count  12299.000000  1.229900e+04  1.229900e+04  1.229900e+04    1.229900e+04   \n",
       "mean    6149.000000  1.848717e-17  8.319225e-17  1.178557e-16    2.773075e-17   \n",
       "std     3550.559815  1.000041e+00  1.000041e+00  1.000041e+00    5.889010e-01   \n",
       "min        0.000000 -6.839360e-01 -1.817993e+00 -1.928330e+00   -2.113198e+00   \n",
       "25%     3074.500000 -6.839360e-01 -1.062657e+00 -8.126678e-01    0.000000e+00   \n",
       "50%     6149.000000 -6.839360e-01  2.465911e-01  2.498672e-01    0.000000e+00   \n",
       "75%     9223.500000  4.788687e-01  1.052282e+00  1.099895e+00    0.000000e+00   \n",
       "max    12298.000000  4.548685e+00  1.505484e+00  1.471783e+00    6.569847e-01   \n",
       "\n",
       "         StatusCode   ProjectCode      Category   SubCategory  HoursEstimate  \\\n",
       "count  1.229900e+04  1.229900e+04  1.229900e+04  1.229900e+04   1.229900e+04   \n",
       "mean  -3.697434e-17 -2.033588e-16  5.546150e-17 -1.201666e-16   4.621792e-17   \n",
       "std    1.000041e+00  1.000041e+00  1.000041e+00  1.000041e+00   1.000041e+00   \n",
       "min   -2.854560e+00 -2.807881e+00 -6.513367e-01 -1.412901e+00  -3.516581e-01   \n",
       "25%   -5.174389e-01 -6.273901e-01 -6.513367e-01 -9.425033e-01  -3.173315e-01   \n",
       "50%   -5.174389e-01 -1.428367e-01 -6.513367e-01 -3.153067e-01  -2.479848e-01   \n",
       "75%    1.040642e+00  5.839935e-01  6.721046e-01  6.254883e-01  -1.092915e-01   \n",
       "max    2.598723e+00  1.795377e+00  1.995546e+00  2.193480e+00   3.120073e+01   \n",
       "\n",
       "        HoursActual  \n",
       "count  1.229900e+04  \n",
       "mean  -9.243584e-18  \n",
       "std    1.000041e+00  \n",
       "min   -1.915761e-01  \n",
       "25%   -1.771702e-01  \n",
       "50%   -1.480674e-01  \n",
       "75%   -6.803464e-02  \n",
       "max    3.604361e+01  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../SiP_dataset-master/SIP_CAT_GAUS.csv', encoding='cp1252') \n",
    "data.fillna(0, inplace = True)\n",
    "\n",
    "data.head()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Priority</th>\n",
       "      <th>AssignedToID</th>\n",
       "      <th>StatusCode</th>\n",
       "      <th>SubCategory</th>\n",
       "      <th>HoursEstimate</th>\n",
       "      <th>HoursActual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.683936</td>\n",
       "      <td>1.099895</td>\n",
       "      <td>1.040642</td>\n",
       "      <td>-0.315307</td>\n",
       "      <td>0.133422</td>\n",
       "      <td>-0.166257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.683936</td>\n",
       "      <td>0.249867</td>\n",
       "      <td>1.040642</td>\n",
       "      <td>-0.315307</td>\n",
       "      <td>-0.109292</td>\n",
       "      <td>-0.089862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.102534</td>\n",
       "      <td>1.099895</td>\n",
       "      <td>1.040642</td>\n",
       "      <td>-0.001708</td>\n",
       "      <td>-0.327734</td>\n",
       "      <td>-0.181536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.641673</td>\n",
       "      <td>0.249867</td>\n",
       "      <td>1.040642</td>\n",
       "      <td>-1.256102</td>\n",
       "      <td>-0.327734</td>\n",
       "      <td>-0.181536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.548685</td>\n",
       "      <td>-1.290809</td>\n",
       "      <td>1.040642</td>\n",
       "      <td>-1.256102</td>\n",
       "      <td>-0.230648</td>\n",
       "      <td>-0.140792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Priority  AssignedToID  StatusCode  SubCategory  HoursEstimate  HoursActual\n",
       "0 -0.683936      1.099895    1.040642    -0.315307       0.133422    -0.166257\n",
       "1 -0.683936      0.249867    1.040642    -0.315307      -0.109292    -0.089862\n",
       "2 -0.102534      1.099895    1.040642    -0.001708      -0.327734    -0.181536\n",
       "3  1.641673      0.249867    1.040642    -1.256102      -0.327734    -0.181536\n",
       "4  4.548685     -1.290809    1.040642    -1.256102      -0.230648    -0.140792"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[relevent_attributes]\n",
    "ROW_COUNT = max(data.count())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples: (8609, 5)\n",
      "Valid examples: (1845, 5)\n",
      "Test examples: (1845, 5)\n"
     ]
    }
   ],
   "source": [
    "# HoursEstimate_filter=HoursEstimate[HoursEstimate[\"HoursEstimate\"]<200]\n",
    "# HoursEstimate_filter=HoursEstimate_filter[HoursEstimate_filter[\"HoursActual\"]<800]\n",
    "\n",
    "x_train_label, xx_test_label, y_train_label, yy_test_label \\\n",
    "              = train_test_split(data[X_attributes].values[:], data[Y_attributes].values[:], test_size=TRAIN_AND_VALIDATION_TEST_SPLIT)\n",
    "x_valid_label, x_test_label, y_valid_label, y_test_label \\\n",
    "              = train_test_split(xx_test_label, yy_test_label, test_size=VALID_AND_TEST_SPLIT)  \n",
    "\n",
    "print(\"Train examples: {}\".format(x_train_label.shape))\n",
    "print(\"Valid examples: {}\".format(x_valid_label.shape))\n",
    "print(\"Test examples: {}\".format(x_test_label.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1845, 5)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Dense(2048, kernel_initializer='normal'), \n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.8),\n",
    "#     tf.keras.layers.Dense(1024,  kernel_initializer='normal'), \n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.8),\n",
    "#     tf.keras.layers.add(tf.keras.layers.Flatten(input_shape = (BATCH_SIZE,x_train_label.shape[1],1))),\n",
    "    tf.keras.layers.Dense(4096, kernel_initializer='normal',input_shape = (x_train_label.shape[1],)), \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.8),\n",
    "    tf.keras.layers.Dense(1024, kernel_initializer='normal'), \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.8),\n",
    "    tf.keras.layers.Dense(512, kernel_initializer='normal'), \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.8),\n",
    "    tf.keras.layers.Dense(64, kernel_initializer='normal'), \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.8),\n",
    "    tf.keras.layers.Dense(1)\n",
    "    \n",
    "    \n",
    "#     tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8609 samples, validate on 1845 samples\n",
      "Epoch 1/350\n",
      "8609/8609 [==============================] - 1s 160us/step - loss: 1.1845 - mean_squared_error: 1.1845 - val_loss: 1.0348 - val_mean_squared_error: 1.0348\n",
      "Epoch 2/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1762 - mean_squared_error: 1.1762 - val_loss: 1.0351 - val_mean_squared_error: 1.0351\n",
      "Epoch 3/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1926 - mean_squared_error: 1.1926 - val_loss: 1.0346 - val_mean_squared_error: 1.0346\n",
      "Epoch 4/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1737 - mean_squared_error: 1.1737 - val_loss: 1.0340 - val_mean_squared_error: 1.0340\n",
      "Epoch 5/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1572 - mean_squared_error: 1.1572 - val_loss: 1.0333 - val_mean_squared_error: 1.0333\n",
      "Epoch 6/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1548 - mean_squared_error: 1.1548 - val_loss: 1.0328 - val_mean_squared_error: 1.0328\n",
      "Epoch 7/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1633 - mean_squared_error: 1.1633 - val_loss: 1.0320 - val_mean_squared_error: 1.0320\n",
      "Epoch 8/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1493 - mean_squared_error: 1.1493 - val_loss: 1.0309 - val_mean_squared_error: 1.0309\n",
      "Epoch 9/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1569 - mean_squared_error: 1.1569 - val_loss: 1.0297 - val_mean_squared_error: 1.0297\n",
      "Epoch 10/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1450 - mean_squared_error: 1.1450 - val_loss: 1.0284 - val_mean_squared_error: 1.0284\n",
      "Epoch 11/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1405 - mean_squared_error: 1.1405 - val_loss: 1.0268 - val_mean_squared_error: 1.0268\n",
      "Epoch 12/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1405 - mean_squared_error: 1.1405 - val_loss: 1.0255 - val_mean_squared_error: 1.0255\n",
      "Epoch 13/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1265 - mean_squared_error: 1.1265 - val_loss: 1.0243 - val_mean_squared_error: 1.0243\n",
      "Epoch 14/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1318 - mean_squared_error: 1.1318 - val_loss: 1.0230 - val_mean_squared_error: 1.0230\n",
      "Epoch 15/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1401 - mean_squared_error: 1.1401 - val_loss: 1.0220 - val_mean_squared_error: 1.0220\n",
      "Epoch 16/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1346 - mean_squared_error: 1.1346 - val_loss: 1.0210 - val_mean_squared_error: 1.0210\n",
      "Epoch 17/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1099 - mean_squared_error: 1.1099 - val_loss: 1.0198 - val_mean_squared_error: 1.0198\n",
      "Epoch 18/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1483 - mean_squared_error: 1.1483 - val_loss: 1.0191 - val_mean_squared_error: 1.0191\n",
      "Epoch 19/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1217 - mean_squared_error: 1.1217 - val_loss: 1.0182 - val_mean_squared_error: 1.0182\n",
      "Epoch 20/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1093 - mean_squared_error: 1.1093 - val_loss: 1.0173 - val_mean_squared_error: 1.0173\n",
      "Epoch 21/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1161 - mean_squared_error: 1.1161 - val_loss: 1.0164 - val_mean_squared_error: 1.0164\n",
      "Epoch 22/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1245 - mean_squared_error: 1.1245 - val_loss: 1.0156 - val_mean_squared_error: 1.0156\n",
      "Epoch 23/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1117 - mean_squared_error: 1.1117 - val_loss: 1.0148 - val_mean_squared_error: 1.0148\n",
      "Epoch 24/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1145 - mean_squared_error: 1.1145 - val_loss: 1.0138 - val_mean_squared_error: 1.0138\n",
      "Epoch 25/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1273 - mean_squared_error: 1.1273 - val_loss: 1.0132 - val_mean_squared_error: 1.0132\n",
      "Epoch 26/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1200 - mean_squared_error: 1.1200 - val_loss: 1.0127 - val_mean_squared_error: 1.0127\n",
      "Epoch 27/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1118 - mean_squared_error: 1.1118 - val_loss: 1.0123 - val_mean_squared_error: 1.0123\n",
      "Epoch 28/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1336 - mean_squared_error: 1.1336 - val_loss: 1.0123 - val_mean_squared_error: 1.0123\n",
      "Epoch 29/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1074 - mean_squared_error: 1.1074 - val_loss: 1.0121 - val_mean_squared_error: 1.0121\n",
      "Epoch 30/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1050 - mean_squared_error: 1.1050 - val_loss: 1.0120 - val_mean_squared_error: 1.0120\n",
      "Epoch 31/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1159 - mean_squared_error: 1.1159 - val_loss: 1.0119 - val_mean_squared_error: 1.0119\n",
      "Epoch 32/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1152 - mean_squared_error: 1.1152 - val_loss: 1.0119 - val_mean_squared_error: 1.0119\n",
      "Epoch 33/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1158 - mean_squared_error: 1.1158 - val_loss: 1.0119 - val_mean_squared_error: 1.0119\n",
      "Epoch 34/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1006 - mean_squared_error: 1.1006 - val_loss: 1.0117 - val_mean_squared_error: 1.0117\n",
      "Epoch 35/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0970 - mean_squared_error: 1.0970 - val_loss: 1.0113 - val_mean_squared_error: 1.0113\n",
      "Epoch 36/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1034 - mean_squared_error: 1.1034 - val_loss: 1.0108 - val_mean_squared_error: 1.0108\n",
      "Epoch 37/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0958 - mean_squared_error: 1.0958 - val_loss: 1.0101 - val_mean_squared_error: 1.0101\n",
      "Epoch 38/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1097 - mean_squared_error: 1.1097 - val_loss: 1.0095 - val_mean_squared_error: 1.0095\n",
      "Epoch 39/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1047 - mean_squared_error: 1.1047 - val_loss: 1.0089 - val_mean_squared_error: 1.0089\n",
      "Epoch 40/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1047 - mean_squared_error: 1.1047 - val_loss: 1.0084 - val_mean_squared_error: 1.0084\n",
      "Epoch 41/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0980 - mean_squared_error: 1.0980 - val_loss: 1.0077 - val_mean_squared_error: 1.0077\n",
      "Epoch 42/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1121 - mean_squared_error: 1.1121 - val_loss: 1.0072 - val_mean_squared_error: 1.0072\n",
      "Epoch 43/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1149 - mean_squared_error: 1.1149 - val_loss: 1.0066 - val_mean_squared_error: 1.0066\n",
      "Epoch 44/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0993 - mean_squared_error: 1.0993 - val_loss: 1.0061 - val_mean_squared_error: 1.0061\n",
      "Epoch 45/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0922 - mean_squared_error: 1.0922 - val_loss: 1.0055 - val_mean_squared_error: 1.0055\n",
      "Epoch 46/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1046 - mean_squared_error: 1.1046 - val_loss: 1.0050 - val_mean_squared_error: 1.0050\n",
      "Epoch 47/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1049 - mean_squared_error: 1.1049 - val_loss: 1.0046 - val_mean_squared_error: 1.0046\n",
      "Epoch 48/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0989 - mean_squared_error: 1.0989 - val_loss: 1.0042 - val_mean_squared_error: 1.0042\n",
      "Epoch 49/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0918 - mean_squared_error: 1.0918 - val_loss: 1.0038 - val_mean_squared_error: 1.0038\n",
      "Epoch 50/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1051 - mean_squared_error: 1.1051 - val_loss: 1.0033 - val_mean_squared_error: 1.0033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0942 - mean_squared_error: 1.0942 - val_loss: 1.0029 - val_mean_squared_error: 1.0029\n",
      "Epoch 52/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0955 - mean_squared_error: 1.0955 - val_loss: 1.0025 - val_mean_squared_error: 1.0025\n",
      "Epoch 53/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0990 - mean_squared_error: 1.0990 - val_loss: 1.0020 - val_mean_squared_error: 1.0020\n",
      "Epoch 54/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0955 - mean_squared_error: 1.0955 - val_loss: 1.0014 - val_mean_squared_error: 1.0014\n",
      "Epoch 55/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1026 - mean_squared_error: 1.1026 - val_loss: 1.0011 - val_mean_squared_error: 1.0011\n",
      "Epoch 56/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1019 - mean_squared_error: 1.1019 - val_loss: 1.0007 - val_mean_squared_error: 1.0007\n",
      "Epoch 57/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0986 - mean_squared_error: 1.0986 - val_loss: 1.0003 - val_mean_squared_error: 1.0003\n",
      "Epoch 58/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1019 - mean_squared_error: 1.1019 - val_loss: 1.0001 - val_mean_squared_error: 1.0001\n",
      "Epoch 59/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1044 - mean_squared_error: 1.1044 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 60/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0936 - mean_squared_error: 1.0936 - val_loss: 0.9998 - val_mean_squared_error: 0.9998\n",
      "Epoch 61/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0913 - mean_squared_error: 1.0913 - val_loss: 0.9995 - val_mean_squared_error: 0.9995\n",
      "Epoch 62/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0850 - mean_squared_error: 1.0850 - val_loss: 0.9992 - val_mean_squared_error: 0.9992\n",
      "Epoch 63/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0801 - mean_squared_error: 1.0801 - val_loss: 0.9988 - val_mean_squared_error: 0.9988\n",
      "Epoch 64/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0953 - mean_squared_error: 1.0953 - val_loss: 0.9984 - val_mean_squared_error: 0.9984\n",
      "Epoch 65/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0981 - mean_squared_error: 1.0981 - val_loss: 0.9981 - val_mean_squared_error: 0.9981\n",
      "Epoch 66/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1023 - mean_squared_error: 1.1023 - val_loss: 0.9978 - val_mean_squared_error: 0.9978\n",
      "Epoch 67/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0824 - mean_squared_error: 1.0824 - val_loss: 0.9974 - val_mean_squared_error: 0.9974\n",
      "Epoch 68/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0864 - mean_squared_error: 1.0864 - val_loss: 0.9969 - val_mean_squared_error: 0.9969\n",
      "Epoch 69/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1236 - mean_squared_error: 1.1236 - val_loss: 0.9968 - val_mean_squared_error: 0.9968\n",
      "Epoch 70/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0857 - mean_squared_error: 1.0857 - val_loss: 0.9965 - val_mean_squared_error: 0.9965\n",
      "Epoch 71/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0844 - mean_squared_error: 1.0844 - val_loss: 0.9961 - val_mean_squared_error: 0.9961\n",
      "Epoch 72/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0841 - mean_squared_error: 1.0841 - val_loss: 0.9955 - val_mean_squared_error: 0.9955\n",
      "Epoch 73/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0952 - mean_squared_error: 1.0952 - val_loss: 0.9951 - val_mean_squared_error: 0.9951\n",
      "Epoch 74/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0886 - mean_squared_error: 1.0886 - val_loss: 0.9946 - val_mean_squared_error: 0.9946\n",
      "Epoch 75/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0853 - mean_squared_error: 1.0853 - val_loss: 0.9942 - val_mean_squared_error: 0.9942\n",
      "Epoch 76/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0963 - mean_squared_error: 1.0963 - val_loss: 0.9939 - val_mean_squared_error: 0.9939\n",
      "Epoch 77/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0827 - mean_squared_error: 1.0827 - val_loss: 0.9937 - val_mean_squared_error: 0.9937\n",
      "Epoch 78/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0787 - mean_squared_error: 1.0787 - val_loss: 0.9932 - val_mean_squared_error: 0.9932\n",
      "Epoch 79/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0926 - mean_squared_error: 1.0926 - val_loss: 0.9930 - val_mean_squared_error: 0.9930\n",
      "Epoch 80/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0827 - mean_squared_error: 1.0827 - val_loss: 0.9926 - val_mean_squared_error: 0.9926\n",
      "Epoch 81/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0850 - mean_squared_error: 1.0850 - val_loss: 0.9923 - val_mean_squared_error: 0.9923\n",
      "Epoch 82/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0783 - mean_squared_error: 1.0783 - val_loss: 0.9920 - val_mean_squared_error: 0.9920\n",
      "Epoch 83/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0811 - mean_squared_error: 1.0811 - val_loss: 0.9918 - val_mean_squared_error: 0.9918\n",
      "Epoch 84/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0788 - mean_squared_error: 1.0788 - val_loss: 0.9916 - val_mean_squared_error: 0.9916\n",
      "Epoch 85/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1215 - mean_squared_error: 1.1215 - val_loss: 0.9915 - val_mean_squared_error: 0.9915\n",
      "Epoch 86/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1190 - mean_squared_error: 1.1190 - val_loss: 0.9915 - val_mean_squared_error: 0.9915\n",
      "Epoch 87/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.1079 - mean_squared_error: 1.1079 - val_loss: 0.9916 - val_mean_squared_error: 0.9916\n",
      "Epoch 88/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0788 - mean_squared_error: 1.0788 - val_loss: 0.9915 - val_mean_squared_error: 0.9915\n",
      "Epoch 89/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0682 - mean_squared_error: 1.0682 - val_loss: 0.9913 - val_mean_squared_error: 0.9913\n",
      "Epoch 90/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0876 - mean_squared_error: 1.0876 - val_loss: 0.9911 - val_mean_squared_error: 0.9911\n",
      "Epoch 91/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0867 - mean_squared_error: 1.0867 - val_loss: 0.9909 - val_mean_squared_error: 0.9909\n",
      "Epoch 92/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0945 - mean_squared_error: 1.0945 - val_loss: 0.9908 - val_mean_squared_error: 0.9908\n",
      "Epoch 93/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0892 - mean_squared_error: 1.0892 - val_loss: 0.9907 - val_mean_squared_error: 0.9907\n",
      "Epoch 94/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0707 - mean_squared_error: 1.0707 - val_loss: 0.9905 - val_mean_squared_error: 0.9905\n",
      "Epoch 95/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0817 - mean_squared_error: 1.0817 - val_loss: 0.9903 - val_mean_squared_error: 0.9903\n",
      "Epoch 96/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0788 - mean_squared_error: 1.0788 - val_loss: 0.9901 - val_mean_squared_error: 0.9901\n",
      "Epoch 97/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0758 - mean_squared_error: 1.0758 - val_loss: 0.9898 - val_mean_squared_error: 0.9898\n",
      "Epoch 98/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0739 - mean_squared_error: 1.0739 - val_loss: 0.9894 - val_mean_squared_error: 0.9894\n",
      "Epoch 99/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0755 - mean_squared_error: 1.0755 - val_loss: 0.9890 - val_mean_squared_error: 0.9890\n",
      "Epoch 100/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0846 - mean_squared_error: 1.0846 - val_loss: 0.9883 - val_mean_squared_error: 0.9883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0768 - mean_squared_error: 1.0768 - val_loss: 0.9875 - val_mean_squared_error: 0.9875\n",
      "Epoch 102/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0729 - mean_squared_error: 1.0729 - val_loss: 0.9867 - val_mean_squared_error: 0.9867\n",
      "Epoch 103/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0801 - mean_squared_error: 1.0801 - val_loss: 0.9859 - val_mean_squared_error: 0.9859\n",
      "Epoch 104/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0772 - mean_squared_error: 1.0772 - val_loss: 0.9850 - val_mean_squared_error: 0.9850\n",
      "Epoch 105/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0817 - mean_squared_error: 1.0817 - val_loss: 0.9842 - val_mean_squared_error: 0.9842\n",
      "Epoch 106/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0851 - mean_squared_error: 1.0851 - val_loss: 0.9835 - val_mean_squared_error: 0.9835\n",
      "Epoch 107/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0683 - mean_squared_error: 1.0683 - val_loss: 0.9829 - val_mean_squared_error: 0.9829\n",
      "Epoch 108/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0703 - mean_squared_error: 1.0703 - val_loss: 0.9823 - val_mean_squared_error: 0.9823\n",
      "Epoch 109/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0678 - mean_squared_error: 1.0678 - val_loss: 0.9817 - val_mean_squared_error: 0.9817\n",
      "Epoch 110/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0746 - mean_squared_error: 1.0746 - val_loss: 0.9812 - val_mean_squared_error: 0.9812\n",
      "Epoch 111/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0660 - mean_squared_error: 1.0660 - val_loss: 0.9807 - val_mean_squared_error: 0.9807\n",
      "Epoch 112/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0827 - mean_squared_error: 1.0827 - val_loss: 0.9802 - val_mean_squared_error: 0.9802\n",
      "Epoch 113/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0925 - mean_squared_error: 1.0925 - val_loss: 0.9800 - val_mean_squared_error: 0.9800\n",
      "Epoch 114/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0770 - mean_squared_error: 1.0770 - val_loss: 0.9798 - val_mean_squared_error: 0.9798\n",
      "Epoch 115/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0795 - mean_squared_error: 1.0795 - val_loss: 0.9797 - val_mean_squared_error: 0.9797\n",
      "Epoch 116/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0781 - mean_squared_error: 1.0781 - val_loss: 0.9796 - val_mean_squared_error: 0.9796\n",
      "Epoch 117/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0786 - mean_squared_error: 1.0786 - val_loss: 0.9796 - val_mean_squared_error: 0.9796\n",
      "Epoch 118/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0664 - mean_squared_error: 1.0664 - val_loss: 0.9795 - val_mean_squared_error: 0.9795\n",
      "Epoch 119/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0702 - mean_squared_error: 1.0702 - val_loss: 0.9793 - val_mean_squared_error: 0.9793\n",
      "Epoch 120/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0774 - mean_squared_error: 1.0774 - val_loss: 0.9792 - val_mean_squared_error: 0.9792\n",
      "Epoch 121/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0750 - mean_squared_error: 1.0750 - val_loss: 0.9791 - val_mean_squared_error: 0.9791\n",
      "Epoch 122/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0727 - mean_squared_error: 1.0727 - val_loss: 0.9789 - val_mean_squared_error: 0.9789\n",
      "Epoch 123/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0634 - mean_squared_error: 1.0634 - val_loss: 0.9787 - val_mean_squared_error: 0.9787\n",
      "Epoch 124/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0676 - mean_squared_error: 1.0676 - val_loss: 0.9785 - val_mean_squared_error: 0.9785\n",
      "Epoch 125/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0765 - mean_squared_error: 1.0765 - val_loss: 0.9783 - val_mean_squared_error: 0.9783\n",
      "Epoch 126/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0620 - mean_squared_error: 1.0620 - val_loss: 0.9783 - val_mean_squared_error: 0.9783\n",
      "Epoch 127/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0791 - mean_squared_error: 1.0791 - val_loss: 0.9783 - val_mean_squared_error: 0.9783\n",
      "Epoch 128/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0743 - mean_squared_error: 1.0743 - val_loss: 0.9782 - val_mean_squared_error: 0.9782\n",
      "Epoch 129/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0883 - mean_squared_error: 1.0883 - val_loss: 0.9784 - val_mean_squared_error: 0.9784\n",
      "Epoch 130/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0624 - mean_squared_error: 1.0624 - val_loss: 0.9786 - val_mean_squared_error: 0.9786\n",
      "Epoch 131/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0775 - mean_squared_error: 1.0775 - val_loss: 0.9788 - val_mean_squared_error: 0.9788\n",
      "Epoch 132/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0798 - mean_squared_error: 1.0798 - val_loss: 0.9791 - val_mean_squared_error: 0.9791\n",
      "Epoch 133/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0757 - mean_squared_error: 1.0757 - val_loss: 0.9793 - val_mean_squared_error: 0.9793\n",
      "Epoch 134/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0621 - mean_squared_error: 1.0621 - val_loss: 0.9793 - val_mean_squared_error: 0.9793\n",
      "Epoch 135/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0668 - mean_squared_error: 1.0668 - val_loss: 0.9792 - val_mean_squared_error: 0.9792\n",
      "Epoch 136/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0613 - mean_squared_error: 1.0613 - val_loss: 0.9791 - val_mean_squared_error: 0.9791\n",
      "Epoch 137/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0588 - mean_squared_error: 1.0588 - val_loss: 0.9789 - val_mean_squared_error: 0.9789\n",
      "Epoch 138/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0780 - mean_squared_error: 1.0780 - val_loss: 0.9788 - val_mean_squared_error: 0.9788\n",
      "Epoch 139/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0649 - mean_squared_error: 1.0649 - val_loss: 0.9786 - val_mean_squared_error: 0.9786\n",
      "Epoch 140/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0612 - mean_squared_error: 1.0612 - val_loss: 0.9784 - val_mean_squared_error: 0.9784\n",
      "Epoch 141/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0582 - mean_squared_error: 1.0582 - val_loss: 0.9780 - val_mean_squared_error: 0.9780\n",
      "Epoch 142/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0647 - mean_squared_error: 1.0647 - val_loss: 0.9776 - val_mean_squared_error: 0.9776\n",
      "Epoch 143/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0650 - mean_squared_error: 1.0650 - val_loss: 0.9772 - val_mean_squared_error: 0.9772\n",
      "Epoch 144/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0550 - mean_squared_error: 1.0550 - val_loss: 0.9767 - val_mean_squared_error: 0.9767\n",
      "Epoch 145/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0639 - mean_squared_error: 1.0639 - val_loss: 0.9761 - val_mean_squared_error: 0.9761\n",
      "Epoch 146/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0640 - mean_squared_error: 1.0640 - val_loss: 0.9756 - val_mean_squared_error: 0.9756\n",
      "Epoch 147/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0592 - mean_squared_error: 1.0592 - val_loss: 0.9750 - val_mean_squared_error: 0.9750\n",
      "Epoch 148/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0535 - mean_squared_error: 1.0535 - val_loss: 0.9744 - val_mean_squared_error: 0.9744\n",
      "Epoch 149/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0783 - mean_squared_error: 1.0783 - val_loss: 0.9740 - val_mean_squared_error: 0.9740\n",
      "Epoch 150/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0555 - mean_squared_error: 1.0555 - val_loss: 0.9737 - val_mean_squared_error: 0.9737\n",
      "Epoch 151/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0673 - mean_squared_error: 1.0673 - val_loss: 0.9733 - val_mean_squared_error: 0.9733\n",
      "Epoch 152/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0515 - mean_squared_error: 1.0515 - val_loss: 0.9729 - val_mean_squared_error: 0.9729\n",
      "Epoch 153/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0652 - mean_squared_error: 1.0652 - val_loss: 0.9727 - val_mean_squared_error: 0.9727\n",
      "Epoch 154/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0602 - mean_squared_error: 1.0602 - val_loss: 0.9724 - val_mean_squared_error: 0.9724\n",
      "Epoch 155/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0642 - mean_squared_error: 1.0642 - val_loss: 0.9722 - val_mean_squared_error: 0.9722\n",
      "Epoch 156/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0743 - mean_squared_error: 1.0743 - val_loss: 0.9721 - val_mean_squared_error: 0.9721\n",
      "Epoch 157/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0885 - mean_squared_error: 1.0885 - val_loss: 0.9721 - val_mean_squared_error: 0.9721\n",
      "Epoch 158/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0713 - mean_squared_error: 1.0713 - val_loss: 0.9722 - val_mean_squared_error: 0.9722\n",
      "Epoch 159/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0444 - mean_squared_error: 1.0444 - val_loss: 0.9722 - val_mean_squared_error: 0.9722\n",
      "Epoch 160/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0563 - mean_squared_error: 1.0563 - val_loss: 0.9722 - val_mean_squared_error: 0.9722\n",
      "Epoch 161/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0563 - mean_squared_error: 1.0563 - val_loss: 0.9722 - val_mean_squared_error: 0.9722\n",
      "Epoch 162/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0650 - mean_squared_error: 1.0650 - val_loss: 0.9724 - val_mean_squared_error: 0.9724\n",
      "Epoch 163/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0813 - mean_squared_error: 1.0813 - val_loss: 0.9725 - val_mean_squared_error: 0.9725\n",
      "Epoch 164/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0551 - mean_squared_error: 1.0551 - val_loss: 0.9725 - val_mean_squared_error: 0.9725\n",
      "Epoch 165/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0650 - mean_squared_error: 1.0650 - val_loss: 0.9724 - val_mean_squared_error: 0.9724\n",
      "Epoch 166/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0521 - mean_squared_error: 1.0521 - val_loss: 0.9722 - val_mean_squared_error: 0.9722\n",
      "Epoch 167/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0609 - mean_squared_error: 1.0609 - val_loss: 0.9720 - val_mean_squared_error: 0.9720\n",
      "Epoch 168/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0478 - mean_squared_error: 1.0478 - val_loss: 0.9718 - val_mean_squared_error: 0.9718\n",
      "Epoch 169/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0595 - mean_squared_error: 1.0595 - val_loss: 0.9715 - val_mean_squared_error: 0.9715\n",
      "Epoch 170/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0585 - mean_squared_error: 1.0585 - val_loss: 0.9711 - val_mean_squared_error: 0.9711\n",
      "Epoch 171/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0472 - mean_squared_error: 1.0472 - val_loss: 0.9706 - val_mean_squared_error: 0.9706\n",
      "Epoch 172/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0481 - mean_squared_error: 1.0481 - val_loss: 0.9701 - val_mean_squared_error: 0.9701\n",
      "Epoch 173/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0588 - mean_squared_error: 1.0588 - val_loss: 0.9696 - val_mean_squared_error: 0.9696\n",
      "Epoch 174/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0762 - mean_squared_error: 1.0762 - val_loss: 0.9693 - val_mean_squared_error: 0.9693\n",
      "Epoch 175/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0606 - mean_squared_error: 1.0606 - val_loss: 0.9690 - val_mean_squared_error: 0.9690\n",
      "Epoch 176/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0500 - mean_squared_error: 1.0500 - val_loss: 0.9688 - val_mean_squared_error: 0.9688\n",
      "Epoch 177/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0580 - mean_squared_error: 1.0580 - val_loss: 0.9685 - val_mean_squared_error: 0.9685\n",
      "Epoch 178/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0565 - mean_squared_error: 1.0565 - val_loss: 0.9683 - val_mean_squared_error: 0.9683\n",
      "Epoch 179/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0425 - mean_squared_error: 1.0425 - val_loss: 0.9680 - val_mean_squared_error: 0.9680\n",
      "Epoch 180/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0623 - mean_squared_error: 1.0623 - val_loss: 0.9678 - val_mean_squared_error: 0.9678\n",
      "Epoch 181/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0686 - mean_squared_error: 1.0686 - val_loss: 0.9677 - val_mean_squared_error: 0.9677\n",
      "Epoch 182/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0614 - mean_squared_error: 1.0614 - val_loss: 0.9677 - val_mean_squared_error: 0.9677\n",
      "Epoch 183/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0697 - mean_squared_error: 1.0697 - val_loss: 0.9680 - val_mean_squared_error: 0.9680\n",
      "Epoch 184/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0683 - mean_squared_error: 1.0683 - val_loss: 0.9682 - val_mean_squared_error: 0.9682\n",
      "Epoch 185/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0630 - mean_squared_error: 1.0630 - val_loss: 0.9686 - val_mean_squared_error: 0.9686\n",
      "Epoch 186/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0534 - mean_squared_error: 1.0534 - val_loss: 0.9689 - val_mean_squared_error: 0.9689\n",
      "Epoch 187/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0498 - mean_squared_error: 1.0498 - val_loss: 0.9694 - val_mean_squared_error: 0.9694\n",
      "Epoch 188/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0390 - mean_squared_error: 1.0390 - val_loss: 0.9696 - val_mean_squared_error: 0.9696\n",
      "Epoch 189/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0655 - mean_squared_error: 1.0655 - val_loss: 0.9699 - val_mean_squared_error: 0.9699\n",
      "Epoch 190/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0498 - mean_squared_error: 1.0498 - val_loss: 0.9702 - val_mean_squared_error: 0.9702\n",
      "Epoch 191/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0644 - mean_squared_error: 1.0644 - val_loss: 0.9704 - val_mean_squared_error: 0.9704\n",
      "Epoch 192/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0426 - mean_squared_error: 1.0426 - val_loss: 0.9705 - val_mean_squared_error: 0.9705\n",
      "Epoch 193/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0688 - mean_squared_error: 1.0688 - val_loss: 0.9705 - val_mean_squared_error: 0.9705\n",
      "Epoch 194/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0427 - mean_squared_error: 1.0427 - val_loss: 0.9705 - val_mean_squared_error: 0.9705\n",
      "Epoch 195/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0475 - mean_squared_error: 1.0475 - val_loss: 0.9703 - val_mean_squared_error: 0.9703\n",
      "Epoch 196/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0697 - mean_squared_error: 1.0697 - val_loss: 0.9704 - val_mean_squared_error: 0.9704\n",
      "Epoch 197/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0531 - mean_squared_error: 1.0531 - val_loss: 0.9704 - val_mean_squared_error: 0.9704\n",
      "Epoch 198/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0610 - mean_squared_error: 1.0610 - val_loss: 0.9703 - val_mean_squared_error: 0.9703\n",
      "Epoch 199/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0562 - mean_squared_error: 1.0562 - val_loss: 0.9701 - val_mean_squared_error: 0.9701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0630 - mean_squared_error: 1.0630 - val_loss: 0.9698 - val_mean_squared_error: 0.9698\n",
      "Epoch 201/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0422 - mean_squared_error: 1.0422 - val_loss: 0.9694 - val_mean_squared_error: 0.9694\n",
      "Epoch 202/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0347 - mean_squared_error: 1.0347 - val_loss: 0.9687 - val_mean_squared_error: 0.9687\n",
      "Epoch 203/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0478 - mean_squared_error: 1.0478 - val_loss: 0.9680 - val_mean_squared_error: 0.9680\n",
      "Epoch 204/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0590 - mean_squared_error: 1.0590 - val_loss: 0.9674 - val_mean_squared_error: 0.9674\n",
      "Epoch 205/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0420 - mean_squared_error: 1.0420 - val_loss: 0.9667 - val_mean_squared_error: 0.9667\n",
      "Epoch 206/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0777 - mean_squared_error: 1.0777 - val_loss: 0.9663 - val_mean_squared_error: 0.9663\n",
      "Epoch 207/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0277 - mean_squared_error: 1.0277 - val_loss: 0.9660 - val_mean_squared_error: 0.9660\n",
      "Epoch 208/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0416 - mean_squared_error: 1.0416 - val_loss: 0.9657 - val_mean_squared_error: 0.9657\n",
      "Epoch 209/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0465 - mean_squared_error: 1.0465 - val_loss: 0.9655 - val_mean_squared_error: 0.9655\n",
      "Epoch 210/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0693 - mean_squared_error: 1.0693 - val_loss: 0.9655 - val_mean_squared_error: 0.9655\n",
      "Epoch 211/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0430 - mean_squared_error: 1.0430 - val_loss: 0.9656 - val_mean_squared_error: 0.9656\n",
      "Epoch 212/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0470 - mean_squared_error: 1.0470 - val_loss: 0.9656 - val_mean_squared_error: 0.9656\n",
      "Epoch 213/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0382 - mean_squared_error: 1.0382 - val_loss: 0.9657 - val_mean_squared_error: 0.9657\n",
      "Epoch 214/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0365 - mean_squared_error: 1.0365 - val_loss: 0.9656 - val_mean_squared_error: 0.9656\n",
      "Epoch 215/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0400 - mean_squared_error: 1.0400 - val_loss: 0.9655 - val_mean_squared_error: 0.9655\n",
      "Epoch 216/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0590 - mean_squared_error: 1.0590 - val_loss: 0.9654 - val_mean_squared_error: 0.9654\n",
      "Epoch 217/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0508 - mean_squared_error: 1.0508 - val_loss: 0.9654 - val_mean_squared_error: 0.9654\n",
      "Epoch 218/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0458 - mean_squared_error: 1.0458 - val_loss: 0.9654 - val_mean_squared_error: 0.9654\n",
      "Epoch 219/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0529 - mean_squared_error: 1.0529 - val_loss: 0.9653 - val_mean_squared_error: 0.9653\n",
      "Epoch 220/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0431 - mean_squared_error: 1.0431 - val_loss: 0.9652 - val_mean_squared_error: 0.9652\n",
      "Epoch 221/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0458 - mean_squared_error: 1.0458 - val_loss: 0.9651 - val_mean_squared_error: 0.9651\n",
      "Epoch 222/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0369 - mean_squared_error: 1.0369 - val_loss: 0.9650 - val_mean_squared_error: 0.9650\n",
      "Epoch 223/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0529 - mean_squared_error: 1.0529 - val_loss: 0.9650 - val_mean_squared_error: 0.9650\n",
      "Epoch 224/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0521 - mean_squared_error: 1.0521 - val_loss: 0.9653 - val_mean_squared_error: 0.9653\n",
      "Epoch 225/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0606 - mean_squared_error: 1.0606 - val_loss: 0.9656 - val_mean_squared_error: 0.9656\n",
      "Epoch 226/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0553 - mean_squared_error: 1.0553 - val_loss: 0.9659 - val_mean_squared_error: 0.9659\n",
      "Epoch 227/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0371 - mean_squared_error: 1.0371 - val_loss: 0.9661 - val_mean_squared_error: 0.9661\n",
      "Epoch 228/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0358 - mean_squared_error: 1.0358 - val_loss: 0.9662 - val_mean_squared_error: 0.9662\n",
      "Epoch 229/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0396 - mean_squared_error: 1.0396 - val_loss: 0.9663 - val_mean_squared_error: 0.9663\n",
      "Epoch 230/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0404 - mean_squared_error: 1.0404 - val_loss: 0.9662 - val_mean_squared_error: 0.9662\n",
      "Epoch 231/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0537 - mean_squared_error: 1.0537 - val_loss: 0.9661 - val_mean_squared_error: 0.9661\n",
      "Epoch 232/350\n",
      "8609/8609 [==============================] - 0s 7us/step - loss: 1.0166 - mean_squared_error: 1.0166 - val_loss: 0.9658 - val_mean_squared_error: 0.9658\n",
      "Epoch 233/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0467 - mean_squared_error: 1.0467 - val_loss: 0.9658 - val_mean_squared_error: 0.9658\n",
      "Epoch 234/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0570 - mean_squared_error: 1.0570 - val_loss: 0.9659 - val_mean_squared_error: 0.9659\n",
      "Epoch 235/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0494 - mean_squared_error: 1.0494 - val_loss: 0.9659 - val_mean_squared_error: 0.9659\n",
      "Epoch 236/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0373 - mean_squared_error: 1.0373 - val_loss: 0.9659 - val_mean_squared_error: 0.9659\n",
      "Epoch 237/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0513 - mean_squared_error: 1.0513 - val_loss: 0.9658 - val_mean_squared_error: 0.9658\n",
      "Epoch 238/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0589 - mean_squared_error: 1.0589 - val_loss: 0.9657 - val_mean_squared_error: 0.9657\n",
      "Epoch 239/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0301 - mean_squared_error: 1.0301 - val_loss: 0.9657 - val_mean_squared_error: 0.9657\n",
      "Epoch 240/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0604 - mean_squared_error: 1.0604 - val_loss: 0.9655 - val_mean_squared_error: 0.9655\n",
      "Epoch 241/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0085 - mean_squared_error: 1.0085 - val_loss: 0.9651 - val_mean_squared_error: 0.9651\n",
      "Epoch 242/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0537 - mean_squared_error: 1.0537 - val_loss: 0.9648 - val_mean_squared_error: 0.9648\n",
      "Epoch 243/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0427 - mean_squared_error: 1.0427 - val_loss: 0.9644 - val_mean_squared_error: 0.9644\n",
      "Epoch 244/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0520 - mean_squared_error: 1.0520 - val_loss: 0.9638 - val_mean_squared_error: 0.9638\n",
      "Epoch 245/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0651 - mean_squared_error: 1.0651 - val_loss: 0.9636 - val_mean_squared_error: 0.9636\n",
      "Epoch 246/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0574 - mean_squared_error: 1.0574 - val_loss: 0.9633 - val_mean_squared_error: 0.9633\n",
      "Epoch 247/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0412 - mean_squared_error: 1.0412 - val_loss: 0.9631 - val_mean_squared_error: 0.9631\n",
      "Epoch 248/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0376 - mean_squared_error: 1.0376 - val_loss: 0.9629 - val_mean_squared_error: 0.9629\n",
      "Epoch 249/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0615 - mean_squared_error: 1.0615 - val_loss: 0.9627 - val_mean_squared_error: 0.9627\n",
      "Epoch 250/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0569 - mean_squared_error: 1.0569 - val_loss: 0.9623 - val_mean_squared_error: 0.9623\n",
      "Epoch 251/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0246 - mean_squared_error: 1.0246 - val_loss: 0.9620 - val_mean_squared_error: 0.9620\n",
      "Epoch 252/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0432 - mean_squared_error: 1.0432 - val_loss: 0.9617 - val_mean_squared_error: 0.9617\n",
      "Epoch 253/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0396 - mean_squared_error: 1.0396 - val_loss: 0.9615 - val_mean_squared_error: 0.9615\n",
      "Epoch 254/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0629 - mean_squared_error: 1.0629 - val_loss: 0.9615 - val_mean_squared_error: 0.9615\n",
      "Epoch 255/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0280 - mean_squared_error: 1.0280 - val_loss: 0.9615 - val_mean_squared_error: 0.9615\n",
      "Epoch 256/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0641 - mean_squared_error: 1.0641 - val_loss: 0.9614 - val_mean_squared_error: 0.9614\n",
      "Epoch 257/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0554 - mean_squared_error: 1.0554 - val_loss: 0.9611 - val_mean_squared_error: 0.9611\n",
      "Epoch 258/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0578 - mean_squared_error: 1.0578 - val_loss: 0.9611 - val_mean_squared_error: 0.9611\n",
      "Epoch 259/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0316 - mean_squared_error: 1.0316 - val_loss: 0.9612 - val_mean_squared_error: 0.9612\n",
      "Epoch 260/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0570 - mean_squared_error: 1.0570 - val_loss: 0.9613 - val_mean_squared_error: 0.9613\n",
      "Epoch 261/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0475 - mean_squared_error: 1.0475 - val_loss: 0.9614 - val_mean_squared_error: 0.9614\n",
      "Epoch 262/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0364 - mean_squared_error: 1.0364 - val_loss: 0.9614 - val_mean_squared_error: 0.9614\n",
      "Epoch 263/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0386 - mean_squared_error: 1.0386 - val_loss: 0.9618 - val_mean_squared_error: 0.9618\n",
      "Epoch 264/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0123 - mean_squared_error: 1.0123 - val_loss: 0.9620 - val_mean_squared_error: 0.9620\n",
      "Epoch 265/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0532 - mean_squared_error: 1.0532 - val_loss: 0.9623 - val_mean_squared_error: 0.9623\n",
      "Epoch 266/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0647 - mean_squared_error: 1.0647 - val_loss: 0.9627 - val_mean_squared_error: 0.9627\n",
      "Epoch 267/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0419 - mean_squared_error: 1.0419 - val_loss: 0.9629 - val_mean_squared_error: 0.9629\n",
      "Epoch 268/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0482 - mean_squared_error: 1.0482 - val_loss: 0.9630 - val_mean_squared_error: 0.9630\n",
      "Epoch 269/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0557 - mean_squared_error: 1.0557 - val_loss: 0.9629 - val_mean_squared_error: 0.9629\n",
      "Epoch 270/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0696 - mean_squared_error: 1.0696 - val_loss: 0.9629 - val_mean_squared_error: 0.9629\n",
      "Epoch 271/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0204 - mean_squared_error: 1.0204 - val_loss: 0.9630 - val_mean_squared_error: 0.9630\n",
      "Epoch 272/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0507 - mean_squared_error: 1.0507 - val_loss: 0.9629 - val_mean_squared_error: 0.9629\n",
      "Epoch 273/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0400 - mean_squared_error: 1.0400 - val_loss: 0.9628 - val_mean_squared_error: 0.9628\n",
      "Epoch 274/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0491 - mean_squared_error: 1.0491 - val_loss: 0.9627 - val_mean_squared_error: 0.9627\n",
      "Epoch 275/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0320 - mean_squared_error: 1.0320 - val_loss: 0.9626 - val_mean_squared_error: 0.9626\n",
      "Epoch 276/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0074 - mean_squared_error: 1.0074 - val_loss: 0.9625 - val_mean_squared_error: 0.9625\n",
      "Epoch 277/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0602 - mean_squared_error: 1.0602 - val_loss: 0.9624 - val_mean_squared_error: 0.9624\n",
      "Epoch 278/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0328 - mean_squared_error: 1.0328 - val_loss: 0.9623 - val_mean_squared_error: 0.9623\n",
      "Epoch 279/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0351 - mean_squared_error: 1.0351 - val_loss: 0.9623 - val_mean_squared_error: 0.9623\n",
      "Epoch 280/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0346 - mean_squared_error: 1.0346 - val_loss: 0.9621 - val_mean_squared_error: 0.9621\n",
      "Epoch 281/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0609 - mean_squared_error: 1.0609 - val_loss: 0.9622 - val_mean_squared_error: 0.9622\n",
      "Epoch 282/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0593 - mean_squared_error: 1.0593 - val_loss: 0.9625 - val_mean_squared_error: 0.9625\n",
      "Epoch 283/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0457 - mean_squared_error: 1.0457 - val_loss: 0.9626 - val_mean_squared_error: 0.9626\n",
      "Epoch 284/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0116 - mean_squared_error: 1.0116 - val_loss: 0.9629 - val_mean_squared_error: 0.9629\n",
      "Epoch 285/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0232 - mean_squared_error: 1.0232 - val_loss: 0.9632 - val_mean_squared_error: 0.9632\n",
      "Epoch 286/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0663 - mean_squared_error: 1.0663 - val_loss: 0.9636 - val_mean_squared_error: 0.9636\n",
      "Epoch 287/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0384 - mean_squared_error: 1.0384 - val_loss: 0.9636 - val_mean_squared_error: 0.9636\n",
      "Epoch 288/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0554 - mean_squared_error: 1.0554 - val_loss: 0.9636 - val_mean_squared_error: 0.9636\n",
      "Epoch 289/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 0.9832 - mean_squared_error: 0.9832 - val_loss: 0.9636 - val_mean_squared_error: 0.9636\n",
      "Epoch 290/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0478 - mean_squared_error: 1.0478 - val_loss: 0.9633 - val_mean_squared_error: 0.9633\n",
      "Epoch 291/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0637 - mean_squared_error: 1.0637 - val_loss: 0.9633 - val_mean_squared_error: 0.9633\n",
      "Epoch 292/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0201 - mean_squared_error: 1.0201 - val_loss: 0.9631 - val_mean_squared_error: 0.9631\n",
      "Epoch 293/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0169 - mean_squared_error: 1.0169 - val_loss: 0.9628 - val_mean_squared_error: 0.9628\n",
      "Epoch 294/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0364 - mean_squared_error: 1.0364 - val_loss: 0.9625 - val_mean_squared_error: 0.9625\n",
      "Epoch 295/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0250 - mean_squared_error: 1.0250 - val_loss: 0.9620 - val_mean_squared_error: 0.9620\n",
      "Epoch 296/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 0.9979 - mean_squared_error: 0.9979 - val_loss: 0.9613 - val_mean_squared_error: 0.9613\n",
      "Epoch 297/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0155 - mean_squared_error: 1.0155 - val_loss: 0.9604 - val_mean_squared_error: 0.9604\n",
      "Epoch 298/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0804 - mean_squared_error: 1.0804 - val_loss: 0.9598 - val_mean_squared_error: 0.9598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0611 - mean_squared_error: 1.0611 - val_loss: 0.9596 - val_mean_squared_error: 0.9596\n",
      "Epoch 300/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0185 - mean_squared_error: 1.0185 - val_loss: 0.9595 - val_mean_squared_error: 0.9595\n",
      "Epoch 301/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0349 - mean_squared_error: 1.0349 - val_loss: 0.9598 - val_mean_squared_error: 0.9598\n",
      "Epoch 302/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0078 - mean_squared_error: 1.0078 - val_loss: 0.9601 - val_mean_squared_error: 0.9601\n",
      "Epoch 303/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0519 - mean_squared_error: 1.0519 - val_loss: 0.9604 - val_mean_squared_error: 0.9604\n",
      "Epoch 304/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0338 - mean_squared_error: 1.0338 - val_loss: 0.9609 - val_mean_squared_error: 0.9609\n",
      "Epoch 305/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0124 - mean_squared_error: 1.0124 - val_loss: 0.9611 - val_mean_squared_error: 0.9611\n",
      "Epoch 306/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0148 - mean_squared_error: 1.0148 - val_loss: 0.9614 - val_mean_squared_error: 0.9614\n",
      "Epoch 307/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0076 - mean_squared_error: 1.0076 - val_loss: 0.9618 - val_mean_squared_error: 0.9618\n",
      "Epoch 308/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0280 - mean_squared_error: 1.0280 - val_loss: 0.9622 - val_mean_squared_error: 0.9622\n",
      "Epoch 309/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0285 - mean_squared_error: 1.0285 - val_loss: 0.9624 - val_mean_squared_error: 0.9624\n",
      "Epoch 310/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0480 - mean_squared_error: 1.0480 - val_loss: 0.9626 - val_mean_squared_error: 0.9626\n",
      "Epoch 311/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 0.9805 - mean_squared_error: 0.9805 - val_loss: 0.9626 - val_mean_squared_error: 0.9626\n",
      "Epoch 312/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0100 - mean_squared_error: 1.0100 - val_loss: 0.9625 - val_mean_squared_error: 0.9625\n",
      "Epoch 313/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0408 - mean_squared_error: 1.0408 - val_loss: 0.9626 - val_mean_squared_error: 0.9626\n",
      "Epoch 314/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 0.9956 - mean_squared_error: 0.9956 - val_loss: 0.9627 - val_mean_squared_error: 0.9627\n",
      "Epoch 315/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0243 - mean_squared_error: 1.0243 - val_loss: 0.9626 - val_mean_squared_error: 0.9626\n",
      "Epoch 316/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0055 - mean_squared_error: 1.0055 - val_loss: 0.9627 - val_mean_squared_error: 0.9627\n",
      "Epoch 317/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0061 - mean_squared_error: 1.0061 - val_loss: 0.9628 - val_mean_squared_error: 0.9628\n",
      "Epoch 318/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0329 - mean_squared_error: 1.0329 - val_loss: 0.9630 - val_mean_squared_error: 0.9630\n",
      "Epoch 319/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 0.9975 - mean_squared_error: 0.9975 - val_loss: 0.9627 - val_mean_squared_error: 0.9627\n",
      "Epoch 320/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0653 - mean_squared_error: 1.0653 - val_loss: 0.9625 - val_mean_squared_error: 0.9625\n",
      "Epoch 321/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0068 - mean_squared_error: 1.0068 - val_loss: 0.9622 - val_mean_squared_error: 0.9622\n",
      "Epoch 322/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0326 - mean_squared_error: 1.0326 - val_loss: 0.9620 - val_mean_squared_error: 0.9620\n",
      "Epoch 323/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0117 - mean_squared_error: 1.0117 - val_loss: 0.9617 - val_mean_squared_error: 0.9617\n",
      "Epoch 324/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0231 - mean_squared_error: 1.0231 - val_loss: 0.9609 - val_mean_squared_error: 0.9609\n",
      "Epoch 325/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0457 - mean_squared_error: 1.0457 - val_loss: 0.9607 - val_mean_squared_error: 0.9607\n",
      "Epoch 326/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0510 - mean_squared_error: 1.0510 - val_loss: 0.9615 - val_mean_squared_error: 0.9615\n",
      "Epoch 327/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0512 - mean_squared_error: 1.0512 - val_loss: 0.9625 - val_mean_squared_error: 0.9625\n",
      "Epoch 328/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0534 - mean_squared_error: 1.0534 - val_loss: 0.9634 - val_mean_squared_error: 0.9634\n",
      "Epoch 329/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0183 - mean_squared_error: 1.0183 - val_loss: 0.9639 - val_mean_squared_error: 0.9639\n",
      "Epoch 330/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 0.9829 - mean_squared_error: 0.9829 - val_loss: 0.9641 - val_mean_squared_error: 0.9641\n",
      "Epoch 331/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0446 - mean_squared_error: 1.0446 - val_loss: 0.9641 - val_mean_squared_error: 0.9641\n",
      "Epoch 332/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0088 - mean_squared_error: 1.0088 - val_loss: 0.9640 - val_mean_squared_error: 0.9640\n",
      "Epoch 333/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0281 - mean_squared_error: 1.0281 - val_loss: 0.9635 - val_mean_squared_error: 0.9635\n",
      "Epoch 334/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0152 - mean_squared_error: 1.0152 - val_loss: 0.9628 - val_mean_squared_error: 0.9628\n",
      "Epoch 335/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0146 - mean_squared_error: 1.0146 - val_loss: 0.9618 - val_mean_squared_error: 0.9618\n",
      "Epoch 336/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0315 - mean_squared_error: 1.0315 - val_loss: 0.9610 - val_mean_squared_error: 0.9610\n",
      "Epoch 337/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0054 - mean_squared_error: 1.0054 - val_loss: 0.9599 - val_mean_squared_error: 0.9599\n",
      "Epoch 338/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 0.9887 - mean_squared_error: 0.9887 - val_loss: 0.9590 - val_mean_squared_error: 0.9590\n",
      "Epoch 339/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 0.9960 - mean_squared_error: 0.9960 - val_loss: 0.9581 - val_mean_squared_error: 0.9581\n",
      "Epoch 340/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 0.9837 - mean_squared_error: 0.9837 - val_loss: 0.9571 - val_mean_squared_error: 0.9571\n",
      "Epoch 341/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0044 - mean_squared_error: 1.0044 - val_loss: 0.9562 - val_mean_squared_error: 0.9562\n",
      "Epoch 342/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0311 - mean_squared_error: 1.0311 - val_loss: 0.9553 - val_mean_squared_error: 0.9553\n",
      "Epoch 343/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0043 - mean_squared_error: 1.0043 - val_loss: 0.9547 - val_mean_squared_error: 0.9547\n",
      "Epoch 344/350\n",
      "8609/8609 [==============================] - 0s 7us/step - loss: 1.0099 - mean_squared_error: 1.0099 - val_loss: 0.9538 - val_mean_squared_error: 0.9538\n",
      "Epoch 345/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0329 - mean_squared_error: 1.0329 - val_loss: 0.9533 - val_mean_squared_error: 0.9533\n",
      "Epoch 346/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0406 - mean_squared_error: 1.0406 - val_loss: 0.9526 - val_mean_squared_error: 0.9526\n",
      "Epoch 347/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0270 - mean_squared_error: 1.0270 - val_loss: 0.9525 - val_mean_squared_error: 0.9525\n",
      "Epoch 348/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8609/8609 [==============================] - 0s 6us/step - loss: 0.9852 - mean_squared_error: 0.9852 - val_loss: 0.9530 - val_mean_squared_error: 0.9530\n",
      "Epoch 349/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0366 - mean_squared_error: 1.0366 - val_loss: 0.9538 - val_mean_squared_error: 0.9538\n",
      "Epoch 350/350\n",
      "8609/8609 [==============================] - 0s 6us/step - loss: 1.0749 - mean_squared_error: 1.0749 - val_loss: 0.9545 - val_mean_squared_error: 0.9545\n",
      "Training time:24.678550958633423\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mean_squared_error'])\n",
    "\n",
    "curr_dt = set_curr_time()\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir='../logs/{0}'.format(curr_dt), histogram_freq=0, write_graph=True)\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=100)\n",
    "\n",
    "tic = time.time()\n",
    "model.fit(\n",
    "    x_train_label,\n",
    "    y_train_label,\n",
    "    epochs = 350,\n",
    "    batch_size = x_train_label.shape[0],\n",
    "    validation_data = (x_valid_label, y_valid_label),\n",
    "    shuffle = True,\n",
    "#     steps_per_epoch = round(ROW_COUNT/BATCH_SIZE),\n",
    "    callbacks=[es,tb_callback])\n",
    "toc = time.time()\n",
    "\n",
    "print('Training time:{}'.format(toc-tic))\n",
    "\n",
    "# model.save('../models/{0}.h5'.format(curr_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('../model/{0}.h5'.format('4096_1024_512_64__'))\n",
    "model_loaded =tf.keras.models.load_model('../model/4096_1024_512_64.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y=model.predict(x_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For error in of 0.5 hours the precision: 5.53\n",
      "For error in of 1 hours the precision: 10.73\n",
      "For error in of 5 hours the precision: 68.67\n",
      "For error in of 10 hours the precision: 83.52\n",
      "For error in of 112 hours the precision: 99.08\n"
     ]
    }
   ],
   "source": [
    "# #accuracy max-min\n",
    "# ERROE_MERGE = 0.5 # in hours\n",
    "# SCALE = (ERROE_MERGE-0.01)/(910 - 0.01)\n",
    "# correct = 0\n",
    "# for i in range(0,len(y_test_label)):    \n",
    "#     if (((pred_y[i] - SCALE) < y_test_label[i][0]) and ((pred_y[i] + SCALE) > y_test_label[i][0])):\n",
    "#         correct += 1\n",
    "# print(correct/len(y_test_label))\n",
    "\n",
    "\n",
    "#accuracy Gussian(mean,std)\n",
    "ERROER_MERGE = [0.5,1,5,10,112] # in hours\n",
    "x_bar = []\n",
    "y_bar = []\n",
    "for error in ERROER_MERGE:\n",
    "    correct = 0\n",
    "    for i in range(0,len(y_test_label)):\n",
    "        scale_pred = (pred_y[i]*68.72187295)+(+13.17546792)\n",
    "        scale_test = (y_test_label[i][0]*68.72187295)+(+13.17546792)\n",
    "\n",
    "        if (((scale_pred - error) < scale_test) and ((scale_pred + error) > scale_test)):\n",
    "            correct += 1\n",
    "    accuracy = np.round(correct*100/len(y_test_label),2)\n",
    "    print(\"For error in of {0} hours the precision: {1}\".format(error,accuracy))\n",
    "    x_bar.append(error)\n",
    "    y_bar.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pos = np.arange(len(x_bar))\n",
    "plt.bar(y_pos, y_bar, align='center')#, width=1.0)\n",
    "\n",
    "plt.xticks(y_pos, x_bar)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Vs Hours')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML - OneHot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Priority</th>\n",
       "      <th>RaisedByID</th>\n",
       "      <th>AssignedToID</th>\n",
       "      <th>AuthorisedByID</th>\n",
       "      <th>HoursEstimate</th>\n",
       "      <th>HoursActual</th>\n",
       "      <th>StatusCode_AUTHORISE</th>\n",
       "      <th>StatusCode_CANCELLED</th>\n",
       "      <th>StatusCode_CHRONICLE</th>\n",
       "      <th>...</th>\n",
       "      <th>SubCategory_Project Management</th>\n",
       "      <th>SubCategory_Release</th>\n",
       "      <th>SubCategory_Research</th>\n",
       "      <th>SubCategory_Staff Management</th>\n",
       "      <th>SubCategory_Staff Recruitment</th>\n",
       "      <th>SubCategory_Support</th>\n",
       "      <th>SubCategory_Technical Specification</th>\n",
       "      <th>SubCategory_Testing</th>\n",
       "      <th>SubCategory_Third Party</th>\n",
       "      <th>SubCategory_Training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>42</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>58</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>42</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>46</td>\n",
       "      <td>13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Priority  RaisedByID  AssignedToID  AuthorisedByID  \\\n",
       "0           0         1          58            58             6.0   \n",
       "1           1         1          58            42             6.0   \n",
       "2           2         2           7            58             6.0   \n",
       "3           3         5          50            42             6.0   \n",
       "4           4        10          46            13             6.0   \n",
       "\n",
       "   HoursEstimate  HoursActual  StatusCode_AUTHORISE  StatusCode_CANCELLED  \\\n",
       "0           14.0         1.75                     0                     0   \n",
       "1            7.0         7.00                     0                     0   \n",
       "2            0.7         0.70                     0                     0   \n",
       "3            0.7         0.70                     0                     0   \n",
       "4            3.5         3.50                     0                     0   \n",
       "\n",
       "   StatusCode_CHRONICLE  ...  SubCategory_Project Management  \\\n",
       "0                     0  ...                               0   \n",
       "1                     0  ...                               0   \n",
       "2                     0  ...                               0   \n",
       "3                     0  ...                               0   \n",
       "4                     0  ...                               0   \n",
       "\n",
       "   SubCategory_Release  SubCategory_Research  SubCategory_Staff Management  \\\n",
       "0                    0                     0                             0   \n",
       "1                    0                     0                             0   \n",
       "2                    0                     0                             0   \n",
       "3                    0                     0                             0   \n",
       "4                    0                     0                             0   \n",
       "\n",
       "   SubCategory_Staff Recruitment  SubCategory_Support  \\\n",
       "0                              0                    0   \n",
       "1                              0                    0   \n",
       "2                              0                    0   \n",
       "3                              0                    0   \n",
       "4                              0                    0   \n",
       "\n",
       "   SubCategory_Technical Specification  SubCategory_Testing  \\\n",
       "0                                    0                    0   \n",
       "1                                    0                    0   \n",
       "2                                    0                    0   \n",
       "3                                    0                    0   \n",
       "4                                    0                    0   \n",
       "\n",
       "   SubCategory_Third Party  SubCategory_Training  \n",
       "0                        0                     0  \n",
       "1                        0                     0  \n",
       "2                        0                     0  \n",
       "3                        0                     0  \n",
       "4                        0                     0  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../SiP_dataset-master/SIP_OneHot.csv', encoding='cp1252') \n",
    "data.fillna(0, inplace = True)\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples: (8609, 61)\n",
      "Valid examples: (1845, 61)\n",
      "Test examples: (1845, 61)\n"
     ]
    }
   ],
   "source": [
    "# HoursEstimate_filter=HoursEstimate[HoursEstimate[\"HoursEstimate\"]<200]\n",
    "# HoursEstimate_filter=HoursEstimate_filter[HoursEstimate_filter[\"HoursActual\"]<800]\n",
    "\n",
    "x_train_label, xx_test_label, y_train_label, yy_test_label \\\n",
    "              = train_test_split(data.loc[:, data.columns != 'HoursActual'].values[:], data[Y_attributes].values[:], test_size=TRAIN_AND_VALIDATION_TEST_SPLIT)\n",
    "x_valid_label, x_test_label, y_valid_label, y_test_label \\\n",
    "              = train_test_split(xx_test_label, yy_test_label, test_size=VALID_AND_TEST_SPLIT)  \n",
    "\n",
    "print(\"Train examples: {}\".format(x_train_label.shape))\n",
    "print(\"Valid examples: {}\".format(x_valid_label.shape))\n",
    "print(\"Test examples: {}\".format(x_test_label.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Dense(2048, kernel_initializer='normal'), \n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.8),\n",
    "#     tf.keras.layers.Dense(1024,  kernel_initializer='normal'), \n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.8),\n",
    "#     tf.keras.layers.add(tf.keras.layers.Flatten(input_shape = (BATCH_SIZE,x_train_label.shape[1],1))),\n",
    "    tf.keras.layers.Dense(8192, kernel_initializer='normal',input_shape = (x_train_label.shape[1],)), \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(2048, kernel_initializer='normal'), \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(128, kernel_initializer='normal'), \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(64, kernel_initializer='normal'), \n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.8),\n",
    "    tf.keras.layers.Dense(1)\n",
    "    \n",
    "    \n",
    "#     tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8609 samples, validate on 1845 samples\n",
      "Epoch 1/300\n",
      "8609/8609 [==============================] - 1s 107us/step - loss: 5259.6235 - mean_squared_error: 5259.6235 - val_loss: 1589.7592 - val_mean_squared_error: 1589.7592\n",
      "Epoch 2/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 5206.8779 - mean_squared_error: 5206.8779 - val_loss: 1585.6847 - val_mean_squared_error: 1585.6847\n",
      "Epoch 3/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 5168.4824 - mean_squared_error: 5168.4824 - val_loss: 1575.9669 - val_mean_squared_error: 1575.9669\n",
      "Epoch 4/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 5125.0601 - mean_squared_error: 5125.0601 - val_loss: 1572.1866 - val_mean_squared_error: 1572.1866\n",
      "Epoch 5/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 5114.5664 - mean_squared_error: 5114.5664 - val_loss: 1582.6741 - val_mean_squared_error: 1582.6741\n",
      "Epoch 6/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 5128.0913 - mean_squared_error: 5128.0913 - val_loss: 1566.7032 - val_mean_squared_error: 1566.7032\n",
      "Epoch 7/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 5107.8940 - mean_squared_error: 5107.8940 - val_loss: 1534.9203 - val_mean_squared_error: 1534.9203\n",
      "Epoch 8/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 5108.0054 - mean_squared_error: 5108.0054 - val_loss: 1516.7351 - val_mean_squared_error: 1516.7351\n",
      "Epoch 9/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 5093.6011 - mean_squared_error: 5093.6011 - val_loss: 1510.6835 - val_mean_squared_error: 1510.6835\n",
      "Epoch 10/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 5091.7271 - mean_squared_error: 5091.7271 - val_loss: 1519.3911 - val_mean_squared_error: 1519.3911\n",
      "Epoch 11/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 5064.1504 - mean_squared_error: 5064.1504 - val_loss: 1521.8961 - val_mean_squared_error: 1521.8961\n",
      "Epoch 12/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 5063.0229 - mean_squared_error: 5063.0229 - val_loss: 1517.5908 - val_mean_squared_error: 1517.5908\n",
      "Epoch 13/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 5039.9189 - mean_squared_error: 5039.9189 - val_loss: 1510.3003 - val_mean_squared_error: 1510.3003\n",
      "Epoch 14/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 5068.9907 - mean_squared_error: 5068.9907 - val_loss: 1502.3070 - val_mean_squared_error: 1502.3070\n",
      "Epoch 15/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 5046.0078 - mean_squared_error: 5046.0078 - val_loss: 1495.1094 - val_mean_squared_error: 1495.1094\n",
      "Epoch 16/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 5068.2935 - mean_squared_error: 5068.2935 - val_loss: 1489.1007 - val_mean_squared_error: 1489.1007\n",
      "Epoch 17/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 5065.9556 - mean_squared_error: 5065.9556 - val_loss: 1487.3768 - val_mean_squared_error: 1487.3768\n",
      "Epoch 18/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 5042.1309 - mean_squared_error: 5042.1309 - val_loss: 1487.7209 - val_mean_squared_error: 1487.7209\n",
      "Epoch 19/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 5039.0312 - mean_squared_error: 5039.0312 - val_loss: 1486.6648 - val_mean_squared_error: 1486.6648\n",
      "Epoch 20/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 5023.5898 - mean_squared_error: 5023.5898 - val_loss: 1480.1987 - val_mean_squared_error: 1480.1987\n",
      "Epoch 21/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 5016.7510 - mean_squared_error: 5016.7510 - val_loss: 1471.0618 - val_mean_squared_error: 1471.0618\n",
      "Epoch 22/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 5037.1191 - mean_squared_error: 5037.1191 - val_loss: 1462.2220 - val_mean_squared_error: 1462.2220\n",
      "Epoch 23/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 5039.0815 - mean_squared_error: 5039.0815 - val_loss: 1457.5657 - val_mean_squared_error: 1457.5657\n",
      "Epoch 24/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 5007.1943 - mean_squared_error: 5007.1943 - val_loss: 1452.5397 - val_mean_squared_error: 1452.5397\n",
      "Epoch 25/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 5017.7637 - mean_squared_error: 5017.7637 - val_loss: 1447.4067 - val_mean_squared_error: 1447.4067\n",
      "Epoch 26/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 5048.8242 - mean_squared_error: 5048.8242 - val_loss: 1438.9279 - val_mean_squared_error: 1438.9279\n",
      "Epoch 27/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4982.4277 - mean_squared_error: 4982.4277 - val_loss: 1424.7067 - val_mean_squared_error: 1424.7067\n",
      "Epoch 28/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4988.1880 - mean_squared_error: 4988.1880 - val_loss: 1410.2535 - val_mean_squared_error: 1410.2535\n",
      "Epoch 29/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4990.0088 - mean_squared_error: 4990.0088 - val_loss: 1401.4507 - val_mean_squared_error: 1401.4507\n",
      "Epoch 30/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4999.5791 - mean_squared_error: 4999.5791 - val_loss: 1397.8387 - val_mean_squared_error: 1397.8387\n",
      "Epoch 31/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4980.8496 - mean_squared_error: 4980.8496 - val_loss: 1396.2620 - val_mean_squared_error: 1396.2620\n",
      "Epoch 32/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4966.3481 - mean_squared_error: 4966.3481 - val_loss: 1396.9359 - val_mean_squared_error: 1396.9359\n",
      "Epoch 33/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4940.3604 - mean_squared_error: 4940.3604 - val_loss: 1395.0079 - val_mean_squared_error: 1395.0079\n",
      "Epoch 34/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4945.1274 - mean_squared_error: 4945.1274 - val_loss: 1392.1636 - val_mean_squared_error: 1392.1636\n",
      "Epoch 35/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4944.2158 - mean_squared_error: 4944.2158 - val_loss: 1388.6606 - val_mean_squared_error: 1388.6606\n",
      "Epoch 36/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4967.6685 - mean_squared_error: 4967.6685 - val_loss: 1384.5336 - val_mean_squared_error: 1384.5336\n",
      "Epoch 37/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4922.3984 - mean_squared_error: 4922.3984 - val_loss: 1381.8594 - val_mean_squared_error: 1381.8594\n",
      "Epoch 38/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4950.6904 - mean_squared_error: 4950.6904 - val_loss: 1380.4910 - val_mean_squared_error: 1380.4910\n",
      "Epoch 39/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4972.1504 - mean_squared_error: 4972.1504 - val_loss: 1378.5450 - val_mean_squared_error: 1378.5450\n",
      "Epoch 40/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4922.5293 - mean_squared_error: 4922.5293 - val_loss: 1376.0596 - val_mean_squared_error: 1376.0596\n",
      "Epoch 41/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4892.0688 - mean_squared_error: 4892.0688 - val_loss: 1377.9238 - val_mean_squared_error: 1377.9238\n",
      "Epoch 42/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4885.9072 - mean_squared_error: 4885.9072 - val_loss: 1380.9951 - val_mean_squared_error: 1380.9951\n",
      "Epoch 43/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4885.8833 - mean_squared_error: 4885.8833 - val_loss: 1383.1659 - val_mean_squared_error: 1383.1659\n",
      "Epoch 44/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4905.2998 - mean_squared_error: 4905.2998 - val_loss: 1383.3151 - val_mean_squared_error: 1383.3151\n",
      "Epoch 45/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4965.4565 - mean_squared_error: 4965.4565 - val_loss: 1382.2733 - val_mean_squared_error: 1382.2733\n",
      "Epoch 46/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4858.0581 - mean_squared_error: 4858.0581 - val_loss: 1383.0225 - val_mean_squared_error: 1383.0225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4856.3428 - mean_squared_error: 4856.3428 - val_loss: 1384.3202 - val_mean_squared_error: 1384.3202\n",
      "Epoch 48/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4886.4229 - mean_squared_error: 4886.4229 - val_loss: 1386.6888 - val_mean_squared_error: 1386.6888\n",
      "Epoch 49/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4828.4810 - mean_squared_error: 4828.4810 - val_loss: 1389.1089 - val_mean_squared_error: 1389.1089\n",
      "Epoch 50/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4881.3374 - mean_squared_error: 4881.3374 - val_loss: 1394.4064 - val_mean_squared_error: 1394.4064\n",
      "Epoch 51/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4866.7070 - mean_squared_error: 4866.7070 - val_loss: 1391.3584 - val_mean_squared_error: 1391.3584\n",
      "Epoch 52/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4883.5054 - mean_squared_error: 4883.5054 - val_loss: 1389.7820 - val_mean_squared_error: 1389.7820\n",
      "Epoch 53/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4854.2764 - mean_squared_error: 4854.2764 - val_loss: 1387.9050 - val_mean_squared_error: 1387.9050\n",
      "Epoch 54/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4832.0967 - mean_squared_error: 4832.0967 - val_loss: 1387.2878 - val_mean_squared_error: 1387.2878\n",
      "Epoch 55/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4867.5635 - mean_squared_error: 4867.5635 - val_loss: 1390.7894 - val_mean_squared_error: 1390.7894\n",
      "Epoch 56/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4856.3931 - mean_squared_error: 4856.3931 - val_loss: 1391.9407 - val_mean_squared_error: 1391.9407\n",
      "Epoch 57/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4876.8691 - mean_squared_error: 4876.8691 - val_loss: 1396.5382 - val_mean_squared_error: 1396.5382\n",
      "Epoch 58/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4888.6348 - mean_squared_error: 4888.6348 - val_loss: 1400.2062 - val_mean_squared_error: 1400.2062\n",
      "Epoch 59/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4840.8501 - mean_squared_error: 4840.8501 - val_loss: 1397.2402 - val_mean_squared_error: 1397.2402\n",
      "Epoch 60/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4860.1768 - mean_squared_error: 4860.1768 - val_loss: 1402.7958 - val_mean_squared_error: 1402.7958\n",
      "Epoch 61/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4831.6250 - mean_squared_error: 4831.6250 - val_loss: 1399.1544 - val_mean_squared_error: 1399.1544\n",
      "Epoch 62/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4849.4951 - mean_squared_error: 4849.4951 - val_loss: 1396.3948 - val_mean_squared_error: 1396.3948\n",
      "Epoch 63/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4909.1030 - mean_squared_error: 4909.1030 - val_loss: 1407.6365 - val_mean_squared_error: 1407.6365\n",
      "Epoch 64/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4802.6099 - mean_squared_error: 4802.6099 - val_loss: 1396.9656 - val_mean_squared_error: 1396.9656\n",
      "Epoch 65/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4811.9248 - mean_squared_error: 4811.9248 - val_loss: 1399.3029 - val_mean_squared_error: 1399.3029\n",
      "Epoch 66/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4826.0327 - mean_squared_error: 4826.0327 - val_loss: 1417.6956 - val_mean_squared_error: 1417.6956\n",
      "Epoch 67/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4816.0298 - mean_squared_error: 4816.0298 - val_loss: 1414.2430 - val_mean_squared_error: 1414.2430\n",
      "Epoch 68/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4854.3984 - mean_squared_error: 4854.3984 - val_loss: 1419.8514 - val_mean_squared_error: 1419.8514\n",
      "Epoch 69/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4819.1138 - mean_squared_error: 4819.1138 - val_loss: 1424.1908 - val_mean_squared_error: 1424.1908\n",
      "Epoch 70/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4781.1846 - mean_squared_error: 4781.1846 - val_loss: 1427.1260 - val_mean_squared_error: 1427.1260\n",
      "Epoch 71/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4765.2671 - mean_squared_error: 4765.2671 - val_loss: 1440.7819 - val_mean_squared_error: 1440.7819\n",
      "Epoch 72/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4769.2471 - mean_squared_error: 4769.2471 - val_loss: 1433.4861 - val_mean_squared_error: 1433.4861\n",
      "Epoch 73/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4785.5376 - mean_squared_error: 4785.5376 - val_loss: 1450.4944 - val_mean_squared_error: 1450.4944\n",
      "Epoch 74/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4769.0835 - mean_squared_error: 4769.0835 - val_loss: 1441.1703 - val_mean_squared_error: 1441.1703\n",
      "Epoch 75/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4748.3208 - mean_squared_error: 4748.3208 - val_loss: 1459.2561 - val_mean_squared_error: 1459.2561\n",
      "Epoch 76/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4777.4980 - mean_squared_error: 4777.4980 - val_loss: 1443.4124 - val_mean_squared_error: 1443.4124\n",
      "Epoch 77/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4722.1484 - mean_squared_error: 4722.1484 - val_loss: 1450.6404 - val_mean_squared_error: 1450.6404\n",
      "Epoch 78/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4820.9541 - mean_squared_error: 4820.9541 - val_loss: 1443.6427 - val_mean_squared_error: 1443.6427\n",
      "Epoch 79/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4718.3452 - mean_squared_error: 4718.3452 - val_loss: 1446.5616 - val_mean_squared_error: 1446.5616\n",
      "Epoch 80/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4745.5498 - mean_squared_error: 4745.5498 - val_loss: 1472.1959 - val_mean_squared_error: 1472.1959\n",
      "Epoch 81/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4755.9829 - mean_squared_error: 4755.9829 - val_loss: 1450.9479 - val_mean_squared_error: 1450.9479\n",
      "Epoch 82/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4745.6455 - mean_squared_error: 4745.6455 - val_loss: 1466.1027 - val_mean_squared_error: 1466.1027\n",
      "Epoch 83/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4742.7188 - mean_squared_error: 4742.7188 - val_loss: 1451.4889 - val_mean_squared_error: 1451.4889\n",
      "Epoch 84/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4697.7905 - mean_squared_error: 4697.7905 - val_loss: 1454.5367 - val_mean_squared_error: 1454.5367\n",
      "Epoch 85/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4767.5845 - mean_squared_error: 4767.5845 - val_loss: 1452.4288 - val_mean_squared_error: 1452.4288\n",
      "Epoch 86/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4740.9702 - mean_squared_error: 4740.9702 - val_loss: 1450.0435 - val_mean_squared_error: 1450.0435\n",
      "Epoch 87/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4773.1670 - mean_squared_error: 4773.1670 - val_loss: 1453.5139 - val_mean_squared_error: 1453.5139\n",
      "Epoch 88/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4684.8755 - mean_squared_error: 4684.8755 - val_loss: 1449.3781 - val_mean_squared_error: 1449.3781\n",
      "Epoch 89/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4646.9141 - mean_squared_error: 4646.9141 - val_loss: 1457.8601 - val_mean_squared_error: 1457.8601\n",
      "Epoch 90/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4735.5234 - mean_squared_error: 4735.5234 - val_loss: 1449.7542 - val_mean_squared_error: 1449.7542\n",
      "Epoch 91/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4731.6772 - mean_squared_error: 4731.6772 - val_loss: 1477.5948 - val_mean_squared_error: 1477.5948\n",
      "Epoch 92/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4697.3945 - mean_squared_error: 4697.3945 - val_loss: 1445.2841 - val_mean_squared_error: 1445.2841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4720.4590 - mean_squared_error: 4720.4590 - val_loss: 1442.6033 - val_mean_squared_error: 1442.6033\n",
      "Epoch 94/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4773.4937 - mean_squared_error: 4773.4937 - val_loss: 1452.0680 - val_mean_squared_error: 1452.0680\n",
      "Epoch 95/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4741.0439 - mean_squared_error: 4741.0439 - val_loss: 1454.3629 - val_mean_squared_error: 1454.3629\n",
      "Epoch 96/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4637.5562 - mean_squared_error: 4637.5562 - val_loss: 1456.8203 - val_mean_squared_error: 1456.8203\n",
      "Epoch 97/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4639.9385 - mean_squared_error: 4639.9385 - val_loss: 1464.0544 - val_mean_squared_error: 1464.0544\n",
      "Epoch 98/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4737.6367 - mean_squared_error: 4737.6367 - val_loss: 1458.7401 - val_mean_squared_error: 1458.7401\n",
      "Epoch 99/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4688.8735 - mean_squared_error: 4688.8735 - val_loss: 1459.6713 - val_mean_squared_error: 1459.6713\n",
      "Epoch 100/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4655.1245 - mean_squared_error: 4655.1245 - val_loss: 1449.1951 - val_mean_squared_error: 1449.1951\n",
      "Epoch 101/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4705.8921 - mean_squared_error: 4705.8921 - val_loss: 1451.1316 - val_mean_squared_error: 1451.1316\n",
      "Epoch 102/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4629.4224 - mean_squared_error: 4629.4224 - val_loss: 1456.4993 - val_mean_squared_error: 1456.4993\n",
      "Epoch 103/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4640.9575 - mean_squared_error: 4640.9575 - val_loss: 1462.1619 - val_mean_squared_error: 1462.1619\n",
      "Epoch 104/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4578.0674 - mean_squared_error: 4578.0674 - val_loss: 1470.0551 - val_mean_squared_error: 1470.0551\n",
      "Epoch 105/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4715.6333 - mean_squared_error: 4715.6333 - val_loss: 1473.2764 - val_mean_squared_error: 1473.2764\n",
      "Epoch 106/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4700.8652 - mean_squared_error: 4700.8652 - val_loss: 1478.0237 - val_mean_squared_error: 1478.0237\n",
      "Epoch 107/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4617.0981 - mean_squared_error: 4617.0981 - val_loss: 1474.7250 - val_mean_squared_error: 1474.7250\n",
      "Epoch 108/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4592.5425 - mean_squared_error: 4592.5425 - val_loss: 1477.2866 - val_mean_squared_error: 1477.2866\n",
      "Epoch 109/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4642.6602 - mean_squared_error: 4642.6602 - val_loss: 1468.0681 - val_mean_squared_error: 1468.0681\n",
      "Epoch 110/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4720.1978 - mean_squared_error: 4720.1978 - val_loss: 1477.3683 - val_mean_squared_error: 1477.3683\n",
      "Epoch 111/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4698.7803 - mean_squared_error: 4698.7803 - val_loss: 1457.9607 - val_mean_squared_error: 1457.9607\n",
      "Epoch 112/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4706.4751 - mean_squared_error: 4706.4751 - val_loss: 1450.9263 - val_mean_squared_error: 1450.9263\n",
      "Epoch 113/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4737.4888 - mean_squared_error: 4737.4888 - val_loss: 1454.2535 - val_mean_squared_error: 1454.2535\n",
      "Epoch 114/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4587.9858 - mean_squared_error: 4587.9858 - val_loss: 1464.8378 - val_mean_squared_error: 1464.8378\n",
      "Epoch 115/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4608.0840 - mean_squared_error: 4608.0840 - val_loss: 1458.1674 - val_mean_squared_error: 1458.1674\n",
      "Epoch 116/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4618.0894 - mean_squared_error: 4618.0894 - val_loss: 1464.1064 - val_mean_squared_error: 1464.1064\n",
      "Epoch 117/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4597.8105 - mean_squared_error: 4597.8105 - val_loss: 1478.9891 - val_mean_squared_error: 1478.9891\n",
      "Epoch 118/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4638.4482 - mean_squared_error: 4638.4482 - val_loss: 1456.9331 - val_mean_squared_error: 1456.9331\n",
      "Epoch 119/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4651.5181 - mean_squared_error: 4651.5181 - val_loss: 1478.5238 - val_mean_squared_error: 1478.5238\n",
      "Epoch 120/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4661.6724 - mean_squared_error: 4661.6724 - val_loss: 1474.1798 - val_mean_squared_error: 1474.1798\n",
      "Epoch 121/300\n",
      "8609/8609 [==============================] - 0s 16us/step - loss: 4497.8257 - mean_squared_error: 4497.8257 - val_loss: 1477.7238 - val_mean_squared_error: 1477.7238\n",
      "Epoch 122/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4532.8320 - mean_squared_error: 4532.8320 - val_loss: 1476.0112 - val_mean_squared_error: 1476.0112\n",
      "Epoch 123/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4653.9814 - mean_squared_error: 4653.9814 - val_loss: 1479.0251 - val_mean_squared_error: 1479.0251\n",
      "Epoch 124/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4674.7100 - mean_squared_error: 4674.7100 - val_loss: 1476.6339 - val_mean_squared_error: 1476.6339\n",
      "Epoch 125/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4631.2588 - mean_squared_error: 4631.2588 - val_loss: 1481.4426 - val_mean_squared_error: 1481.4426\n",
      "Epoch 126/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4633.9478 - mean_squared_error: 4633.9478 - val_loss: 1501.0507 - val_mean_squared_error: 1501.0507\n",
      "Epoch 127/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4539.1094 - mean_squared_error: 4539.1094 - val_loss: 1464.6323 - val_mean_squared_error: 1464.6323\n",
      "Epoch 128/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4506.9297 - mean_squared_error: 4506.9297 - val_loss: 1558.0271 - val_mean_squared_error: 1558.0271\n",
      "Epoch 129/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4632.1152 - mean_squared_error: 4632.1152 - val_loss: 1459.0681 - val_mean_squared_error: 1459.0681\n",
      "Epoch 130/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4669.8682 - mean_squared_error: 4669.8682 - val_loss: 1511.9634 - val_mean_squared_error: 1511.9634\n",
      "Epoch 131/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4581.0640 - mean_squared_error: 4581.0640 - val_loss: 1542.9088 - val_mean_squared_error: 1542.9088\n",
      "Epoch 132/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4594.4839 - mean_squared_error: 4594.4839 - val_loss: 1464.0593 - val_mean_squared_error: 1464.0593\n",
      "Epoch 133/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4500.8257 - mean_squared_error: 4500.8257 - val_loss: 1470.7930 - val_mean_squared_error: 1470.7930\n",
      "Epoch 134/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4559.3242 - mean_squared_error: 4559.3242 - val_loss: 1486.5319 - val_mean_squared_error: 1486.5319\n",
      "Epoch 135/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4584.5000 - mean_squared_error: 4584.5000 - val_loss: 1465.0948 - val_mean_squared_error: 1465.0948\n",
      "Epoch 136/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4511.1797 - mean_squared_error: 4511.1797 - val_loss: 1514.2936 - val_mean_squared_error: 1514.2936\n",
      "Epoch 137/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4626.8740 - mean_squared_error: 4626.8740 - val_loss: 1463.1023 - val_mean_squared_error: 1463.1023\n",
      "Epoch 138/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4539.8320 - mean_squared_error: 4539.8320 - val_loss: 1455.2512 - val_mean_squared_error: 1455.2512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4568.2183 - mean_squared_error: 4568.2183 - val_loss: 1479.8420 - val_mean_squared_error: 1479.8420\n",
      "Epoch 140/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4632.6523 - mean_squared_error: 4632.6523 - val_loss: 1468.2150 - val_mean_squared_error: 1468.2150\n",
      "Epoch 141/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4581.8857 - mean_squared_error: 4581.8857 - val_loss: 1453.9594 - val_mean_squared_error: 1453.9594\n",
      "Epoch 142/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4606.8066 - mean_squared_error: 4606.8066 - val_loss: 1465.6029 - val_mean_squared_error: 1465.6029\n",
      "Epoch 143/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4537.4087 - mean_squared_error: 4537.4087 - val_loss: 1490.5009 - val_mean_squared_error: 1490.5009\n",
      "Epoch 144/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4498.9478 - mean_squared_error: 4498.9478 - val_loss: 1455.7850 - val_mean_squared_error: 1455.7850\n",
      "Epoch 145/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4530.7422 - mean_squared_error: 4530.7422 - val_loss: 1457.7430 - val_mean_squared_error: 1457.7430\n",
      "Epoch 146/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4538.2515 - mean_squared_error: 4538.2515 - val_loss: 1472.1178 - val_mean_squared_error: 1472.1178\n",
      "Epoch 147/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4560.2256 - mean_squared_error: 4560.2256 - val_loss: 1459.6481 - val_mean_squared_error: 1459.6481\n",
      "Epoch 148/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4447.8550 - mean_squared_error: 4447.8550 - val_loss: 1463.0507 - val_mean_squared_error: 1463.0507\n",
      "Epoch 149/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4540.8970 - mean_squared_error: 4540.8970 - val_loss: 1471.0564 - val_mean_squared_error: 1471.0564\n",
      "Epoch 150/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4560.4692 - mean_squared_error: 4560.4692 - val_loss: 1454.0056 - val_mean_squared_error: 1454.0056\n",
      "Epoch 151/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4540.5215 - mean_squared_error: 4540.5215 - val_loss: 1466.7734 - val_mean_squared_error: 1466.7734\n",
      "Epoch 152/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4579.8574 - mean_squared_error: 4579.8574 - val_loss: 1454.8385 - val_mean_squared_error: 1454.8385\n",
      "Epoch 153/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4460.4458 - mean_squared_error: 4460.4458 - val_loss: 1452.1427 - val_mean_squared_error: 1452.1427\n",
      "Epoch 154/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4420.1724 - mean_squared_error: 4420.1724 - val_loss: 1491.6573 - val_mean_squared_error: 1491.6573\n",
      "Epoch 155/300\n",
      "8609/8609 [==============================] - 0s 14us/step - loss: 4610.8818 - mean_squared_error: 4610.8818 - val_loss: 1462.4020 - val_mean_squared_error: 1462.4020\n",
      "Epoch 156/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4472.1436 - mean_squared_error: 4472.1436 - val_loss: 1471.1941 - val_mean_squared_error: 1471.1941\n",
      "Epoch 157/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4496.8154 - mean_squared_error: 4496.8154 - val_loss: 1551.7144 - val_mean_squared_error: 1551.7144\n",
      "Epoch 158/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4383.3813 - mean_squared_error: 4383.3813 - val_loss: 1498.1342 - val_mean_squared_error: 1498.1342\n",
      "Epoch 159/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4420.9639 - mean_squared_error: 4420.9639 - val_loss: 1482.6525 - val_mean_squared_error: 1482.6525\n",
      "Epoch 160/300\n",
      "8609/8609 [==============================] - 0s 15us/step - loss: 4342.5879 - mean_squared_error: 4342.5879 - val_loss: 1551.5000 - val_mean_squared_error: 1551.5000\n",
      "Epoch 00160: early stopping\n",
      "Training time:24.169837474822998\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mean_squared_error'])\n",
    "\n",
    "curr_dt = set_curr_time()\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir='../logs/{0}'.format(curr_dt), histogram_freq=0, write_graph=True)\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=120)\n",
    "\n",
    "\n",
    "tic = time.time()\n",
    "model.fit(\n",
    "    x_train_label,\n",
    "    y_train_label,\n",
    "    epochs = 300,\n",
    "    batch_size = x_train_label.shape[0],\n",
    "    validation_data = (x_valid_label, y_valid_label),\n",
    "    shuffle = True,\n",
    "    callbacks=[es,tb_callback])\n",
    "toc = time.time()\n",
    "\n",
    "print('Training time:{}'.format(toc-tic))\n",
    "pred_y=model.predict(x_test_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "ERROE_MERGE = 0.5 # in hours\n",
    "correct = 0\n",
    "for i in range(0,len(y_test_label)):\n",
    "    scale_pred = (pred_y[i]*68.72187295)+(+13.17546792)\n",
    "    scale_test = (y_test_label[i][0]*68.72187295)+(+13.17546792)\n",
    "\n",
    "    if (((scale_pred - ERROE_MERGE) < scale_test) and ((scale_pred + ERROE_MERGE) > scale_test)):\n",
    "        correct += 1\n",
    "print(correct/len(y_test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
